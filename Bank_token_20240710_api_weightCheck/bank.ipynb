{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef445a4-e455-4a73-9314-d4a018bfc85d",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6186a3-328f-4c4c-af0d-7b807660c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "path_project = \"../\"\n",
    "path_funcs = \"../funcs\"\n",
    "sys.path.append(path_project)\n",
    "sys.path.append(path_funcs)\n",
    "\n",
    "\n",
    "from bank_loop import * \n",
    "\n",
    "\n",
    "# lib for IDEP.\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f605f3b-bcaa-4400-8cdf-1261b55879fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze >> requirements_20240702.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb32cd0-5804-49c1-97df-37dde86a64b0",
   "metadata": {},
   "source": [
    "# IDEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b9e95-1feb-4120-b441-7bdd46424247",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc67a9f-ac45-4083-b3f1-43cfadda4fa9",
   "metadata": {},
   "source": [
    "### save df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8865f9-9dcc-4276-9e3f-34338172a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 2000 # at least 2 days for 15T II value to be synced.\n",
    "# days = 200 # at least 2 days for 15T II value to be synced.\n",
    "\n",
    "end_date = None\n",
    "# end_date = \"2023-12-20\"\n",
    "\n",
    "interval = '1m'\n",
    "interval = '5m'\n",
    "# interval = '15m'\n",
    "interval = '30m'\n",
    "# interval = '4h'\n",
    "\n",
    "intervals = ['4h', '15m', '30m', '1h', '2h', ]\n",
    "# intervals = ['30m', '1h', '2h', '4h']\n",
    "\n",
    "limit = 1500\n",
    "\n",
    "\n",
    "symbols = [data['symbol'] for data in bank.exchange_info()['symbols'] if 'USDT' in data['symbol'] if '_' not in data['symbol']]\n",
    "# symbols = ['DOTUSDT']\n",
    "\n",
    "\n",
    "\n",
    "for interval in intervals:\n",
    "    for index_symbol, bank.symbol in enumerate(symbols):\n",
    "\n",
    "        # if index_symbol < 4:\n",
    "        #     continue\n",
    "        if index_symbol > 130:\n",
    "            break\n",
    "        \n",
    "        # return end_date is calculated date by concat_candlestick.\n",
    "        bank.df_res, end_date = bank.concat_candlestick(bank,\n",
    "                                                      interval,\n",
    "                                                      days,\n",
    "                                                      limit=limit,\n",
    "                                                      end_date=end_date,\n",
    "                                                      show_process=True,\n",
    "                                                      timesleep=0.25) # 0.3 is mininum term for this API.\n",
    "        # break\n",
    "\n",
    "        if len(bank.df_res) > 0:\n",
    "            bank.df_res['timestamp'] = bank.df_res.index\n",
    "            bank.df_res['timestamp'] = bank.df_res['timestamp'].apply(lambda x : int(datetime.timestamp(x)))\n",
    "\n",
    "            os.makedirs(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/df_res/{}\".format(interval), exist_ok=True)            \n",
    "            # bank.df_res.to_parquet(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/df_res/{}/{}_{}.parquet\".format(interval, bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "            bank.df_res.reset_index(drop=True).to_feather(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/df_res/{}/{}_{}.ftr\".format(interval, bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20abcf3-0adb-4c3c-bc25-9a08bad473f2",
   "metadata": {},
   "source": [
    "### save table_trade_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4942a-e8c3-4b98-8a15-694e4be3ea5e",
   "metadata": {},
   "source": [
    "#### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c180d-3cd5-4a08-a854-1b7da690f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    adj. functionals.\n",
    "    add 'add_zone'\n",
    "    apply get_trade_result (v1.4.2).\n",
    "\n",
    "last confirmed at, 20240627 1339.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "priceBox_indicator = 'DC'\n",
    "# priceBox_indicator = 'BB'\n",
    "priceBox_value = 20\n",
    "# priceBox_value = 60\n",
    "\n",
    "point_mode = 'CROSS'\n",
    "point_indicator = 'CCI'\n",
    "# point_indicator = 'II'\n",
    "# point_indicator = 'DC'\n",
    "# point_indicator = 'BB'\n",
    "point_value = 20\n",
    "# point_value = 21\n",
    "# point_value = 30\n",
    "\n",
    "zone_indicator = None\n",
    "# zone_indicator = 'MA'\n",
    "zone_value = 30\n",
    "\n",
    "dir_name_strategy = \"priceBox_{}_point_{}_{}\".format(priceBox_indicator, point_mode, point_indicator)\n",
    "\n",
    "\n",
    "intervals = ['4h', '15m', '30m', '1h', '2h', ]\n",
    "\n",
    "\n",
    "\n",
    "for interval in intervals:    \n",
    "\n",
    "    # save path take interval as input.\n",
    "    path_df_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/public/df_result/{}\".format(interval)\n",
    "    \n",
    "    # path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/priceBox_DC_point_Cross_DC/table_trade_result/{}_{}/{}/\".format(priceBox_value, point_value, interval)\n",
    "    path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator, interval)\n",
    "    os.makedirs(path_dir_table_trade_res, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    for index, file_name in enumerate(os.listdir(path_df_res)):\n",
    "    # for index, bank.symbol in enumerate(symbols):\n",
    "\n",
    "        # if index <= 163:\n",
    "        #     continue\n",
    "        # if 'DOT' not in file_name:\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        bank.df_res = pd.read_feather(os.path.join(path_df_res, file_name)) # 1000SATSUSDT_202406052249.ftr             \n",
    "        bank.df_res['datetime'] = bank.df_res['timestamp'].apply(datetime.fromtimestamp)\n",
    "        bank.df_res.set_index('datetime', inplace=True)\n",
    "        bank.symbol = file_name.split('_')[0]\n",
    "\n",
    "\n",
    "        \n",
    "        bank.df_res, \\\n",
    "        point_index_long, \\\n",
    "        point_index_short = get_point_index(bank.df_res,\n",
    "                                            point_mode,\n",
    "                                            point_indicator,\n",
    "                                            point_value,\n",
    "                                            interval)\n",
    "\n",
    "        \n",
    "        # bank.df_res, \\\n",
    "        # point_index_long, \\\n",
    "        # point_index_short = add_zone(bank.df_res, \n",
    "        #                              zone_indicator,\n",
    "        #                              zone_value, \n",
    "        #                              interval,\n",
    "        #                              point_index_long,\n",
    "        #                              point_index_short)\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        v1.1\n",
    "            add spread_arr\n",
    "        v1.2\n",
    "            remove quantity info from table.\n",
    "            reject status=DataEnd\n",
    "            add symbol for winRatio calibration.\n",
    "            add timestamp for amount agg. check.\n",
    "        v1.3\n",
    "            add timestamp column and timestamp_entry & exit derives from it.\n",
    "        v1.4\n",
    "            add LONG position.\n",
    "                LONG SHORT one table.\n",
    "            apply functional mode.\n",
    "            \n",
    "            v1.4.1\n",
    "                remove fee.\n",
    "                \n",
    "            v1.4.2\n",
    "                add get_priceBox (v2.1)\n",
    "                modify logical miss for TP / SL in LONG.\n",
    "                modify zip to list(zip) for price_validation.\n",
    "        \n",
    "        last confirmed at, 20240627 0946.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        data_len = len(bank.df_res)\n",
    "        \n",
    "        # use for check TP / SL\n",
    "        high = bank.df_res.high.to_numpy()\n",
    "        low = bank.df_res.low.to_numpy()    \n",
    "        \n",
    "        \n",
    "        data_list = [] \n",
    "        for bank.side_open in ['BUY', 'SELL']:\n",
    "        # for bank.side_open in ['BUY']:\n",
    "        # for bank.side_open in ['SELL']:\n",
    "        # for bank.side_open in [bank.side_open]:    \n",
    "            \n",
    "            \n",
    "            if bank.side_open == 'SELL':\n",
    "                point_index = point_index_short\n",
    "            else:\n",
    "                point_index = point_index_long\n",
    "        \n",
    "            \n",
    "            priceBox_upper, \\\n",
    "            priceBox_lower, \\\n",
    "            close = get_priceBox(bank.df_res,\n",
    "                                     priceBox_indicator,\n",
    "                                     priceBox_value,\n",
    "                                     interval,\n",
    "                                     bank.side_open)\n",
    "        \n",
    "            \n",
    "            # price_arr use priceBox differed by side_open.\n",
    "            price_take_profit_arr, \\\n",
    "            price_entry_arr, \\\n",
    "            price_stop_loss_arr, \\\n",
    "            index_valid_bool = get_price_arr(bank.side_open, \n",
    "                                         priceBox_upper, \n",
    "                                         priceBox_lower,\n",
    "                                         close,\n",
    "                                         point_index_short,\n",
    "                                         point_index_long)\n",
    "        \n",
    "            \n",
    "            trade_arr_valid = np.array(list(zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr)), dtype=[('0', int), ('1', float), ('2', float), ('3', float)])[index_valid_bool]\n",
    "            \n",
    "            for idx_entry, price_take_profit, price_entry, price_stop_loss in trade_arr_valid:\n",
    "            \n",
    "                # init.\n",
    "                status = None\n",
    "                status_entry = 0\n",
    "                \n",
    "                \n",
    "                # trade stops when price reaches TP / SL\n",
    "                    # start from the next bar. (current bar = signal_open)\n",
    "                idx_realtime = idx_entry + 1\n",
    "                while 1:\n",
    "            \n",
    "                        # no more data. (primary cause + 1 above)\n",
    "                    if idx_realtime >= data_len:\n",
    "                        status = 'DataEnd'\n",
    "                        break\n",
    "        \n",
    "                    #     # check entry execution.\n",
    "                    # if bank.side_open == 'SELL':  \n",
    "                    #     if high[idx_realtime] > price_entry: # (very conservative use '>')\n",
    "                    #         status_entry = 1\n",
    "                    # else:\n",
    "                    #     if low[idx_realtime] < price_entry: # (very conservative use '<')\n",
    "                    #         status_entry = 1\n",
    "            \n",
    "                    \n",
    "                    if bank.side_open == 'SELL':  \n",
    "                        # check take_profit (conservative use '<')            \n",
    "                        if low[idx_realtime] < price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '>=')    \n",
    "                        elif high[idx_realtime] >= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "                    else:\n",
    "                        # check take_profit (conservative use '>')            \n",
    "                        if high[idx_realtime] > price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '<=')    \n",
    "                        elif low[idx_realtime] <= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "            \n",
    "                    idx_realtime += 1\n",
    "            \n",
    "                # if trade is done,\n",
    "                    # add row to the table\n",
    "                if status is not None:\n",
    "                    if status in ['TP', 'SL']:            \n",
    "                        if bank.side_open == 'SELL': \n",
    "                            row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]\n",
    "                        else:\n",
    "                            row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]                \n",
    "                        data_list.append(row)\n",
    "                        \n",
    "                # bank.push_msg(bank, status)\n",
    "        \n",
    "        \n",
    "        columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss']\n",
    "        table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "        \n",
    "        \n",
    "        table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "        \n",
    "        timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "        table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "        table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "        \n",
    "        \n",
    "        columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit'] \n",
    "        table_trade_result = table_trade_result[columns_new] \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # save table_trade_result\n",
    "        \n",
    "        # path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/{}/{}/\".format(interval, period_DC)\n",
    "        # path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_SHORT_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "        path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))                                                 \n",
    "        table_trade_result.reset_index(drop=True).to_feather(path_file_table_trade_res)\n",
    "\n",
    "        bank.sys_log.debug(\"path_file_table_trade_res : {}\".format(path_file_table_trade_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95c4bf-d296-4ec1-bd4a-863c8a2d7276",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab758d-53d1-45ea-a066-3b88af60c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = ['4h', '15m', '30m', '1h', '2h', ]\n",
    "period_DC = 60\n",
    "        \n",
    "# band_upper = 1\n",
    "# band_lower = 0.0\n",
    "\n",
    "target_loss = 50 # USDT\n",
    "\n",
    "# threshold_winRatio = 0.8\n",
    "# threshold_incomeTotal = 0.0\n",
    "\n",
    "\n",
    "for interval in intervals:    \n",
    "    \n",
    "    path_df_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/public/df_res/{}\".format(interval)\n",
    "    \n",
    "    for file_name in os.listdir(path_df_res):\n",
    "    # for index_symbol, bank.symbol in enumerate(symbols):\n",
    "\n",
    "        # if index_symbol <= 139:\n",
    "        #     continue\n",
    "        # if 'DOT' not in file_name:\n",
    "        #     continue\n",
    "        \n",
    "        # return end_date is calculated date by concat_candlestick.\n",
    "        # bank.df_res, end_date = bank.concat_candlestick(bank,\n",
    "        #                                               interval,\n",
    "        #                                               days,\n",
    "        #                                               limit=limit,\n",
    "        #                                               end_date=end_date,\n",
    "        #                                               show_process=True,\n",
    "        #                                               timesleep=0.2)\n",
    "\n",
    "\n",
    "        # bank.df_res = pd.read_parquet(os.path.join(path_df_res, file_name)) # 1000SATSUSDT_202406052249.ftr  \n",
    "        bank.df_res = pd.read_feather(os.path.join(path_df_res, file_name)) # 1000SATSUSDT_202406052249.ftr             \n",
    "        bank.df_res['datetime'] = bank.df_res['timestamp'].apply(datetime.fromtimestamp)\n",
    "        bank.df_res.set_index('datetime', inplace=True)\n",
    "        bank.symbol = file_name.split('_')[0]\n",
    "        \n",
    "\n",
    "        \n",
    "        bank.df_res = get_II(bank.df_res)\n",
    "        bank.df_res = get_DC(bank.df_res, period_DC, interval=interval) #.tail()    \n",
    "        bank.df_res = get_DC_perentage(bank.df_res, period_DC, interval=interval) #.tail()\n",
    "        \n",
    "        iiSource = bank.df_res.iiSource.to_numpy()\n",
    "        iiSource_back_1 = bank.df_res.iiSource.shift(1).to_numpy()\n",
    "        iiSource_back_2 = bank.df_res.iiSource.shift(2).to_numpy()\n",
    "        \n",
    "        cross_over = np.where((iiSource > 0) & (0 > iiSource_back_1), 1, 0)\n",
    "        cross_under = np.where((iiSource < 0) & (0 < iiSource_back_1), 1, 0)    \n",
    "        \n",
    "        point_index_long = np.argwhere(cross_over).ravel()\n",
    "        point_index_short = np.argwhere(cross_under).ravel()\n",
    "        \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            remove spread_arr.\n",
    "        \n",
    "        last confirmed at, 20240605 1439.\n",
    "        \"\"\"\n",
    "        DC_upper = bank.df_res['DC_{}{}_upper'.format(interval, period_DC)].to_numpy()\n",
    "        DC_lower = bank.df_res['DC_{}{}_lower'.format(interval, period_DC)].to_numpy()\n",
    "        close = bank.df_res.close.to_numpy()    \n",
    "        \n",
    "        \n",
    "        # if bank.side_open == 'SELL':    \n",
    "        #     price_take_profit_arr = DC_lower[point_index_short]\n",
    "        #     price_entry_arr = close[point_index_short]\n",
    "        #     price_stop_loss_arr = DC_upper[point_index_short]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        v1.1\n",
    "            add spread_arr\n",
    "        v1.2\n",
    "            remove quantity info from table.\n",
    "            reject status=DataEnd\n",
    "            add symbol for winRatio calibration.\n",
    "            add timestamp for amount agg. check.\n",
    "        v1.3\n",
    "            add timestamp column and timestamp_entry & exit derives from it.\n",
    "        v1.4\n",
    "            add LONG position.\n",
    "                LONG SHORT one table.\n",
    "        \n",
    "        last confirmed at, 20240607 1102.\n",
    "        \"\"\"\n",
    "        \n",
    "        data_len = len(bank.df_res)\n",
    "        \n",
    "        # use for check TP / SL\n",
    "        high = bank.df_res.high.to_numpy()\n",
    "        low = bank.df_res.low.to_numpy()    \n",
    "        \n",
    "        \n",
    "        data_list = [] \n",
    "        for bank.side_open in ['BUY', 'SELL']:\n",
    "        # for bank.side_open in [bank.side_open]:\n",
    "        \n",
    "            # bank.side_open = 'BUY'    \n",
    "            \n",
    "            if bank.side_open == 'SELL':\n",
    "                point_index = point_index_short\n",
    "                price_take_profit_arr = DC_lower[point_index_short]\n",
    "                price_entry_arr = close[point_index_short]\n",
    "                price_stop_loss_arr = DC_upper[point_index_short]\n",
    "            else:\n",
    "                point_index = point_index_long\n",
    "                price_take_profit_arr = DC_upper[point_index_long]\n",
    "                price_entry_arr = close[point_index_long]\n",
    "                price_stop_loss_arr = DC_lower[point_index_long]\n",
    "                \n",
    "            \n",
    "            \n",
    "            for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "            \n",
    "                # init.\n",
    "                status = None\n",
    "                # amount = 500 # temporary static (USDT)\n",
    "                # amount = 50 / spread # temporary static (USDT)\n",
    "                # quantity = 100 # temporary static   \n",
    "                # leverage = 1 # temporary static        \n",
    "                fee_entry = 0.0005 # temporary static\n",
    "                fee_exit = 0.0005 # temporary static\n",
    "                \n",
    "                # trade stops when price reaches TP / SL\n",
    "                    # start from the next bar. (current bar = signal_open)        \n",
    "                idx_realtime = idx_entry + 1\n",
    "                while 1:\n",
    "            \n",
    "                        # no more data. (primary cause + 1 above)\n",
    "                    if idx_realtime >= data_len:\n",
    "                        status = 'DataEnd'\n",
    "                        break\n",
    "            \n",
    "                    \n",
    "                    if bank.side_open == 'SELL':  \n",
    "                        # check take_profit (conservative use '<')            \n",
    "                        if low[idx_realtime] < price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '>=')    \n",
    "                        elif high[idx_realtime] >= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "                    else:\n",
    "                        # check take_profit (conservative use '>')            \n",
    "                        if low[idx_realtime] > price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '<=')    \n",
    "                        elif high[idx_realtime] <= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "            \n",
    "                    idx_realtime += 1\n",
    "            \n",
    "                # if trade is done,\n",
    "                    # add row to the table\n",
    "                if status is not None:\n",
    "                    if status in ['TP', 'SL']:            \n",
    "                        if bank.side_open == 'SELL': \n",
    "                            row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]\n",
    "                        else:\n",
    "                            row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]                \n",
    "                        data_list.append(row)\n",
    "                        \n",
    "                # bank.push_msg(bank, status)\n",
    "        \n",
    "        \n",
    "        columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'fee_entry', 'fee_exit']\n",
    "        columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit', 'fee_entry', 'fee_exit'] \n",
    "        \n",
    "        table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "        table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "        \n",
    "        timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "        table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "        table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "        \n",
    "        table_trade_result = table_trade_result[columns_new] \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        # \"\"\"\n",
    "        # v1.1\n",
    "        #     define ~ to_numpy() as a var. for keep usage\n",
    "        #     add RRratio_adj_fee\n",
    "        #     modify income & commission to income & commission\n",
    "        # v1.2\n",
    "        #     move RRratio to anal phase.\n",
    "        #     set target_loss.\n",
    "        #         income calculated from quantity.\n",
    "        # v1.3\n",
    "        \n",
    "        # last confirmed at, 20240607 1444.\n",
    "        # \"\"\"\n",
    "        \n",
    "        # price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "        # price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "        # price_entry = table_trade_result.price_entry.to_numpy()\n",
    "        # price_exit = table_trade_result.price_exit.to_numpy()\n",
    "        \n",
    "        # fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "        # fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "        \n",
    "        \n",
    "        # target_loss = 50 # USDT\n",
    "        # loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "        # quantity = target_loss / loss\n",
    "        \n",
    "        # table_trade_result['loss'] = loss\n",
    "        # table_trade_result['quantity'] = quantity\n",
    "        \n",
    "        \n",
    "        # amount_entry = price_entry * quantity\n",
    "        # amount_exit = price_exit * quantity\n",
    "        \n",
    "        # # if bank.side_open == 'SELL':\n",
    "        # #     income = amount_entry - amount_exit # SELL\n",
    "        # # else:\n",
    "        # #     income = amount_exit - amount_entry # BUY    \n",
    "        # commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "        \n",
    "        # table_trade_result['income'] = amount_exit - amount_entry\n",
    "        # table_trade_result['income'] = np.where(table_trade_result.position.to_numpy() == 'SHORT', -table_trade_result.income.to_numpy(), table_trade_result.income.to_numpy())\n",
    "        # table_trade_result['commission'] = commission\n",
    "        # table_trade_result['income - commission'] = table_trade_result.income.to_numpy() - commission\n",
    "\n",
    "        \n",
    "\n",
    "        # # point (sparse value)\n",
    "        \n",
    "        # # zone (continuous value)\n",
    "        #     # default\n",
    "        # table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "        # table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))        \n",
    "        # # table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "\n",
    "        # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)    \n",
    "        # table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/{}/{}/\".format(interval, period_DC)\n",
    "        # path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_SHORT_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "        path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "                                                 \n",
    "        os.makedirs(path_dir_table_trade_res, exist_ok=True)\n",
    "        table_trade_result.reset_index(drop=True).to_feather(path_file_table_trade_res)\n",
    "\n",
    "        bank.sys_log.debug(\"path_file_table_trade_res : {}\".format(path_file_table_trade_res))\n",
    "                                                 \n",
    "        \n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            add symbol to pivot_table index.\n",
    "        \n",
    "        last confirmed at, 20240605 1106.\n",
    "        \"\"\"\n",
    "        # try:                    \n",
    "        #     table_trade_result_pivot = table_trade_result.pivot_table(index=table_trade_result.RRratio_adj_fee_category, columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "        #     table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "        #     table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "        #     table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "            \n",
    "        # except Exception as e:\n",
    "        #     self.push_msg(self, str(e))\n",
    "            \n",
    "        # else:\n",
    "        #     # threshold_winRatio = 0.8\n",
    "        #     # threshold_incomeTotal = 0.0\n",
    "            \n",
    "        #     table_trade_result_pivot_adj_threshold = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)]\n",
    "            \n",
    "        #     for index_category, category in enumerate(table_trade_result_pivot_adj_threshold.index.tolist()):\n",
    "            \n",
    "        #         table_trade_result_anal = table_trade_result[table_trade_result.RRratio_adj_fee_category == category]\n",
    "        #         table_trade_result_len = len(table_trade_result)\n",
    "        #         table_trade_result_anal_len = len(table_trade_result_anal)\n",
    "                \n",
    "        #         winRatio = len(table_trade_result_anal[table_trade_result_anal.status=='TP']) / table_trade_result_anal_len\n",
    "                \n",
    "        #         print(\"category : {}\".format(category))\n",
    "        #         print(\"winRatio : {}\".format(winRatio))\n",
    "        #         print(\"frequency_total : {}\".format(table_trade_result_len))\n",
    "        #         print(\"frequency : {}\".format(table_trade_result_anal_len))\n",
    "        \n",
    "        #         title = \"symbol : {}\\n\".format(bank.symbol)\n",
    "        #         title += \"category : {}\\n\".format(category)\n",
    "        #         title += \"winRatio : {:.2f}\\n\".format(winRatio)\n",
    "        #         title += \"frequency_total : {}\\n\".format(table_trade_result_len)\n",
    "        #         title += \"frequency : {}\".format(table_trade_result_anal_len)\n",
    "                \n",
    "        #         plt.title(title, fontsize=10)\n",
    "        #         plt.step(np.arange(len(table_trade_result_anal)), np.cumsum(table_trade_result_anal['income - commission'].to_numpy()))\n",
    "                \n",
    "        #         plt.tight_layout()\n",
    "                \n",
    "        #         # path_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\DC_II_cross\\image\\{}_{}.png\".format(bank.symbol, index_category)\n",
    "        #         # plt.savefig(path_save_fig)\n",
    "        #         plt.show()\n",
    "    \n",
    "        \n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c83b2-3a17-45c2-967b-1c351734898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = ['4h', '15m', '30m', '1h', '2h', ]\n",
    "period_DC = 60\n",
    "        \n",
    "# band_upper = 1\n",
    "# band_lower = 0.0\n",
    "\n",
    "target_loss = 50 # USDT\n",
    "\n",
    "# threshold_winRatio = 0.8\n",
    "# threshold_incomeTotal = 0.0\n",
    "\n",
    "\n",
    "for interval in intervals:    \n",
    "    \n",
    "    path_df_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/public/df_res/{}\".format(interval)\n",
    "    \n",
    "    for file_name in os.listdir(path_df_res):\n",
    "    # for index_symbol, bank.symbol in enumerate(symbols):\n",
    "\n",
    "        # if index_symbol <= 139:\n",
    "        #     continue\n",
    "        # if 'DOT' not in file_name:\n",
    "        #     continue\n",
    "        \n",
    "        # return end_date is calculated date by concat_candlestick.\n",
    "        # bank.df_res, end_date = bank.concat_candlestick(bank,\n",
    "        #                                               interval,\n",
    "        #                                               days,\n",
    "        #                                               limit=limit,\n",
    "        #                                               end_date=end_date,\n",
    "        #                                               show_process=True,\n",
    "        #                                               timesleep=0.2)\n",
    "\n",
    "\n",
    "        # bank.df_res = pd.read_parquet(os.path.join(path_df_res, file_name)) # 1000SATSUSDT_202406052249.ftr  \n",
    "        bank.df_res = pd.read_feather(os.path.join(path_df_res, file_name)) # 1000SATSUSDT_202406052249.ftr             \n",
    "        bank.df_res['datetime'] = bank.df_res['timestamp'].apply(datetime.fromtimestamp)\n",
    "        bank.df_res.set_index('datetime', inplace=True)\n",
    "        bank.symbol = file_name.split('_')[0]\n",
    "        \n",
    "\n",
    "        \n",
    "        bank.df_res = get_II(bank.df_res)\n",
    "        bank.df_res = get_DC(bank.df_res, period_DC, interval=interval) #.tail()    \n",
    "        bank.df_res = get_DC_perentage(bank.df_res, period_DC, interval=interval) #.tail()\n",
    "        \n",
    "        iiSource = bank.df_res.iiSource.to_numpy()\n",
    "        iiSource_back_1 = bank.df_res.iiSource.shift(1).to_numpy()\n",
    "        iiSource_back_2 = bank.df_res.iiSource.shift(2).to_numpy()\n",
    "        \n",
    "        cross_over = np.where((iiSource > 0) & (0 > iiSource_back_1), 1, 0)\n",
    "        cross_under = np.where((iiSource < 0) & (0 < iiSource_back_1), 1, 0)    \n",
    "        \n",
    "        point_index_long = np.argwhere(cross_over).ravel()\n",
    "        point_index_short = np.argwhere(cross_under).ravel()\n",
    "        \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            remove spread_arr.\n",
    "        \n",
    "        last confirmed at, 20240605 1439.\n",
    "        \"\"\"\n",
    "        DC_upper = bank.df_res['DC_{}{}_upper'.format(interval, period_DC)].to_numpy()\n",
    "        DC_lower = bank.df_res['DC_{}{}_lower'.format(interval, period_DC)].to_numpy()\n",
    "        close = bank.df_res.close.to_numpy()    \n",
    "        \n",
    "        \n",
    "        # if bank.side_open == 'SELL':    \n",
    "        #     price_take_profit_arr = DC_lower[point_index_short]\n",
    "        #     price_entry_arr = close[point_index_short]\n",
    "        #     price_stop_loss_arr = DC_upper[point_index_short]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        v1.1\n",
    "            add spread_arr\n",
    "        v1.2\n",
    "            remove quantity info from table.\n",
    "            reject status=DataEnd\n",
    "            add symbol for winRatio calibration.\n",
    "            add timestamp for amount agg. check.\n",
    "        v1.3\n",
    "            add timestamp column and timestamp_entry & exit derives from it.\n",
    "        v1.4\n",
    "            add LONG position.\n",
    "                LONG SHORT one table.\n",
    "        \n",
    "        last confirmed at, 20240607 1102.\n",
    "        \"\"\"\n",
    "        \n",
    "        data_len = len(bank.df_res)\n",
    "        \n",
    "        # use for check TP / SL\n",
    "        high = bank.df_res.high.to_numpy()\n",
    "        low = bank.df_res.low.to_numpy()    \n",
    "        \n",
    "        \n",
    "        data_list = [] \n",
    "        for bank.side_open in ['BUY', 'SELL']:\n",
    "        # for bank.side_open in [bank.side_open]:\n",
    "        \n",
    "            # bank.side_open = 'BUY'    \n",
    "            \n",
    "            if bank.side_open == 'SELL':\n",
    "                point_index = point_index_short\n",
    "                price_take_profit_arr = DC_lower[point_index_short]\n",
    "                price_entry_arr = close[point_index_short]\n",
    "                price_stop_loss_arr = DC_upper[point_index_short]\n",
    "            else:\n",
    "                point_index = point_index_long\n",
    "                price_take_profit_arr = DC_upper[point_index_long]\n",
    "                price_entry_arr = close[point_index_long]\n",
    "                price_stop_loss_arr = DC_lower[point_index_long]\n",
    "                \n",
    "            \n",
    "            \n",
    "            for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "            \n",
    "                # init.\n",
    "                status = None\n",
    "                # amount = 500 # temporary static (USDT)\n",
    "                # amount = 50 / spread # temporary static (USDT)\n",
    "                # quantity = 100 # temporary static   \n",
    "                # leverage = 1 # temporary static        \n",
    "                fee_entry = 0.0005 # temporary static\n",
    "                fee_exit = 0.0005 # temporary static\n",
    "                \n",
    "                # trade stops when price reaches TP / SL\n",
    "                    # start from the next bar. (current bar = signal_open)        \n",
    "                idx_realtime = idx_entry + 1\n",
    "                while 1:\n",
    "            \n",
    "                        # no more data. (primary cause + 1 above)\n",
    "                    if idx_realtime >= data_len:\n",
    "                        status = 'DataEnd'\n",
    "                        break\n",
    "            \n",
    "                    \n",
    "                    if bank.side_open == 'SELL':  \n",
    "                        # check take_profit (conservative use '<')            \n",
    "                        if low[idx_realtime] < price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '>=')    \n",
    "                        elif high[idx_realtime] >= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "                    else:\n",
    "                        # check take_profit (conservative use '>')            \n",
    "                        if low[idx_realtime] > price_take_profit:\n",
    "                            status = 'TP'\n",
    "                            break\n",
    "                            \n",
    "                            # check stop_loss (conservative use '<=')    \n",
    "                        elif high[idx_realtime] <= price_stop_loss:\n",
    "                            status = 'SL'\n",
    "                            break\n",
    "            \n",
    "                    idx_realtime += 1\n",
    "            \n",
    "                # if trade is done,\n",
    "                    # add row to the table\n",
    "                if status is not None:\n",
    "                    if status in ['TP', 'SL']:            \n",
    "                        if bank.side_open == 'SELL': \n",
    "                            row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]\n",
    "                        else:\n",
    "                            row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]                \n",
    "                        data_list.append(row)\n",
    "                        \n",
    "                # bank.push_msg(bank, status)\n",
    "        \n",
    "        \n",
    "        columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'fee_entry', 'fee_exit']\n",
    "        columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit', 'fee_entry', 'fee_exit'] \n",
    "        \n",
    "        table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "        table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "        \n",
    "        timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "        table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "        table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "        \n",
    "        table_trade_result = table_trade_result[columns_new] \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        # \"\"\"\n",
    "        # v1.1\n",
    "        #     define ~ to_numpy() as a var. for keep usage\n",
    "        #     add RRratio_adj_fee\n",
    "        #     modify income & commission to income & commission\n",
    "        # v1.2\n",
    "        #     move RRratio to anal phase.\n",
    "        #     set target_loss.\n",
    "        #         income calculated from quantity.\n",
    "        # v1.3\n",
    "        \n",
    "        # last confirmed at, 20240607 1444.\n",
    "        # \"\"\"\n",
    "        \n",
    "        # price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "        # price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "        # price_entry = table_trade_result.price_entry.to_numpy()\n",
    "        # price_exit = table_trade_result.price_exit.to_numpy()\n",
    "        \n",
    "        # fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "        # fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "        \n",
    "        \n",
    "        # target_loss = 50 # USDT\n",
    "        # loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "        # quantity = target_loss / loss\n",
    "        \n",
    "        # table_trade_result['loss'] = loss\n",
    "        # table_trade_result['quantity'] = quantity\n",
    "        \n",
    "        \n",
    "        # amount_entry = price_entry * quantity\n",
    "        # amount_exit = price_exit * quantity\n",
    "        \n",
    "        # # if bank.side_open == 'SELL':\n",
    "        # #     income = amount_entry - amount_exit # SELL\n",
    "        # # else:\n",
    "        # #     income = amount_exit - amount_entry # BUY    \n",
    "        # commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "        \n",
    "        # table_trade_result['income'] = amount_exit - amount_entry\n",
    "        # table_trade_result['income'] = np.where(table_trade_result.position.to_numpy() == 'SHORT', -table_trade_result.income.to_numpy(), table_trade_result.income.to_numpy())\n",
    "        # table_trade_result['commission'] = commission\n",
    "        # table_trade_result['income - commission'] = table_trade_result.income.to_numpy() - commission\n",
    "\n",
    "        \n",
    "\n",
    "        # # point (sparse value)\n",
    "        \n",
    "        # # zone (continuous value)\n",
    "        #     # default\n",
    "        # table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "        # table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))        \n",
    "        # # table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "\n",
    "        # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)    \n",
    "        # table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/{}/{}/\".format(interval, period_DC)\n",
    "        # path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_SHORT_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "        path_file_table_trade_res = os.path.join(path_dir_table_trade_res, \"{}_{}.ftr\".format(bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "                                                 \n",
    "        os.makedirs(path_dir_table_trade_res, exist_ok=True)\n",
    "        table_trade_result.reset_index(drop=True).to_feather(path_file_table_trade_res)\n",
    "\n",
    "        bank.sys_log.debug(\"path_file_table_trade_res : {}\".format(path_file_table_trade_res))\n",
    "                                                 \n",
    "        \n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            add symbol to pivot_table index.\n",
    "        \n",
    "        last confirmed at, 20240605 1106.\n",
    "        \"\"\"\n",
    "        # try:                    \n",
    "        #     table_trade_result_pivot = table_trade_result.pivot_table(index=table_trade_result.RRratio_adj_fee_category, columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "        #     table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "        #     table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "        #     table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "            \n",
    "        # except Exception as e:\n",
    "        #     self.push_msg(self, str(e))\n",
    "            \n",
    "        # else:\n",
    "        #     # threshold_winRatio = 0.8\n",
    "        #     # threshold_incomeTotal = 0.0\n",
    "            \n",
    "        #     table_trade_result_pivot_adj_threshold = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)]\n",
    "            \n",
    "        #     for index_category, category in enumerate(table_trade_result_pivot_adj_threshold.index.tolist()):\n",
    "            \n",
    "        #         table_trade_result_anal = table_trade_result[table_trade_result.RRratio_adj_fee_category == category]\n",
    "        #         table_trade_result_len = len(table_trade_result)\n",
    "        #         table_trade_result_anal_len = len(table_trade_result_anal)\n",
    "                \n",
    "        #         winRatio = len(table_trade_result_anal[table_trade_result_anal.status=='TP']) / table_trade_result_anal_len\n",
    "                \n",
    "        #         print(\"category : {}\".format(category))\n",
    "        #         print(\"winRatio : {}\".format(winRatio))\n",
    "        #         print(\"frequency_total : {}\".format(table_trade_result_len))\n",
    "        #         print(\"frequency : {}\".format(table_trade_result_anal_len))\n",
    "        \n",
    "        #         title = \"symbol : {}\\n\".format(bank.symbol)\n",
    "        #         title += \"category : {}\\n\".format(category)\n",
    "        #         title += \"winRatio : {:.2f}\\n\".format(winRatio)\n",
    "        #         title += \"frequency_total : {}\\n\".format(table_trade_result_len)\n",
    "        #         title += \"frequency : {}\".format(table_trade_result_anal_len)\n",
    "                \n",
    "        #         plt.title(title, fontsize=10)\n",
    "        #         plt.step(np.arange(len(table_trade_result_anal)), np.cumsum(table_trade_result_anal['income - commission'].to_numpy()))\n",
    "                \n",
    "        #         plt.tight_layout()\n",
    "                \n",
    "        #         # path_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\DC_II_cross\\image\\{}_{}.png\".format(bank.symbol, index_category)\n",
    "        #         # plt.savefig(path_save_fig)\n",
    "        #         plt.show()\n",
    "    \n",
    "        \n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6ba3b-a21d-4877-875b-ad40faa123b3",
   "metadata": {},
   "source": [
    "### load table_trade res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf9bd9-e138-473e-ba7e-78ceb54f250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_strategy = \"priceBox_DC_point_Cross_DC\"\n",
    "\n",
    "priceBox_value = 60\n",
    "point_value = 30\n",
    "\n",
    "interval = '15m'\n",
    "interval = '30m'\n",
    "# interval = '1h'\n",
    "# interval = '2h'\n",
    "# interval = '4h'\n",
    "\n",
    "\n",
    "# path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_res/{}/{}/\".format(dir_name_strategy, interval, period_DC)\n",
    "path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, interval)\n",
    "\n",
    "\n",
    "table_trade_res_list = []\n",
    "for index_file, file_name in enumerate(os.listdir(path_dir_table_trade_res)):    \n",
    "\n",
    "    # if 'DOT' in file_name:\n",
    "    #     pass\n",
    "    \n",
    "        path_file = os.path.join(path_dir_table_trade_res, file_name)\n",
    "        \n",
    "        if os.path.isfile(path_file):\n",
    "            table_trade_result_individual = pd.read_feather(path_file)\n",
    "            # table_trade_result_individual.iloc[:, :13].to_feather(path_file)\n",
    "            table_trade_res_list.append(table_trade_result_individual)\n",
    "\n",
    "table_trade_result = pd.concat(table_trade_res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcb658-f4d7-42c8-ad33-e309aab3fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5986c-26ef-47e6-837c-af3b52945659",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_entry = table_trade_result['timestamp_entry'].to_numpy()\n",
    "timestamp_min = table_trade_result['timestamp_entry'].min()\n",
    "timestamp_max = table_trade_result['timestamp_entry'].max()\n",
    "\n",
    "train_ratio = 0.7\n",
    "timestamp_train = timestamp_min + (timestamp_max - timestamp_min) * train_ratio\n",
    "\n",
    "table_trade_result['dataType'] = np.where(timestamp_entry < timestamp_train, 'TRAIN', 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c38717-5da4-4301-ac22-b3ca0e284f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe73ce1-431b-45aa-9c13-b1e41dc9f1e3",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00cacfa-df9f-401e-8328-1f9e544a0b6f",
   "metadata": {},
   "source": [
    "### v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f8c5e-91f8-4bec-8384-a9872485c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    adj. bank.concat_candlestick\n",
    "    add timestamp column.\n",
    "v2.1\n",
    "    get data with feather.  \n",
    "\n",
    "last confirmed at, 20240607 1108.\n",
    "\"\"\"\n",
    "\n",
    "path_df_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/public/df_res/15m\"\n",
    "file_name = \"BANDUSDT_202406060214.ftr\"\n",
    "\n",
    "bank.df_res = pd.read_feather(os.path.join(path_df_res, file_name))\n",
    "bank.df_res['datetime'] = bank.df_res['timestamp'].apply(datetime.fromtimestamp)\n",
    "bank.df_res.set_index('datetime', inplace=True)\n",
    "bank.symbol = file_name.split('_')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f008c24-5775-4c50-85d8-27e1a66e02e3",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d61098-9597-4109-93ff-f5ae0d675213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    adj. bank.concat_candlestick\n",
    "    add timestamp column.\n",
    "\n",
    "last confirmed at, 20240606 0649.\n",
    "\"\"\"\n",
    "\n",
    "days = 3 # at least 2 days for 15T II value to be synced.\n",
    "# days = 600 # at least 2 days for 15T II value to be synced.\n",
    "\n",
    "end_date = None  # \"2023-01-06\" \"2021-04-12\" \"2021-03-23\"\n",
    "# end_date = \"2023-12-20\"\n",
    "\n",
    "intervals = ['15m']\n",
    "# intervals = ['1m']\n",
    "# intervals = ['1m', '3m', '5m', '15m', '30m', '1h', '4h', '1d']\n",
    "# interval = '15m'\n",
    "limit = 1500\n",
    "\n",
    "\n",
    "# bank.symbol = 'THETAUSDT'\n",
    "symbols = ['BCHUSDT', 'BICOUSDT']\n",
    "symbols = ['BICOUSDT']\n",
    "\n",
    "# bank.symbol = 'DOTUSDT'\n",
    "# symbols = ['BCHUSDT']\n",
    "# bank_exchange_info = bank.exchange_info()\n",
    "# symbols = [data['symbol'] for data in bank.exchange_info()['symbols'] if 'USDT' in data['symbol'] if '_' not in data['symbol']]\n",
    "\n",
    "for interval in intervals:\n",
    "    for bank.symbol in symbols:    \n",
    "        \n",
    "        # bank.df_res, end_date = bank.concat_candlestick(bank,\n",
    "        #                                               interval,\n",
    "        #                                               days,\n",
    "        #                                               limit=limit,\n",
    "        #                                               end_date=end_date,\n",
    "        #                                               show_process=True,\n",
    "        #                                               timesleep=0.2)\n",
    "        \n",
    "        bank.df_res = get_df_new(bank, \n",
    "                                 interval, \n",
    "                                 days, \n",
    "                                 limit=1500,\n",
    "                                 end_date=end_date,\n",
    "                                 timesleep=0)\n",
    "        \n",
    "        bank.df_res['timestamp'] = bank.df_res.index\n",
    "        bank.df_res['timestamp'] = bank.df_res['timestamp'].apply(lambda x : int(datetime.timestamp(x)))\n",
    "        \n",
    "        \n",
    "        # bank.df_res['datetime_index'] = bank.df_res.index\n",
    "        # print((bank.df_res.datetime == bank.df_res.datetime_index).sum() == len(bank.df_res))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fab69-9475-45b3-a5ec-1302357ba9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bank.df_res))\n",
    "bank.df_res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e977d-471b-45c5-b2e6-cc86a17eb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_15T = to_htf(bank.df_res, '15T', offset=0)#.tail()\n",
    "# bank.df_res = to_htf(bank.df_res, bank.timeframe, offset=0)\n",
    "df_res_15m = bank.df_res.copy()\n",
    "\n",
    "(df_res_15m.loc['2024-06-09 00:15:00':'2024-06-10 16:15:00'].iloc[:, :5] == df_res_15T.loc['2024-06-09 00:15:00':'2024-06-10 16:15:00'].iloc[:, :5])#.describe() #.tail()\n",
    "df_res_15T#.head()\n",
    "# df_res_15m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef14d53-9e0a-4ef5-be12-4ae99416bc20",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131b84a-06c5-4b98-b536-d04642ce83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 600 # at least 2 days for 15T II value to be synced.\n",
    "end_date = None  # \"2023-01-06\" \"2021-04-12\" \"2021-03-23\"\n",
    "# end_date = \"2023-12-20\"\n",
    "intervals = ['1m']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "interval = '15m'\n",
    "limit = 1500\n",
    "\n",
    "# bank.symbol = 'THETAUSDT'\n",
    "symbols = ['BCHUSDT', 'BICOUSDT']\n",
    "symbols = ['DOTUSDT']\n",
    "# symbols = ['BCHUSDT']\n",
    "# bank_exchange_info = bank.exchange_info()\n",
    "# symbols = [data['symbol'] for data in bank.exchange_info()['symbols'] if 'USDT' in data['symbol'] if '_' not in data['symbol']]\n",
    "\n",
    "# while 1:\n",
    "for bank.symbol in symbols:    \n",
    "    \n",
    "    bank.df_res, end_date = concat_candlestick_v2(bank.symbol,\n",
    "                                                  interval,\n",
    "                                                  days,\n",
    "                                                  limit=limit,\n",
    "                                                  end_date=end_date,\n",
    "                                                  show_process=True,\n",
    "                                                  timesleep=0.2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38ec1e-cb51-4f4b-9f6e-4c57444eac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bank.df_res.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f29ded-7feb-4f39-a6ab-8efeafe3561f",
   "metadata": {},
   "source": [
    "## get_point_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd35e4-662d-4be4-8a1f-907e3cb560e7",
   "metadata": {},
   "source": [
    "### v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947fc99-46d2-43ca-a8f4-06d42cac315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_index(df, \n",
    "                    mode,\n",
    "                    indicator,  \n",
    "                    point_value,\n",
    "                    interval,\n",
    "                    return_bool=False):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        rearrange later.\n",
    "    v2.1\n",
    "        integrate input, output.\n",
    "        add return_bool for Bank.\n",
    "\n",
    "    last confirmed at, 20240627 1957.\n",
    "    \"\"\"\n",
    "\n",
    "    cross_over = []\n",
    "    cross_under = []\n",
    "    \n",
    "    indicator_value = np.nan\n",
    "    \n",
    "    if mode == 'CROSS':\n",
    "        if indicator == 'II':\n",
    "            df = get_II(df, period=point_value)\n",
    "            \n",
    "            indicator_value = df.iiSource.to_numpy()\n",
    "            indicator_value_back_1 = df.iiSource.shift(1).to_numpy()\n",
    "            base_value = 0\n",
    "              \n",
    "            cross_over = np.where((indicator_value > base_value) & (base_value > indicator_value_back_1), 1, 0)\n",
    "            cross_under = np.where((indicator_value < base_value) & (base_value < indicator_value_back_1), 1, 0)    \n",
    "\n",
    "        \n",
    "        elif indicator == 'DC':            \n",
    "            df = get_DC(df, period=point_value, interval=interval)\n",
    "            \n",
    "            # indicator_value = df['DC_{}{}_upper'.format(interval, point_value).to_numpy()\n",
    "            DC_upper_back_1 = df['DC_{}{}_upper'.format(interval, point_value)].shift(1).to_numpy()\n",
    "            DC_upper_back_2 = df['DC_{}{}_upper'.format(interval, point_value)].shift(2).to_numpy()\n",
    "            # indicator_value = df['DC_{}{}_lower'.format(interval, point_value).to_numpy()\n",
    "            DC_lower_back_1 = df['DC_{}{}_lower'.format(interval, point_value)].shift(1).to_numpy()\n",
    "            DC_lower_back_2 = df['DC_{}{}_lower'.format(interval, point_value)].shift(2).to_numpy()\n",
    "            # base_value = df.close.to_numpy()\n",
    "    \n",
    "            close = df.close.to_numpy()\n",
    "            close_back_1 = df.close.to_numpy()\n",
    "            \n",
    "            cross_over = np.where((close > DC_upper_back_1), 1, 0) # close cannot be higher / lower than DC.\n",
    "            cross_under = np.where((close < DC_lower_back_1), 1, 0)\n",
    "\n",
    "        \n",
    "        elif indicator == 'CCI':  \n",
    "            df = get_CCI(df, period=point_value, interval=interval)\n",
    "\n",
    "            indicator_name = \"CCI_{}{}\".format(interval, point_value)\n",
    "            \n",
    "            indicator_value = df[indicator_name].to_numpy()\n",
    "            indicator_value_back_1 = df[indicator_name].shift(1).to_numpy()\n",
    "            base_value = 0\n",
    "              \n",
    "            cross_over = np.where((indicator_value > base_value) & (base_value > indicator_value_back_1), 1, 0)\n",
    "            cross_under = np.where((indicator_value < base_value) & (base_value < indicator_value_back_1), 1, 0)    \n",
    "\n",
    "        \n",
    "        elif indicator == 'BB':\n",
    "            df = get_BB(df, point_value, 1, interval, level=2)\n",
    "            \n",
    "            BB_upper = df['BB_{}{}_upper'.format(interval, point_value)].to_numpy() \n",
    "            BB_lower = df['BB_{}{}_lower'.format(interval, point_value)].to_numpy()\n",
    "    \n",
    "            close = df.close.to_numpy()            \n",
    "            price_open = df.open.to_numpy()\n",
    "            \n",
    "            cross_over = np.where((close > BB_upper) & (BB_upper > price_open), 1, 0)\n",
    "            cross_under = np.where((close < BB_lower) & (BB_lower < price_open), 1, 0)\n",
    "            \n",
    "\n",
    "    if return_bool:\n",
    "        return df, cross_over, cross_under\n",
    "    else:\n",
    "        point_index_long = np.argwhere(cross_over).ravel()\n",
    "        point_index_short = np.argwhere(cross_under).ravel()    \n",
    "        \n",
    "        return df, point_index_long, point_index_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7cc25-63a3-4a56-a041-f6efbe38a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_mode = 'CROSS'\n",
    "point_indicator = 'II'\n",
    "point_value = 21\n",
    "\n",
    "bank.df_res, \\\n",
    "point_index_long, \\\n",
    "point_index_short = get_point_index(bank.df_res,\n",
    "                                    point_mode,\n",
    "                                    point_indicator,\n",
    "                                    point_value,\n",
    "                                    interval,\n",
    "                                    return_bool=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2b6ba-7e75-42d5-af13-822460f59115",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(point_index_long)\n",
    "point_index_long\n",
    "# len(bank.df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad7048-cb59-4e0b-88c8-8e13c274dbbd",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf3c33-e4a5-41f8-8cac-ed807f88c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_index(df, \n",
    "                    mode,\n",
    "                    indicator,  \n",
    "                    point_value,\n",
    "                    interval):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        rearrange later.\n",
    "\n",
    "    last confirmed at, 20240626 0933.\n",
    "    \"\"\"\n",
    "\n",
    "    point_index_long = np.array([])#.ravel()\n",
    "    point_index_short = np.array([])#.ravel()\n",
    "    \n",
    "    indicator_value = np.nan\n",
    "    \n",
    "    if mode == 'CROSS':\n",
    "        if indicator == 'II':\n",
    "            df = get_II(df, period=point_value)\n",
    "            \n",
    "            indicator_value = df.iiSource.to_numpy()\n",
    "            indicator_value_back_1 = df.iiSource.shift(1).to_numpy()\n",
    "            base_value = 0\n",
    "              \n",
    "            cross_over = np.where((indicator_value > base_value) & (base_value > indicator_value_back_1), 1, 0)\n",
    "            cross_under = np.where((indicator_value < base_value) & (base_value < indicator_value_back_1), 1, 0)    \n",
    "\n",
    "        \n",
    "        elif indicator == 'DC':            \n",
    "            df = get_DC(df, period=point_value, interval=interval)\n",
    "            \n",
    "            # indicator_value = df['DC_{}{}_upper'.format(interval, point_value).to_numpy()\n",
    "            DC_upper_back_1 = df['DC_{}{}_upper'.format(interval, point_value)].shift(1).to_numpy()\n",
    "            DC_upper_back_2 = df['DC_{}{}_upper'.format(interval, point_value)].shift(2).to_numpy()\n",
    "            # indicator_value = df['DC_{}{}_lower'.format(interval, point_value).to_numpy()\n",
    "            DC_lower_back_1 = df['DC_{}{}_lower'.format(interval, point_value)].shift(1).to_numpy()\n",
    "            DC_lower_back_2 = df['DC_{}{}_lower'.format(interval, point_value)].shift(2).to_numpy()\n",
    "            # base_value = df.close.to_numpy()\n",
    "    \n",
    "            close = df.close.to_numpy()\n",
    "            close_back_1 = df.close.to_numpy()\n",
    "            \n",
    "            cross_over = np.where((close > DC_upper_back_1), 1, 0) # close cannot be higher / lower than DC.\n",
    "            cross_under = np.where((close < DC_lower_back_1), 1, 0)\n",
    "\n",
    "        \n",
    "        elif indicator == 'CCI':  \n",
    "            df = get_CCI(df, period=point_value, interval=interval) \n",
    "\n",
    "            indicator_name = \"CCI_{}{}\".format(interval, point_value)\n",
    "            \n",
    "            indicator_value = df[indicator_name].to_numpy()\n",
    "            indicator_value_back_1 = df[indicator_name].shift(1).to_numpy()\n",
    "            base_value = 0\n",
    "              \n",
    "            cross_over = np.where((indicator_value > base_value) & (base_value > indicator_value_back_1), 1, 0)\n",
    "            cross_under = np.where((indicator_value < base_value) & (base_value < indicator_value_back_1), 1, 0)    \n",
    "\n",
    "        \n",
    "        elif indicator == 'BB':\n",
    "            df = get_BB(df, point_value, 1, interval, level=2)\n",
    "            \n",
    "            BB_upper = df['BB_{}{}_upper'.format(interval, point_value)].to_numpy() \n",
    "            BB_lower = df['BB_{}{}_lower'.format(interval, point_value)].to_numpy()\n",
    "    \n",
    "            close = df.close.to_numpy()            \n",
    "            price_open = df.open.to_numpy()\n",
    "            \n",
    "            cross_over = np.where((close > BB_upper) & (BB_upper > price_open), 1, 0)\n",
    "            cross_under = np.where((close < BB_lower) & (BB_lower < price_open), 1, 0)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            return df, point_index_long, point_index_short\n",
    "        \n",
    "        point_index_long = np.argwhere(cross_over).ravel()\n",
    "        point_index_short = np.argwhere(cross_under).ravel()\n",
    "    \n",
    "        \n",
    "    # if not pd.isnull(indicator_value):\n",
    "    #     if mode == 'CROSS':      \n",
    "\n",
    "    return df, point_index_long, point_index_short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9240c21-5e64-4f80-ac0d-e3b34b79aab6",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685dd93-0e3a-410c-a80b-bb42ddba2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.df_res = get_II(bank.df_res)\n",
    "# bank.df_res = get_DC(bank.df_res, period_DC, interval=interval) #.tail()    \n",
    "# bank.df_res = get_DC_perentage(bank.df_res, period_DC, interval=interval) #.tail()\n",
    "\n",
    "iiSource = bank.df_res.iiSource.to_numpy()\n",
    "iiSource_back_1 = bank.df_res.iiSource.shift(1).to_numpy()\n",
    "iiSource_back_2 = bank.df_res.iiSource.shift(2).to_numpy()\n",
    "\n",
    "cross_over = np.where((iiSource > 0) & (0 > iiSource_back_1), 1, 0)\n",
    "cross_under = np.where((iiSource < 0) & (0 < iiSource_back_1), 1, 0)    \n",
    "\n",
    "point_index_long = np.argwhere(cross_over).ravel()\n",
    "point_index_short = np.argwhere(cross_under).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907c176-4ef9-4a60-8605-25d382abf30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.argwhere(cross_over).ravel()))\n",
    "print(len(np.argwhere(cross_under).ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ab2aa-aada-4cfb-9358-c303b6368059",
   "metadata": {},
   "source": [
    "## add zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce34896-b769-4963-aa50-e2354224c9a6",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b35715-fd1a-44a0-86ce-9be64eab2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zone(df, \n",
    "             indicator,\n",
    "             zone_value, \n",
    "             interval,\n",
    "             point_index_long,\n",
    "             point_index_short):\n",
    "\n",
    "    if indicator == 'MA':\n",
    "        df = get_MA(df, \n",
    "                   zone_value, \n",
    "                   interval)\n",
    "    \n",
    "    \n",
    "        close = df['close'].to_numpy()\n",
    "        MA1 = df['MA_{}{}'.format(interval, zone_value)].to_numpy()\n",
    "        \n",
    "        zone_bool_long = close[point_index_long] > MA1[point_index_long]\n",
    "        zone_bool_short = close[point_index_short] < MA1[point_index_short] \n",
    "        \n",
    "        point_index_long = point_index_long[zone_bool_long]\n",
    "        point_index_short = point_index_short[zone_bool_short]\n",
    "\n",
    "    return df, point_index_long, point_index_short\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0373750-aaff-4bb1-85fd-4cee5257c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.df_res, \\\n",
    "point_index_long, \\\n",
    "point_index_short = add_zone(bank.df_res, \n",
    "                             'MA',\n",
    "                             30, \n",
    "                             interval,\n",
    "                             point_index_long,\n",
    "                             point_index_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f196218-e36a-43ba-9f78-88cadea8ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_index_long\n",
    "bank.df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d7c74-25b1-4c8d-9cfa-a02c489e4da1",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132acfa-4e6a-4e63-965c-d7438b0a189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = '15m'\n",
    "period_DC = 60     \n",
    "band_upper = 1\n",
    "band_lower = 0.0\n",
    "\n",
    "DC_percentage = bank.df_res['DC_{}{}_percentage'.format(interval, period_DC)].to_numpy()        \n",
    "point_short_add_zone = np.where(cross_under & (band_lower < DC_percentage) & (DC_percentage < band_upper), 1, 0)        \n",
    "\n",
    "point_index_short = np.argwhere(point_short_add_zone).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c01aed-55a1-45d4-820e-0cb467ec1b26",
   "metadata": {},
   "source": [
    "## get_priceBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1fc71-2124-4333-8ec2-99da2110c6f6",
   "metadata": {},
   "source": [
    "### v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d20e5-270e-4f29-bd0b-8eabecd402c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priceBox(df,\n",
    "                 indicator,\n",
    "                 priceBox_value,\n",
    "                 interval,\n",
    "                 side_open):\n",
    "    \n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        remove spread_arr.\n",
    "        add side_open BUY.\n",
    "    v2.1\n",
    "        divide by side_open\n",
    "    \n",
    "    last confirmed at, 20240626 0954.\n",
    "    \"\"\"\n",
    "    \n",
    "    # public.\n",
    "    close = df.close.to_numpy()\n",
    "\n",
    "    if indicator == 'DC':    \n",
    "        df = get_DC(df, \n",
    "                     priceBox_value, \n",
    "                     interval=interval)    \n",
    "\n",
    "        # public.\n",
    "        priceBox_upper = df['DC_{}{}_upper'.format(interval, priceBox_value)].to_numpy()\n",
    "        priceBox_lower = df['DC_{}{}_lower'.format(interval, priceBox_value)].to_numpy()\n",
    "\n",
    "    \n",
    "    elif indicator == 'BB':        \n",
    "        # df = get_BB(df, priceBox_value, 1, interval, level=2) # temporary, cause using point_indiator 'BB'.\n",
    "\n",
    "        if side_open == 'BUY':\n",
    "            priceBox_upper = df['BB_{}{}_upper2'.format(interval, priceBox_value)].to_numpy() \n",
    "            priceBox_lower = df['BB_{}{}_base'.format(interval, priceBox_value)].to_numpy()\n",
    "        else:\n",
    "            priceBox_upper = df['BB_{}{}_base'.format(interval, priceBox_value)].to_numpy()\n",
    "            priceBox_lower = df['BB_{}{}_lower2'.format(interval, priceBox_value)].to_numpy() \n",
    "\n",
    "    return priceBox_upper, priceBox_lower, close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc2e4d-e1a7-4f45-a38e-5935797d677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "priceBox_indicator = 'BB'\n",
    "priceBox_indicator = 'DC'\n",
    "priceBox_value = 60\n",
    "bank.side_open = 'BUY'\n",
    "\n",
    "priceBox_upper, \\\n",
    "priceBox_lower, \\\n",
    "close = get_priceBox(bank.df_res,\n",
    "                     priceBox_indicator,\n",
    "                     priceBox_value,\n",
    "                     interval,\n",
    "                     bank.side_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a6fae-c382-4590-903c-9a90eea6dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "priceBox_upper # 0.39924293, 0.39920699, 0.39922767])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164c2af-b9e6-4828-afc0-de3d57c9d8c0",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804f2fd-5a59-4edb-ab12-0283a44d1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priceBox(df,\n",
    "                 indicator,\n",
    "                 priceBox_value,\n",
    "                 interval):\n",
    "    \n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        remove spread_arr.\n",
    "        add side_open BUY.\n",
    "    \n",
    "    last confirmed at, 20240621 1729.\n",
    "    \"\"\"\n",
    "\n",
    "    if indicator == 'DC':    \n",
    "        df = get_DC(df, \n",
    "                     priceBox_value, \n",
    "                     interval=interval) #.tail()    \n",
    "        # df = get_DC_perentage(df, priceBox_value, interval=interval) #.tail()\n",
    "    \n",
    "        \n",
    "        priceBox_upper = df['DC_{}{}_upper'.format(interval, priceBox_value)].to_numpy()\n",
    "        priceBox_lower = df['DC_{}{}_lower'.format(interval, priceBox_value)].to_numpy()\n",
    "        close = df.close.to_numpy()\n",
    "\n",
    "    \n",
    "    elif indicator == 'BB':        \n",
    "        # df = get_BB(df, point_value, 1, interval, level=2) # temporary, cause using point_indiator 'BB'.\n",
    "        \n",
    "        BB_upper = df['BB_{}{}_upper'.format(interval, point_value)].to_numpy() \n",
    "        BB_lower = df['BB_{}{}_lower'.format(interval, point_value)].to_numpy()\n",
    "\n",
    "    return priceBox_upper, priceBox_lower, close\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5ecf8-64a7-453e-bfc4-15750b197e5f",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec19ae-22a0-4543-a46f-123028bf67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_upper = bank.df_res['DC_{}{}_upper'.format(interval, period_DC)].to_numpy()\n",
    "DC_lower = bank.df_res['DC_{}{}_lower'.format(interval, period_DC)].to_numpy()\n",
    "close = bank.df_res.close.to_numpy()    \n",
    "\n",
    "\n",
    "if bank.side_open == 'SELL':    \n",
    "    price_take_profit_arr = DC_lower[point_index_short]\n",
    "    price_entry_arr = close[point_index_short]\n",
    "    price_stop_loss_arr = DC_upper[point_index_short]\n",
    "    \n",
    "    # spread_arr = abs(price_take_profit_arr - price_stop_loss_arr)\n",
    "    spread_arr = abs(price_entry_arr - price_stop_loss_arr)\n",
    "    \n",
    "    # bank.price_take_profit = DC_lower[point_index_short][index_number]\n",
    "    # bank.price_entry = close[point_index_short][index_number]\n",
    "    # bank.price_stop_loss = DC_upper[point_index_short][index_number]\n",
    "\n",
    "print(price_take_profit_arr)\n",
    "print(price_entry_arr)\n",
    "print(price_stop_loss_arr)\n",
    "print(spread_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a5598-58de-4b8a-b07d-fa4cb0fa250f",
   "metadata": {},
   "source": [
    "## get_price_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db1892-3cdd-4232-8dce-b9c3ddee00ba",
   "metadata": {},
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0f768-814f-4af4-a193-5d0ccfb078f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_arr(side_open, \n",
    "                 box_upper, \n",
    "                 box_lower,\n",
    "                 close,\n",
    "                 point_index_short,\n",
    "                 point_index_long):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add price_validation\n",
    "\n",
    "    last confirmed at, 20240627 2032.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if side_open == 'SELL':    \n",
    "        price_take_profit_arr = box_lower[point_index_short]\n",
    "        price_entry_arr = close[point_index_short]\n",
    "        price_stop_loss_arr = box_upper[point_index_short]\n",
    "        \n",
    "        index_valid_bool = (price_take_profit_arr < price_entry_arr) & (price_entry_arr < price_stop_loss_arr)        \n",
    "    else:\n",
    "        price_take_profit_arr = box_upper[point_index_long]\n",
    "        price_entry_arr = close[point_index_long]\n",
    "        price_stop_loss_arr = box_lower[point_index_long]     \n",
    "\n",
    "        index_valid_bool = (price_take_profit_arr > price_entry_arr) & (price_entry_arr > price_stop_loss_arr)\n",
    "\n",
    "    \n",
    "    return price_take_profit_arr, price_entry_arr, price_stop_loss_arr, index_valid_bool\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43898ff1-3bec-4ee3-9ebd-3e28db408b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_take_profit_arr, \\\n",
    "price_entry_arr, \\\n",
    "price_stop_loss_arr, \\\n",
    "index_valid_bool = get_price_arr(bank.side_open, \n",
    "                             priceBox_upper, \n",
    "                             priceBox_lower,\n",
    "                             close,\n",
    "                             point_index_short,\n",
    "                             point_index_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f35490-c2c8-4259-be57-863a1ed0b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank.side_open)\n",
    "print(price_take_profit_arr)\n",
    "print(price_entry_arr)\n",
    "print(price_stop_loss_arr)\n",
    "print(index_valid_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18951ed8-25cd-401b-9f4a-e6a48bbb79bb",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a406aa3-a26f-4c39-9c70-eacd83f03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_arr(side_open, \n",
    "                 box_upper, \n",
    "                 box_lower,\n",
    "                 close,\n",
    "                 point_index_short,\n",
    "                 point_index_long):\n",
    "    \n",
    "    \n",
    "    if side_open == 'SELL':    \n",
    "        price_take_profit_arr = box_lower[point_index_short]\n",
    "        price_entry_arr = close[point_index_short]\n",
    "        price_stop_loss_arr = box_upper[point_index_short]\n",
    "    else:\n",
    "        price_take_profit_arr = box_upper[point_index_long]\n",
    "        price_entry_arr = close[point_index_long]\n",
    "        price_stop_loss_arr = box_lower[point_index_long]     \n",
    "\n",
    "    return price_take_profit_arr, price_entry_arr, price_stop_loss_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a4d69-2158-4aaa-b6de-53f09b48a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_take_profit_arr, \\\n",
    "price_entry_arr, \\\n",
    "price_stop_loss_arr = get_price_arr(bank.side_open, \n",
    "                                     priceBox_upper, \n",
    "                                     priceBox_lower,\n",
    "                                     close,\n",
    "                                     point_index_short,\n",
    "                                     point_index_long)\n",
    "\n",
    "print(bank.side_open)\n",
    "print(price_take_profit_arr)\n",
    "print(price_entry_arr)\n",
    "print(price_stop_loss_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a0189-2d5c-4e58-8b01-1991701acd26",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975be6b-dc4d-4d79-850e-9215701e7891",
   "metadata": {},
   "source": [
    "### get data (as numpy arr.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550881d-311e-4dfe-83bc-f8a433717b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_col_ohlc = ['open', 'high', 'low', 'close']\n",
    "\n",
    "# outer_col_stepline = ['iiSource']\n",
    "# outer_col_stepline = ['CCI_15m20']\n",
    "\n",
    "\n",
    "data_price_ohlc = bank.df_res[price_col_ohlc].to_numpy()\n",
    "# data_price_stepline_point = bank.df_res[price_col_stepline_point].to_numpy()\n",
    "# data_outer_stepline = bank.df_res[outer_col_stepline].to_numpy()\n",
    "\n",
    "\n",
    "data_price_ohlc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c47d5b-5db8-4ae9-8f5a-3d67db63bc0c",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58d2a3-3ef2-4f08-8991-dc13fa306ea5",
   "metadata": {},
   "source": [
    "#### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f0615-eee2-400a-a2c8-2aae50445d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(30, 18), dpi=60)\n",
    "nrows, ncols = 2, 2\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                       ncols=ncols,\n",
    "                       height_ratios=[3, 1]\n",
    "                       )\n",
    "\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "candle_plot_v2(ax1, data_price_ohlc, alpha=1.0, wickwidth=1.0)\n",
    "\n",
    "step_col_plot_v2(ax1, priceBox_upper, linewidth=1)\n",
    "step_col_plot_v2(ax1, priceBox_lower, linewidth=1)\n",
    "\n",
    "# step_col_plot_v2(ax1, data_price_stepline_point, linewidth=1, color='magenta')\n",
    "\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[3])\n",
    "# step_col_plot_v2(ax2, data_outer_stepline, linewidth=1)\n",
    "ax2.axhline(0, color=\"#ffffff\")\n",
    "\n",
    "\n",
    "data_len = len(data_price_ohlc)\n",
    "ax1.set_xlim(0, data_len)\n",
    "ax2.set_xlim(0, data_len)\n",
    "\n",
    "\n",
    "[ax1.axvline(idx, linestyle='--', color='#2196f3') for idx in point_index_long]\n",
    "[ax2.axvline(idx, linestyle='--', color='#2196f3') for idx in point_index_long]\n",
    "\n",
    "[ax1.axvline(idx, linestyle='--', color='#ff0000') for idx in point_index_short]\n",
    "[ax2.axvline(idx, linestyle='--', color='#ff0000') for idx in point_index_short]\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c41f0e-c2a5-4f44-bc23-de0aa20a4e29",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07528481-db35-43eb-9d03-5df0a1646d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_col_ohlc = ['open', 'high', 'low', 'close']\n",
    "\n",
    "# outer_col_stepline = ['iiSource']\n",
    "outer_col_stepline = ['CCI_15m20']\n",
    "\n",
    "# price_col_stepline_priceBox = ['DC_{}{}_upper'.format(interval, priceBox_value), 'DC_{}{}_lower'.format(interval, priceBox_value), 'DC_{}{}_base'.format(interval, priceBox_value)]\n",
    "# price_col_stepline_point = ['DC_{}{}_upper'.format(interval, point_value), 'DC_{}{}_lower'.format(interval, point_value), 'DC_{}{}_base'.format(interval, point_value)]\n",
    "\n",
    "\n",
    "data_price_ohlc = bank.df_res[price_col_ohlc].to_numpy()\n",
    "# data_price_stepline_priceBox = bank.df_res[price_col_stepline_priceBox].to_numpy()\n",
    "# data_price_stepline_point = bank.df_res[price_col_stepline_point].to_numpy()\n",
    "data_outer_stepline = bank.df_res[outer_col_stepline].to_numpy()\n",
    "\n",
    "data_len = len(data_price_ohlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1bd32-4aac-4b27-82dc-6767b8c0d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(30, 18), dpi=60)\n",
    "nrows, ncols = 2, 2\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                       ncols=ncols,\n",
    "                       height_ratios=[3, 1]\n",
    "                       )\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "candle_plot_v2(ax1, data_price_ohlc, alpha=1.0, wickwidth=1.0)\n",
    "step_col_plot_v2(ax1, priceBox_upper, linewidth=1)\n",
    "step_col_plot_v2(ax1, priceBox_lower, linewidth=1)\n",
    "# step_col_plot_v2(ax1, data_price_stepline_priceBox, linewidth=1)\n",
    "# step_col_plot_v2(ax1, data_price_stepline_point, linewidth=1, color='magenta')\n",
    "\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(gs[3])\n",
    "step_col_plot_v2(ax2, data_outer_stepline, linewidth=1)\n",
    "ax2.axhline(0, color=\"#ffffff\")\n",
    "\n",
    "ax1.set_xlim(0, data_len)\n",
    "ax2.set_xlim(0, data_len)\n",
    "\n",
    "# [ax1.axvline(idx, linestyle='--', color='#2196f3') for idx in np.argwhere(cross_over).ravel()]\n",
    "# [ax2.axvline(idx, linestyle='--', color='#2196f3') for idx in np.argwhere(cross_over).ravel()]\n",
    "\n",
    "# [ax1.axvline(idx, linestyle='--', color='#ff0000') for idx in np.argwhere(cross_under).ravel()]\n",
    "# [ax2.axvline(idx, linestyle='--', color='#ff0000') for idx in np.argwhere(cross_under).ravel()]\n",
    "[ax1.axvline(idx, linestyle='--', color='#2196f3') for idx in point_index_long]\n",
    "[ax2.axvline(idx, linestyle='--', color='#2196f3') for idx in point_index_long]\n",
    "\n",
    "[ax1.axvline(idx, linestyle='--', color='#ff0000') for idx in point_index_short]\n",
    "[ax2.axvline(idx, linestyle='--', color='#ff0000') for idx in point_index_short]\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3c59b-fc96-4483-90fd-cb895dc51d39",
   "metadata": {},
   "source": [
    "### loop (table_trade_result adj.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196202c-275f-4b7b-a920-d7fbdfdab762",
   "metadata": {},
   "source": [
    "#### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e9953-4aab-4a22-a21c-3ddee38dd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164622db-bc48-459e-b578-125d8908fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for status, idx_entry, idx_exit in table_trade_result[['status', 'idx_entry', 'idx_exit']].to_numpy():\n",
    "\n",
    "\n",
    "    index_plot_start = idx_entry - 2 # entry start from the next_bar of point.\n",
    "    # index_plot_start = idx_entry - 1\n",
    "    index_plot_end = idx_exit + 1\n",
    "    \n",
    "        \n",
    "    data_len = len(data_price_ohlc[index_plot_start:index_plot_end])     \n",
    "\n",
    "    \n",
    "    plt.style.use(['dark_background', 'fast'])\n",
    "    fig = plt.figure(figsize=(30, 18), dpi=60)\n",
    "    nrows, ncols = 2, 2\n",
    "    gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                           ncols=ncols,\n",
    "                           height_ratios=[3, 1]\n",
    "                           )\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[1])\n",
    "    candle_plot_v2(ax1, data_price_ohlc[index_plot_start:index_plot_end], alpha=1.0, wickwidth=1.0)\n",
    "    \n",
    "    step_col_plot_v2(ax1, priceBox_upper[index_plot_start:index_plot_end], linewidth=1)\n",
    "    step_col_plot_v2(ax1, priceBox_lower[index_plot_start:index_plot_end], linewidth=1)\n",
    "    \n",
    "    plt.title(status)\n",
    "\n",
    "\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[3])\n",
    "    # step_col_plot_v2(ax2, data_outer_stepline, linewidth=1)\n",
    "    ax2.axhline(0, color=\"#ffffff\")   \n",
    "    \n",
    "\n",
    "    \n",
    "    ax1.set_xlim(0, data_len)\n",
    "    ax2.set_xlim(0, data_len)\n",
    "    \n",
    "    plt.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe1c60-3d53-4f1d-897b-445c6bf101b0",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6d7e5-9a05-4f88-84a9-359cfd5e148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_entry, idx_exit in table_trade_result[['idx_entry', 'idx_exit']].to_numpy():\n",
    "\n",
    "    price_col_ohlc = ['open', 'high', 'low', 'close']\n",
    "    # price_col_stepline = ['DC_{}{}_upper'.format(interval, period_DC), 'DC_{}{}_lower'.format(interval, period_DC), 'DC_{}{}_base'.format(interval, period_DC)]\n",
    "    # outer_col_stepline = ['iiSource']\n",
    "\n",
    "    index_plot_start = idx_entry - 2 # entry start from the next_bar of point.\n",
    "    # index_plot_start = idx_entry - 1\n",
    "    index_plot_end = idx_exit + 1\n",
    "    # data_price_ohlc = bank.df_res[price_col_ohlc].to_numpy()[index_plot_start:index_plot_end]\n",
    "    # data_price_stepline = bank.df_res[price_col_stepline].to_numpy()[index_plot_start:index_plot_end]\n",
    "    # # data_outer_stepline = bank.df_res[outer_col_stepline].to_numpy()[index_plot_start:index_plot_end]\n",
    "        \n",
    "    # data_len = len(data_price_ohlc)    \n",
    "    # data_price_ohlc.shape\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.style.use(['dark_background', 'fast'])\n",
    "    fig = plt.figure(figsize=(30, 18), dpi=60)\n",
    "    nrows, ncols = 2, 2\n",
    "    gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                           ncols=ncols,\n",
    "                           height_ratios=[3, 1]\n",
    "                           )\n",
    "    \n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[1])\n",
    "    candle_plot_v2(ax1, data_price_ohlc, alpha=1.0, wickwidth=1.0)\n",
    "    \n",
    "    # step_col_plot_v2(ax1, data_price_stepline, linewidth=1)    \n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[3])\n",
    "    # step_col_plot_v2(ax2, data_outer_stepline, linewidth=1)\n",
    "    ax2.axhline(0, color=\"#ffffff\")   \n",
    "    \n",
    "    \n",
    "    ax1.set_xlim(0, data_len)\n",
    "    ax2.set_xlim(0, data_len)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e67cc7-80d1-4e4b-8a3c-f88e496d77b0",
   "metadata": {},
   "source": [
    "## get trade_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536b8a6-83a5-4dbf-a102-a746a3fc30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_table_trade_result(bank, point_index_short, point_index_long, priceBox_indicator, priceBox_value, interval):\n",
    "   \n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add spread_arr\n",
    "    v1.2\n",
    "        remove quantity info from table.\n",
    "        reject status=DataEnd\n",
    "        add symbol for winRatio calibration.\n",
    "        add timestamp for amount agg. check.\n",
    "    v1.3\n",
    "        add timestamp column and timestamp_entry & exit derives from it.\n",
    "    v1.4\n",
    "        add LONG position.\n",
    "            LONG SHORT one table.\n",
    "        apply functional mode.\n",
    "        \n",
    "        v1.4.1\n",
    "            remove fee.        \n",
    "        v1.4.2\n",
    "            add get_priceBox (v2.1)\n",
    "            modify logical miss for TP / SL in LONG.\n",
    "            modify zip to list(zip) for price_validation.\n",
    "\n",
    "        this funciton only allow 'bank', modify it...\n",
    "    \n",
    "    last confirmed at, 20240708 1053.\n",
    "    \"\"\"\n",
    "\n",
    "    data_len = len(bank.df_res)\n",
    "    high = bank.df_res.high.to_numpy()\n",
    "    low = bank.df_res.low.to_numpy()\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for side_open in ['BUY', 'SELL']:  # Iterate through both 'SELL' and 'BUY' sides\n",
    "\n",
    "        if side_open == 'SELL':\n",
    "            point_index = point_index_short\n",
    "        else:\n",
    "            point_index = point_index_long\n",
    "\n",
    "        priceBox_upper, priceBox_lower, close = get_priceBox(bank.df_res,\n",
    "                                                             priceBox_indicator,\n",
    "                                                             priceBox_value,\n",
    "                                                             interval,\n",
    "                                                             side_open)\n",
    "\n",
    "        price_take_profit_arr, price_entry_arr, price_stop_loss_arr, index_valid_bool = get_price_arr(side_open,\n",
    "                                                                                                     priceBox_upper,\n",
    "                                                                                                     priceBox_lower,\n",
    "                                                                                                     close,\n",
    "                                                                                                     point_index_short,\n",
    "                                                                                                     point_index_long)\n",
    "\n",
    "        trade_arr_valid = np.array(list(zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr)), \n",
    "                                   dtype=[('0', int), ('1', float), ('2', float), ('3', float)])[index_valid_bool]\n",
    "\n",
    "        for idx_entry, price_take_profit, price_entry, price_stop_loss in trade_arr_valid:\n",
    "            status = None\n",
    "            idx_realtime = idx_entry + 1\n",
    "\n",
    "            while True:\n",
    "                if idx_realtime >= data_len:\n",
    "                    status = 'DataEnd'\n",
    "                    break\n",
    "\n",
    "                if side_open == 'SELL':\n",
    "                    if low[idx_realtime] < price_take_profit:\n",
    "                        status = 'TP'\n",
    "                        break\n",
    "                    elif high[idx_realtime] >= price_stop_loss:\n",
    "                        status = 'SL'\n",
    "                        break\n",
    "                else:\n",
    "                    if high[idx_realtime] > price_take_profit:\n",
    "                        status = 'TP'\n",
    "                        break\n",
    "                    elif low[idx_realtime] <= price_stop_loss:\n",
    "                        status = 'SL'\n",
    "                        break\n",
    "\n",
    "                idx_realtime += 1\n",
    "     \n",
    "            if status in ['TP', 'SL']:\n",
    "                position = 'SHORT' if side_open == 'SELL' else 'LONG'\n",
    "                price_exit = price_take_profit if status == 'TP' else price_stop_loss\n",
    "                \n",
    "                row = [bank.symbol, position, status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, price_exit]\n",
    "                \n",
    "                data_list.append(row)\n",
    "\n",
    "    columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit']\n",
    "    table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "    timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "    table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "    table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "\n",
    "    return table_trade_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23a874-a8de-4d2c-b099-d2e137f5867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result = get_trade_result_table(bank, point_index_short, point_index_long, priceBox_indicator, priceBox_value, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa8c25-8fd1-49e0-b443-29b72089350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(table_trade_result != table_trade_result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6bb9f-16ee-4e4a-94f7-385a03ebc010",
   "metadata": {},
   "source": [
    "### v1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961e8d5-0946-44bf-b5cb-942f3835611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "v1.2\n",
    "    remove quantity info from table.\n",
    "    reject status=DataEnd\n",
    "    add symbol for winRatio calibration.\n",
    "    add timestamp for amount agg. check.\n",
    "v1.3\n",
    "    add timestamp column and timestamp_entry & exit derives from it.\n",
    "v1.4\n",
    "    add LONG position.\n",
    "        LONG SHORT one table.\n",
    "    apply functional mode.\n",
    "    \n",
    "    v1.4.1\n",
    "        remove fee.        \n",
    "    v1.4.2\n",
    "        add get_priceBox (v2.1)\n",
    "        modify logical miss for TP / SL in LONG.\n",
    "        modify zip to list(zip) for price_validation.\n",
    "\n",
    "last confirmed at, 20240627 2032.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()    \n",
    "\n",
    "\n",
    "data_list = [] \n",
    "for bank.side_open in ['BUY', 'SELL']:\n",
    "# for bank.side_open in ['BUY']:\n",
    "# for bank.side_open in ['SELL']:\n",
    "# for bank.side_open in [bank.side_open]:    \n",
    "    \n",
    "    \n",
    "    if bank.side_open == 'SELL':\n",
    "        point_index = point_index_short\n",
    "    else:\n",
    "        point_index = point_index_long\n",
    "\n",
    "    \n",
    "    priceBox_upper, \\\n",
    "    priceBox_lower, \\\n",
    "    close = get_priceBox(bank.df_res,\n",
    "                             priceBox_indicator,\n",
    "                             priceBox_value,\n",
    "                             interval,\n",
    "                             bank.side_open)\n",
    "\n",
    "    \n",
    "    # price_arr use priceBox differed by side_open.\n",
    "    price_take_profit_arr, \\\n",
    "    price_entry_arr, \\\n",
    "    price_stop_loss_arr, \\\n",
    "    index_valid_bool = get_price_arr(bank.side_open, \n",
    "                                 priceBox_upper, \n",
    "                                 priceBox_lower,\n",
    "                                 close,\n",
    "                                 point_index_short,\n",
    "                                 point_index_long)\n",
    "\n",
    "    \n",
    "    trade_arr_valid = np.array(list(zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr)), dtype=[('0', int), ('1', float), ('2', float), ('3', float)])[index_valid_bool]\n",
    "        \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in trade_arr_valid:\n",
    "    \n",
    "        # init.\n",
    "        status = None\n",
    "        status_entry = 0\n",
    "        \n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)\n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "    \n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "\n",
    "            #     # check entry execution.\n",
    "            # if bank.side_open == 'SELL':  \n",
    "            #     if high[idx_realtime] > price_entry: # (very conservative use '>')\n",
    "            #         status_entry = 1\n",
    "            # else:\n",
    "            #     if low[idx_realtime] < price_entry: # (very conservative use '<')\n",
    "            #         status_entry = 1\n",
    "    \n",
    "            \n",
    "            if bank.side_open == 'SELL':  \n",
    "                # check take_profit (conservative use '<')            \n",
    "                if low[idx_realtime] < price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '>=')    \n",
    "                elif high[idx_realtime] >= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "            else:\n",
    "                # check take_profit (conservative use '>')            \n",
    "                if high[idx_realtime] > price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '<=')    \n",
    "                elif low[idx_realtime] <= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "    \n",
    "            idx_realtime += 1\n",
    "    \n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "            if status in ['TP', 'SL']:            \n",
    "                if bank.side_open == 'SELL': \n",
    "                    row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]\n",
    "                else:\n",
    "                    row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]                \n",
    "                data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss']\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "\n",
    "timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "\n",
    "\n",
    "columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit'] \n",
    "table_trade_result = table_trade_result[columns_new] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff4731-5180-4734-b691-a0cbf8f755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b2fe1-1967-44dd-b65c-68a8b9f26f19",
   "metadata": {},
   "source": [
    "### v1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe48c5-2287-45fd-b0bd-7be8e5670968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "v1.2\n",
    "    remove quantity info from table.\n",
    "    reject status=DataEnd\n",
    "    add symbol for winRatio calibration.\n",
    "    add timestamp for amount agg. check.\n",
    "v1.3\n",
    "    add timestamp column and timestamp_entry & exit derives from it.\n",
    "v1.4\n",
    "    add LONG position.\n",
    "        LONG SHORT one table.\n",
    "    apply functional mode.\n",
    "v1.4.1\n",
    "    remove fee.\n",
    "\n",
    "last confirmed at, 20240621 1732.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()    \n",
    "\n",
    "\n",
    "data_list = [] \n",
    "# for bank.side_open in ['BUY', 'SELL']:\n",
    "for bank.side_open in ['BUY']:\n",
    "# for bank.side_open in [bank.side_open]:    \n",
    "    \n",
    "    \n",
    "    if bank.side_open == 'SELL':\n",
    "        point_index = point_index_short\n",
    "    else:\n",
    "        point_index = point_index_long\n",
    "        \n",
    "        \n",
    "    price_take_profit_arr, \\\n",
    "    price_entry_arr, \\\n",
    "    price_stop_loss_arr = get_price_arr(bank.side_open, \n",
    "                                 priceBox_upper, \n",
    "                                 priceBox_lower,\n",
    "                                 close,\n",
    "                                 point_index_short,\n",
    "                                 point_index_long)\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "    \n",
    "        # init.\n",
    "        status = None\n",
    "        \n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "    \n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "    \n",
    "            \n",
    "            if bank.side_open == 'SELL':  \n",
    "                # check take_profit (conservative use '<')            \n",
    "                if low[idx_realtime] < price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '>=')    \n",
    "                elif high[idx_realtime] >= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "            else:\n",
    "                # check take_profit (conservative use '>')            \n",
    "                if low[idx_realtime] > price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '<=')    \n",
    "                elif high[idx_realtime] <= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "    \n",
    "            idx_realtime += 1\n",
    "    \n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "            if status in ['TP', 'SL']:            \n",
    "                if bank.side_open == 'SELL': \n",
    "                    row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]\n",
    "                else:\n",
    "                    row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss]                \n",
    "                data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss']\n",
    "columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit'] \n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "\n",
    "timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "\n",
    "table_trade_result = table_trade_result[columns_new] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d5f86-6539-4fc1-be79-7205c84ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc4288c-d58f-4aa4-9d7b-120d268560d7",
   "metadata": {},
   "source": [
    "### v1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa48dd8-13ac-40f3-b76b-9448ab4f1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "v1.2\n",
    "    remove quantity info from table.\n",
    "    reject status=DataEnd\n",
    "    add symbol for winRatio calibration.\n",
    "    add timestamp for amount agg. check.\n",
    "v1.3\n",
    "    add timestamp column and timestamp_entry & exit derives from it.\n",
    "v1.4\n",
    "    add LONG position.\n",
    "        LONG SHORT one table.\n",
    "    apply functional mode.\n",
    "\n",
    "last confirmed at, 20240618 1416.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()    \n",
    "\n",
    "\n",
    "data_list = [] \n",
    "for bank.side_open in ['BUY', 'SELL']:\n",
    "# for bank.side_open in [bank.side_open]:\n",
    "\n",
    "    # bank.side_open = 'BUY'    \n",
    "    \n",
    "    if bank.side_open == 'SELL':\n",
    "        point_index = point_index_short\n",
    "    else:\n",
    "        point_index = point_index_long\n",
    "        \n",
    "    price_take_profit_arr, \\\n",
    "    price_entry_arr, \\\n",
    "    price_stop_loss_arr = get_price_arr(bank.side_open, \n",
    "                                 priceBox_upper, \n",
    "                                 priceBox_lower,\n",
    "                                 close,\n",
    "                                 point_index_short,\n",
    "                                 point_index_long)\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "    \n",
    "        # init.\n",
    "        status = None\n",
    "        # amount = 500 # temporary static (USDT)\n",
    "        # amount = 50 / spread # temporary static (USDT)\n",
    "        # quantity = 100 # temporary static   \n",
    "        # leverage = 1 # temporary static        \n",
    "        fee_entry = 0.0005 # temporary static\n",
    "        fee_exit = 0.0005 # temporary static\n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "    \n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "    \n",
    "            \n",
    "            if bank.side_open == 'SELL':  \n",
    "                # check take_profit (conservative use '<')            \n",
    "                if low[idx_realtime] < price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '>=')    \n",
    "                elif high[idx_realtime] >= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "            else:\n",
    "                # check take_profit (conservative use '>')            \n",
    "                if low[idx_realtime] > price_take_profit:\n",
    "                    status = 'TP'\n",
    "                    break\n",
    "                    \n",
    "                    # check stop_loss (conservative use '<=')    \n",
    "                elif high[idx_realtime] <= price_stop_loss:\n",
    "                    status = 'SL'\n",
    "                    break\n",
    "    \n",
    "            idx_realtime += 1\n",
    "    \n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "            if status in ['TP', 'SL']:            \n",
    "                if bank.side_open == 'SELL': \n",
    "                    row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]\n",
    "                else:\n",
    "                    row = [bank.symbol, 'LONG', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]                \n",
    "                data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'fee_entry', 'fee_exit']\n",
    "columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit', 'fee_entry', 'fee_exit'] \n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "\n",
    "timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "\n",
    "table_trade_result = table_trade_result[columns_new] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8a667-36df-44a4-893e-110a40a5e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_trade_result.position.head())#.describe()\n",
    "print(table_trade_result.position.tail())#.describe()\n",
    "# table_trade_result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9aeab9-1ed0-4c6d-9437-bda335b88a97",
   "metadata": {},
   "source": [
    "### v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141989ad-139f-484c-9157-885883391cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "v1.2\n",
    "    remove quantity info from table.\n",
    "    reject status=DataEnd\n",
    "    add symbol for winRatio calibration.\n",
    "    add timestamp for amount agg. check.\n",
    "v1.3\n",
    "    add timestamp column and timestamp_entry & exit derives from it.\n",
    "\n",
    "last confirmed at, 20240606 0144.\n",
    "\"\"\"\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()    \n",
    "\n",
    "if bank.side_open == 'SELL':  \n",
    "\n",
    "    data_list = [] \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index_short, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "\n",
    "        # init.\n",
    "        status = None\n",
    "        # amount = 500 # temporary static (USDT)\n",
    "        # amount = 50 / spread # temporary static (USDT)\n",
    "        # quantity = 100 # temporary static   \n",
    "        # leverage = 1 # temporary static        \n",
    "        fee_entry = 0.0005 # temporary static\n",
    "        fee_exit = 0.0005 # temporary static\n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "\n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "                \n",
    "                # check take_profit (conservative use '<')            \n",
    "            if low[idx_realtime] < price_take_profit:\n",
    "                status = 'TP'\n",
    "                break\n",
    "                \n",
    "                # check stop_loss (conservative use '>=')    \n",
    "            elif high[idx_realtime] >= price_stop_loss:\n",
    "                status = 'SL'\n",
    "                break\n",
    "\n",
    "            idx_realtime += 1\n",
    "\n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "            if status in ['TP', 'SL']:\n",
    "                \n",
    "                row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]\n",
    "                data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'fee_entry', 'fee_exit']\n",
    "columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit', 'fee_entry', 'fee_exit'] \n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "\n",
    "timestamp = bank.df_res['timestamp'].to_numpy()\n",
    "table_trade_result['timestamp_entry'] = timestamp[table_trade_result.idx_entry]\n",
    "table_trade_result['timestamp_exit'] = timestamp[table_trade_result.idx_exit]\n",
    "\n",
    "table_trade_result = table_trade_result[columns_new] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb83f4f-4aed-4157-8fc6-e257015b5308",
   "metadata": {},
   "source": [
    "### v1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de386d8-ef4f-4d00-af4a-155fb7c59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "v1.2\n",
    "    remove quantity info from table.\n",
    "    reject status=DataEnd\n",
    "    add symbol for winRatio calibration.\n",
    "    add timestamp for amount agg. check.\n",
    "\n",
    "last confirmed at, 20240605 1445.\n",
    "\"\"\"\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()    \n",
    "\n",
    "if bank.side_open == 'SELL':  \n",
    "\n",
    "    data_list = [] \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index_short, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "\n",
    "        # init.\n",
    "        status = None\n",
    "        # amount = 500 # temporary static (USDT)\n",
    "        # amount = 50 / spread # temporary static (USDT)\n",
    "        # quantity = 100 # temporary static   \n",
    "        # leverage = 1 # temporary static        \n",
    "        fee_entry = 0.0005 # temporary static\n",
    "        fee_exit = 0.0005 # temporary static\n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "\n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "                \n",
    "                # check take_profit (conservative use '<')            \n",
    "            if low[idx_realtime] < price_take_profit:\n",
    "                status = 'TP'\n",
    "                break\n",
    "                \n",
    "                # check stop_loss (conservative use '>=')    \n",
    "            elif high[idx_realtime] >= price_stop_loss:\n",
    "                status = 'SL'\n",
    "                break\n",
    "\n",
    "            idx_realtime += 1\n",
    "\n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "            if status in ['TP', 'SL']:\n",
    "                \n",
    "                row = [bank.symbol, 'SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, fee_entry, fee_exit]\n",
    "                data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['symbol', 'position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'fee_entry', 'fee_exit']\n",
    "columns_new = ['symbol', 'position', 'status', 'timestamp_entry', 'timestamp_exit', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'price_exit', 'fee_entry', 'fee_exit'] \n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "table_trade_result['timestamp_entry'] = bank.df_res.index[table_trade_result.idx_entry]\n",
    "table_trade_result['timestamp_entry'] = table_trade_result['timestamp_entry'].apply(lambda x : int(datetime.timestamp(x)))\n",
    "table_trade_result['timestamp_exit'] = bank.df_res.index[table_trade_result.idx_exit]\n",
    "table_trade_result['timestamp_exit'] = table_trade_result['timestamp_exit'].apply(lambda x : int(datetime.timestamp(x)))\n",
    "\n",
    "table_trade_result = table_trade_result[columns_new] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc3698-1ec0-4ece-b95c-937e9fd69ab2",
   "metadata": {},
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e7b0f-20b2-48d5-9750-29eb2ac54578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    add spread_arr\n",
    "\n",
    "last confirmed at, 20240601 2237.\n",
    "\"\"\"\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()\n",
    "\n",
    "# param.\n",
    "# amount_dynamic = 1\n",
    "# spread = 0.1\n",
    "\n",
    "quantity_static = 1\n",
    "\n",
    "\n",
    "if bank.side_open == 'SELL':  \n",
    "\n",
    "    data_list = [] \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss, spread in zip(point_index_short, price_take_profit_arr, price_entry_arr, price_stop_loss_arr, spread_arr):\n",
    "\n",
    "        # init.\n",
    "        status = None\n",
    "        # amount = 500 # temporary static (USDT)\n",
    "        amount = 50 / spread # temporary static (USDT)\n",
    "        quantity = 1 # temporary static   \n",
    "        leverage = 1 # temporary static        \n",
    "        fee_entry = 0.0005 # temporary static\n",
    "        fee_exit = 0.0005 # temporary static\n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "\n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "                \n",
    "                # check take_profit (conservative use '<')            \n",
    "            if low[idx_realtime] < price_take_profit:\n",
    "                status = 'TP'\n",
    "                break\n",
    "                \n",
    "                # check stop_loss (conservative use '>=')    \n",
    "            elif high[idx_realtime] >= price_stop_loss:\n",
    "                status = 'SL'\n",
    "                break\n",
    "\n",
    "            idx_realtime += 1\n",
    "\n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "\n",
    "            # quantity : dynamic\n",
    "            if not quantity_static:\n",
    "                quantity = amount / price_entry\n",
    "            \n",
    "            row = ['SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, spread, amount, quantity, leverage, fee_entry, fee_exit]\n",
    "            data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'spread', 'amount', 'quantity', 'leverage', 'fee_entry', 'fee_exit']\n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "# table_trade_result['profit'] = np.nan\n",
    "# table_trade_result['fee'] = np.nan\n",
    "\n",
    "columns_new = ['position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss',  'price_exit', 'amount', 'quantity', 'leverage', 'fee_entry', 'fee_exit', 'spread', 'DC_percentage'] \n",
    "table_trade_result = table_trade_result[columns_new]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8eb4b5-a5cb-469a-a2b2-95072de18695",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79b543-b888-44fd-8909-cc2d951378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output\n",
    "    trade mode\n",
    "        duplication allow\n",
    "            on\n",
    "                = even if trade is not done on a symbol, allow another signal_open.\n",
    "            off        \n",
    "    \n",
    "    table\n",
    "        side_open\n",
    "        \n",
    "        index\n",
    "            open\n",
    "            entry\n",
    "                currently, = open\n",
    "            close\n",
    "        price\n",
    "            entry\n",
    "            exit\n",
    "                TP\n",
    "                SL    \n",
    "                \n",
    "        leverage\n",
    "        fee\n",
    "                currently, 0.001 (0.0005 * 2)\n",
    "                \n",
    "        profit\n",
    "            graph\n",
    "        winRatio\n",
    "        frequency\n",
    "\n",
    "method\n",
    "    check price touch\n",
    "        price_TP / SL\n",
    "\n",
    "input \n",
    "    data (ohlcv)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "data_len = len(bank.df_res)\n",
    "\n",
    "# use for check TP / SL\n",
    "high = bank.df_res.high.to_numpy()\n",
    "low = bank.df_res.low.to_numpy()\n",
    "\n",
    "# param.\n",
    "quantity_static = 1\n",
    "\n",
    "if bank.side_open == 'SELL':  \n",
    "\n",
    "    data_list = [] \n",
    "    \n",
    "    for idx_entry, price_take_profit, price_entry, price_stop_loss in zip(point_index_short, price_take_profit_arr, price_entry_arr, price_stop_loss_arr):\n",
    "\n",
    "        # init.\n",
    "        status = None\n",
    "        amount = 500 # temporary static (USDT)\n",
    "        quantity = 100 # temporary static   \n",
    "        leverage = 1 # temporary static        \n",
    "        fee_entry = 0.0005 # temporary static\n",
    "        fee_exit = 0.0005 # temporary static\n",
    "        \n",
    "        # trade stops when price reaches TP / SL\n",
    "            # start from the next bar. (current bar = signal_open)        \n",
    "        idx_realtime = idx_entry + 1\n",
    "        while 1:\n",
    "\n",
    "                # no more data. (primary cause + 1 above)\n",
    "            if idx_realtime >= data_len:\n",
    "                status = 'DataEnd'\n",
    "                break\n",
    "                \n",
    "                # check take_profit (conservative use '<')            \n",
    "            if low[idx_realtime] < price_take_profit:\n",
    "                status = 'TP'\n",
    "                break\n",
    "                \n",
    "                # check stop_loss (conservative use '>=')    \n",
    "            elif high[idx_realtime] >= price_stop_loss:\n",
    "                status = 'SL'\n",
    "                break\n",
    "\n",
    "            idx_realtime += 1\n",
    "\n",
    "        # if trade is done,\n",
    "            # add row to the table\n",
    "        if status is not None:\n",
    "\n",
    "            # quantity : dynamic\n",
    "            if not quantity_static:\n",
    "                quantity = amount / price_entry\n",
    "            \n",
    "            row = ['SHORT', status, idx_entry, idx_realtime, price_take_profit, price_entry, price_stop_loss, amount, quantity, leverage, fee_entry, fee_exit]\n",
    "            data_list.append(row)\n",
    "                \n",
    "        # bank.push_msg(bank, status)\n",
    "\n",
    "\n",
    "columns = ['position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss', 'amount', 'quantity', 'leverage', 'fee_entry', 'fee_exit']\n",
    "\n",
    "table_trade_result = pd.DataFrame(data_list, columns=columns)\n",
    "\n",
    "table_trade_result['price_exit'] = np.where(table_trade_result.status == 'TP', table_trade_result.price_take_profit, table_trade_result.price_stop_loss)\n",
    "table_trade_result['spread'] = abs(table_trade_result.price_take_profit - table_trade_result.price_stop_loss)\n",
    "table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "# table_trade_result['profit'] = np.nan\n",
    "# table_trade_result['fee'] = np.nan\n",
    "\n",
    "columns_new = ['position', 'status', 'idx_entry', 'idx_exit', 'price_take_profit', 'price_entry', 'price_stop_loss',  'price_exit', 'amount', 'quantity', 'leverage', 'fee_entry', 'fee_exit', 'spread', 'DC_percentage'] \n",
    "table_trade_result = table_trade_result[columns_new]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63401217-acbc-408b-a551-abb7acc6c62d",
   "metadata": {},
   "source": [
    "## get_leverage_limit_by_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbee6a-9522-4bb8-9221-075069ffde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leverage_limit_by_symbol(self, ):\n",
    "    \n",
    "    server_time = self.time()['serverTime']\n",
    "    data  = self.leverage_brackets(\n",
    "                         recvWindow=6000, \n",
    "                         timestamp=server_time)\n",
    "    \n",
    "    max_leverage = {}  # Dictionary to store max initialLeverage for each symbol    \n",
    "    \n",
    "    # Iterate over each symbol's data\n",
    "    for item in data:\n",
    "        symbol = item['symbol']\n",
    "        brackets = item['brackets']\n",
    "        \n",
    "        # Initialize max_leverage with the first bracket's initialLeverage\n",
    "        max_initial_leverage = brackets[0]['initialLeverage']\n",
    "        \n",
    "        # Iterate through brackets to find the maximum initialLeverage\n",
    "        for bracket in brackets:\n",
    "            if bracket['initialLeverage'] > max_initial_leverage:\n",
    "                max_initial_leverage = bracket['initialLeverage']\n",
    "        \n",
    "        # Store the max initialLeverage for the symbol\n",
    "        max_leverage[symbol] = max_initial_leverage\n",
    "    \n",
    "    return max_leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255bfd9-8dd0-4690-9a45-b230f2cd63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_limits = get_leverage_limit_by_symbol(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d2145-10a2-4172-b11e-4859ad64f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aac44b-1cf0-4590-b499-ec92748af88f",
   "metadata": {},
   "source": [
    "## set quantity (= get income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e5fe8-3c63-4f5c-97ab-d65b37c78d26",
   "metadata": {},
   "source": [
    "### v1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c063cb-7689-49bc-815e-4e61522790be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_quantity(table_trade_result,                  \n",
    "                 leverage_limits,\n",
    "                 target_loss, \n",
    "                 target_loss_pct, \n",
    "                 target_leverage=None, \n",
    "                 fee_entry=0.0002, \n",
    "                 fee_exit=0.0005,\n",
    "                 unit_RRratio_adj_fee=np.arange(0, 2, 0.1),\n",
    "                 leverage_rejection=False,\n",
    "                 ):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        define ~ to_numpy() as a var. for keep usage\n",
    "        add RRratio_adj_fee\n",
    "        modify income & commission to income & commission\n",
    "    v1.2\n",
    "        move RRratio to anal phase.\n",
    "        set target_loss.\n",
    "            income calculated from quantity.\n",
    "    v1.3\n",
    "        modify 'income' to support LONG & SHORT one table.\n",
    "        add loss_pct\n",
    "        add profit.\n",
    "    v1.4\n",
    "        rearrange with to_numpy()\n",
    "        \n",
    "        v1.4.1\n",
    "            \"fee will be placed in here.\"\n",
    "            apply leverage_limit_user = None.\n",
    "        v1.4.2\n",
    "            modify to functional.\n",
    "            adj. leverage_limit_user min = 1.\n",
    "            modify loss_pct (multiply 100)\n",
    "            modify leverage_limit_user logic.\n",
    "            modify concept of target_loss & target_loss_concept.\n",
    "            modify input params to fee_entry & fee_exit.\n",
    "            include RRratio by default.\n",
    "                considering leverage_rejection & functional.\n",
    "            add leverage_limit_server.\n",
    "        v1.4.3\n",
    "            add target_loss col.\n",
    "    \n",
    "    last confirmed at, 20240708 1256.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert relevant columns to numpy arrays for calculations\n",
    "    price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "    price_entry = table_trade_result.price_entry.to_numpy()\n",
    "    price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "    price_exit = table_trade_result.price_exit.to_numpy()\n",
    "    position = table_trade_result.position.to_numpy()\n",
    "\n",
    "    # Set fee values and include them in the DataFrame\n",
    "    table_trade_result['fee_entry'] = fee_entry\n",
    "    table_trade_result['fee_exit'] = fee_exit\n",
    "    fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "    fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "    # Calculate loss and loss percentage for quantity = 1\n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit)\n",
    "    loss_pct = loss / price_entry * 100\n",
    "    table_trade_result['loss'] = loss\n",
    "    table_trade_result['loss (%)'] = loss_pct\n",
    "\n",
    "    # Determine quantity\n",
    "    if target_loss is None:\n",
    "        amount_entry = 15  # default minimum amount\n",
    "        quantity = amount_entry / price_entry\n",
    "    else:\n",
    "        quantity = target_loss / loss\n",
    "\n",
    "    table_trade_result['target_loss'] = target_loss\n",
    "    table_trade_result['quantity'] = quantity\n",
    "\n",
    "    # Calculate entry and exit amounts\n",
    "    amount_entry = price_entry * quantity\n",
    "    amount_exit = price_exit * quantity\n",
    "\n",
    "    # Calculate commission and income\n",
    "    commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "    income = np.where(position == 'SHORT', amount_entry - amount_exit, amount_exit - amount_entry)\n",
    "\n",
    "    table_trade_result['commission'] = commission\n",
    "    table_trade_result['income'] = income\n",
    "    table_trade_result['income - commission'] = income - commission\n",
    "    table_trade_result['amount_entry'] = amount_entry\n",
    "\n",
    "    \n",
    "    leverage_limit_server = table_trade_result['symbol'].map(leverage_limits)\n",
    "    table_trade_result['leverage_limit_server'] = leverage_limit_server\n",
    "\n",
    "    # Calculate leverage limit and adjust leverage if needed\n",
    "    leverage_limit_user = np.maximum(1, np.floor(100 / loss_pct).astype(int))\n",
    "    table_trade_result['leverage_limit_user'] = leverage_limit_user\n",
    "\n",
    "    leverage_limit = np.minimum(leverage_limit_server, leverage_limit_user)\n",
    "\n",
    "    if target_loss_pct is None:\n",
    "        leverage = np.minimum(target_leverage, leverage_limit) if target_leverage else leverage_limit\n",
    "    else:\n",
    "        leverage = np.minimum(np.maximum(1, np.floor(target_loss_pct / loss_pct).astype(int)), leverage_limit)\n",
    "\n",
    "    table_trade_result['leverage'] = leverage\n",
    "    table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "\n",
    "    # Calculate profit and profit percentage\n",
    "    profit = (income - commission) / amount_entry * leverage\n",
    "    table_trade_result['profit'] = profit\n",
    "    table_trade_result['profit (%)'] = profit * 100\n",
    "    \n",
    "        \n",
    "    # zone (continuous value)\n",
    "        # default\n",
    "    table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "    table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "    table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "    \n",
    "    # Leverage rejection if needed\n",
    "    if leverage_rejection:\n",
    "        assert target_loss_pct is not None, \"target_loss_pct must be provided if leverage_rejection is True.\"\n",
    "        table_trade_result = table_trade_result[target_loss_pct > loss_pct]\n",
    "        \n",
    "    return table_trade_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1627e-0ee0-47ff-a1f5-da43017bc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 15 # USDT, for amount_entry.\n",
    "# target_loss = None\n",
    "\n",
    "target_loss_pct = 30 # %, for leverage.\n",
    "target_loss_pct = 100\n",
    "target_loss_pct = None\n",
    "\n",
    "target_leverage = 1\n",
    "target_leverage = 5\n",
    "target_leverage = None\n",
    "\n",
    "\n",
    "fee_limit = 0.0002\n",
    "fee_market = 0.0005\n",
    "\n",
    "leverage_rejection = True\n",
    "leverage_rejection = False\n",
    "\n",
    "\n",
    "table_trade_result_agg = set_quantity(table_trade_result_agg,       \n",
    "# table_trade_result = set_quantity(table_trade_result,         \n",
    "                                     leverage_limits,\n",
    "                                     target_loss, \n",
    "                                     target_loss_pct, \n",
    "                                     target_leverage, \n",
    "                                     fee_market, \n",
    "                                     fee_market,\n",
    "                                     np.arange(0, 2, 0.1),\n",
    "                                     leverage_rejection,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a1568-369b-4f02-ab5f-acc3b8e1eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg[table_trade_result_agg.status=='SL']\n",
    "# table_trade_result_agg[table_trade_result_agg.status=='TP']\n",
    "# table_trade_result_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5847b4b-ab87-42bc-a286-1fd685dc0488",
   "metadata": {},
   "source": [
    "### v1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e107e-7d74-4c39-8a80-3b2ca353da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_quantity(table_trade_result,                  \n",
    "                 leverage_limits,\n",
    "                 target_loss, \n",
    "                 target_loss_pct, \n",
    "                 target_leverage=None, \n",
    "                 fee_entry=0.0002, \n",
    "                 fee_exit=0.0005,\n",
    "                 unit_RRratio_adj_fee=np.arange(0, 2, 0.1),\n",
    "                 leverage_rejection=False,\n",
    "                 ):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        define ~ to_numpy() as a var. for keep usage\n",
    "        add RRratio_adj_fee\n",
    "        modify income & commission to income & commission\n",
    "    v1.2\n",
    "        move RRratio to anal phase.\n",
    "        set target_loss.\n",
    "            income calculated from quantity.\n",
    "    v1.3\n",
    "        modify 'income' to support LONG & SHORT one table.\n",
    "        add loss_pct\n",
    "        add profit.\n",
    "    v1.4\n",
    "        rearrange with to_numpy()\n",
    "        \n",
    "        v1.4.1\n",
    "            \"fee will be placed in here.\"\n",
    "            apply leverage_limit_user = None.\n",
    "        v1.4.2\n",
    "            modify to functional.\n",
    "            adj. leverage_limit_user min = 1.\n",
    "            modify loss_pct (multiply 100)\n",
    "            modify leverage_limit_user logic.\n",
    "            modify concept of target_loss & target_loss_concept.\n",
    "            modify input params to fee_entry & fee_exit.\n",
    "            include RRratio by default.\n",
    "                considering leverage_rejection & functional.\n",
    "            add leverage_limit_server.\n",
    "    \n",
    "    last confirmed at, 20240630 1939.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert relevant columns to numpy arrays for calculations\n",
    "    price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "    price_entry = table_trade_result.price_entry.to_numpy()\n",
    "    price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "    price_exit = table_trade_result.price_exit.to_numpy()\n",
    "    position = table_trade_result.position.to_numpy()\n",
    "\n",
    "    # Set fee values and include them in the DataFrame\n",
    "    table_trade_result['fee_entry'] = fee_entry\n",
    "    table_trade_result['fee_exit'] = fee_exit\n",
    "    fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "    fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "    # Calculate loss and loss percentage for quantity = 1\n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit)\n",
    "    loss_pct = loss / price_entry * 100\n",
    "    table_trade_result['loss'] = loss\n",
    "    table_trade_result['loss (%)'] = loss_pct\n",
    "\n",
    "    # Determine quantity\n",
    "    if target_loss is None:\n",
    "        amount_entry = 15  # default minimum amount\n",
    "        quantity = amount_entry / price_entry\n",
    "    else:\n",
    "        quantity = target_loss / loss\n",
    "\n",
    "    table_trade_result['quantity'] = quantity\n",
    "\n",
    "    # Calculate entry and exit amounts\n",
    "    amount_entry = price_entry * quantity\n",
    "    amount_exit = price_exit * quantity\n",
    "\n",
    "    # Calculate commission and income\n",
    "    commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "    income = np.where(position == 'SHORT', amount_entry - amount_exit, amount_exit - amount_entry)\n",
    "\n",
    "    table_trade_result['commission'] = commission\n",
    "    table_trade_result['income'] = income\n",
    "    table_trade_result['income - commission'] = income - commission\n",
    "    table_trade_result['amount_entry'] = amount_entry\n",
    "\n",
    "    \n",
    "    leverage_limit_server = table_trade_result['symbol'].map(leverage_limits)\n",
    "    table_trade_result['leverage_limit_server'] = leverage_limit_server\n",
    "\n",
    "    # Calculate leverage limit and adjust leverage if needed\n",
    "    leverage_limit_user = np.maximum(1, np.floor(100 / loss_pct).astype(int))\n",
    "    table_trade_result['leverage_limit_user'] = leverage_limit_user\n",
    "\n",
    "    leverage_limit = np.minimum(leverage_limit_server, leverage_limit_user)\n",
    "\n",
    "    if target_loss_pct is None:\n",
    "        leverage = np.minimum(target_leverage, leverage_limit) if target_leverage else leverage_limit\n",
    "    else:\n",
    "        leverage = np.minimum(np.maximum(1, np.floor(target_loss_pct / loss_pct).astype(int)), leverage_limit)\n",
    "\n",
    "    table_trade_result['leverage'] = leverage\n",
    "    table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "\n",
    "    # Calculate profit and profit percentage\n",
    "    profit = (income - commission) / amount_entry * leverage\n",
    "    table_trade_result['profit'] = profit\n",
    "    table_trade_result['profit (%)'] = profit * 100\n",
    "    \n",
    "        \n",
    "    # zone (continuous value)\n",
    "        # default\n",
    "    table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "    table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "    table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "    \n",
    "    # Leverage rejection if needed\n",
    "    if leverage_rejection:\n",
    "        assert target_loss_pct is not None, \"target_loss_pct must be provided if leverage_rejection is True.\"\n",
    "        table_trade_result = table_trade_result[target_loss_pct > loss_pct]\n",
    "        \n",
    "    return table_trade_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3448dd8-8d2f-4486-9bda-ec0153e12641",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 15 # USDT, for amount_entry.\n",
    "target_loss = None\n",
    "\n",
    "target_loss_pct = 30 # %, for leverage.\n",
    "target_loss_pct = 100\n",
    "target_loss_pct = None\n",
    "\n",
    "target_leverage = 1\n",
    "target_leverage = 5\n",
    "target_leverage = None\n",
    "\n",
    "\n",
    "fee_limit = 0.0002\n",
    "fee_market = 0.0005\n",
    "\n",
    "leverage_rejection = True\n",
    "leverage_rejection = False\n",
    "\n",
    "\n",
    "table_trade_result_agg = set_quantity(table_trade_result_agg,       \n",
    "# table_trade_result = set_quantity(table_trade_result,         \n",
    "                                     leverage_limits,\n",
    "                                     target_loss, \n",
    "                                     target_loss_pct, \n",
    "                                     target_leverage, \n",
    "                                     fee_market, \n",
    "                                     fee_market,\n",
    "                                     np.arange(0, 2, 0.1),\n",
    "                                     leverage_rejection,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709f30d-27fc-4e61-95c9-c3b17ad90ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg[table_trade_result_agg.status=='SL']\n",
    "# table_trade_result_agg[table_trade_result_agg.status=='TP']\n",
    "# table_trade_result_agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b55e6-7a2f-47ac-a1f2-d0a8210065fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_limits = get_leverage_limit_by_symbol(data)\n",
    "\n",
    "table_trade_result_agg['leverage_limit_server'] = table_trade_result_agg['symbol'].map(leverage_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630ce42-0b02-4fab-917a-37941867d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad935f-f4ab-46aa-81a5-53a4ce3a1c90",
   "metadata": {},
   "source": [
    "### v1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963d085-3a2f-4616-a81f-d71df81a4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    define ~ to_numpy() as a var. for keep usage\n",
    "    add RRratio_adj_fee\n",
    "    modify income & commission to income & commission\n",
    "v1.2\n",
    "    move RRratio to anal phase.\n",
    "    set target_loss.\n",
    "        income calculated from quantity.\n",
    "v1.3\n",
    "    modify 'income' to support LONG & SHORT one table.\n",
    "    add loss_pct\n",
    "    add profit.\n",
    "v1.4\n",
    "    rearrange with to_numpy()\n",
    "v1.4.1\n",
    "    \"fee will be placed in here.\"\n",
    "    apply leverage_limit = None.\n",
    "\n",
    "last confirmed at, 20240621 1750.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "fee_limit = 0.0002\n",
    "fee_market = 0.0005\n",
    "\n",
    "target_loss = 5 # USDT\n",
    "\n",
    "target_loss_pct = 0.1\n",
    "\n",
    "target_leverage = 1\n",
    "# target_leverage = 10\n",
    "\n",
    "\n",
    "\n",
    "price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "price_entry = table_trade_result.price_entry.to_numpy()\n",
    "price_exit = table_trade_result.price_exit.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "table_trade_result['fee_entry'] = fee_market\n",
    "table_trade_result['fee_exit'] = fee_market\n",
    "\n",
    "fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "loss_pct = loss / price_entry # this is official pct for SHORT. price_entry is an initial_price in SHORT position too.\n",
    "# loss_pct = np.where(table_trade_result.position.to_numpy() == 'SHORT', loss / price_stop_loss, loss / price_entry)\n",
    "quantity = target_loss / loss\n",
    "\n",
    "table_trade_result['loss'] = loss\n",
    "table_trade_result['loss_pct'] = loss_pct\n",
    "table_trade_result['quantity'] = quantity\n",
    "\n",
    "\n",
    "\n",
    "amount_entry = price_entry * quantity\n",
    "amount_exit = price_exit * quantity\n",
    "\n",
    "commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "\n",
    "income = amount_exit - amount_entry\n",
    "income = np.where(table_trade_result.position.to_numpy() == 'SHORT', -income, income)\n",
    "\n",
    "table_trade_result['commission'] = commission\n",
    "table_trade_result['income'] = income\n",
    "table_trade_result['income - commission'] = income - commission\n",
    "\n",
    "\n",
    "\n",
    "table_trade_result['amount_entry'] = amount_entry\n",
    "leverage_limit = (table_trade_result['amount_entry'] / target_loss).apply(math.floor).to_numpy() # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "# table_trade_result['leverage_limit'] = (amount_entry / target_loss).astype(int) # math support multiple options\n",
    "table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "\n",
    "\n",
    "\n",
    "if target_leverage is None:\n",
    "        leverage = leverage_limit\n",
    "else:\n",
    "    leverage = np.where(target_leverage > leverage_limit, leverage_limit, target_leverage)\n",
    "table_trade_result['leverage'] = leverage\n",
    "table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "\n",
    "table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount_entry * leverage\n",
    "table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb66cd5-5eaa-4f33-8ffb-54222cfc3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e79d12-bdf3-4466-977b-6e32c231985a",
   "metadata": {},
   "source": [
    "### v1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538ca9a-c7eb-4281-a624-b25d97075707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    define ~ to_numpy() as a var. for keep usage\n",
    "    add RRratio_adj_fee\n",
    "    modify income & commission to income & commission\n",
    "v1.2\n",
    "    move RRratio to anal phase.\n",
    "    set target_loss.\n",
    "        income calculated from quantity.\n",
    "v1.3\n",
    "    modify 'income' to support LONG & SHORT one table.\n",
    "    add loss_pct\n",
    "    add profit.\n",
    "v1.4\n",
    "    rearrange with to_numpy()\n",
    "    \"fee will be placed in here.\"\n",
    "\n",
    "last confirmed at, 20240611 1158.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "target_loss = 5 # USDT\n",
    "\n",
    "target_loss_pct = 0.05 # USDT\n",
    "\n",
    "target_leverage = 1\n",
    "# target_leverage = 10\n",
    "\n",
    "\n",
    "\n",
    "price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "price_entry = table_trade_result.price_entry.to_numpy()\n",
    "price_exit = table_trade_result.price_exit.to_numpy()\n",
    "\n",
    "fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "loss_pct = loss / price_entry # this is official pct for SHORT. price_entry is an initial_price in SHORT position too.\n",
    "# loss_pct = np.where(table_trade_result.position.to_numpy() == 'SHORT', loss / price_stop_loss, loss / price_entry)\n",
    "quantity = target_loss / loss\n",
    "\n",
    "table_trade_result['loss'] = loss\n",
    "table_trade_result['loss_pct'] = loss_pct\n",
    "table_trade_result['quantity'] = quantity\n",
    "\n",
    "\n",
    "\n",
    "amount_entry = price_entry * quantity\n",
    "amount_exit = price_exit * quantity\n",
    "\n",
    "commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "\n",
    "income = amount_exit - amount_entry\n",
    "income = np.where(table_trade_result.position.to_numpy() == 'SHORT', -income, income)\n",
    "\n",
    "table_trade_result['commission'] = commission\n",
    "table_trade_result['income'] = income\n",
    "table_trade_result['income - commission'] = income - commission\n",
    "\n",
    "\n",
    "\n",
    "table_trade_result['amount_entry'] = amount_entry\n",
    "leverage_limit = (table_trade_result['amount_entry'] / target_loss).apply(math.floor).to_numpy() # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "# table_trade_result['leverage_limit'] = (amount_entry / target_loss).astype(int) # math support multiple options\n",
    "table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "\n",
    "\n",
    "\n",
    "leverage = np.where(target_leverage > leverage_limit, leverage_limit, target_leverage)\n",
    "table_trade_result['leverage'] = leverage\n",
    "table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "\n",
    "table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount_entry * leverage\n",
    "table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f37a7-4042-4322-bfe4-ff39d9fd06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36e704-f5b4-4147-9369-cee4baf7a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f80c88-0509-4325-a2c9-5afe8f2f4092",
   "metadata": {},
   "source": [
    "### v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3328f-0bcc-42ee-b633-86420f181f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    define ~ to_numpy() as a var. for keep usage\n",
    "    add RRratio_adj_fee\n",
    "    modify income & commission to income & commission\n",
    "v1.2\n",
    "    move RRratio to anal phase.\n",
    "    set target_loss.\n",
    "        income calculated from quantity.\n",
    "v1.3\n",
    "    modify 'income' to support LONG & SHORT one table.\n",
    "    add loss_pct\n",
    "    add profit.\n",
    "\n",
    "last confirmed at, 20240607 1444.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "target_loss = 5 # USDT\n",
    "\n",
    "leverage = 1\n",
    "leverage = 10\n",
    "\n",
    "\n",
    "\n",
    "price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "price_entry = table_trade_result.price_entry.to_numpy()\n",
    "price_exit = table_trade_result.price_exit.to_numpy()\n",
    "\n",
    "fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "\n",
    "loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "# loss_pct = loss / price_entry\n",
    "quantity = target_loss / loss\n",
    "\n",
    "table_trade_result['loss'] = loss\n",
    "table_trade_result['quantity'] = quantity\n",
    "\n",
    "\n",
    "amount_entry = price_entry * quantity\n",
    "amount_exit = price_exit * quantity\n",
    "\n",
    "# if bank.side_open == 'SELL':\n",
    "#     income = amount_entry - amount_exit # SELL\n",
    "# else:\n",
    "#     income = amount_exit - amount_entry # BUY    \n",
    "commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "\n",
    "table_trade_result['income'] = amount_exit - amount_entry\n",
    "table_trade_result['income'] = np.where(table_trade_result.position.to_numpy() == 'SHORT', -table_trade_result.income.to_numpy(), table_trade_result.income.to_numpy())\n",
    "table_trade_result['commission'] = commission\n",
    "table_trade_result['income - commission'] = table_trade_result.income.to_numpy() - commission\n",
    "\n",
    "\n",
    "\n",
    "amount = table_trade_result.price_entry.to_numpy() * table_trade_result.quantity.to_numpy()\n",
    "table_trade_result['amount'] = amount\n",
    "table_trade_result['leverage_limit'] = (table_trade_result['amount'] / target_loss).apply(math.floor) # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "# table_trade_result['leverage_limit'] = (amount / target_loss).astype(int) # math support multiple options\n",
    "\n",
    "leverage_limit = table_trade_result.leverage_limit.to_numpy()\n",
    "table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "\n",
    "leverage_limit = table_trade_result.leverage_limit.to_numpy()\n",
    "table_trade_result['leverage'] = np.where(leverage > leverage_limit, leverage_limit, leverage)\n",
    "\n",
    "leverage = table_trade_result.leverage.to_numpy()\n",
    "table_trade_result['amount_adj_leverage'] = amount / leverage\n",
    "\n",
    "table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount * leverage\n",
    "table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc99dac-5a48-4acf-9e78-9173559d1a46",
   "metadata": {},
   "source": [
    "### v1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb6df6-1e72-4182-b657-773c4157bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    define ~ to_numpy() as a var. for keep usage\n",
    "    add RRratio_adj_fee\n",
    "    modify income & commission to income & commission\n",
    "v1.2\n",
    "    move RRratio to anal phase.\n",
    "    set target_loss.\n",
    "        income calculated from quantity.\n",
    "\n",
    "last confirmed at, 20240607 0743.\n",
    "\"\"\"\n",
    "\n",
    "price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "price_entry = table_trade_result.price_entry.to_numpy()\n",
    "price_exit = table_trade_result.price_exit.to_numpy()\n",
    "\n",
    "fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "\n",
    "target_loss = 50 # USDT\n",
    "loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "quantity = target_loss / loss\n",
    "\n",
    "table_trade_result['loss'] = loss\n",
    "table_trade_result['quantity'] = quantity\n",
    "\n",
    "\n",
    "amount_entry = price_entry * quantity\n",
    "amount_exit = price_exit * quantity\n",
    "\n",
    "if bank.side_open == 'SELL':\n",
    "    income = amount_entry - amount_exit # SELL\n",
    "else:\n",
    "    income = amount_exit - amount_entry # BUY    \n",
    "commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "\n",
    "table_trade_result['income'] = income\n",
    "table_trade_result['commission'] = commission\n",
    "table_trade_result['income - commission'] = income - commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01befd-8891-49eb-97c0-1f1d0220481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "winRatio = len(table_trade_result[table_trade_result.status=='TP']) / len(table_trade_result)\n",
    "print(\"winRatio : {}\".format(winRatio))\n",
    "\n",
    "\n",
    "# plt.plot(np.cumsum(table_trade_result['income - commission'].to_numpy()))\n",
    "plt.step(np.arange(len(table_trade_result)), np.cumsum(table_trade_result['income - commission'].to_numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8317791-09c1-4d26-8616-dbed35b8d6a7",
   "metadata": {},
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ac0d9-2634-4672-9785-b4815552e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.1\n",
    "    define ~ to_numpy() as a var. for keep usage\n",
    "    add RRratio_adj_fee\n",
    "    modify income & commission to income & commission\n",
    "\n",
    "last confirmed at, 20240602 0926.\n",
    "\"\"\"\n",
    "\n",
    "price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "price_entry = table_trade_result.price_entry.to_numpy()\n",
    "price_exit = table_trade_result.price_exit.to_numpy()\n",
    "\n",
    "quantity = table_trade_result.quantity.to_numpy()\n",
    "\n",
    "fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "\n",
    "amount_take_profit = price_take_profit * quantity\n",
    "amount_stop_loss = price_stop_loss * quantity\n",
    "amount_entry = price_entry * quantity\n",
    "amount_exit = price_exit * quantity\n",
    "\n",
    "income = amount_entry - amount_exit\n",
    "commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "\n",
    "\n",
    "table_trade_result['RRratio'] = (amount_take_profit - amount_entry) / (amount_entry - amount_stop_loss)\n",
    "table_trade_result['RRratio_adj_fee'] = (amount_take_profit - amount_entry - (amount_entry * fee_entry + amount_take_profit * fee_exit)) / (amount_entry - amount_stop_loss - (amount_entry * fee_entry + amount_stop_loss * fee_exit))\n",
    "\n",
    "table_trade_result['income'] = income\n",
    "table_trade_result['commission'] = commission\n",
    "table_trade_result['income - commission'] = income - commission\n",
    "table_trade_result['amount * spread'] = table_trade_result.amount.to_numpy() * table_trade_result.spread.to_numpy()\n",
    "\n",
    "\n",
    "# print(amount_entry)\n",
    "# print(amount_exit)\n",
    "# print(income)\n",
    "print(income.sum())\n",
    "print(commission.sum())\n",
    "print((income - commission).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39743ce8-313d-4c8e-a147-de73e257dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "winRatio = len(table_trade_result[table_trade_result.status=='TP']) / len(table_trade_result)\n",
    "print(winRatio)\n",
    "\n",
    "\n",
    "plt.plot(np.cumsum(table_trade_result.income - table_trade_result.commission))\n",
    "# plt.step(np.arange(len(table_trade_result)), np.cumsum(table_trade_result.income - table_trade_result.commission))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d5911-9567-4536-9ff4-d0263b4005fd",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335c027-5d2f-4467-8092-d13848dd7208",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_entry = table_trade_result.price_entry.to_numpy() * table_trade_result.quantity.to_numpy()\n",
    "amount_exit = table_trade_result.price_exit.to_numpy() * table_trade_result.quantity.to_numpy()\n",
    "\n",
    "profit = amount_entry - amount_exit\n",
    "fee = amount_entry * table_trade_result.fee_entry.to_numpy() + amount_exit * table_trade_result.fee_exit.to_numpy()\n",
    "\n",
    "# table_trade_result['amount'] = amount_entry\n",
    "table_trade_result['profit'] = profit\n",
    "table_trade_result['fee'] = fee\n",
    "table_trade_result['profit - fee'] = profit - fee\n",
    "table_trade_result['amount * spread'] = table_trade_result.amount.to_numpy() * table_trade_result.spread.to_numpy()\n",
    "\n",
    "print(amount_entry)\n",
    "print(amount_exit)\n",
    "print(profit)\n",
    "print(profit.sum())\n",
    "print(fee.sum())\n",
    "print((profit - fee).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae2313-914b-489e-9c05-90234a500707",
   "metadata": {},
   "outputs": [],
   "source": [
    "winRatio = len(table_trade_result[table_trade_result.status=='TP']) / len(table_trade_result)\n",
    "print(winRatio)\n",
    "\n",
    "\n",
    "plt.plot(np.cumsum(table_trade_result.profit - fee))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dbe18-6c7c-4ac4-8304-0b25428c61a9",
   "metadata": {},
   "source": [
    "## set RRratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f9b41-3e1a-45bd-80d2-14a25f171279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point (sparse value)\n",
    "\n",
    "# zone (continuous value)\n",
    "    # default\n",
    "table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "# table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "\n",
    "# unit_RRratio_adj_fee = np.arange(0, 1, 0.1)\n",
    "unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c938cf5-0618-4b1f-91a7-788c21e48def",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579a6a8-be62-49d9-903d-8c5d0121a005",
   "metadata": {},
   "source": [
    "## get winRatio & frequency (pivoting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46f4db-dd2d-454c-a29c-826ab3ac61c3",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78024242-04b3-4595-aade-d5f104a552c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    add symbol to pivot_table index.\n",
    "\n",
    "last confirmed at, 20240605 1106.\n",
    "\"\"\"\n",
    "\n",
    "table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed57745-ca40-416c-b4e0-4a538b454282",
   "metadata": {},
   "source": [
    "### v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fa9aa-97b4-4378-b00f-9f8c26211645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    add symbol to pivot_table index.\n",
    "v2.1\n",
    "    add dataType\n",
    "\n",
    "last confirmed at, 20240619 0826.\n",
    "\"\"\"\n",
    "\n",
    "# table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['dataType', 'status', 'income - commission'], aggfunc={'dataType': 'count', 'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "# table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'dataType', 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "table_trade_result_pivot = table_trade_result.pivot_table(index=['dataType', table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577e55d-4d1f-4aec-a70e-4192f5522305",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebec0d0-da4a-47c8-a30f-d2c7f0f84b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "symbol_extracted = symbol_extracted.droplevel([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417266a3-7dba-43fa-afaa-9baaa3d43198",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd1340-5445-4b9c-b493-99c81e8ce414",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c861d4-5bf2-46c4-88ef-783a48d70696",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_pivot = table_trade_result.pivot_table(index=table_trade_result.RRratio_adj_fee_category, columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f58a5e-d402-4a00-8bd8-43a504c8497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_winRatio = 0.8\n",
    "threshold_incomeTotal = 0.0\n",
    "\n",
    "table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e926c-9181-44e2-97c6-1710e94f95e5",
   "metadata": {},
   "source": [
    "## anchor position & RRratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc66229-b56a-48ab-a896-a0e8cd875f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.0\n",
    "    assert to execute this phase.\n",
    "        table_trade_result_backup is input for below phase.\n",
    "\"\"\"\n",
    "table_trade_result_backup = table_trade_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd302e-9df0-4331-af94-a7a49bef0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result = table_trade_result_backup # reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71efaf-29a9-4cf0-9064-fd0dfdec43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result#_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce33d55-a2e0-46eb-85a9-782541a24d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 'LONG'\n",
    "# position = 'SHORT'\n",
    "\n",
    "RRratio_adj_fee_category = '(0.1, 0.2]' # if catergory gets larger, lesser frequency (= lower reliability) & lower winRatio \n",
    "# RRratio_adj_fee_category = '(0.2, 0.3]'\n",
    "# RRratio_adj_fee_category = '(0.3, 0.4]'\n",
    "# RRratio_adj_fee_category = '(0.4, 0.5]'\n",
    "# RRratio_adj_fee_category = '(0.5, 0.6]'\n",
    "# RRratio_adj_fee_category = '(0.6, 0.7]'\n",
    "RRratio_adj_fee_category = '(0.7, 0.8]'\n",
    "RRratio_adj_fee_category = '(0.8, 0.9]'\n",
    "# RRratio_adj_fee_category = '(0.9, 1.0]'\n",
    "# RRratio_adj_fee_category = '(1.0, 1.1]'\n",
    "# RRratio_adj_fee_category = '(1.1, 1.2]'\n",
    "# RRratio_adj_fee_category = '(1.2, 1.3]'\n",
    "# RRratio_adj_fee_category = '(1.5, 1.6]'\n",
    "# RRratio_adj_fee_category = '(1.8, 1.9]'\n",
    "\n",
    "table_trade_result = table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "# table_trade_result = table_trade_result[table_trade_result.dataType == 'TRAIN']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "v2.0\n",
    "    add symbol to pivot_table index.\n",
    "\n",
    "last confirmed at, 20240605 1106.\n",
    "\"\"\"\n",
    "\n",
    "table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee94311-d06e-4afb-b1c2-bd38c8c40fe0",
   "metadata": {},
   "source": [
    "### add_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e65b7-2169-431f-90bc-2c1ebe4a2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datatype(table_trade_result, train_ratio=0.7):\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits the table_trade_result DataFrame into train and test sets based on the timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    - table_trade_result (pd.DataFrame): DataFrame containing trade results with 'timestamp_entry' column.\n",
    "    - train_ratio (float): Ratio of data to be used for training. Default is 0.7 (70%).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an additional 'dataType' column indicating 'TRAIN' or 'TEST'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 'timestamp_entry' column to numpy array for calculations\n",
    "    timestamp_entry = table_trade_result['timestamp_entry'].to_numpy()\n",
    "\n",
    "    # Find minimum and maximum timestamps\n",
    "    timestamp_min = timestamp_entry.min()\n",
    "    timestamp_max = timestamp_entry.max()\n",
    "\n",
    "    # Calculate the threshold timestamp for splitting into train and test sets\n",
    "    timestamp_train = timestamp_min + (timestamp_max - timestamp_min) * train_ratio\n",
    "\n",
    "    # Assign 'TRAIN' or 'TEST' labels based on the timestamp threshold\n",
    "    table_trade_result['dataType'] = np.where(timestamp_entry < timestamp_train, 'TRAIN', 'TEST')\n",
    "\n",
    "    return table_trade_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2f441-c468-4822-9e1f-47fb115a503d",
   "metadata": {},
   "source": [
    "### convert_to_position_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b67fda-ee7f-4179-b125-b74accadf0a0",
   "metadata": {},
   "source": [
    "#### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20355440-d289-4b19-b95c-4d5f59e9a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_position_single(df):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        modify to timestamp mode.\n",
    "            = using public index\n",
    "                private index : idx_entry & exit.\n",
    "\n",
    "    last confiremd at, 20240703 0732.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort trades by entry index in ascending order\n",
    "    df = df.sort_values(by='timestamp_entry').reset_index(drop=True)\n",
    "    \n",
    "    # List to store the result\n",
    "    result = []\n",
    "    \n",
    "    # Variable to store the exit index of the current position\n",
    "    current_timestamp_exit = -1\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Add trades that start after the current position's exit index\n",
    "        if row['timestamp_entry'] > current_timestamp_exit:\n",
    "            result.append(row)\n",
    "            current_timestamp_exit = row['timestamp_exit']\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f9f99-ab35-4c0f-839e-40819c58a85b",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9738c2-65c2-47e1-b240-aef1c0ef9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_position_single(df):\n",
    "#     # Sort trades by entry index in ascending order\n",
    "#     df = df.sort_values(by='idx_entry').reset_index(drop=True)\n",
    "    \n",
    "#     # List to store the result\n",
    "#     result = []\n",
    "    \n",
    "#     # Variable to store the exit index of the current position\n",
    "#     current_exit_idx = -1\n",
    "    \n",
    "#     for idx, row in df.iterrows():\n",
    "#         # Add trades that start after the current position's exit index\n",
    "#         if row['idx_entry'] > current_exit_idx:\n",
    "#             result.append(row)\n",
    "#             current_exit_idx = row['idx_exit']\n",
    "    \n",
    "#     return pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638c8df-3e59-442d-ab90-e8f23a7abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_position_single(table_trade_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a3e35-5790-4b4a-ae6c-be7856c95fb1",
   "metadata": {},
   "source": [
    "### get_amount_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c894-6d87-435a-a8e8-42c10329d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amount_agg(table_trade_result_agg, \n",
    "                   interval):\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalize the timestamps in the given table and aggregate the amounts based on the time intervals.\n",
    "\n",
    "    Args:\n",
    "    - table_trade_result_agg (DataFrame): DataFrame containing trade results with columns 'timestamp_entry', 'timestamp_exit', and 'amount_entry_adj_leverage'.\n",
    "    - interval (str): Time interval string to convert to minutes.\n",
    "\n",
    "    Returns:\n",
    "    - map_amount_agg (ndarray): Aggregated amount array based on normalized time intervals.\n",
    "    - map_amount_agg_max (float): Maximum value in the aggregated amount array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize timestamps\n",
    "    timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "    table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "    table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "\n",
    "    minutes = itv_to_number(interval)\n",
    "    timestamp_unit = 60 * minutes\n",
    "    table_trade_result_agg['timemap_entry'] //= timestamp_unit\n",
    "    table_trade_result_agg['timemap_exit'] //= timestamp_unit\n",
    "\n",
    "    map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]) + 1) # last timemap_exit index can be mapped.\n",
    "    for row in table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy():\n",
    "        index_start, index_end, amount = row\n",
    "        map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "\n",
    "    map_amount_agg_max = map_amount_agg.max()\n",
    "\n",
    "    return map_amount_agg, map_amount_agg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29380c-710e-4893-b460-483a11cb075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_amount_agg, \\\n",
    "map_amount_agg_max = get_amount_agg(table_trade_result_agg, \n",
    "                                   interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc72d4-ef6f-4b4e-be10-a906c9e046d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_amount_agg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28cc52-2590-4c98-8996-e9d234469f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(map_amount_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418102da-49b7-4ca0-afa6-5eb9a28e7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3048e05-dbe7-468c-a84e-51d5ea8c5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_amount_agg(trades_df):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Calculate the minimum amount required to execute all trades successfully, considering overlapping trades.\n",
    "\n",
    "#     Parameters:\n",
    "#     trades_df (pd.DataFrame): A DataFrame containing 'idx_entry', 'idx_exit', and 'amount_entry_adj_leverage' columns.\n",
    "\n",
    "#     Returns:\n",
    "#     float: The minimum amount required to execute all trades.\n",
    "#     \"\"\"\n",
    "#     # Find the maximum exit index\n",
    "#     max_idx = trades_df[\"idx_exit\"].max()\n",
    "\n",
    "#     # Initialize an array to store the required amount at each time unit\n",
    "#     amount_per_time_unit = np.zeros(max_idx + 1)\n",
    "\n",
    "#     # Accumulate the amount_entry_adj_leverage for each trade over its duration\n",
    "#     for _, row in trades_df.iterrows():\n",
    "#         amount_per_time_unit[row[\"idx_entry\"]:row[\"idx_exit\"] + 1] += row[\"amount_entry_adj_leverage\"]\n",
    "\n",
    "#     # The minimum required amount to execute all trades is the maximum value in the amount_per_time_unit array\n",
    "#     min_required_amount = amount_per_time_unit.max()\n",
    "\n",
    "#     return min_required_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457aa6f-1865-402d-a662-1a143bae47f8",
   "metadata": {},
   "source": [
    "### get_minimum_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b34a8-caf5-4f92-a2e1-45269a20476a",
   "metadata": {},
   "source": [
    "#### v1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5370de-b762-43ec-929c-658ab2926c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_assets(trade_data):\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        arrange income-commission by timemap.\n",
    "    v1.1\n",
    "        simplified by gpt.\n",
    "        \n",
    "        v1.1.1\n",
    "            vectorization. (lower latency)\n",
    "            reorder output.\n",
    "        v1.1.2\n",
    "            apply dynamic target_loss.\n",
    "        \n",
    "    last confirmed at, 20240708 1300.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Normalize timestamps\n",
    "    timestamp_min = trade_data['timestamp_entry'].min()\n",
    "    trade_data['timemap_entry'] = (trade_data['timestamp_entry'] - timestamp_min) // 60\n",
    "    trade_data['timemap_exit'] = (trade_data['timestamp_exit'] - timestamp_min) // 60\n",
    "       \n",
    "    # Combine entry and exit events into a single DataFrame\n",
    "    events = pd.concat([\n",
    "        trade_data[['timemap_entry', 'amount_entry_adj_leverage']].rename(columns={'timemap_entry': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='entry'),\n",
    "        trade_data[['timemap_exit', 'amount_entry_adj_leverage', 'income - commission']].rename(columns={'timemap_exit': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='exit')\n",
    "    ]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Initialize variables\n",
    "    current_assets = 0\n",
    "    assets_min_required = 0\n",
    "    assets_over_time = np.zeros(len(events))\n",
    "\n",
    "    # Update current assets using vectorized operations\n",
    "    # entry_mask = events['event'] == 'entry'\n",
    "    # exit_mask = events['event'] == 'exit'\n",
    "\n",
    "    # events.loc[entry_mask, 'current_assets'] = -events.loc[entry_mask, 'amount'] #.cumsum()\n",
    "    # events.loc[exit_mask, 'current_assets'] = (\n",
    "    #     events.loc[exit_mask, 'amount'] + events.loc[exit_mask, 'income - commission']) #.cumsum()\n",
    "\n",
    "    # current_assets = events['current_assets'].fillna(0)\n",
    "    # # current_assets[exit_mask] += current_assets.shift(1).fillna(0)[exit_mask]\n",
    "    \n",
    "    current_assets = np.where(events['event'] == 'entry', -events['amount'], events['amount'] + events['income - commission'].fillna(0))\n",
    "    events['current_assets'] = current_assets\n",
    "\n",
    "    # Calculate minimum assets required and maximum drawdown\n",
    "    assets_over_time = current_assets.cumsum()\n",
    "\n",
    "    \n",
    "    assets_drawdown = abs(assets_over_time - np.maximum.accumulate(assets_over_time))\n",
    "    assets_drawdown_max = assets_drawdown.max() # = original start asset with static target_loss.\n",
    "    asset_divider = (assets_drawdown_max - assets_drawdown) / trade_data['amount_entry_adj_leverage'].mean() # = divider.\n",
    "    \n",
    "    events['asset_divider'] = asset_divider\n",
    "    events['target_loss'] = assets_drawdown_max / asset_divider   \n",
    "    \n",
    "\n",
    "    events_entry = events[events.event=='entry'] \n",
    "    \n",
    "    # trade_data['asset_divider'] = events_entry['asset_divider'].values\n",
    "    # trade_data['target_loss'] = events_entry['target_loss'].values\n",
    "    target_loss_dynamic = events_entry['target_loss'].values\n",
    "\n",
    "    return events, assets_over_time, assets_drawdown_max, target_loss_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcdb60-756e-48a7-8430-672d02177b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capital = 50\n",
    "current_capital = initial_capital\n",
    "\n",
    "# 거래 필터링\n",
    "events_list = []\n",
    "entries = []\n",
    "\n",
    "for _, row in events.iterrows():\n",
    "    if row.event == 'entry':\n",
    "        if current_capital + row['current_assets'] >= 0:\n",
    "            events_list.append(row)\n",
    "            current_capital += row['current_assets']\n",
    "            entries.append(row['amount'])  # Entry 기록\n",
    "    else:\n",
    "        if row['amount'] in entries:\n",
    "            events_list.append(row)\n",
    "            current_capital += row['current_assets']\n",
    "            entries.remove(row['amount'])  # Exit 처리\n",
    "\n",
    "# 결과 데이터프레임 생성\n",
    "events_executed = pd.DataFrame(events_list)\n",
    "events_executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d9c6d-f66c-40bf-99d5-5dfea4e2e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71a839-3b59-4be1-9159-f8116725b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, \\\n",
    "assets_over_time, \\\n",
    "assets_drawdown_max, \\\n",
    "target_loss_dynamic = get_minimum_assets(\n",
    "                                        table_trade_result_agg\n",
    "                                        # table_trade_result_agg_dynamic\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceac484-fe56-4d97-a691-6235fc831be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events\n",
    "assets_over_time[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1e77f-153e-480f-abff-1a4b02aeb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(events)\n",
    "# print(assets_min_required) \n",
    "print(assets_over_time[-1]) \n",
    "print(assets_drawdown_max)\n",
    "print(assets_drawdown_max / target_loss)\n",
    "\n",
    "# # print(assets_over_time[-1])\n",
    "# print(abs(assets_over_time[-1] / assets_min_required))\n",
    "# print(abs(assets_over_time[-1] / assets_max_drawdown))\n",
    "\n",
    "# print(abs(assets_min_required / target_loss))\n",
    "# print(abs(assets_max_drawdown / target_loss))\n",
    "\n",
    "plt.step(range(len(assets_over_time)), assets_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76006b-89c2-4cbe-9c75-0111c8a12359",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg_dynamic = set_quantity(table_trade_result_agg.copy(),       \n",
    "# table_trade_result = set_quantity(table_trade_result,         \n",
    "                                     leverage_limits,\n",
    "                                     target_loss_dynamic, \n",
    "                                     # 15, \n",
    "                                     target_loss_pct, \n",
    "                                     target_leverage, \n",
    "                                     fee_market, \n",
    "                                     fee_market,\n",
    "                                     np.arange(0, 2, 0.1),\n",
    "                                     leverage_rejection,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292de11b-a966-4569-a896-3cef8bb17323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_trade_result_agg\n",
    "# table_trade_result_agg_dynamic\n",
    "table_trade_result_agg_dynamic[table_trade_result_agg_dynamic.status=='SL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c96be5-ad3f-4915-8a99-c086e19e732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_commission = table_trade_result_agg['income - commission'].fillna(0).cumsum().to_numpy()\n",
    "print((income_commission - np.maximum.accumulate(income_commission)).min())\n",
    "print(income_commission[-1])\n",
    "\n",
    "plt.step(range(len(income_commission)), income_commission)\n",
    "# plt.show()\n",
    "\n",
    "income_commission = table_trade_result_agg_dynamic['income - commission'].fillna(0).cumsum().to_numpy()\n",
    "print((income_commission - np.maximum.accumulate(income_commission)).min())\n",
    "\n",
    "plt.step(range(len(income_commission)), income_commission)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eeeea9-cedd-47d9-997c-944e29a6f6d2",
   "metadata": {},
   "source": [
    "#### v1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17880e-6941-4358-afe6-b5ee7f7e834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_assets(trade_data):\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        arrange income-commission by timemap.\n",
    "    v1.1\n",
    "        simplified by gpt.\n",
    "        \n",
    "        v1.1.1\n",
    "            vectorization. (lower latency)\n",
    "            reorder output.\n",
    "        \n",
    "    last confirmed at, 20240704 1658.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Normalize timestamps\n",
    "    timestamp_min = trade_data['timestamp_entry'].min()\n",
    "    trade_data['timemap_entry'] = (trade_data['timestamp_entry'] - timestamp_min) // 60\n",
    "    trade_data['timemap_exit'] = (trade_data['timestamp_exit'] - timestamp_min) // 60\n",
    "       \n",
    "    # Combine entry and exit events into a single DataFrame\n",
    "    events = pd.concat([\n",
    "        trade_data[['timemap_entry', 'amount_entry_adj_leverage']].rename(columns={'timemap_entry': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='entry'),\n",
    "        trade_data[['timemap_exit', 'amount_entry_adj_leverage', 'income - commission']].rename(columns={'timemap_exit': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='exit')\n",
    "    ]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    current_assets = np.where(events['event'] == 'entry', -events['amount'], events['amount'] + events['income - commission'].fillna(0))\n",
    "    events['current_assets'] = current_assets\n",
    "\n",
    "    # Calculate minimum assets required and maximum drawdown\n",
    "    assets_over_time = current_assets.cumsum()\n",
    "    assets_min_required = assets_over_time.min()\n",
    "    max_drawdown = (assets_over_time - np.maximum.accumulate(assets_over_time)).min()\n",
    "    \n",
    "    plt.step(range(len(assets_over_time)), assets_over_time)\n",
    "    plt.show()\n",
    "\n",
    "    return events, assets_over_time, assets_min_required, max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e80df-daec-4046-9672-a5adc79b9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, \\\n",
    "assets_over_time, \\\n",
    "assets_min_required, \\\n",
    "assets_max_drawdown = get_minimum_assets(table_trade_result_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ac9f0-476f-4bbb-a181-4a966145ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18642d55-2103-4760-83ee-3d869df44997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawdowns.mean()\n",
    "# plt.plot(drawdowns)\n",
    "\n",
    "# print(events)\n",
    "print(assets_min_required) \n",
    "# # print(assets_over_time) \n",
    "print(assets_max_drawdown)\n",
    "\n",
    "# print(assets_over_time[-1])\n",
    "print(abs(assets_over_time[-1] / assets_min_required))\n",
    "print(abs(assets_over_time[-1] / assets_max_drawdown))\n",
    "\n",
    "print(abs(assets_min_required / target_loss))\n",
    "print(abs(assets_max_drawdown / target_loss))\n",
    "\n",
    "\n",
    "# plt.plot(assets_over_time)\n",
    "plt.step(range(len(assets_over_time)), assets_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d0c71-b78d-4cc4-b822-4fc74139b738",
   "metadata": {},
   "source": [
    "#### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ceab5-89e8-461d-854f-86518e43d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_assets(trade_data):\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        arrange income-commission by timemap.\n",
    "    v1.1\n",
    "        simplified by gpt.\n",
    "        \n",
    "    last confirmed at, 20240703 1105.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize timestamps\n",
    "    timestamp_min = trade_data['timestamp_entry'].min()\n",
    "    trade_data['timemap_entry'] = (trade_data['timestamp_entry'] - timestamp_min) // 60\n",
    "    trade_data['timemap_exit'] = (trade_data['timestamp_exit'] - timestamp_min) // 60\n",
    "       \n",
    "    # Combine entry and exit events into a single DataFrame\n",
    "    events = pd.concat([\n",
    "        trade_data[['timemap_entry', 'amount_entry_adj_leverage']].rename(columns={'timemap_entry': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='entry'),\n",
    "        trade_data[['timemap_exit', 'amount_entry_adj_leverage', 'income - commission']].rename(columns={'timemap_exit': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='exit')\n",
    "    ]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Initialize variables\n",
    "    current_assets = 0\n",
    "    assets_min_required = 0\n",
    "    assets_max_drawdown = 0  # Initialize maximum drawdown\n",
    "\n",
    "    assets_over_time = []  # List to store current_assets for each time unit\n",
    "\n",
    "    # Iterate over each event and update the current assets\n",
    "    for _, event in events.iterrows():\n",
    "        if event['event'] == 'entry':\n",
    "            current_assets -= event['amount']\n",
    "            assets_min_required = min(assets_min_required, current_assets)\n",
    "        elif event['event'] == 'exit':\n",
    "            current_assets += event['amount']\n",
    "            current_assets += event['income - commission']\n",
    "\n",
    "        # Store the current_assets for this time unit\n",
    "        assets_over_time.append(current_assets)\n",
    "        \n",
    "    # Calculate maximum drawdown       \n",
    "    assets_over_time_arr = np.array(assets_over_time)\n",
    "    drawdowns = assets_over_time_arr - np.maximum.accumulate(assets_over_time_arr)\n",
    "    assets_max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "\n",
    "    return events, assets_min_required, assets_over_time, assets_max_drawdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b07102-ca04-43fb-b6f1-3c32ed52dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, \\\n",
    "assets_min_required, \\\n",
    "assets_over_time, \\\n",
    "assets_max_drawdown = get_minimum_assets(table_trade_result_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37696ff-b647-47b4-a099-077b592ae707",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(assets_over_time) #  = assets_min_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eef711-48fd-4267-ba46-b688eaa0b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawdowns.mean()\n",
    "# plt.plot(drawdowns)\n",
    "\n",
    "print(events)\n",
    "print(assets_min_required) \n",
    "# print(assets_over_time) \n",
    "print(assets_max_drawdown)\n",
    "\n",
    "print(assets_over_time[-1])\n",
    "print(abs(assets_over_time[-1] / assets_min_required))\n",
    "print(abs(assets_over_time[-1] / assets_max_drawdown))\n",
    "\n",
    "print(abs(assets_min_required / target_loss))\n",
    "print(abs(assets_max_drawdown / target_loss))\n",
    "\n",
    "\n",
    "# plt.plot(assets_over_time)\n",
    "plt.step(range(len(assets_over_time)), assets_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f5f3b-6d60-4736-abec-61812ec225d7",
   "metadata": {},
   "source": [
    "#### v1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fe069-8a97-4dfb-92a1-959c24a98935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_minimum_assets_from_events(events):\n",
    "    # Initialize variables\n",
    "    current_assets = 0\n",
    "    min_required_assets = 0\n",
    "\n",
    "    # List to store current_assets for each time unit\n",
    "    assets_over_time = []\n",
    "\n",
    "    # Iterate over each event and update the current assets\n",
    "    for _, event in events.iterrows():\n",
    "        if event['event'] == 'entry':\n",
    "            current_assets -= event['amount']\n",
    "            min_required_assets = min(min_required_assets, current_assets)\n",
    "        elif event['event'] == 'exit':\n",
    "            current_assets += event['amount']\n",
    "            current_assets += event['income - commission']\n",
    "\n",
    "        # Store the current_assets for this time unit\n",
    "        assets_over_time.append(current_assets)\n",
    "\n",
    "    return min_required_assets\n",
    "\n",
    "def get_events_from_trade_data(trade_data):\n",
    "    # Combine entry and exit events into a single DataFrame\n",
    "    events = pd.concat([\n",
    "        trade_data[['timemap_entry', 'amount_entry_adj_leverage']].rename(columns={'timemap_entry': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='entry'),\n",
    "        trade_data[['timemap_exit', 'amount_entry_adj_leverage', 'income - commission']].rename(columns={'timemap_exit': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='exit')\n",
    "    ]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "    return events\n",
    "\n",
    "def get_max_min_required_assets_from_rows(trade_data):\n",
    "    # Normalize timestamps\n",
    "    timestamp_min = trade_data['timestamp_entry'].min()\n",
    "    trade_data['timemap_entry'] = (trade_data['timestamp_entry'] - timestamp_min) // 60\n",
    "    trade_data['timemap_exit'] = (trade_data['timestamp_exit'] - timestamp_min) // 60\n",
    "    \n",
    "    # Get the combined events DataFrame\n",
    "    events = get_events_from_trade_data(trade_data)\n",
    "    \n",
    "    min_required_assets_list = []\n",
    "    \n",
    "    # Iterate over each row to use it as the start point\n",
    "    for start_index in range(len(events)):\n",
    "        if events.iloc[start_index]['event'] == 'entry':\n",
    "            sub_events = events.iloc[start_index:].reset_index(drop=True)\n",
    "            min_required_assets = get_minimum_assets_from_events(sub_events)\n",
    "            min_required_assets_list.append(min_required_assets)\n",
    "        \n",
    "    max_min_required_assets = min(min_required_assets_list)\n",
    "    return max_min_required_assets\n",
    "    # return min_required_assets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286afdd8-9039-4628-9f3b-128d1f65cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_required_assets = get_max_min_required_assets_from_rows(table_trade_result_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b93b6b-2baa-4044-9e30-8f43b87d7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_required_assets\n",
    "# len(max_min_required_assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7bdac-9ed8-4a98-8d3c-26133839e94c",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b7923-a769-4900-bc91-b1d3fc403713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_minimum_assets(trade_data):\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        arrange income-commission by timemap.\n",
    "\n",
    "    last confirmed at, 20240703 1105.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize timestamps\n",
    "    timestamp_min = trade_data['timestamp_entry'].iloc[0]\n",
    "    trade_data['timemap_entry'] = trade_data['timestamp_entry'] - timestamp_min\n",
    "    trade_data['timemap_exit'] = trade_data['timestamp_exit'] - timestamp_min\n",
    "\n",
    "    minutes = itv_to_number(interval)\n",
    "    timestamp_unit = 60 * minutes\n",
    "    trade_data['timemap_entry'] //= timestamp_unit\n",
    "    trade_data['timemap_exit'] //= timestamp_unit\n",
    "    \n",
    "    # Combine entry and exit events into a single DataFrame\n",
    "    events = pd.concat([\n",
    "        trade_data[['timemap_entry', 'amount_entry_adj_leverage']].rename(columns={'timemap_entry': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='entry'),\n",
    "        trade_data[['timemap_exit', 'amount_entry_adj_leverage', 'income - commission']].rename(columns={'timemap_exit': 'timestamp', 'amount_entry_adj_leverage': 'amount'}).assign(event='exit')\n",
    "    ]).sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Initialize variables\n",
    "    current_assets = 0\n",
    "    min_required_assets = 0\n",
    "    max_drawdown = 0  # Initialize maximum drawdown\n",
    "\n",
    "    assets_over_time = []  # List to store current_assets for each time unit\n",
    "\n",
    "    # Iterate over each event and update the current assets\n",
    "    for _, event in events.iterrows():\n",
    "        if event['event'] == 'entry':\n",
    "            current_assets -= event['amount']\n",
    "            min_required_assets = min(min_required_assets, current_assets)\n",
    "        elif event['event'] == 'exit':\n",
    "            current_assets += event['amount']\n",
    "            current_assets += event['income - commission']\n",
    "\n",
    "        # Store the current_assets for this time unit\n",
    "        assets_over_time.append(current_assets)\n",
    "        \n",
    "    # Calculate maximum drawdown       \n",
    "    assets_over_time_arr = np.array(assets_over_time)\n",
    "    drawdowns = assets_over_time_arr - np.maximum.accumulate(assets_over_time_arr)\n",
    "    max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "\n",
    "    return events, min_required_assets, assets_over_time, max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c8077-41bf-4f32-9e59-915820fa0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, min_required_assets, assets_over_time, max_drawdown = get_minimum_assets(table_trade_result_agg)\n",
    "# events, min_required_assets, assets_over_time, max_drawdown = get_minimum_assets(table_trade_result_agg[table_trade_result_agg.dataType == 'TEST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00aefa9-7bc7-48b0-961f-3d4a54b20446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events)\n",
    "print(min_required_assets) \n",
    "# print(assets_over_time) \n",
    "print(max_drawdown)\n",
    "\n",
    "# plt.plot(assets_over_time)\n",
    "plt.step(range(len(assets_over_time)), assets_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14ea3b-c70e-426b-915c-9c7d7bf3b884",
   "metadata": {},
   "source": [
    "### get_periodic_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de66e49-ac5b-4088-9c29-e4d263423b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periodic_profit(table_trade_result_agg, profit, mode='SIMPLE'):\n",
    "    \"\"\"\n",
    "    Calculate daily, monthly, and yearly profit rates based on simple or compound interest.\n",
    "    \n",
    "    Parameters:\n",
    "    table_trade_result_agg (pd.DataFrame): DataFrame containing trade results with timestamp entries and exits.\n",
    "    profit (float): The total profit in percentage.\n",
    "    mode (str): Mode of calculation ('SIMPLE' or 'COMPOUND').\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Daily, monthly, and yearly profit rates in percentage.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the total duration in seconds\n",
    "    duration_seconds = table_trade_result_agg.timestamp_exit.max() - table_trade_result_agg.timestamp_entry.min()\n",
    "    \n",
    "    # Define constants\n",
    "    SECONDS_IN_A_DAY = 86400\n",
    "    SECONDS_IN_A_MONTH = 30 * SECONDS_IN_A_DAY\n",
    "    SECONDS_IN_A_YEAR = 365 * SECONDS_IN_A_DAY\n",
    "    \n",
    "    # Convert duration to days, months, and years\n",
    "    duration_days = duration_seconds / SECONDS_IN_A_DAY\n",
    "    duration_months = duration_seconds / SECONDS_IN_A_MONTH\n",
    "    duration_years = duration_seconds / SECONDS_IN_A_YEAR\n",
    "    \n",
    "    # Convert profit from percentage to decimal\n",
    "    profit_decimal = profit / 100\n",
    "    \n",
    "    if mode == 'SIMPLE':\n",
    "        # Calculate simple interest rates\n",
    "        profit_daily = profit_decimal / duration_days * 100\n",
    "        profit_monthly = profit_decimal / duration_months * 100\n",
    "        profit_yearly = profit_decimal / duration_years * 100\n",
    "    else:\n",
    "        # Calculate compound interest rates\n",
    "        profit_daily = ((1 + profit_decimal) ** (1 / duration_days) - 1) * 100\n",
    "        profit_monthly = ((1 + profit_decimal) ** (1 / duration_months) - 1) * 100\n",
    "        profit_yearly = ((1 + profit_decimal) ** (1 / duration_years) - 1) * 100\n",
    "\n",
    "    return profit_daily, profit_monthly, profit_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390840a-f553-4919-815b-0ee771d0928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_max = abs(assets_over_time[-1] / min_required_assets) * 100\n",
    "profit_min = abs(assets_over_time[-1] / max_drawdown) * 100\n",
    "\n",
    "get_periodic_profit(table_trade_result_agg, \n",
    "                    # profit_max, \n",
    "                    np.nan, \n",
    "                    mode='SIMPLE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c6c2b-d1a1-48ea-acf9-aa5d5da819df",
   "metadata": {},
   "source": [
    "### get_output_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7e827-a237-479f-9857-9432de12b904",
   "metadata": {},
   "source": [
    "#### v1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1e488-3540-49f0-a852-42fd982dcbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_row(table_trade_result_agg, \n",
    "                symbol_extracted, \n",
    "                symbol_extracted_len, \n",
    "                symbol_extracted_len_pct, \n",
    "                interval, \n",
    "                target_loss,\n",
    "                target_loss_pct,\n",
    "                target_leverage, \n",
    "                position, \n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio, \n",
    "                threshold_frequency, \n",
    "                threshold_frequencyTotal, \n",
    "                path_dir_save_fig,\n",
    "                mode_position='SINGLE',\n",
    "                mode_profit='SIMPLE',\n",
    "                show_figure=False,\n",
    "                save_figure=False):\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add target_loss_pct\n",
    "    v1.2\n",
    "        simplified by gpt.\n",
    "        modify get_amount_agg algorithm which uses index_entry & exit instead timemap.\n",
    "        \n",
    "        v1.2.1\n",
    "            add divide bar on title.\n",
    "    v1.3\n",
    "        modify get_amount_agg to get_minimum_assets.\n",
    "        \n",
    "        v1.3.1\n",
    "            add mode_position.\n",
    "\n",
    "    last confirmed at, 20240708 2251.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate win ratio\n",
    "    frequencyTotal = len(table_trade_result_agg)    \n",
    "    winRatio = len(table_trade_result_agg[table_trade_result_agg.status == 'TP']) / frequencyTotal\n",
    "    \n",
    "    # Calculate cumulative and final profit percentage\n",
    "    profit_pct_cum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy()) if mode_profit == 'SIMPLE' else (np.cumprod(table_trade_result_agg['profit'].to_numpy() + 1) - 1) * 100\n",
    "    profit_pct_final = profit_pct_cum[-1] if profit_pct_cum.size > 0 else 0\n",
    "\n",
    "    frequencyMean = frequencyTotal / symbol_extracted_len if symbol_extracted_len != 0 else 0\n",
    "\n",
    "    # Calculate Sharpe and Sortino Ratios\n",
    "    profit = table_trade_result_agg.profit.to_numpy()\n",
    "    mean_return = np.mean(profit) if profit.size > 0 else 0\n",
    "    std_return = np.std(profit) if profit.size > 0 else 0\n",
    "    sharpe_ratio = (mean_return - 0) / std_return if std_return != 0 else 0\n",
    "    downside_returns = profit[profit < 0]\n",
    "    downside_deviation = np.std(downside_returns) if downside_returns.size > 0 else 0\n",
    "    sortino_ratio = (mean_return - 0) / downside_deviation if downside_deviation != 0 else 0\n",
    "\n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.cumsum(profit)\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "    cumulative_returns_min, cumulative_returns_max = cumulative_returns.min(), cumulative_returns.max()\n",
    "    cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min) if cumulative_returns_max - cumulative_returns_min != 0 else np.zeros_like(cumulative_returns)\n",
    "    drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "    max_drawdown_scaled = np.min(drawdowns_scaled) if drawdowns_scaled.size > 0 else 0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    total_profit = np.sum(profit[profit > 0])\n",
    "    total_loss = -np.sum(profit[profit < 0])\n",
    "    profit_factor = total_profit / total_loss if total_loss != 0 else 0\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    x = np.linspace(0, 1, cumulative_returns_scaled.size)\n",
    "    y_actual = x\n",
    "    y_predicted = cumulative_returns_scaled\n",
    "    mse = mean_squared_error(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "    r2 = r2_score(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "\n",
    "    if mode_profit == 'SIMPLE':        \n",
    "        events, \\\n",
    "        assets_over_time, \\\n",
    "        assets_min_required, \\\n",
    "        assets_max_drawdown = get_minimum_assets(table_trade_result_agg)\n",
    "        \n",
    "        profit_pct_final_min = abs(assets_over_time[-1] / assets_max_drawdown) * 100\n",
    "        profit_pct_final_max = abs(assets_over_time[-1] / assets_min_required) * 100\n",
    "    else:\n",
    "        assets_min_required = np.nan\n",
    "        assets_max_drawdown = np.nan\n",
    "        profit_pct_final_min = profit_pct_final\n",
    "        profit_pct_final_max = profit_pct_final   \n",
    "        \n",
    "    assets_min_required_const = abs(assets_min_required / target_loss)\n",
    "    assets_max_drawdown_const = abs(assets_max_drawdown / target_loss)\n",
    "    \n",
    "        \n",
    "    profit_pct_daily, \\\n",
    "    profit_pct_monthly, \\\n",
    "    profit_pct_yearly = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final,\n",
    "                                        mode_profit) \n",
    "    profit_pct_daily_min, \\\n",
    "    profit_pct_monthly_min, \\\n",
    "    profit_pct_yearly_min = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final_min,\n",
    "                                        mode_profit)\n",
    "    profit_pct_daily_max, \\\n",
    "    profit_pct_monthly_max, \\\n",
    "    profit_pct_yearly_max = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final_max,\n",
    "                                        mode_profit)\n",
    "\n",
    "    \n",
    "    row = [\n",
    "        interval,\n",
    "        target_loss,\n",
    "        target_loss_pct,\n",
    "        target_leverage,\n",
    "        position,\n",
    "        RRratio_adj_fee_category,\n",
    "        threshold_winRatio,\n",
    "        threshold_frequency,\n",
    "        threshold_frequencyTotal,\n",
    "        mode_position,\n",
    "        \n",
    "        \"{}\".format(symbol_extracted.tolist()),\n",
    "        symbol_extracted_len,\n",
    "        symbol_extracted_len_pct,\n",
    "        \n",
    "        frequencyTotal,\n",
    "        frequencyMean,\n",
    "        \n",
    "        winRatio,\n",
    "        \n",
    "        assets_min_required_const,\n",
    "        assets_max_drawdown_const,\n",
    "        profit_pct_final,\n",
    "        profit_pct_daily, \n",
    "        profit_pct_monthly,\n",
    "        profit_pct_yearly,\n",
    "        profit_pct_final_min,\n",
    "        profit_pct_daily_min, \n",
    "        profit_pct_monthly_min,\n",
    "        profit_pct_yearly_min,\n",
    "        profit_pct_final_max,\n",
    "        profit_pct_daily_max, \n",
    "        profit_pct_monthly_max,\n",
    "        profit_pct_yearly_max,\n",
    "        \n",
    "        mean_return,\n",
    "        std_return,\n",
    "        max_drawdown,\n",
    "        max_drawdown_scaled,\n",
    "        sharpe_ratio,\n",
    "        sortino_ratio,\n",
    "        profit_factor,\n",
    "        mse,\n",
    "        r2,\n",
    "    ]\n",
    "    \n",
    "    # Generate title string\n",
    "    title = (\n",
    "        f\"interval : {interval}\\n\"\n",
    "        f\"target_loss : {target_loss}\\n\"\n",
    "        f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "        f\"target_leverage : {target_leverage}\\n\"\n",
    "        f\"position : {position}\\n\"\n",
    "        f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "        f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "        f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "        f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "        f\"mode_position : {mode_position}\\n\"\n",
    "        f\"mode_profit : {mode_profit}\\n\"\n",
    "        f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "        f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"frequencyTotal : {frequencyTotal}\\n\"\n",
    "        f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"winRatio : {winRatio:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"assets_min_required_const : {assets_min_required_const:.2f}\\n\"\n",
    "        f\"assets_max_drawdown_const : {assets_max_drawdown_const:.2f}\\n\"\n",
    "        f\"profit_pct_final : {profit_pct_final:.2f} ({profit_pct_final_min:.2f}~{profit_pct_final_max:.2f})\\n\"\n",
    "        f\"profit_pct_daily : {profit_pct_daily:.2f} ({profit_pct_daily_min:.2f}~{profit_pct_daily_max:.2f})\\n\"\n",
    "        f\"profit_pct_monthly : {profit_pct_monthly:.2f} ({profit_pct_monthly_min:.2f}~{profit_pct_monthly_max:.2f})\\n\"\n",
    "        f\"profit_pct_yearly : {profit_pct_yearly:.2f} ({profit_pct_yearly_min:.2f}~{profit_pct_yearly_max:.2f})\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"mean_return : {mean_return:.2f}\\n\"\n",
    "        f\"std_return : {std_return:.2f}\\n\"\n",
    "        f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "        f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "        f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "        f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "        f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "        f\"mse : {mse:.2f}\\n\"\n",
    "        f\"r2 : {r2:.2f}\"\n",
    "    )\n",
    "    \n",
    "    # # Mapping row indices to variable names for title generation\n",
    "    # row_labels = [\n",
    "    #         \"interval\",\n",
    "    #         \"target_loss\",\n",
    "    #         \"target_loss_pct\",\n",
    "    #         \"target_leverage\",\n",
    "    #         \"position\",\n",
    "    #         \"RRratio_adj_fee_category\",\n",
    "    #         \"threshold_winRatio\",\n",
    "    #         \"threshold_frequency\",\n",
    "    #         \"threshold_frequencyTotal\",\n",
    "    #         \"symbol_extracted_len\",\n",
    "    #         \"symbol_extracted_len_pct\",\n",
    "    #         \"frequencyTotal\",\n",
    "    #         \"frequencyMean\",\n",
    "    #         \"winRatio\",\n",
    "    #         \"profit_pct_final\",\n",
    "    #         \"mean_return\",\n",
    "    #         \"std_return\",\n",
    "    #         \"max_drawdown\",\n",
    "    #         \"max_drawdown_scaled\",\n",
    "    #         \"sharpe_ratio\",\n",
    "    #         \"sortino_ratio\",\n",
    "    #         \"profit_factor\",\n",
    "    #         \"mse\",\n",
    "    #         \"r2\",\n",
    "    #         \"assets_max_drawdown\"\n",
    "    #         ]\n",
    "\n",
    "        \n",
    "    if show_figure:\n",
    "    \n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "        # Create a GridSpec layout with 2 columns\n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1], wspace=0.1)\n",
    "    \n",
    "        # Create a subplot for the main plot\n",
    "        ax_plot = fig.add_subplot(gs[0])\n",
    "        ax_plot.step(np.arange(len(table_trade_result_agg)), profit_pct_cum)\n",
    "    \n",
    "        # Add vertical lines to mark the change points between TRAIN and TEST data        \n",
    "        change_indices = np.where(table_trade_result_agg['dataType'].values[:-1] != table_trade_result_agg['dataType'].values[1:])[0] + 1\n",
    "        for idx in change_indices:\n",
    "            ax_plot.axvline(x=idx, color='r', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "        # Create a subplot for the title\n",
    "        ax_title = fig.add_subplot(gs[1])\n",
    "        ax_title.axis('off')\n",
    "        ax_title.text(0, 0.5, title, ha='left', va='center', fontsize=8, wrap=True)\n",
    "    \n",
    "        # Apply constrained_layout to the figure\n",
    "        # fig.constrained_layout()\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        if save_figure:\n",
    "            # payload = f\"{interval}_{target_loss}_{target_loss_pct}_{target_leverage}_{position}_{RRratio_adj_fee_category}_{threshold_winRatio:.2f}_{threshold_frequency}_{threshold_frequencyTotal}_{mode_position}\"\n",
    "            payload = (\n",
    "                    f\"{interval}_{target_loss}_{target_loss_pct}_{target_leverage}_\"\n",
    "                    f\"{position}_{RRratio_adj_fee_category}_{threshold_winRatio:.2f}_\"\n",
    "                    f\"{threshold_frequency}_{threshold_frequencyTotal}_{mode_position}_{mode_profit}\"\n",
    "                    )\n",
    "            plt.savefig(os.path.join(path_dir_save_fig, f\"{payload}.png\"))\n",
    "        # else:\n",
    "        plt.show()\n",
    "        \n",
    "        plt.close('all')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297118b6-2c46-4a3c-b6b1-e4abccc5c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = get_output_row(table_trade_result_agg, \n",
    "                    symbol_extracted, \n",
    "                    symbol_extracted_len, \n",
    "                    symbol_extracted_len_pct, \n",
    "                    interval,\n",
    "                    target_loss, \n",
    "                    target_loss_pct, \n",
    "                    target_leverage,\n",
    "                    position,\n",
    "                    RRratio_adj_fee_category, \n",
    "                    threshold_winRatio,\n",
    "                    threshold_frequency, \n",
    "                    threshold_frequencyTotal, \n",
    "                    path_dir_save_fig,\n",
    "                    mode_position,\n",
    "                    mode_profit, \n",
    "                    show_figure, \n",
    "                    save_figure, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2de804-e5ca-450c-a18b-290225761c23",
   "metadata": {},
   "source": [
    "#### v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf365ca3-eb63-4b11-88d1-8321f00da34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_row(table_trade_result_agg, \n",
    "                symbol_extracted, \n",
    "                symbol_extracted_len, \n",
    "                symbol_extracted_len_pct, \n",
    "                interval, \n",
    "                target_loss,\n",
    "                target_loss_pct,\n",
    "                target_leverage, \n",
    "                position, \n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio, \n",
    "                threshold_frequency, \n",
    "                threshold_frequencyTotal, \n",
    "                path_dir_save_fig,\n",
    "                mode_profit='SIMPLE',\n",
    "                show_figure=False,\n",
    "                save_figure=False):\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add target_loss_pct\n",
    "    v1.2\n",
    "        simplified by gpt.\n",
    "        modify get_amount_agg algorithm which uses index_entry & exit instead timemap.\n",
    "        \n",
    "        v1.2.1\n",
    "            add divide bar on title.\n",
    "    v1.3\n",
    "        modify get_amount_agg to get_minimum_assets.\n",
    "\n",
    "    last confirmed at, 20240704 1601.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate win ratio\n",
    "    frequencyTotal = len(table_trade_result_agg)    \n",
    "    winRatio = len(table_trade_result_agg[table_trade_result_agg.status == 'TP']) / frequencyTotal\n",
    "    \n",
    "    # Calculate cumulative and final profit percentage\n",
    "    profit_pct_cum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy()) if mode_profit == 'SIMPLE' else (np.cumprod(table_trade_result_agg['profit'].to_numpy() + 1) - 1) * 100\n",
    "    profit_pct_final = profit_pct_cum[-1] if profit_pct_cum.size > 0 else 0\n",
    "\n",
    "    frequencyMean = frequencyTotal / symbol_extracted_len if symbol_extracted_len != 0 else 0\n",
    "\n",
    "    # Calculate Sharpe and Sortino Ratios\n",
    "    profit = table_trade_result_agg.profit.to_numpy()\n",
    "    mean_return = np.mean(profit) if profit.size > 0 else 0\n",
    "    std_return = np.std(profit) if profit.size > 0 else 0\n",
    "    sharpe_ratio = (mean_return - 0) / std_return if std_return != 0 else 0\n",
    "    downside_returns = profit[profit < 0]\n",
    "    downside_deviation = np.std(downside_returns) if downside_returns.size > 0 else 0\n",
    "    sortino_ratio = (mean_return - 0) / downside_deviation if downside_deviation != 0 else 0\n",
    "\n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.cumsum(profit)\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "    cumulative_returns_min, cumulative_returns_max = cumulative_returns.min(), cumulative_returns.max()\n",
    "    cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min) if cumulative_returns_max - cumulative_returns_min != 0 else np.zeros_like(cumulative_returns)\n",
    "    drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "    max_drawdown_scaled = np.min(drawdowns_scaled) if drawdowns_scaled.size > 0 else 0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    total_profit = np.sum(profit[profit > 0])\n",
    "    total_loss = -np.sum(profit[profit < 0])\n",
    "    profit_factor = total_profit / total_loss if total_loss != 0 else 0\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    x = np.linspace(0, 1, cumulative_returns_scaled.size)\n",
    "    y_actual = x\n",
    "    y_predicted = cumulative_returns_scaled\n",
    "    mse = mean_squared_error(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "    r2 = r2_score(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "\n",
    "    if mode_profit == 'SIMPLE':        \n",
    "        events, \\\n",
    "        assets_over_time, \\\n",
    "        assets_min_required, \\\n",
    "        assets_max_drawdown = get_minimum_assets(table_trade_result_agg)\n",
    "        \n",
    "        profit_pct_final_min = abs(assets_over_time[-1] / assets_max_drawdown) * 100\n",
    "        profit_pct_final_max = abs(assets_over_time[-1] / assets_min_required) * 100\n",
    "    else:\n",
    "        assets_min_required = np.nan\n",
    "        assets_max_drawdown = np.nan\n",
    "        profit_pct_final_min = profit_pct_final\n",
    "        profit_pct_final_max = profit_pct_final   \n",
    "        \n",
    "    assets_min_required_const = abs(assets_min_required / target_loss)\n",
    "    assets_max_drawdown_const = abs(assets_max_drawdown / target_loss)\n",
    "    \n",
    "        \n",
    "    profit_pct_daily, \\\n",
    "    profit_pct_monthly, \\\n",
    "    profit_pct_yearly = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final,\n",
    "                                        mode_profit) \n",
    "    profit_pct_daily_min, \\\n",
    "    profit_pct_monthly_min, \\\n",
    "    profit_pct_yearly_min = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final_min,\n",
    "                                        mode_profit)\n",
    "    profit_pct_daily_max, \\\n",
    "    profit_pct_monthly_max, \\\n",
    "    profit_pct_yearly_max = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final_max,\n",
    "                                        mode_profit)\n",
    "\n",
    "    \n",
    "    row = [\n",
    "        interval,\n",
    "        target_loss,\n",
    "        target_loss_pct,\n",
    "        target_leverage,\n",
    "        position,\n",
    "        RRratio_adj_fee_category,\n",
    "        threshold_winRatio,\n",
    "        threshold_frequency,\n",
    "        threshold_frequencyTotal,\n",
    "        \"{}\".format(symbol_extracted.tolist()),\n",
    "        symbol_extracted_len,\n",
    "        symbol_extracted_len_pct,\n",
    "        \n",
    "        frequencyTotal,\n",
    "        frequencyMean,\n",
    "        \n",
    "        winRatio,\n",
    "        \n",
    "        assets_min_required_const,\n",
    "        assets_max_drawdown_const,\n",
    "        profit_pct_final,\n",
    "        profit_pct_daily, \n",
    "        profit_pct_monthly,\n",
    "        profit_pct_yearly,\n",
    "        profit_pct_final_min,\n",
    "        profit_pct_daily_min, \n",
    "        profit_pct_monthly_min,\n",
    "        profit_pct_yearly_min,\n",
    "        profit_pct_final_max,\n",
    "        profit_pct_daily_max, \n",
    "        profit_pct_monthly_max,\n",
    "        profit_pct_yearly_max,\n",
    "        \n",
    "        mean_return,\n",
    "        std_return,\n",
    "        max_drawdown,\n",
    "        max_drawdown_scaled,\n",
    "        sharpe_ratio,\n",
    "        sortino_ratio,\n",
    "        profit_factor,\n",
    "        mse,\n",
    "        r2,\n",
    "    ]\n",
    "    \n",
    "    # Generate title string\n",
    "    title = (\n",
    "        f\"interval : {interval}\\n\"\n",
    "        f\"target_loss : {target_loss}\\n\"\n",
    "        f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "        f\"target_leverage : {target_leverage}\\n\"\n",
    "        f\"position : {position}\\n\"\n",
    "        f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "        f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "        f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "        f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "        f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "        f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"frequencyTotal : {frequencyTotal}\\n\"\n",
    "        f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"winRatio : {winRatio:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"assets_min_required_const : {assets_min_required_const:.2f}\\n\"\n",
    "        f\"assets_max_drawdown_const : {assets_max_drawdown_const:.2f}\\n\"\n",
    "        f\"profit_pct_final : {profit_pct_final:.2f} ({profit_pct_final_min:.2f}~{profit_pct_final_max:.2f})\\n\"\n",
    "        f\"profit_pct_daily : {profit_pct_daily:.2f} ({profit_pct_daily_min:.2f}~{profit_pct_daily_max:.2f})\\n\"\n",
    "        f\"profit_pct_monthly : {profit_pct_monthly:.2f} ({profit_pct_monthly_min:.2f}~{profit_pct_monthly_max:.2f})\\n\"\n",
    "        f\"profit_pct_yearly : {profit_pct_yearly:.2f} ({profit_pct_yearly_min:.2f}~{profit_pct_yearly_max:.2f})\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"mean_return : {mean_return:.2f}\\n\"\n",
    "        f\"std_return : {std_return:.2f}\\n\"\n",
    "        f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "        f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "        f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "        f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "        f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "        f\"mse : {mse:.2f}\\n\"\n",
    "        f\"r2 : {r2:.2f}\"\n",
    "    )\n",
    "    \n",
    "    # # Mapping row indices to variable names for title generation\n",
    "    # row_labels = [\n",
    "    #         \"interval\",\n",
    "    #         \"target_loss\",\n",
    "    #         \"target_loss_pct\",\n",
    "    #         \"target_leverage\",\n",
    "    #         \"position\",\n",
    "    #         \"RRratio_adj_fee_category\",\n",
    "    #         \"threshold_winRatio\",\n",
    "    #         \"threshold_frequency\",\n",
    "    #         \"threshold_frequencyTotal\",\n",
    "    #         \"symbol_extracted_len\",\n",
    "    #         \"symbol_extracted_len_pct\",\n",
    "    #         \"frequencyTotal\",\n",
    "    #         \"frequencyMean\",\n",
    "    #         \"winRatio\",\n",
    "    #         \"profit_pct_final\",\n",
    "    #         \"mean_return\",\n",
    "    #         \"std_return\",\n",
    "    #         \"max_drawdown\",\n",
    "    #         \"max_drawdown_scaled\",\n",
    "    #         \"sharpe_ratio\",\n",
    "    #         \"sortino_ratio\",\n",
    "    #         \"profit_factor\",\n",
    "    #         \"mse\",\n",
    "    #         \"r2\",\n",
    "    #         \"assets_max_drawdown\"\n",
    "    #         ]\n",
    "\n",
    "        \n",
    "    if show_figure:\n",
    "    \n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "        # Create a GridSpec layout with 2 columns\n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1], wspace=0.1)\n",
    "    \n",
    "        # Create a subplot for the main plot\n",
    "        ax_plot = fig.add_subplot(gs[0])\n",
    "        ax_plot.step(np.arange(len(table_trade_result_agg)), profit_pct_cum)\n",
    "    \n",
    "        # Add vertical lines to mark the change points between TRAIN and TEST data        \n",
    "        change_indices = np.where(table_trade_result_agg['dataType'].values[:-1] != table_trade_result_agg['dataType'].values[1:])[0] + 1\n",
    "        for idx in change_indices:\n",
    "            ax_plot.axvline(x=idx, color='r', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "        # Create a subplot for the title\n",
    "        ax_title = fig.add_subplot(gs[1])\n",
    "        ax_title.axis('off')\n",
    "        ax_title.text(0, 0.5, title, ha='left', va='center', fontsize=8, wrap=True)\n",
    "    \n",
    "        # Apply constrained_layout to the figure\n",
    "        # fig.constrained_layout()\n",
    "        # fig.tight_layout()\n",
    "\n",
    "        if save_figure:\n",
    "            payload = f\"{interval}_{target_loss}_{target_loss_pct}_{target_leverage}_{position}_{RRratio_adj_fee_category}_{threshold_winRatio:.2f}_{threshold_frequency}_{threshold_frequencyTotal}\"\n",
    "            plt.savefig(os.path.join(path_dir_save_fig, f\"{payload}.png\"))\n",
    "        # else:\n",
    "        plt.show()\n",
    "        \n",
    "        plt.close('all')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93e603-29fe-436c-8bf0-b36eadce39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = get_output_row(table_trade_result_agg, \n",
    "                    symbol_extracted, \n",
    "                    symbol_extracted_len, \n",
    "                    symbol_extracted_len_pct, \n",
    "                    interval,\n",
    "                    target_loss, \n",
    "                    target_loss_pct, \n",
    "                    target_leverage,\n",
    "                    position,\n",
    "                    RRratio_adj_fee_category, \n",
    "                    threshold_winRatio,\n",
    "                    threshold_frequency, \n",
    "                    threshold_frequencyTotal, \n",
    "                    path_dir_save_fig,\n",
    "                    mode_profit, \n",
    "                    show_figure, \n",
    "                    # save_figure, \n",
    "                    1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c783432-2c02-4f27-997c-f0aafc678830",
   "metadata": {},
   "source": [
    "#### v1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f4b06-53dc-4959-8767-d8d58b1f2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_row(table_trade_result_agg, \n",
    "                symbol_extracted, \n",
    "                symbol_extracted_len, \n",
    "                symbol_extracted_len_pct, \n",
    "                interval, \n",
    "                target_loss,\n",
    "                target_loss_pct,\n",
    "                target_leverage, \n",
    "                position, \n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio, \n",
    "                threshold_frequency, \n",
    "                threshold_frequencyTotal, \n",
    "                path_dir_save_fig,\n",
    "                mode_profit='SIMPLE',\n",
    "                show_figure=False,\n",
    "                save_figure=False):\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add target_loss_pct\n",
    "    v1.2\n",
    "        simplified by gpt.\n",
    "        modify get_amount_agg algorithm which uses index_entry & exit instead timemap.\n",
    "        \n",
    "        v1.2.1\n",
    "            add divide bar on title.\n",
    "\n",
    "    last confirmed at, 20240703 0908.\n",
    "    \"\"\"\n",
    "\n",
    "    # # Helper function to convert interval to number of minutes\n",
    "    # def itv_to_number(interval):\n",
    "    #     interval_map = {'1m': 1, '5m': 5, '15m': 15, '30m': 30, '1h': 60, '4h': 240, '1d': 1440}\n",
    "    #     return interval_map.get(interval, 1)\n",
    "    \n",
    "    # Calculate win ratio\n",
    "    frequencyTotal = len(table_trade_result_agg)    \n",
    "    winRatio = len(table_trade_result_agg[table_trade_result_agg.status == 'TP']) / frequencyTotal\n",
    "    \n",
    "    # Calculate cumulative and final profit percentage\n",
    "    profit_pct_cum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy()) if mode_profit == 'SIMPLE' else (np.cumprod(table_trade_result_agg['profit'].to_numpy() + 1) - 1) * 100\n",
    "    profit_pct_final = profit_pct_cum[-1] if profit_pct_cum.size > 0 else 0\n",
    "\n",
    "    frequencyMean = frequencyTotal / symbol_extracted_len if symbol_extracted_len != 0 else 0\n",
    "\n",
    "    # Calculate Sharpe and Sortino Ratios\n",
    "    profit = table_trade_result_agg.profit.to_numpy()\n",
    "    mean_return = np.mean(profit) if profit.size > 0 else 0\n",
    "    std_return = np.std(profit) if profit.size > 0 else 0\n",
    "    sharpe_ratio = (mean_return - 0) / std_return if std_return != 0 else 0\n",
    "    downside_returns = profit[profit < 0]\n",
    "    downside_deviation = np.std(downside_returns) if downside_returns.size > 0 else 0\n",
    "    sortino_ratio = (mean_return - 0) / downside_deviation if downside_deviation != 0 else 0\n",
    "\n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.cumsum(profit)\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "    cumulative_returns_min, cumulative_returns_max = cumulative_returns.min(), cumulative_returns.max()\n",
    "    cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min) if cumulative_returns_max - cumulative_returns_min != 0 else np.zeros_like(cumulative_returns)\n",
    "    drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "    max_drawdown_scaled = np.min(drawdowns_scaled) if drawdowns_scaled.size > 0 else 0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    total_profit = np.sum(profit[profit > 0])\n",
    "    total_loss = -np.sum(profit[profit < 0])\n",
    "    profit_factor = total_profit / total_loss if total_loss != 0 else 0\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    x = np.linspace(0, 1, cumulative_returns_scaled.size)\n",
    "    y_actual = x\n",
    "    y_predicted = cumulative_returns_scaled\n",
    "    mse = mean_squared_error(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "    r2 = r2_score(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "\n",
    "    \n",
    "    map_amount_agg, \\\n",
    "    map_amount_agg_max = get_amount_agg(table_trade_result_agg,\n",
    "                                           interval)\n",
    "    \n",
    "    \n",
    "    profit_pct_daily, \\\n",
    "    profit_pct_monthly, \\\n",
    "    profit_pct_yearly = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final,\n",
    "                                        mode_profit)    \n",
    "\n",
    "    \n",
    "    row = [\n",
    "        interval,\n",
    "        target_loss,\n",
    "        target_loss_pct,\n",
    "        target_leverage,\n",
    "        position,\n",
    "        RRratio_adj_fee_category,\n",
    "        threshold_winRatio,\n",
    "        threshold_frequency,\n",
    "        threshold_frequencyTotal,\n",
    "        \"{}\".format(symbol_extracted.tolist()),\n",
    "        symbol_extracted_len,\n",
    "        symbol_extracted_len_pct,\n",
    "        frequencyTotal,\n",
    "        frequencyMean,\n",
    "        winRatio,\n",
    "        profit_pct_final,\n",
    "        profit_pct_daily,       # Changed to profit_pct_daily\n",
    "        profit_pct_monthly,     # Changed to profit_pct_monthly\n",
    "        profit_pct_yearly,      # Changed to profit_pct_yearly\n",
    "        mean_return,\n",
    "        std_return,\n",
    "        max_drawdown,\n",
    "        max_drawdown_scaled,\n",
    "        sharpe_ratio,\n",
    "        sortino_ratio,\n",
    "        profit_factor,\n",
    "        mse,\n",
    "        r2,\n",
    "        map_amount_agg_max,\n",
    "    ]\n",
    "    \n",
    "    # Generate title string\n",
    "    title = (\n",
    "        f\"interval : {interval}\\n\"\n",
    "        f\"target_loss : {target_loss}\\n\"\n",
    "        f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "        f\"target_leverage : {target_leverage}\\n\"\n",
    "        f\"position : {position}\\n\"\n",
    "        f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "        f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "        f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "        f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "        f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "        f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"frequencyTotal : {frequencyTotal}\\n\"\n",
    "        f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"winRatio : {winRatio:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"profit_pct_final : {profit_pct_final:.2f}\\n\"\n",
    "        f\"profit_pct_daily : {profit_pct_daily:.2f}\\n\"          # Changed to profit_pct_daily\n",
    "        f\"profit_pct_monthly : {profit_pct_monthly:.2f}\\n\"      # Changed to profit_pct_monthly\n",
    "        f\"profit_pct_yearly : {profit_pct_yearly:.2f}\\n\"        # Changed to profit_pct_yearly\n",
    "        f\"mean_return : {mean_return:.2f}\\n\"\n",
    "        f\"std_return : {std_return:.2f}\\n\"\n",
    "        f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "        f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "        f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "        f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "        f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "        f\"mse : {mse:.2f}\\n\"\n",
    "        f\"r2 : {r2:.2f}\\n\"\n",
    "        f\"map_amount_agg_max : {map_amount_agg_max:.2f}\"\n",
    "    )\n",
    "    \n",
    "    # # Mapping row indices to variable names for title generation\n",
    "    # row_labels = [\n",
    "    #         \"interval\",\n",
    "    #         \"target_loss\",\n",
    "    #         \"target_loss_pct\",\n",
    "    #         \"target_leverage\",\n",
    "    #         \"position\",\n",
    "    #         \"RRratio_adj_fee_category\",\n",
    "    #         \"threshold_winRatio\",\n",
    "    #         \"threshold_frequency\",\n",
    "    #         \"threshold_frequencyTotal\",\n",
    "    #         \"symbol_extracted_len\",\n",
    "    #         \"symbol_extracted_len_pct\",\n",
    "    #         \"frequencyTotal\",\n",
    "    #         \"frequencyMean\",\n",
    "    #         \"winRatio\",\n",
    "    #         \"profit_pct_final\",\n",
    "    #         \"mean_return\",\n",
    "    #         \"std_return\",\n",
    "    #         \"max_drawdown\",\n",
    "    #         \"max_drawdown_scaled\",\n",
    "    #         \"sharpe_ratio\",\n",
    "    #         \"sortino_ratio\",\n",
    "    #         \"profit_factor\",\n",
    "    #         \"mse\",\n",
    "    #         \"r2\",\n",
    "    #         \"map_amount_agg_max\"\n",
    "    #         ]\n",
    "\n",
    "\n",
    "    # # Generate title string from row and labels\n",
    "    # title = \"\\n\".join([f\"{label} : {value}\" if not isinstance(value, float) else f\"{label} : {value:.2f}\" for label, value in zip(row_labels, row)])\n",
    "    # print(title)\n",
    "\n",
    "\n",
    "    if show_figure:\n",
    "        fig = plt.figure()\n",
    "        plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cum)\n",
    "        \n",
    "        # income - commission cannot apply cumprod concept yet.\n",
    "            # profit_pct_cum can explain cumprod, cause it's independent from target_loss (quantity).\n",
    "        # income_commission_sum = np.cumsum(table_trade_result_agg['income - commission'].to_numpy())\n",
    "        # plt.step(np.arange(len(table_trade_result_agg)), income_commission_sum)\n",
    "        \n",
    "        # Add vertical lines to mark the change points between TRAIN and TEST data        \n",
    "        change_indices = np.where(table_trade_result_agg['dataType'].values[:-1] != table_trade_result_agg['dataType'].values[1:])[0] + 1\n",
    "        for idx in change_indices:\n",
    "            plt.axvline(x=idx, color='r', linestyle='--', linewidth=0.5)\n",
    "            \n",
    "        plt.title(title, x=0.01, y=0, fontsize=8, horizontalalignment='left')\n",
    "\n",
    "        if save_figure:\n",
    "            fig.tight_layout()\n",
    "            # plt.subplots_adjust(left=0.1, right=0.1, bottom=0.0, top=0.0, wspace=0.2, hspace=0.2)\n",
    "            payload = f\"{interval}_{target_loss}_{target_loss_pct}_{target_leverage}_{position}_{RRratio_adj_fee_category}_{threshold_winRatio}_{threshold_frequency}_{threshold_frequencyTotal}\"\n",
    "            plt.savefig(os.path.join(path_dir_save_fig, f\"{payload}.png\"))\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3881b-4521-428e-b84d-ce1f4b7dae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = get_output_row(table_trade_result_agg, \n",
    "                    symbol_extracted, \n",
    "                    symbol_extracted_len, \n",
    "                    symbol_extracted_len_pct, \n",
    "                    interval,\n",
    "                    target_loss, \n",
    "                    target_loss_pct, \n",
    "                    target_leverage,\n",
    "                    position,\n",
    "                    RRratio_adj_fee_category, \n",
    "                    threshold_winRatio,\n",
    "                    threshold_frequency, \n",
    "                    threshold_frequencyTotal, \n",
    "                    path_dir_save_fig,\n",
    "                    mode_profit, \n",
    "                    show_figure, \n",
    "                    save_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcf6b0-d581-44e3-80b5-1b68bed04de0",
   "metadata": {},
   "source": [
    "#### v1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff760b9-ac88-4fa9-b8e0-f2dfd3d800f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_row(table_trade_result_agg, \n",
    "                symbol_extracted, \n",
    "                symbol_extracted_len, \n",
    "                symbol_extracted_len_pct, \n",
    "                interval, \n",
    "                target_loss,\n",
    "                target_loss_pct,\n",
    "                target_leverage, \n",
    "                position, \n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio, \n",
    "                threshold_frequency, \n",
    "                threshold_frequencyTotal, \n",
    "                path_dir_save_fig,\n",
    "                mode_profit='SIMPLE',\n",
    "                show_figure=False,\n",
    "                save_figure=False):\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add target_loss_pct\n",
    "    v1.2\n",
    "        simplified by gpt.\n",
    "        modify get_amount_agg algorithm which uses index_entry & exit instead timemap.\n",
    "\n",
    "    last confirmed at, 20240630 1805.\n",
    "    \"\"\"\n",
    "\n",
    "    # # Helper function to convert interval to number of minutes\n",
    "    # def itv_to_number(interval):\n",
    "    #     interval_map = {'1m': 1, '5m': 5, '15m': 15, '30m': 30, '1h': 60, '4h': 240, '1d': 1440}\n",
    "    #     return interval_map.get(interval, 1)\n",
    "    \n",
    "    # Calculate win ratio\n",
    "    frequencyTotal = len(table_trade_result_agg)    \n",
    "    winRatio = len(table_trade_result_agg[table_trade_result_agg.status == 'TP']) / frequencyTotal\n",
    "    \n",
    "    # Calculate cumulative and final profit percentage\n",
    "    profit_pct_cum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy()) if mode_profit == 'SIMPLE' else (np.cumprod(table_trade_result_agg['profit'].to_numpy() + 1) - 1) * 100\n",
    "    profit_pct_final = profit_pct_cum[-1] if profit_pct_cum.size > 0 else 0\n",
    "\n",
    "    frequencyMean = frequencyTotal / symbol_extracted_len if symbol_extracted_len != 0 else 0\n",
    "\n",
    "    # Calculate Sharpe and Sortino Ratios\n",
    "    profit = table_trade_result_agg.profit.to_numpy()\n",
    "    mean_return = np.mean(profit) if profit.size > 0 else 0\n",
    "    std_return = np.std(profit) if profit.size > 0 else 0\n",
    "    sharpe_ratio = (mean_return - 0) / std_return if std_return != 0 else 0\n",
    "    downside_returns = profit[profit < 0]\n",
    "    downside_deviation = np.std(downside_returns) if downside_returns.size > 0 else 0\n",
    "    sortino_ratio = (mean_return - 0) / downside_deviation if downside_deviation != 0 else 0\n",
    "\n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.cumsum(profit)\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdowns) if drawdowns.size > 0 else 0\n",
    "    cumulative_returns_min, cumulative_returns_max = cumulative_returns.min(), cumulative_returns.max()\n",
    "    cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min) if cumulative_returns_max - cumulative_returns_min != 0 else np.zeros_like(cumulative_returns)\n",
    "    drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "    max_drawdown_scaled = np.min(drawdowns_scaled) if drawdowns_scaled.size > 0 else 0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    total_profit = np.sum(profit[profit > 0])\n",
    "    total_loss = -np.sum(profit[profit < 0])\n",
    "    profit_factor = total_profit / total_loss if total_loss != 0 else 0\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    x = np.linspace(0, 1, cumulative_returns_scaled.size)\n",
    "    y_actual = x\n",
    "    y_predicted = cumulative_returns_scaled\n",
    "    mse = mean_squared_error(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "    r2 = r2_score(y_actual, y_predicted) if y_actual.size > 0 and y_predicted.size > 0 else 0\n",
    "\n",
    "    \n",
    "    map_amount_agg_max = get_amount_agg(table_trade_result_agg)\n",
    "\n",
    "    profit_pct_daily, \\\n",
    "    profit_pct_monthly, \\\n",
    "    profit_pct_yearly = get_periodic_profit(table_trade_result_agg, \n",
    "                                        profit_pct_final,\n",
    "                                        mode_profit)    \n",
    "\n",
    "    \n",
    "    row = [\n",
    "        interval,\n",
    "        target_loss,\n",
    "        target_loss_pct,\n",
    "        target_leverage,\n",
    "        position,\n",
    "        RRratio_adj_fee_category,\n",
    "        threshold_winRatio,\n",
    "        threshold_frequency,\n",
    "        threshold_frequencyTotal,\n",
    "        \"{}\".format(symbol_extracted.tolist()),\n",
    "        symbol_extracted_len,\n",
    "        symbol_extracted_len_pct,\n",
    "        frequencyTotal,\n",
    "        frequencyMean,\n",
    "        winRatio,\n",
    "        profit_pct_final,\n",
    "        profit_pct_daily,       # Changed to profit_pct_daily\n",
    "        profit_pct_monthly,     # Changed to profit_pct_monthly\n",
    "        profit_pct_yearly,      # Changed to profit_pct_yearly\n",
    "        mean_return,\n",
    "        std_return,\n",
    "        max_drawdown,\n",
    "        max_drawdown_scaled,\n",
    "        sharpe_ratio,\n",
    "        sortino_ratio,\n",
    "        profit_factor,\n",
    "        mse,\n",
    "        r2,\n",
    "        map_amount_agg_max,\n",
    "    ]\n",
    "    \n",
    "    # Generate title string\n",
    "    title = (\n",
    "        f\"interval : {interval}\\n\"\n",
    "        f\"target_loss : {target_loss}\\n\"\n",
    "        f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "        f\"target_leverage : {target_leverage}\\n\"\n",
    "        f\"position : {position}\\n\"\n",
    "        f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "        f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "        f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "        f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "        f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "        f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"frequencyTotal : {frequencyTotal}\\n\"\n",
    "        f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"winRatio : {winRatio:.2f}\\n\"\n",
    "        f\"------------------------\\n\"\n",
    "        f\"profit_pct_final : {profit_pct_final:.2f}\\n\"\n",
    "        f\"profit_pct_daily : {profit_pct_daily:.2f}\\n\"          # Changed to profit_pct_daily\n",
    "        f\"profit_pct_monthly : {profit_pct_monthly:.2f}\\n\"      # Changed to profit_pct_monthly\n",
    "        f\"profit_pct_yearly : {profit_pct_yearly:.2f}\\n\"        # Changed to profit_pct_yearly\n",
    "        f\"mean_return : {mean_return:.2f}\\n\"\n",
    "        f\"std_return : {std_return:.2f}\\n\"\n",
    "        f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "        f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "        f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "        f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "        f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "        f\"mse : {mse:.2f}\\n\"\n",
    "        f\"r2 : {r2:.2f}\\n\"\n",
    "        f\"map_amount_agg_max : {map_amount_agg_max:.2f}\"\n",
    "    )\n",
    "\n",
    "    # title = (\n",
    "    #     f\"interval : {interval}\\n\"\n",
    "    #     f\"target_loss : {target_loss}\\n\"\n",
    "    #     f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "    #     f\"target_leverage : {target_leverage}\\n\"\n",
    "    #     f\"position : {position}\\n\"\n",
    "    #     f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "    #     f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "    #     f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "    #     f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "    #     f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "    #     f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "    #     f\"frequencyTotal : {frequencyTotal} ------------------------\\n\"\n",
    "    #     f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "    #     f\"winRatio : {winRatio:.2f} ------------------------\\n\"\n",
    "    #     f\"profit_pct_final : {profit_pct_final:.2f} ------------------------\\n\"\n",
    "    #     f\"profit_pct_daily : {profit_pct_daily:.2f}\\n\"          # Changed to profit_pct_daily\n",
    "    #     f\"profit_pct_monthly : {profit_pct_monthly:.2f}\\n\"      # Changed to profit_pct_monthly\n",
    "    #     f\"profit_pct_yearly : {profit_pct_yearly:.2f}\\n\"        # Changed to profit_pct_yearly\n",
    "    #     f\"mean_return : {mean_return:.2f}\\n\"\n",
    "    #     f\"std_return : {std_return:.2f}\\n\"\n",
    "    #     f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "    #     f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "    #     f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "    #     f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "    #     f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "    #     f\"mse : {mse:.2f}\\n\"\n",
    "    #     f\"r2 : {r2:.2f}\\n\"\n",
    "    #     f\"map_amount_agg_max : {map_amount_agg_max:.2f}\"\n",
    "    # )\n",
    "\n",
    "    # title = (\n",
    "    #     f\"interval : {interval}\\n\"\n",
    "    #     f\"target_loss : {target_loss}\\n\"\n",
    "    #     f\"target_loss_pct : {target_loss_pct}\\n\"\n",
    "    #     f\"target_leverage : {target_leverage}\\n\"\n",
    "    #     f\"position : {position}\\n\"\n",
    "    #     f\"RRratio_adj_fee_category : {RRratio_adj_fee_category}\\n\"\n",
    "    #     f\"threshold_winRatio : {threshold_winRatio:.2f}\\n\"\n",
    "    #     f\"threshold_frequency : {threshold_frequency}\\n\"\n",
    "    #     f\"threshold_frequencyTotal : {threshold_frequencyTotal}\\n\"\n",
    "    #     f\"symbol_extracted_len : {symbol_extracted_len}\\n\"\n",
    "    #     f\"symbol_extracted_len_pct : {symbol_extracted_len_pct:.2f}\\n\"\n",
    "    #     f\"frequencyTotal : {frequencyTotal}\\n\"\n",
    "    #     f\"frequencyMean : {frequencyMean:.2f}\\n\"\n",
    "    #     f\"winRatio : {winRatio:.2f}\\n\"\n",
    "    #     f\"profit_pct_final : {profit_pct_final:.2f}\\n\"\n",
    "    #     f\"profit_pct_daily : {profit_pct_daily:.2f}\\n\"          # Changed to profit_pct_daily\n",
    "    #     f\"profit_pct_monthly : {profit_pct_monthly:.2f}\\n\"      # Changed to profit_pct_monthly\n",
    "    #     f\"profit_pct_yearly : {profit_pct_yearly:.2f}\\n\"        # Changed to profit_pct_yearly\n",
    "    #     f\"mean_return : {mean_return:.2f}\\n\"\n",
    "    #     f\"std_return : {std_return:.2f}\\n\"\n",
    "    #     f\"max_drawdown : {max_drawdown:.2f}\\n\"\n",
    "    #     f\"max_drawdown_scaled : {max_drawdown_scaled:.2f}\\n\"\n",
    "    #     f\"sharpe_ratio : {sharpe_ratio:.2f}\\n\"\n",
    "    #     f\"sortino_ratio : {sortino_ratio:.2f}\\n\"\n",
    "    #     f\"profit_factor : {profit_factor:.2f}\\n\"\n",
    "    #     f\"mse : {mse:.2f}\\n\"\n",
    "    #     f\"r2 : {r2:.2f}\\n\"\n",
    "    #     f\"map_amount_agg_max : {map_amount_agg_max:.2f}\"\n",
    "    # )\n",
    "\n",
    "    \n",
    "    # # Mapping row indices to variable names for title generation\n",
    "    # row_labels = [\n",
    "    #         \"interval\",\n",
    "    #         \"target_loss\",\n",
    "    #         \"target_loss_pct\",\n",
    "    #         \"target_leverage\",\n",
    "    #         \"position\",\n",
    "    #         \"RRratio_adj_fee_category\",\n",
    "    #         \"threshold_winRatio\",\n",
    "    #         \"threshold_frequency\",\n",
    "    #         \"threshold_frequencyTotal\",\n",
    "    #         \"symbol_extracted_len\",\n",
    "    #         \"symbol_extracted_len_pct\",\n",
    "    #         \"frequencyTotal\",\n",
    "    #         \"frequencyMean\",\n",
    "    #         \"winRatio\",\n",
    "    #         \"profit_pct_final\",\n",
    "    #         \"mean_return\",\n",
    "    #         \"std_return\",\n",
    "    #         \"max_drawdown\",\n",
    "    #         \"max_drawdown_scaled\",\n",
    "    #         \"sharpe_ratio\",\n",
    "    #         \"sortino_ratio\",\n",
    "    #         \"profit_factor\",\n",
    "    #         \"mse\",\n",
    "    #         \"r2\",\n",
    "    #         \"map_amount_agg_max\"\n",
    "    #         ]\n",
    "\n",
    "\n",
    "    # # Generate title string from row and labels\n",
    "    # title = \"\\n\".join([f\"{label} : {value}\" if not isinstance(value, float) else f\"{label} : {value:.2f}\" for label, value in zip(row_labels, row)])\n",
    "    # print(title)\n",
    "\n",
    "\n",
    "    if show_figure:\n",
    "        fig = plt.figure()\n",
    "        plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cum)\n",
    "        \n",
    "        # Add vertical lines to mark the change points between TRAIN and TEST data        \n",
    "        change_indices = np.where(table_trade_result_agg['dataType'].values[:-1] != table_trade_result_agg['dataType'].values[1:])[0] + 1\n",
    "        for idx in change_indices:\n",
    "            plt.axvline(x=idx, color='r', linestyle='--', linewidth=0.5)\n",
    "            \n",
    "        plt.title(title, x=0.01, y=-0.1, fontsize=10, horizontalalignment='left')\n",
    "\n",
    "        if save_figure:\n",
    "            fig.tight_layout()\n",
    "            # plt.subplots_adjust(left=0.1, right=0.1, bottom=0.0, top=0.0, wspace=0.2, hspace=0.2)\n",
    "            payload = f\"{interval}_{target_loss}_{target_loss_pct}_{target_leverage}_{position}_{RRratio_adj_fee_category}_{threshold_winRatio}_{threshold_frequency}_{threshold_frequencyTotal}\"\n",
    "            plt.savefig(os.path.join(path_dir_save_fig, f\"{payload}.png\"))\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c1fc4-a40a-4aea-98c1-791892667b6a",
   "metadata": {},
   "source": [
    "#### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82726f-dcde-40d0-a674-bf3520ff6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_row(table_trade_result_agg, \n",
    "                symbol_extracted, \n",
    "                symbol_extracted_len, \n",
    "                symbol_extracted_len_pct, \n",
    "                interval, \n",
    "                target_loss,\n",
    "                target_loss_pct,\n",
    "                target_leverage, \n",
    "                position, \n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio, \n",
    "                threshold_frequency, \n",
    "                threshold_frequencyTotal, \n",
    "                path_dir_save_fig,\n",
    "                mode_profit='SIMPLE',\n",
    "                show_figure=False,\n",
    "                save_figure=False):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        add target_loss_pct\n",
    "\n",
    "    last confirmed at, 20240629 0937.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate win ratio\n",
    "    frequencyTotal = len(table_trade_result_agg)    \n",
    "    winRatio = len(table_trade_result_agg[table_trade_result_agg.status == 'TP']) / frequencyTotal\n",
    "\n",
    "    # Calculate cumulative and final profit percentage\n",
    "    if mode_profit == 'SIMPLE':\n",
    "        profit_pct_cum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy())\n",
    "    else:\n",
    "        profit_pct_cum = (np.cumprod(table_trade_result_agg['profit'].to_numpy() + 1) - 1) * 100\n",
    "    profit_pct_final = profit_pct_cum[-1] if profit_pct_cum.size > 0 else 0\n",
    "\n",
    "    frequencyMean = frequencyTotal / symbol_extracted_len if symbol_extracted_len != 0 else 0\n",
    "\n",
    "    # Calculate Sharpe Ratio\n",
    "    profit = table_trade_result_agg.profit.to_numpy()\n",
    "    risk_free_rate = 0  # Assumed to be 0 for simplicity\n",
    "    mean_return = np.mean(profit) if len(profit) > 0 else 0\n",
    "    std_return = np.std(profit) if len(profit) > 0 else 0\n",
    "    sharpe_ratio = (mean_return - risk_free_rate) / std_return if std_return != 0 else 0\n",
    "\n",
    "    # Calculate Sortino Ratio\n",
    "    downside_returns = profit[profit < 0]\n",
    "    downside_deviation = np.std(downside_returns) if len(downside_returns) > 0 else 0\n",
    "    sortino_ratio = (mean_return - risk_free_rate) / downside_deviation if downside_deviation != 0 else 0\n",
    "\n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.cumsum(profit)\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    max_drawdown = np.min(drawdowns) if len(drawdowns) > 0 else 0\n",
    "\n",
    "    cumulative_returns_min = cumulative_returns.min() if len(cumulative_returns) > 0 else 0\n",
    "    cumulative_returns_max = cumulative_returns.max() if len(cumulative_returns) > 0 else 0\n",
    "    if cumulative_returns_max - cumulative_returns_min != 0:\n",
    "        cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min)\n",
    "    else:\n",
    "        cumulative_returns_scaled = np.zeros_like(cumulative_returns)\n",
    "    drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "    max_drawdown_scaled = np.min(drawdowns_scaled) if len(drawdowns_scaled) > 0 else 0\n",
    "\n",
    "    # Calculate Profit Factor\n",
    "    total_profit = np.sum(profit[profit > 0])\n",
    "    total_loss = -np.sum(profit[profit < 0])\n",
    "    profit_factor = total_profit / total_loss if total_loss != 0 else 0\n",
    "\n",
    "    # Calculate MSE and R2\n",
    "    x = np.linspace(0, 1, len(cumulative_returns_scaled))\n",
    "    y_actual = x\n",
    "    y_predicted = cumulative_returns_scaled\n",
    "    mse = mean_squared_error(y_actual, y_predicted) if len(y_actual) > 0 and len(y_predicted) > 0 else 0\n",
    "    r2 = r2_score(y_actual, y_predicted) if len(y_actual) > 0 and len(y_predicted) > 0 else 0\n",
    "\n",
    "    # Normalize timestamps\n",
    "    timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "    table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "    table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "\n",
    "    minutes = itv_to_number(interval)\n",
    "    timestamp_unit = 60 * minutes\n",
    "    table_trade_result_agg['timemap_entry'] /= timestamp_unit\n",
    "    table_trade_result_agg['timemap_exit'] /= timestamp_unit\n",
    "\n",
    "    map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]))\n",
    "    for row in table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy():\n",
    "        index_start, index_end, amount = row\n",
    "        map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "\n",
    "    map_amount_agg_max = map_amount_agg.max()\n",
    "\n",
    "    row = [\n",
    "        interval,\n",
    "        target_loss,\n",
    "        target_loss_pct,\n",
    "        target_leverage,\n",
    "        position,\n",
    "        RRratio_adj_fee_category,\n",
    "        threshold_winRatio,\n",
    "        threshold_frequency,\n",
    "        threshold_frequencyTotal,\n",
    "        \"{}\".format(symbol_extracted.tolist()),\n",
    "        symbol_extracted_len,\n",
    "        symbol_extracted_len_pct,\n",
    "        frequencyTotal,\n",
    "        frequencyMean,\n",
    "        winRatio,\n",
    "        profit_pct_final,\n",
    "        mean_return,\n",
    "        std_return,\n",
    "        max_drawdown,\n",
    "        max_drawdown_scaled,\n",
    "        sharpe_ratio,\n",
    "        sortino_ratio,\n",
    "        profit_factor,\n",
    "        mse,\n",
    "        r2,\n",
    "        map_amount_agg_max,\n",
    "    ]\n",
    "\n",
    "    title = ''\n",
    "    title += 'interval : {}\\n'.format(interval)\n",
    "    title += 'target_loss : {}\\n'.format(target_loss)\n",
    "    title += 'target_loss_pct : {}\\n'.format(target_loss_pct)\n",
    "    title += 'target_leverage : {}\\n'.format(target_leverage)\n",
    "    title += 'position : {}\\n'.format(position)\n",
    "    title += 'RRratio_adj_fee_category : {}\\n'.format(RRratio_adj_fee_category)\n",
    "    title += 'threshold_winRatio : {:.2f}\\n'.format(threshold_winRatio)\n",
    "    title += 'threshold_frequency : {}\\n'.format(threshold_frequency)\n",
    "    title += 'threshold_frequencyTotal : {}\\n'.format(threshold_frequencyTotal)\n",
    "    title += 'symbol_extracted_len : {}\\n'.format(symbol_extracted_len)\n",
    "    title += 'symbol_extracted_len_pct : {:.2f}\\n'.format(symbol_extracted_len_pct)\n",
    "    title += 'frequencyTotal : {}\\n'.format(frequencyTotal)\n",
    "    title += 'frequencyMean : {:.2f}\\n'.format(frequencyMean)\n",
    "    title += 'winRatio : {:.2f}\\n'.format(winRatio)\n",
    "    title += 'profit_pct_final : {:.2f}\\n'.format(profit_pct_final)\n",
    "    title += 'mean_return : {:.2f}\\n'.format(mean_return)\n",
    "    title += 'std_return : {:.2f}\\n'.format(std_return)\n",
    "    title += 'max_drawdown : {:.2f}\\n'.format(max_drawdown)\n",
    "    title += 'max_drawdown_scaled : {:.2f}\\n'.format(max_drawdown_scaled)\n",
    "    title += 'sharpe_ratio : {:.2f}\\n'.format(sharpe_ratio)\n",
    "    title += 'sortino_ratio : {:.2f}\\n'.format(sortino_ratio)\n",
    "    title += 'profit_factor : {:.2f}\\n'.format(profit_factor)\n",
    "    title += 'mse : {:.2f}\\n'.format(mse)\n",
    "    title += 'r2 : {:.2f}\\n'.format(r2)\n",
    "    title += 'map_amount_agg_max : {:.2f}'.format(map_amount_agg_max)\n",
    "\n",
    "    print(title)\n",
    "    clear_output()\n",
    "\n",
    "    if show_figure:\n",
    "        plt.figure()\n",
    "        plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cum)\n",
    "        plt.title(title, y=0., fontsize=10)\n",
    "\n",
    "        if save_figure:\n",
    "            plt.tight_layout()\n",
    "            payload = '{} {} {}\t{} {} {} {:.2f}'.format(interval, \n",
    "                                                        target_loss, \n",
    "                                                        target_loss_pct, \n",
    "                                                        target_leverage, \n",
    "                                                        position,\n",
    "                                                        RRratio_adj_fee_category, \n",
    "                                                        threshold_winRatio, \n",
    "                                                        threshold_frequency, \n",
    "                                                        threshold_frequencyTotal).split(' ')\n",
    "            \n",
    "            plt.savefig(os.path.join(path_dir_save_fig, \"{}.png\".format(payload)))\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ab646-206b-459f-9dcc-60953acb88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = get_output_row(table_trade_result_agg, \n",
    "                    symbol_extracted, \n",
    "                    symbol_extracted_len, \n",
    "                    symbol_extracted_len_pct, \n",
    "                    interval,\n",
    "                    target_loss, \n",
    "                    target_loss_pct, \n",
    "                    target_leverage,\n",
    "                    position,\n",
    "                    RRratio_adj_fee_category, \n",
    "                    threshold_winRatio,\n",
    "                    threshold_frequency, \n",
    "                    threshold_frequencyTotal, \n",
    "                    path_dir_save_fig,\n",
    "                    mode_profit, \n",
    "                    show_figure, \n",
    "                    save_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdeccbd-2f46-49b5-828c-3bfca4cbcf70",
   "metadata": {},
   "source": [
    "### get threshold_winRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaac158-a0a8-4e6f-9e4b-0c631536e717",
   "metadata": {},
   "source": [
    "#### v2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de3cde-cd89-4722-8e99-bbd41eb5a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_table(path_dir_table_trade_res):\n",
    "    table_trade_res_list = []\n",
    "    for index, file_name in enumerate(os.listdir(path_dir_table_trade_res)):        \n",
    "        path_file = os.path.join(path_dir_table_trade_res, file_name)        \n",
    "        if os.path.isfile(path_file):\n",
    "            table_trade_result_individual = pd.read_feather(path_file)\n",
    "            table_trade_res_list.append(table_trade_result_individual)\n",
    "    return pd.concat(table_trade_res_list)\n",
    "\n",
    "def process_table(table_trade_result, train_ratio, leverage_limits, target_loss, target_loss_pct, target_leverage, fee_market, unit_RRratio_adj_fee, leverage_rejection):\n",
    "    table_trade_result = add_datatype(table_trade_result, train_ratio)\n",
    "    table_trade_result = set_quantity(table_trade_result, leverage_limits, target_loss, target_loss_pct, target_leverage, fee_market, fee_market, unit_RRratio_adj_fee, leverage_rejection)\n",
    "    return table_trade_result\n",
    "\n",
    "def pivot_table(table_trade_result, positions, RRratio_adj_fee_categories):\n",
    "    table_trade_result_backup = table_trade_result.copy()\n",
    "    for position in positions:        \n",
    "        for RRratio_adj_fee_category in RRratio_adj_fee_categories:            \n",
    "            yield table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "\n",
    "def extract_symbols(table_trade_result_train, threshold_winRatio, threshold_frequency, threshold_incomeTotal=None):\n",
    "    table_trade_result_pivot = table_trade_result_train.pivot_table(index=[table_trade_result_train.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result_train.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "    table_trade_result_pivot['frequency'] = table_trade_result_pivot[('status', 'SL')] + table_trade_result_pivot[('status', 'TP')]\n",
    "    table_trade_result_pivot['winRatio'] = table_trade_result_pivot[('status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "    table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "    if threshold_incomeTotal is not None:\n",
    "        return table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)]\n",
    "    else:\n",
    "        return table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)]\n",
    "\n",
    "def process_aggregated_results(table_trade_result, symbol_extracted, mode_position):\n",
    "    table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "    table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "    if mode_position == 'SINGLE':\n",
    "        table_trade_result_agg = convert_to_position_single(table_trade_result_agg)\n",
    "    return table_trade_result_agg\n",
    "\n",
    "def main_process(intervals, dir_name_strategy, priceBox_value, point_value, zone_indicator, train_ratio, leverage_limits, target_loss, target_loss_pct, target_leverage, fee_market, unit_RRratio_adj_fee, leverage_rejection, positions, range_winRatio, threshold_frequency, threshold_frequencyTotal, path_dir_save_fig, mode_position, mode_profit, show_figure, save_figure):\n",
    "    result_list = []\n",
    "    for interval in intervals:        \n",
    "        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator, interval)    \n",
    "        table_trade_result = load_table(path_dir_table_trade_res)\n",
    "        \n",
    "        bank.sys_log.debug(\"IDEP : elasped time, load table_trade_result : {:.4f}s\".format(time.time() - start_time))\n",
    "        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        table_trade_result = process_table(table_trade_result, train_ratio, leverage_limits, target_loss, target_loss_pct, target_leverage, fee_market, unit_RRratio_adj_fee, leverage_rejection)\n",
    "\n",
    "        bank.sys_log.debug(\"IDEP : elasped time, process table : {:.4f}s\".format(time.time() - start_time))\n",
    "        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        RRratio_adj_fee_categories = np.unique(table_trade_result.RRratio_adj_fee_category) if len(positions) == 2 else []\n",
    "\n",
    "        for table_trade_result_train in pivot_table(table_trade_result, positions, RRratio_adj_fee_categories):\n",
    "            table_trade_result_train = table_trade_result[table_trade_result.dataType == 'TRAIN'] # extract symbol from TRAIN data only.\n",
    "\n",
    "            bank.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            try:\n",
    "                table_trade_result_pivot = table_trade_result_train.pivot_table(index=[table_trade_result_train.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result_train.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot['frequency'] = table_trade_result_pivot[('status', 'SL')] + table_trade_result_pivot[('status', 'TP')]\n",
    "                table_trade_result_pivot['winRatio'] = table_trade_result_pivot[('status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "                table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "            except Exception as e:\n",
    "                print(\"error in pivoting : {}\".format(e))\n",
    "                continue     \n",
    "\n",
    "            bank.sys_log.debug(\"IDEP : elasped time, pivoting : {:.4f}s\".format(time.time() - start_time))\n",
    "            bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "            for threshold_winRatio in range_winRatio:\n",
    "                bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                symbol_extracted = extract_symbols(table_trade_result_train, threshold_winRatio, threshold_frequency).index.droplevel()\n",
    "                symbol_extracted_len = len(symbol_extracted)\n",
    "                symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "\n",
    "                bank.sys_log.debug(\"IDEP : elasped time, symbol_extraction : {:.4f}s\".format(time.time() - start_time))\n",
    "                bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "                if symbol_extracted_len > 0:\n",
    "                    table_trade_result_agg = process_aggregated_results(table_trade_result, symbol_extracted, mode_position)\n",
    "                    frequencyTotal = len(table_trade_result_agg)\n",
    "\n",
    "                    if frequencyTotal > threshold_frequencyTotal:\n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()\n",
    "\n",
    "                        row = get_output_row(table_trade_result_agg, symbol_extracted, symbol_extracted_len, symbol_extracted_len_pct, interval, target_loss, target_loss_pct, target_leverage, position, RRratio_adj_fee_category, threshold_winRatio, threshold_frequency, threshold_frequencyTotal, path_dir_save_fig, mode_position, mode_profit, show_figure, save_figure)\n",
    "\n",
    "                        bank.sys_log.debug(\"IDEP : elasped time, get_output_row : {:.4f}s\".format(time.time() - start_time))\n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "                        result_list.append(row)\n",
    "    return result_list\n",
    "\n",
    "# Call the main process with appropriate arguments\n",
    "result = main_process(intervals, dir_name_strategy, priceBox_value, point_value, zone_indicator, train_ratio, leverage_limits, target_loss, target_loss_pct, target_leverage, fee_market, unit_RRratio_adj_fee, leverage_rejection, positions, range_winRatio, threshold_frequency, threshold_frequencyTotal, path_dir_save_fig, mode_position, mode_profit, show_figure, save_figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f0066-fa6c-4a39-9838-332ba5f0acb8",
   "metadata": {},
   "source": [
    "#### v2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16b9a5-1fb6-4c28-aaf4-5fcb6a696b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_limits = get_leverage_limit_by_symbol(bank)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a131a-96de-41f6-aaa6-0af4e0e9e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    make a table_trade_result_anchor.\n",
    "    loop for all.\n",
    "    eval. indicator added.\n",
    "        ~ mse, r2\n",
    "v2.1\n",
    "    apply functional.\n",
    "    add memory management.\n",
    "        in plt.savefig, not solved..\n",
    "    apply dataType.\n",
    "    \n",
    "    v2.1.1\n",
    "        apply set_quantity v1.4.1\n",
    "    v2.1.2\n",
    "        apply set_quantity v1.4.2\n",
    "        add phase for latency check.\n",
    "        add mode_position to get_output_row\n",
    "\n",
    "last confirmed at, 20240708 2256.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "priceBox_indicator = 'DC'\n",
    "# priceBox_indicator = 'BB'\n",
    "priceBox_value = 20\n",
    "priceBox_value = 60\n",
    "\n",
    "point_mode = 'CROSS'\n",
    "point_indicator = 'CCI'\n",
    "point_indicator = 'II'\n",
    "# point_indicator = 'DC'\n",
    "# point_indicator = 'BB'\n",
    "point_value = 20\n",
    "point_value = 21\n",
    "# point_value = 30\n",
    "\n",
    "zone_indicator = None\n",
    "# zone_indicator = 'MA'\n",
    "zone_value = 30\n",
    "\n",
    "dir_name_strategy = \"priceBox_{}_point_{}_{}\".format(priceBox_indicator, point_mode, point_indicator)\n",
    "\n",
    "\n",
    "\n",
    "intervals = [ '15m', '30m', '1h', '2h', '4h',]\n",
    "# intervals = ['30m', '1h', '2h', '4h',]\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_loss = 15 # USDT, for amount_entry.\n",
    "# target_loss = None\n",
    "\n",
    "target_loss_pct = 10 # %, for leverage.\n",
    "target_loss_pct = 15 # %, for leverage.\n",
    "target_loss_pct = 100\n",
    "# target_loss_pct = None\n",
    "\n",
    "leverage_rejection = True\n",
    "# leverage_rejection = False\n",
    "\n",
    "target_leverage = 1\n",
    "# target_leverage = 2\n",
    "# target_leverage = None\n",
    "\n",
    "\n",
    "\n",
    "fee_limit = 0.0002\n",
    "fee_market = 0.0005\n",
    "\n",
    "unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "\n",
    "\n",
    "\n",
    "mode_position = 'SINGLE'\n",
    "mode_position = 'MULTIPLE'\n",
    "\n",
    "mode_profit = 'SIMPLE'\n",
    "# mode_profit = 'COMPOUND'\n",
    "\n",
    "\n",
    "\n",
    "positions = ['LONG', 'SHORT']\n",
    "\n",
    "range_winRatio = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "threshold_frequency = 0\n",
    "threshold_frequencyTotal = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "payload = '4h_15_100_1_LONG_(1.6, 1.7]_0.42_0.0_50.0'\n",
    "# payload = '4h_15_100_1_LONG_(1.6, 1.7]_0.45_0.0_50.0'\n",
    "# payload = '4h_15_100_1_LONG_(0.0, 0.1]_0.90_0.0_50.0_SINGLE'\n",
    "# payload = '4h_15_100_1_LONG_(0.0, 0.1]_0.90_0.0_50.0_MULTIPLE'\n",
    "\n",
    "# payload = '2h\t15\t100\t1\tSHORT\t(0.3, 0.4]\t0.77\t0\t50'\n",
    "payload = re.split(r'[\\t_]', payload)\n",
    "\n",
    "\n",
    "intervals = [payload[0]]\n",
    "# target_loss = int(payload[1])\n",
    "# target_loss_pct = int(payload[2])\n",
    "# target_leverage = int(payload[3])\n",
    "positions = [payload[4]]\n",
    "RRratio_adj_fee_categories = [payload[5]]\n",
    "range_winRatio = [float(payload[6])]\n",
    "threshold_frequency = float(payload[7])\n",
    "threshold_frequencyTotal = float(payload[8])\n",
    "# mode_position = payload[9]\n",
    "\n",
    "\n",
    "\n",
    "show_figure = 1\n",
    "save_figure = 1\n",
    "\n",
    "\n",
    "# path_dir_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\{}\\image\\{}_{}\\total\".format(dir_name_strategy, priceBox_value, point_value)\n",
    "path_dir_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\{}\\image\\{}_{}\\{}\\total\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator)\n",
    "os.makedirs(path_dir_save_fig, exist_ok=True)\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for interval in intervals:\n",
    "    \n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # load table\n",
    "        # will be replace with sql.\n",
    "    path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator, interval)    \n",
    "    \n",
    "    table_trade_res_list = []\n",
    "    for index, file_name in enumerate(os.listdir(path_dir_table_trade_res)):    \n",
    "    \n",
    "        # if 'DOT' in file_name:\n",
    "        #     pass\n",
    "        \n",
    "            path_file = os.path.join(path_dir_table_trade_res, file_name)\n",
    "            \n",
    "            if os.path.isfile(path_file):\n",
    "                table_trade_result_individual = pd.read_feather(path_file)\n",
    "                # table_trade_result_individual.iloc[:, :13].to_feather(path_file)\n",
    "                table_trade_res_list.append(table_trade_result_individual)\n",
    "    \n",
    "    table_trade_result = pd.concat(table_trade_res_list)\n",
    "    \n",
    "    bank.sys_log.debug(\"IDEP : elasped time, load table_trade_result : {:.4f}s\".format(time.time() - start_time))\n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "\n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # making table_trade_result_agg & table_trade_result_anchor\n",
    "    table_trade_result = add_datatype(table_trade_result, \n",
    "                                      train_ratio)\n",
    "\n",
    "    bank.sys_log.debug(\"IDEP : elasped time, add_datatype : {:.4f}s\".format(time.time() - start_time))\n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    table_trade_result = set_quantity(table_trade_result,\n",
    "                                      leverage_limits,\n",
    "                                      target_loss, \n",
    "                                      target_loss_pct, \n",
    "                                      target_leverage, \n",
    "                                      fee_market, \n",
    "                                      fee_market,\n",
    "                                      unit_RRratio_adj_fee,\n",
    "                                      leverage_rejection,\n",
    "                                      )\n",
    "    \n",
    "    bank.sys_log.debug(\"IDEP : elasped time, set_quantity : {:.4f}s\".format(time.time() - start_time))\n",
    "    bank.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        assert to execute this phase.\n",
    "            table_trade_result_backup is input for below phase.\n",
    "    \"\"\"\n",
    "    table_trade_result_backup = table_trade_result.copy()\n",
    "    if len(positions) == 2:\n",
    "        RRratio_adj_fee_categories = np.unique(table_trade_result_backup.RRratio_adj_fee_category) # when payload exists, we should not use it.\n",
    "\n",
    "    for position in positions:\n",
    "        \n",
    "        for RRratio_adj_fee_category in RRratio_adj_fee_categories:\n",
    "            \n",
    "            table_trade_result = table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "            table_trade_result_train = table_trade_result[table_trade_result.dataType == 'TRAIN'] # extract symbol from TRAIN data only.\n",
    "    \n",
    "\n",
    "            bank.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                \"\"\"\n",
    "                v2.0\n",
    "                    add symbol to pivot_table index.\n",
    "                \n",
    "                last confirmed at, 20240605 1106.\n",
    "                \"\"\"\n",
    "                \n",
    "                # table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot = table_trade_result_train.pivot_table(index=[table_trade_result_train.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result_train.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "                table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "                table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"error in pivoting : {}\".format(e))\n",
    "                continue     \n",
    "                \n",
    "            bank.sys_log.debug(\"IDEP : elasped time, pivoting : {:.4f}s\".format(time.time() - start_time))\n",
    "            bank.sys_log.debug(\"------------------------------------------------\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold_winRatio in range_winRatio:\n",
    "                \n",
    "                bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                start_time = time.time()\n",
    "            \n",
    "                # symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)].index\n",
    "                symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "                symbol_extracted = symbol_extracted.droplevel()\n",
    "                symbol_extracted_len = len(symbol_extracted)\n",
    "                symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "                \n",
    "                bank.sys_log.debug(\"IDEP : elasped time, symbol_extraction : {:.4f}s\".format(time.time() - start_time))\n",
    "                bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                \n",
    "                if symbol_extracted_len > 0:  \n",
    "                    \n",
    "                    # table_trade_result_backup['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result_backup.symbol]\n",
    "                    # table_trade_result_agg = table_trade_result_backup[table_trade_result_backup.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                    table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "                    table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "\n",
    "                    if mode_position == 'SINGLE':\n",
    "                        \n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                        table_trade_result_agg = convert_to_position_single(table_trade_result_agg)\n",
    "                        # table_trade_result_agg = table_trade_result_agg.sort_values('timestamp_entry')                    \n",
    "                        \n",
    "                        bank.sys_log.debug(\"IDEP : elasped time, get_output_row : {:.4f}s\".format(time.time() - start_time))\n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                            \n",
    "                    frequencyTotal = len(table_trade_result_agg)\n",
    "            \n",
    "                    \n",
    "                    if frequencyTotal > threshold_frequencyTotal:     \n",
    "                        \n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                        row = get_output_row(table_trade_result_agg, \n",
    "                                        symbol_extracted, \n",
    "                                        symbol_extracted_len, \n",
    "                                        symbol_extracted_len_pct, \n",
    "                                        interval,\n",
    "                                        target_loss, \n",
    "                                        target_loss_pct, \n",
    "                                        target_leverage,\n",
    "                                        position,\n",
    "                                        RRratio_adj_fee_category, \n",
    "                                        threshold_winRatio,\n",
    "                                        threshold_frequency, \n",
    "                                        threshold_frequencyTotal, \n",
    "                                        path_dir_save_fig,\n",
    "                                        mode_position, \n",
    "                                        mode_profit, \n",
    "                                        show_figure, \n",
    "                                        save_figure)\n",
    "                        \n",
    "                        bank.sys_log.debug(\"IDEP : elasped time, get_output_row : {:.4f}s\".format(time.time() - start_time))\n",
    "                        bank.sys_log.debug(\"------------------------------------------------\")\n",
    "                        \n",
    "                        result_list.append(row)\n",
    "\n",
    "                        # print(f\"{interval} {RRratio_adj_fee_category} {threshold_winRatio}\", end='\\r')                            \n",
    "        #                 break\n",
    "        #         break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c607e4a-5e78-40f7-abbd-8bb590bf5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg_1 = table_trade_result_agg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7eb32-5598-4715-957a-955916308615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_trade_result_agg\n",
    "# table_trade_result_agg[table_trade_result_agg.status=='SL']\n",
    "table_trade_result_agg[table_trade_result_agg.status=='TP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93471fef-8d5e-441f-a086-d8838d15bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380f4f5-a40f-4888-98eb-be3d1a872137",
   "metadata": {},
   "source": [
    "#### v2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324814a-103b-466d-a586-0b1fb0e83c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    make a table_trade_result_anchor.\n",
    "    loop for all.\n",
    "    eval. indicator added.\n",
    "        ~ mse, r2\n",
    "v2.1\n",
    "    apply functional.\n",
    "    add memory management.\n",
    "        in plt.savefig, not solved..\n",
    "    apply dataType.\n",
    "    \n",
    "    v2.1.1\n",
    "        apply set_quantity v1.4.1\n",
    "\n",
    "last confirmed at, 20240621 1746.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "priceBox_indicator = 'DC'\n",
    "# priceBox_indicator = 'BB'\n",
    "priceBox_value = 20\n",
    "priceBox_value = 60\n",
    "\n",
    "point_mode = 'CROSS'\n",
    "point_indicator = 'CCI'\n",
    "point_indicator = 'II'\n",
    "# point_indicator = 'DC'\n",
    "# point_indicator = 'BB'\n",
    "point_value = 20\n",
    "point_value = 21\n",
    "# point_value = 30\n",
    "\n",
    "zone_indicator = None\n",
    "# zone_indicator = 'MA'\n",
    "zone_value = 30\n",
    "\n",
    "dir_name_strategy = \"priceBox_{}_point_{}_{}\".format(priceBox_indicator, point_mode, point_indicator)\n",
    "\n",
    "\n",
    "intervals = [ '15m', '30m', '1h', '2h', '4h',]\n",
    "# intervals = ['30m', '1h', '2h', '4h',]\n",
    "\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "\n",
    "\n",
    "fee_limit = 0.0002\n",
    "fee_market = 0.0005\n",
    "\n",
    "target_loss = 15 # USDT\n",
    "\n",
    "target_leverage = 1\n",
    "target_leverage = None\n",
    "\n",
    "\n",
    "\n",
    "positions = ['LONG', 'SHORT']\n",
    "\n",
    "range_winRatio = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "\n",
    "threshold_frequency = 0\n",
    "threshold_frequencyTotal = 50\n",
    "\n",
    "\n",
    "\n",
    "payload = '4h\t15\t\tLONG\t(0.0, 0.1]\t0.86\t0\t50'.split('\\t')\n",
    "intervals = [payload[0]]\n",
    "positions = [payload[3]]\n",
    "RRratio_adj_fee_categories = [payload[4]]\n",
    "range_winRatio = [float(payload[5])]\n",
    "threshold_frequency = float(payload[6])\n",
    "threshold_frequencyTotal = float(payload[7])\n",
    "\n",
    "\n",
    "\n",
    "show_figure = 1\n",
    "save_figure = 0\n",
    "\n",
    "\n",
    "# path_dir_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\{}\\image\\{}_{}\\total\".format(dir_name_strategy, priceBox_value, point_value)\n",
    "path_dir_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\{}\\image\\{}_{}\\{}\\total\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator)\n",
    "os.makedirs(path_dir_save_fig, exist_ok=True)\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for interval in intervals:\n",
    "    \n",
    "    # path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, interval)\n",
    "    path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator, interval)\n",
    "    \n",
    "    \n",
    "    table_trade_res_list = []\n",
    "    for index, file_name in enumerate(os.listdir(path_dir_table_trade_res)):    \n",
    "    \n",
    "        # if 'DOT' in file_name:\n",
    "        #     pass\n",
    "        \n",
    "            path_file = os.path.join(path_dir_table_trade_res, file_name)\n",
    "            \n",
    "            if os.path.isfile(path_file):\n",
    "                table_trade_result_individual = pd.read_feather(path_file)\n",
    "                # table_trade_result_individual.iloc[:, :13].to_feather(path_file)\n",
    "                table_trade_res_list.append(table_trade_result_individual)\n",
    "    \n",
    "    table_trade_result = pd.concat(table_trade_res_list)\n",
    "\n",
    "    \n",
    "    timestamp_entry = table_trade_result['timestamp_entry'].to_numpy()\n",
    "    timestamp_min = table_trade_result['timestamp_entry'].min()\n",
    "    timestamp_max = table_trade_result['timestamp_entry'].max()\n",
    "    \n",
    "    # train_ratio = 0.7\n",
    "    timestamp_train = timestamp_min + (timestamp_max - timestamp_min) * train_ratio\n",
    "    \n",
    "    table_trade_result['dataType'] = np.where(timestamp_entry < timestamp_train, 'TRAIN', 'TEST')\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        define ~ to_numpy() as a var. for keep usage\n",
    "        add RRratio_adj_fee\n",
    "        modify income & commission to income & commission\n",
    "    v1.2\n",
    "        move RRratio to anal phase.\n",
    "        set target_loss.\n",
    "            income calculated from quantity.\n",
    "    v1.3\n",
    "        modify 'income' to support LONG & SHORT one table.\n",
    "        add loss_pct\n",
    "        add profit.\n",
    "    v1.4\n",
    "        rearrange with to_numpy()\n",
    "    v1.4.1\n",
    "        \"fee will be placed in here.\"\n",
    "    \n",
    "    last confirmed at, 20240611 1158.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # fee_entry = 0.0005 # temporary static\n",
    "    # fee_exit = 0.0005 # temporary static\n",
    "    \n",
    "    # target_loss = 5 # USDT\n",
    "    \n",
    "    # target_loss_pct = 0.05 # USDT\n",
    "    \n",
    "    # target_leverage = 1\n",
    "    # target_leverage = 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "    price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "    price_entry = table_trade_result.price_entry.to_numpy()\n",
    "    price_exit = table_trade_result.price_exit.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    table_trade_result['fee_entry'] = fee_market\n",
    "    table_trade_result['fee_exit'] = fee_market\n",
    "    \n",
    "    fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "    fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "    loss_pct = loss / price_entry # this is official pct for SHORT. price_entry is an initial_price in SHORT position too.\n",
    "    # loss_pct = np.where(table_trade_result.position.to_numpy() == 'SHORT', loss / price_stop_loss, loss / price_entry)\n",
    "    quantity = target_loss / loss\n",
    "    \n",
    "    table_trade_result['loss'] = loss\n",
    "    table_trade_result['loss_pct'] = loss_pct\n",
    "    table_trade_result['quantity'] = quantity\n",
    "    \n",
    "    \n",
    "    \n",
    "    amount_entry = price_entry * quantity\n",
    "    amount_exit = price_exit * quantity\n",
    "    \n",
    "    commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "    \n",
    "    income = amount_exit - amount_entry\n",
    "    income = np.where(table_trade_result.position.to_numpy() == 'SHORT', -income, income)\n",
    "    \n",
    "    table_trade_result['commission'] = commission\n",
    "    table_trade_result['income'] = income\n",
    "    table_trade_result['income - commission'] = income - commission\n",
    "    \n",
    "    \n",
    "    \n",
    "    table_trade_result['amount_entry'] = amount_entry\n",
    "    leverage_limit = (table_trade_result['amount_entry'] / target_loss).apply(math.floor).to_numpy() # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "    # table_trade_result['leverage_limit'] = (amount_entry / target_loss).astype(int) # math support multiple options\n",
    "    table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "\n",
    "    \n",
    "    if target_leverage is None:\n",
    "        leverage = leverage_limit\n",
    "    else:\n",
    "        leverage = np.where(target_leverage > leverage_limit, leverage_limit, target_leverage)\n",
    "    table_trade_result['leverage'] = leverage\n",
    "    table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "    \n",
    "    table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount_entry * leverage\n",
    "    table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # point (sparse value)\n",
    "    \n",
    "    # zone (continuous value)\n",
    "        # default\n",
    "    table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "    table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "    # table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "    \n",
    "    # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)\n",
    "    # unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "    table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        assert to execute this phase.\n",
    "            table_trade_result_backup is input for below phase.\n",
    "    \"\"\"\n",
    "    table_trade_result_backup = table_trade_result.copy()\n",
    "    if len(positions) == 2:\n",
    "        RRratio_adj_fee_categories = np.unique(table_trade_result_backup.RRratio_adj_fee_category) # when payload exists, we should not use it.\n",
    "\n",
    "    for position in positions:\n",
    "    # position = 'LONG'\n",
    "    # position = 'SHORT'\n",
    "        \n",
    "        for RRratio_adj_fee_category in RRratio_adj_fee_categories:            \n",
    "            # RRratio_adj_fee_category = '(0.1, 0.2]' # if catergory gets larger, lesser frequency (= lower reliability) & lower winRatio \n",
    "            table_trade_result = table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "            table_trade_result_train = table_trade_result[table_trade_result.dataType == 'TRAIN'] # extract symbol from TRAIN data only.\n",
    "    \n",
    "\n",
    "            try:\n",
    "                \n",
    "                \"\"\"\n",
    "                v2.0\n",
    "                    add symbol to pivot_table index.\n",
    "                \n",
    "                last confirmed at, 20240605 1106.\n",
    "                \"\"\"\n",
    "                \n",
    "                # table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot = table_trade_result_train.pivot_table(index=[table_trade_result_train.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result_train.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "                table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "                table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"error in pivoting : {}\".format(e))\n",
    "                continue            \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            # range_winRatio = np.arange(0.3, 1.0, 0.01) # could know the minimum value for profit rightTopness. \n",
    "            \n",
    "            # threshold_winRatio = 0.82\n",
    "            \n",
    "            # threshold_frequency = 0\n",
    "            # threshold_frequency = 40\n",
    "            # threshold_frequency = 70\n",
    "            \n",
    "            # threshold_frequencyTotal = 0\n",
    "            # threshold_frequencyTotal = 50\n",
    "            # threshold_incomeTotal = 0.0 # answer should be set before!\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold_winRatio in range_winRatio:\n",
    "                \n",
    "                # symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)].index\n",
    "                symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "                symbol_extracted = symbol_extracted.droplevel()\n",
    "                # symbol_extracted\n",
    "                symbol_extracted_len = len(symbol_extracted)\n",
    "                symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "                \n",
    "                if symbol_extracted_len > 0:  \n",
    "                    \n",
    "                    # table_trade_result_backup['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result_backup.symbol]\n",
    "                    # table_trade_result_agg = table_trade_result_backup[table_trade_result_backup.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                    table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "                    table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                    \n",
    "                    # table_trade_result_agg = convert_to_position_single(table_trade_result_agg)                    \n",
    "                            \n",
    "                    frequencyTotal = len(table_trade_result_agg)\n",
    "            \n",
    "                    \n",
    "                    if frequencyTotal > threshold_frequencyTotal:     \n",
    "                        \n",
    "                        winRatio = len(table_trade_result_agg[table_trade_result_agg.status=='TP']) / frequencyTotal\n",
    "                        profit_pct_cumsum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy())\n",
    "                        profit_pct_sum = profit_pct_cumsum[-1]\n",
    "            \n",
    "                        frequencyMean = frequencyTotal / symbol_extracted_len\n",
    "            \n",
    "                        # sharpRatio\n",
    "                        profit = table_trade_result_agg.profit.to_numpy()            \n",
    "                        \n",
    "                        # Risk-free rate (assumed to be 0 for simplicity)\n",
    "                        risk_free_rate = 0\n",
    "                        \n",
    "                        # Calculate various metrics\n",
    "                        mean_return = np.mean(profit)\n",
    "                        std_return = np.std(profit)\n",
    "                        sharpe_ratio = (mean_return - risk_free_rate) / std_return\n",
    "                        \n",
    "                        # Calculate Sortino Ratio\n",
    "                            # focus on downside more.\n",
    "                                # safe oriented.\n",
    "                        downside_returns = profit[profit < 0]\n",
    "                        downside_deviation = np.std(downside_returns)\n",
    "                        sortino_ratio = (mean_return - risk_free_rate) / downside_deviation\n",
    "                        \n",
    "                        # Calculate Maximum Drawdown\n",
    "                        cumulative_returns = np.cumsum(profit)\n",
    "                        drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "                        max_drawdown = np.min(drawdowns)\n",
    "                        \n",
    "                        cumulative_returns_min = cumulative_returns.min()\n",
    "                        cumulative_returns_max = cumulative_returns.max()\n",
    "                        cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min)\n",
    "                        drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "                        max_drawdown_scaled = np.min(drawdowns_scaled)\n",
    "                        # # Min-Max Normalization for a single MDD\n",
    "                        # min_mdd = drawdowns.max()  # assuming the minimum possible MDD is 0\n",
    "                        # max_mdd = drawdowns.min()  # assuming the maximum possible MDD is 1\n",
    "                        \n",
    "                        # # Normalize the Max Drawdown to the range [0, 1]\n",
    "                        # normalized_max_drawdown = (max_drawdown - min_mdd) / (max_mdd - min_mdd)\n",
    "                        \n",
    "                        # Calculate Calmar Ratio\n",
    "                        # annual_return = mean_return * 12  # Assuming monthly profit\n",
    "                        # calmar_ratio = annual_return / -max_drawdown\n",
    "                        \n",
    "                        # Calculate Profit Factor\n",
    "                        total_profit = np.sum(profit[profit > 0])\n",
    "                        total_loss = -np.sum(profit[profit < 0])\n",
    "                        profit_factor = total_profit / total_loss\n",
    "\n",
    "                        \n",
    "                        x = np.linspace(0, 1, len(cumulative_returns_scaled))\n",
    "                        # y_actual = x**2\n",
    "                        y_actual = x # v0.2 : closer concept to 'consistency'\n",
    "                        y_predicted = cumulative_returns_scaled\n",
    "                        \n",
    "                        mse = mean_squared_error(y_actual, y_predicted)                        \n",
    "                        r2 = r2_score(y_actual, y_predicted)\n",
    "                        \n",
    "\n",
    "                        timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "                        table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "                        table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "                        \n",
    "                        minutes = itv_to_number(interval)\n",
    "                        timestamp_unit = 60 * minutes # 15min. case\n",
    "                        table_trade_result_agg['timemap_entry'] /= timestamp_unit\n",
    "                        table_trade_result_agg['timemap_exit'] /= timestamp_unit\n",
    "                        \n",
    "                        \n",
    "                        map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]))\n",
    "                        for cnt, (row) in enumerate(table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy()):\n",
    "                            \n",
    "                            index_start, index_end, amount = row                            \n",
    "                            map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "                        \n",
    "                        map_amount_agg_max = map_amount_agg.max()\n",
    "                            \n",
    "            \n",
    "                        row = [\n",
    "                            interval,\n",
    "                            target_loss,\n",
    "                            target_leverage,\n",
    "                            position,\n",
    "                            RRratio_adj_fee_category,\n",
    "                            threshold_winRatio,\n",
    "                            threshold_frequency,\n",
    "                            threshold_frequencyTotal,\n",
    "                            \"{}\".format(symbol_extracted.tolist()),\n",
    "                            symbol_extracted_len,\n",
    "                            symbol_extracted_len_pct,\n",
    "                            frequencyTotal,\n",
    "                            frequencyMean,\n",
    "                            winRatio,\n",
    "                            profit_pct_sum,\n",
    "                            mean_return,\n",
    "                            std_return,\n",
    "                            max_drawdown,\n",
    "                            max_drawdown_scaled,\n",
    "                            sharpe_ratio,\n",
    "                            sortino_ratio,\n",
    "                            profit_factor,\n",
    "                            mse,\n",
    "                            r2,\n",
    "                            map_amount_agg_max,\n",
    "                        ]\n",
    "                        \n",
    "                        result_list.append(row)\n",
    "                        \n",
    "                        title = ''\n",
    "                        title += 'interval : {}\\n'.format(interval)\n",
    "                        title += 'target_loss : {}\\n'.format(target_loss)\n",
    "                        title += 'target_leverage : {}\\n'.format(target_leverage)\n",
    "                        title += 'position : {}\\n'.format(position)\n",
    "                        title += 'RRratio_adj_fee_category : {}\\n'.format(RRratio_adj_fee_category)\n",
    "                        title += 'threshold_winRatio : {:.2f}\\n'.format(threshold_winRatio)\n",
    "                        title += 'threshold_frequency : {}\\n'.format(threshold_frequency)\n",
    "                        title += 'threshold_frequencyTotal : {}\\n'.format(threshold_frequencyTotal)\n",
    "                        # title += 'symbol_extracted : {}\\n'.format(symbol_extracted)\n",
    "                        title += 'symbol_extracted_len : {}\\n'.format(symbol_extracted_len)\n",
    "                        title += 'symbol_extracted_len_pct : {:.2f}\\n'.format(symbol_extracted_len_pct)\n",
    "                        title += 'frequencyTotal : {}\\n'.format(frequencyTotal)\n",
    "                        title += 'frequencyMean : {:.2f}\\n'.format(frequencyMean)\n",
    "                        title += 'winRatio : {:.2f}\\n'.format(winRatio)\n",
    "                        title += 'profit_pct_sum : {:.2f}\\n'.format(profit_pct_sum)\n",
    "                        title += 'mean_return : {:.2f}\\n'.format(mean_return)\n",
    "                        title += 'std_return : {:.2f}\\n'.format(std_return)\n",
    "                        title += 'max_drawdown : {:.2f}\\n'.format(max_drawdown)\n",
    "                        title += 'max_drawdown_scaled : {:.2f}\\n'.format(max_drawdown_scaled)\n",
    "                        title += 'sharpe_ratio : {:.2f}\\n'.format(sharpe_ratio)\n",
    "                        title += 'sortino_ratio : {:.2f}\\n'.format(sortino_ratio)\n",
    "                        title += 'profit_factor : {:.2f}\\n'.format(profit_factor)\n",
    "                        title += 'mse : {:.2f}\\n'.format(mse)\n",
    "                        title += 'r2 : {:.2f}\\n'.format(r2)\n",
    "                        title += 'map_amount_agg_max : {:.2f}'.format(map_amount_agg_max)\n",
    "                        \n",
    "                        \n",
    "                        print(title)    \n",
    "                        clear_output()\n",
    "                        \n",
    "\n",
    "                        if show_figure:\n",
    "                            plt.figure()\n",
    "                            plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cumsum)\n",
    "                            plt.title(title, y=0., fontsize=10)\n",
    "\n",
    "                            if save_figure:\n",
    "                                plt.tight_layout()\n",
    "                                payload = '{}\t{}\t{}\t{}\t{}\t{:.2f}'.format(interval, target_loss, target_leverage, position, RRratio_adj_fee_category, threshold_winRatio, threshold_frequency, threshold_frequencyTotal).split('\\t')                                \n",
    "                                plt.savefig(os.path.join(path_dir_save_fig, \"{}.png\".format(payload)))\n",
    "                            else:\n",
    "                                plt.show() # require some time.\n",
    "                                \n",
    "                            plt.close('all')\n",
    "                            # gc.collect() # require time a lot...\n",
    "                            \n",
    "        #                 break\n",
    "        #         break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d3b8a-7f04-46d8-abd8-702207f781ce",
   "metadata": {},
   "source": [
    "#### v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b155bfa-ea95-49ab-8904-896e0d84bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    make a table_trade_result_anchor.\n",
    "    loop for all.\n",
    "    eval. indicator added.\n",
    "        ~ mse, r2\n",
    "v2.1\n",
    "    apply functional.\n",
    "    add memory management.\n",
    "        in plt.savefig, not solved..\n",
    "    apply dataType.\n",
    "\n",
    "last confirmed at, 20240619 0943.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dir_name_strategy = \"priceBox_DC_point_Cross_DC\"\n",
    "# dir_name_strategy = \"priceBox_DC_point_Cross_II\"\n",
    "\n",
    "priceBox_value = 60\n",
    "\n",
    "point_value = 30\n",
    "# point_value = 21\n",
    "\n",
    "\n",
    "intervals = [ '15m', '30m', '1h', '2h', '4h',]\n",
    "# intervals = ['30m', '1h', '2h', '4h',]\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "target_loss = 15 # USDT\n",
    "\n",
    "target_leverage = 1\n",
    "target_leverage = None\n",
    "\n",
    "\n",
    "positions = ['LONG', 'SHORT']\n",
    "\n",
    "range_winRatio = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "\n",
    "threshold_frequency = 0\n",
    "threshold_frequencyTotal = 50\n",
    "\n",
    "\n",
    "\n",
    "# payload = '2h\t15\t\tLONG\t(1.3, 1.4]\t0.5\t0\t50'.split('\\t')\n",
    "# # payload = '30m\t5\t1\tSHORT\t(0.5, 0.6]\t0.7\t0\t50'.split('\\t')\n",
    "# intervals = [payload[0]]\n",
    "# positions = [payload[3]]\n",
    "# RRratio_adj_fee_categories = [payload[4]]\n",
    "# range_winRatio = [float(payload[5])]\n",
    "# threshold_frequency = float(payload[6])\n",
    "# threshold_frequencyTotal = float(payload[7])\n",
    "\n",
    "\n",
    "\n",
    "show_figure = 1\n",
    "save_figure = 0\n",
    "\n",
    "\n",
    "path_dir_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\{}\\image\\{}_{}\\total\".format(dir_name_strategy, priceBox_value, point_value)\n",
    "os.makedirs(path_dir_save_fig, exist_ok=True)\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for interval in intervals:\n",
    "    \n",
    "    path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result/{}_{}/{}/\".format(dir_name_strategy, priceBox_value, point_value, interval)\n",
    "    \n",
    "    \n",
    "    table_trade_res_list = []\n",
    "    for index, file_name in enumerate(os.listdir(path_dir_table_trade_res)):    \n",
    "    \n",
    "        # if 'DOT' in file_name:\n",
    "        #     pass\n",
    "        \n",
    "            path_file = os.path.join(path_dir_table_trade_res, file_name)\n",
    "            \n",
    "            if os.path.isfile(path_file):\n",
    "                table_trade_result_individual = pd.read_feather(path_file)\n",
    "                # table_trade_result_individual.iloc[:, :13].to_feather(path_file)\n",
    "                table_trade_res_list.append(table_trade_result_individual)\n",
    "    \n",
    "    table_trade_result = pd.concat(table_trade_res_list)\n",
    "\n",
    "\n",
    "    \n",
    "    timestamp_entry = table_trade_result['timestamp_entry'].to_numpy()\n",
    "    timestamp_min = table_trade_result['timestamp_entry'].min()\n",
    "    timestamp_max = table_trade_result['timestamp_entry'].max()\n",
    "    \n",
    "    # train_ratio = 0.7\n",
    "    timestamp_train = timestamp_min + (timestamp_max - timestamp_min) * train_ratio\n",
    "    \n",
    "    table_trade_result['dataType'] = np.where(timestamp_entry < timestamp_train, 'TRAIN', 'TEST')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        define ~ to_numpy() as a var. for keep usage\n",
    "        add RRratio_adj_fee\n",
    "        modify income & commission to income & commission\n",
    "    v1.2\n",
    "        move RRratio to anal phase.\n",
    "        set target_loss.\n",
    "            income calculated from quantity.\n",
    "    v1.3\n",
    "        modify 'income' to support LONG & SHORT one table.\n",
    "        add loss_pct\n",
    "        add profit.\n",
    "    v1.4\n",
    "        rearrange with to_numpy()\n",
    "    \n",
    "    last confirmed at, 20240611 1158.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # target_loss = 5 # USDT\n",
    "    \n",
    "    # target_loss_pct = 0.05 # USDT\n",
    "    \n",
    "    # target_leverage = 1\n",
    "    # target_leverage = 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "    price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "    price_entry = table_trade_result.price_entry.to_numpy()\n",
    "    price_exit = table_trade_result.price_exit.to_numpy()\n",
    "    \n",
    "    fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "    fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "    loss_pct = loss / price_entry # this is official pct for SHORT. price_entry is an initial_price in SHORT position too.\n",
    "    # loss_pct = np.where(table_trade_result.position.to_numpy() == 'SHORT', loss / price_stop_loss, loss / price_entry)\n",
    "    quantity = target_loss / loss\n",
    "    \n",
    "    table_trade_result['loss'] = loss\n",
    "    table_trade_result['loss_pct'] = loss_pct\n",
    "    table_trade_result['quantity'] = quantity\n",
    "    \n",
    "    \n",
    "    \n",
    "    amount_entry = price_entry * quantity\n",
    "    amount_exit = price_exit * quantity\n",
    "    \n",
    "    commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "    \n",
    "    income = amount_exit - amount_entry\n",
    "    income = np.where(table_trade_result.position.to_numpy() == 'SHORT', -income, income)\n",
    "    \n",
    "    table_trade_result['commission'] = commission\n",
    "    table_trade_result['income'] = income\n",
    "    table_trade_result['income - commission'] = income - commission\n",
    "    \n",
    "    \n",
    "    \n",
    "    table_trade_result['amount_entry'] = amount_entry\n",
    "    leverage_limit = (table_trade_result['amount_entry'] / target_loss).apply(math.floor).to_numpy() # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "    # table_trade_result['leverage_limit'] = (amount_entry / target_loss).astype(int) # math support multiple options\n",
    "    table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    if target_leverage is None:\n",
    "        leverage = leverage_limit\n",
    "    else:\n",
    "        leverage = np.where(target_leverage > leverage_limit, leverage_limit, target_leverage)\n",
    "    table_trade_result['leverage'] = leverage\n",
    "    table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "    \n",
    "    table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount_entry * leverage\n",
    "    table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # point (sparse value)\n",
    "    \n",
    "    # zone (continuous value)\n",
    "        # default\n",
    "    table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "    table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "    # table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "    \n",
    "    # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)\n",
    "    # unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "    table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        assert to execute this phase.\n",
    "            table_trade_result_backup is input for below phase.\n",
    "    \"\"\"\n",
    "    table_trade_result_backup = table_trade_result.copy()\n",
    "    if len(positions) == 2:\n",
    "        RRratio_adj_fee_categories = np.unique(table_trade_result_backup.RRratio_adj_fee_category) # when payload exists, we should not use it.\n",
    "\n",
    "    for position in positions:\n",
    "    # position = 'LONG'\n",
    "    # position = 'SHORT'\n",
    "        \n",
    "        for RRratio_adj_fee_category in RRratio_adj_fee_categories:            \n",
    "            # RRratio_adj_fee_category = '(0.1, 0.2]' # if catergory gets larger, lesser frequency (= lower reliability) & lower winRatio \n",
    "            table_trade_result = table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "            table_trade_result_train = table_trade_result[table_trade_result.dataType == 'TRAIN'] # extract symbol from TRAIN data only.\n",
    "    \n",
    "\n",
    "            try:\n",
    "                \n",
    "                \"\"\"\n",
    "                v2.0\n",
    "                    add symbol to pivot_table index.\n",
    "                \n",
    "                last confirmed at, 20240605 1106.\n",
    "                \"\"\"\n",
    "                \n",
    "                # table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot = table_trade_result_train.pivot_table(index=[table_trade_result_train.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result_train.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "                table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "                table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "                table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"error in pivoting : {}\".format(e))\n",
    "                continue            \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            # range_winRatio = np.arange(0.3, 1.0, 0.01) # could know the minimum value for profit rightTopness. \n",
    "            \n",
    "            # threshold_winRatio = 0.82\n",
    "            \n",
    "            # threshold_frequency = 0\n",
    "            # threshold_frequency = 40\n",
    "            # threshold_frequency = 70\n",
    "            \n",
    "            # threshold_frequencyTotal = 0\n",
    "            # threshold_frequencyTotal = 50\n",
    "            # threshold_incomeTotal = 0.0 # answer should be set before!\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold_winRatio in range_winRatio:\n",
    "                \n",
    "                # symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)].index\n",
    "                symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "                symbol_extracted = symbol_extracted.droplevel()\n",
    "                # symbol_extracted\n",
    "                symbol_extracted_len = len(symbol_extracted)\n",
    "                symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "                \n",
    "                if symbol_extracted_len > 0:  \n",
    "                    \n",
    "                    # table_trade_result_backup['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result_backup.symbol]\n",
    "                    # table_trade_result_agg = table_trade_result_backup[table_trade_result_backup.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                    table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "                    table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                            \n",
    "                    frequencyTotal = len(table_trade_result_agg)\n",
    "            \n",
    "                    \n",
    "                    if frequencyTotal > threshold_frequencyTotal:     \n",
    "                        \n",
    "                        winRatio = len(table_trade_result_agg[table_trade_result_agg.status=='TP']) / frequencyTotal\n",
    "                        profit_pct_cumsum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy())\n",
    "                        profit_pct_sum = profit_pct_cumsum[-1]\n",
    "            \n",
    "                        frequencyMean = frequencyTotal / symbol_extracted_len\n",
    "            \n",
    "                        # sharpRatio\n",
    "                        profit = table_trade_result_agg.profit.to_numpy()            \n",
    "                        \n",
    "                        # Risk-free rate (assumed to be 0 for simplicity)\n",
    "                        risk_free_rate = 0\n",
    "                        \n",
    "                        # Calculate various metrics\n",
    "                        mean_return = np.mean(profit)\n",
    "                        std_return = np.std(profit)\n",
    "                        sharpe_ratio = (mean_return - risk_free_rate) / std_return\n",
    "                        \n",
    "                        # Calculate Sortino Ratio\n",
    "                            # focus on downside more.\n",
    "                                # safe oriented.\n",
    "                        downside_returns = profit[profit < 0]\n",
    "                        downside_deviation = np.std(downside_returns)\n",
    "                        sortino_ratio = (mean_return - risk_free_rate) / downside_deviation\n",
    "                        \n",
    "                        # Calculate Maximum Drawdown\n",
    "                        cumulative_returns = np.cumsum(profit)\n",
    "                        drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "                        max_drawdown = np.min(drawdowns)\n",
    "                        \n",
    "                        cumulative_returns_min = cumulative_returns.min()\n",
    "                        cumulative_returns_max = cumulative_returns.max()\n",
    "                        cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min)\n",
    "                        drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "                        max_drawdown_scaled = np.min(drawdowns_scaled)\n",
    "                        # # Min-Max Normalization for a single MDD\n",
    "                        # min_mdd = drawdowns.max()  # assuming the minimum possible MDD is 0\n",
    "                        # max_mdd = drawdowns.min()  # assuming the maximum possible MDD is 1\n",
    "                        \n",
    "                        # # Normalize the Max Drawdown to the range [0, 1]\n",
    "                        # normalized_max_drawdown = (max_drawdown - min_mdd) / (max_mdd - min_mdd)\n",
    "                        \n",
    "                        # Calculate Calmar Ratio\n",
    "                        # annual_return = mean_return * 12  # Assuming monthly profit\n",
    "                        # calmar_ratio = annual_return / -max_drawdown\n",
    "                        \n",
    "                        # Calculate Profit Factor\n",
    "                        total_profit = np.sum(profit[profit > 0])\n",
    "                        total_loss = -np.sum(profit[profit < 0])\n",
    "                        profit_factor = total_profit / total_loss\n",
    "\n",
    "                        \n",
    "                        x = np.linspace(0, 1, len(cumulative_returns_scaled))\n",
    "                        # y_actual = x**2\n",
    "                        y_actual = x # v0.2 : closer concept to 'consistency'\n",
    "                        y_predicted = cumulative_returns_scaled\n",
    "                        \n",
    "                        mse = mean_squared_error(y_actual, y_predicted)                        \n",
    "                        r2 = r2_score(y_actual, y_predicted)\n",
    "                        \n",
    "\n",
    "                        timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "                        table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "                        table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "                        \n",
    "                        minutes = itv_to_number(interval)\n",
    "                        timestamp_unit = 60 * minutes # 15min. case\n",
    "                        table_trade_result_agg['timemap_entry'] /= timestamp_unit\n",
    "                        table_trade_result_agg['timemap_exit'] /= timestamp_unit\n",
    "                        \n",
    "                        \n",
    "                        map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]))\n",
    "                        for cnt, (row) in enumerate(table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy()):\n",
    "                            \n",
    "                            index_start, index_end, amount = row                            \n",
    "                            map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "                        \n",
    "                        map_amount_agg_max = map_amount_agg.max()\n",
    "                            \n",
    "            \n",
    "                        row = [\n",
    "                            interval,\n",
    "                            target_loss,\n",
    "                            target_leverage,\n",
    "                            position,\n",
    "                            RRratio_adj_fee_category,\n",
    "                            threshold_winRatio,\n",
    "                            threshold_frequency,\n",
    "                            threshold_frequencyTotal,\n",
    "                            \"{}\".format(symbol_extracted.tolist()),\n",
    "                            symbol_extracted_len,\n",
    "                            symbol_extracted_len_pct,\n",
    "                            frequencyTotal,\n",
    "                            frequencyMean,\n",
    "                            winRatio,\n",
    "                            profit_pct_sum,\n",
    "                            mean_return,\n",
    "                            std_return,\n",
    "                            max_drawdown,\n",
    "                            max_drawdown_scaled,\n",
    "                            sharpe_ratio,\n",
    "                            sortino_ratio,\n",
    "                            profit_factor,\n",
    "                            mse,\n",
    "                            r2,\n",
    "                            map_amount_agg_max,\n",
    "                        ]\n",
    "                        \n",
    "                        result_list.append(row)\n",
    "                        \n",
    "                        title = ''\n",
    "                        title += 'interval : {}\\n'.format(interval)\n",
    "                        title += 'target_loss : {}\\n'.format(target_loss)\n",
    "                        title += 'target_leverage : {}\\n'.format(target_leverage)\n",
    "                        title += 'position : {}\\n'.format(position)\n",
    "                        title += 'RRratio_adj_fee_category : {}\\n'.format(RRratio_adj_fee_category)\n",
    "                        title += 'threshold_winRatio : {:.2f}\\n'.format(threshold_winRatio)\n",
    "                        title += 'threshold_frequency : {}\\n'.format(threshold_frequency)\n",
    "                        title += 'threshold_frequencyTotal : {}\\n'.format(threshold_frequencyTotal)\n",
    "                        # title += 'symbol_extracted : {}\\n'.format(symbol_extracted)\n",
    "                        title += 'symbol_extracted_len : {}\\n'.format(symbol_extracted_len)\n",
    "                        title += 'symbol_extracted_len_pct : {:.2f}\\n'.format(symbol_extracted_len_pct)\n",
    "                        title += 'frequencyTotal : {}\\n'.format(frequencyTotal)\n",
    "                        title += 'frequencyMean : {:.2f}\\n'.format(frequencyMean)\n",
    "                        title += 'winRatio : {:.2f}\\n'.format(winRatio)\n",
    "                        title += 'profit_pct_sum : {:.2f}\\n'.format(profit_pct_sum)\n",
    "                        title += 'mean_return : {:.2f}\\n'.format(mean_return)\n",
    "                        title += 'std_return : {:.2f}\\n'.format(std_return)\n",
    "                        title += 'max_drawdown : {:.2f}\\n'.format(max_drawdown)\n",
    "                        title += 'max_drawdown_scaled : {:.2f}\\n'.format(max_drawdown_scaled)\n",
    "                        title += 'sharpe_ratio : {:.2f}\\n'.format(sharpe_ratio)\n",
    "                        title += 'sortino_ratio : {:.2f}\\n'.format(sortino_ratio)\n",
    "                        title += 'profit_factor : {:.2f}\\n'.format(profit_factor)\n",
    "                        title += 'mse : {:.2f}\\n'.format(mse)\n",
    "                        title += 'r2 : {:.2f}\\n'.format(r2)\n",
    "                        title += 'map_amount_agg_max : {:.2f}'.format(map_amount_agg_max)\n",
    "                        \n",
    "                        \n",
    "                        print(title)    \n",
    "                        clear_output()\n",
    "                        \n",
    "\n",
    "                        if show_figure:\n",
    "                            plt.figure()\n",
    "                            plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cumsum)\n",
    "                            plt.title(title, y=0., fontsize=10)\n",
    "\n",
    "                            if save_figure:\n",
    "                                plt.tight_layout()\n",
    "                                payload = '{}\t{}\t{}\t{}\t{}\t{:.2f}'.format(interval, target_loss, target_leverage, position, RRratio_adj_fee_category, threshold_winRatio, threshold_frequency, threshold_frequencyTotal).split('\\t')                                \n",
    "                                plt.savefig(os.path.join(path_dir_save_fig, \"{}.png\".format(payload)))\n",
    "                            else:\n",
    "                                plt.show() # require some time.\n",
    "                                \n",
    "                            plt.close('all')\n",
    "                            # gc.collect() # require time a lot...\n",
    "                            \n",
    "        #                 break\n",
    "        #         break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c1dfc-3be0-4cae-a179-8e1201f4032f",
   "metadata": {},
   "source": [
    "#### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96859f92-90f2-4287-94ad-851a54ff3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    make a table_trade_result_anchor.\n",
    "    loop for all.\n",
    "    eval. indicator added.\n",
    "        ~ mse, r2\n",
    "\n",
    "last confirmed at, 20240612 1037.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "intervals = [ '15m', '30m', '1h', '2h', '4h',]\n",
    "\n",
    "target_loss = 15 # USDT\n",
    "\n",
    "target_leverage = 1\n",
    "target_leverage = None\n",
    "\n",
    "period_DC = 60\n",
    "\n",
    "positions = ['LONG', 'SHORT']\n",
    "\n",
    "RRratio_adj_fee_categories = np.unique(table_trade_result_backup.RRratio_adj_fee_category)\n",
    "\n",
    "range_winRatio = np.arange(0.3, 1.0, 0.01)\n",
    "\n",
    "# payload = '30m\t5\t1\tLONG\t(0.6, 0.7]\t0.68\t0\t50'.split('\\t')\n",
    "# intervals = [payload[0]]\n",
    "# positions = [payload[3]]\n",
    "# RRratio_adj_fee_categories = [payload[4]]\n",
    "# range_winRatio = [float(payload[5])]\n",
    "# threshold_frequency = float(payload[6])\n",
    "# threshold_frequencyTotal = float(payload[7])\n",
    "\n",
    "show_figure = 1\n",
    "save_figure = 0\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for interval in intervals:\n",
    "    \n",
    "    path_dir_table_trade_res = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_result/{}/{}/\".format(interval, period_DC)\n",
    "    \n",
    "    \n",
    "    table_trade_res_list = []\n",
    "    for index_file, file_name in enumerate(os.listdir(path_dir_table_trade_res)):    \n",
    "    \n",
    "        # if 'DOT' in file_name:\n",
    "        #     pass\n",
    "        \n",
    "            path_file = os.path.join(path_dir_table_trade_res, file_name)\n",
    "            \n",
    "            if os.path.isfile(path_file):\n",
    "                table_trade_result_individual = pd.read_feather(path_file)\n",
    "                # table_trade_result_individual.iloc[:, :13].to_feather(path_file)\n",
    "                table_trade_res_list.append(table_trade_result_individual)\n",
    "    \n",
    "    table_trade_result = pd.concat(table_trade_res_list)\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        define ~ to_numpy() as a var. for keep usage\n",
    "        add RRratio_adj_fee\n",
    "        modify income & commission to income & commission\n",
    "    v1.2\n",
    "        move RRratio to anal phase.\n",
    "        set target_loss.\n",
    "            income calculated from quantity.\n",
    "    v1.3\n",
    "        modify 'income' to support LONG & SHORT one table.\n",
    "        add loss_pct\n",
    "        add profit.\n",
    "    v1.4\n",
    "        rearrange with to_numpy()\n",
    "    \n",
    "    last confirmed at, 20240611 1158.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # target_loss = 5 # USDT\n",
    "    \n",
    "    # target_loss_pct = 0.05 # USDT\n",
    "    \n",
    "    # target_leverage = 1\n",
    "    # target_leverage = 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    price_take_profit = table_trade_result.price_take_profit.to_numpy()\n",
    "    price_stop_loss = table_trade_result.price_stop_loss.to_numpy()\n",
    "    price_entry = table_trade_result.price_entry.to_numpy()\n",
    "    price_exit = table_trade_result.price_exit.to_numpy()\n",
    "    \n",
    "    fee_entry = table_trade_result.fee_entry.to_numpy()\n",
    "    fee_exit = table_trade_result.fee_exit.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit) # default quantity = 1\n",
    "    loss_pct = loss / price_entry # this is official pct for SHORT. price_entry is an initial_price in SHORT position too.\n",
    "    # loss_pct = np.where(table_trade_result.position.to_numpy() == 'SHORT', loss / price_stop_loss, loss / price_entry)\n",
    "    quantity = target_loss / loss\n",
    "    \n",
    "    table_trade_result['loss'] = loss\n",
    "    table_trade_result['loss_pct'] = loss_pct\n",
    "    table_trade_result['quantity'] = quantity\n",
    "    \n",
    "    \n",
    "    \n",
    "    amount_entry = price_entry * quantity\n",
    "    amount_exit = price_exit * quantity\n",
    "    \n",
    "    commission = amount_entry * fee_entry + amount_exit * fee_exit\n",
    "    \n",
    "    income = amount_exit - amount_entry\n",
    "    income = np.where(table_trade_result.position.to_numpy() == 'SHORT', -income, income)\n",
    "    \n",
    "    table_trade_result['commission'] = commission\n",
    "    table_trade_result['income'] = income\n",
    "    table_trade_result['income - commission'] = income - commission\n",
    "    \n",
    "    \n",
    "    \n",
    "    table_trade_result['amount_entry'] = amount_entry\n",
    "    leverage_limit = (table_trade_result['amount_entry'] / target_loss).apply(math.floor).to_numpy() # apply support series. # floor : amount_adj_leverage > target_loss.\n",
    "    # table_trade_result['leverage_limit'] = (amount_entry / target_loss).astype(int) # math support multiple options\n",
    "    table_trade_result['leverage_limit'] = np.where(leverage_limit < 1, 1, leverage_limit) # min leverage = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    if target_leverage is None:\n",
    "        leverage = leverage_limit\n",
    "    else:\n",
    "        leverage = np.where(target_leverage > leverage_limit, leverage_limit, target_leverage)\n",
    "    table_trade_result['leverage'] = leverage\n",
    "    table_trade_result['amount_entry_adj_leverage'] = amount_entry / leverage\n",
    "    \n",
    "    table_trade_result['profit'] = table_trade_result['income - commission'].to_numpy() / amount_entry * leverage\n",
    "    table_trade_result['profit (%)'] = table_trade_result.profit.to_numpy() * 100\n",
    "\n",
    "    # point (sparse value)\n",
    "    \n",
    "    # zone (continuous value)\n",
    "        # default\n",
    "    table_trade_result['RRratio'] = abs(price_take_profit - price_entry) / abs(price_entry - price_stop_loss)\n",
    "    table_trade_result['RRratio_adj_fee'] = (abs(price_take_profit - price_entry) - (price_entry * fee_entry + price_take_profit * fee_exit)) / (abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit))\n",
    "    # table_trade_result['DC_percentage'] = DC_percentage[table_trade_result.idx_entry]\n",
    "    \n",
    "    # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)\n",
    "    unit_RRratio_adj_fee = np.arange(0, 2, 0.1)\n",
    "    table_trade_result['RRratio_adj_fee_category'] = pd.cut(table_trade_result['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        assert to execute this phase.\n",
    "            table_trade_result_backup is input for below phase.\n",
    "    \"\"\"\n",
    "    table_trade_result_backup = table_trade_result.copy()\n",
    "    \n",
    "\n",
    "    for position in positions:\n",
    "    # position = 'LONG'\n",
    "    # position = 'SHORT'\n",
    "        \n",
    "        for RRratio_adj_fee_category in RRratio_adj_fee_categories:\n",
    "            # RRratio_adj_fee_category = '(0.1, 0.2]' # if catergory gets larger, lesser frequency (= lower reliability) & lower winRatio \n",
    "            table_trade_result = table_trade_result_backup[(table_trade_result_backup.position == position) & (table_trade_result_backup.RRratio_adj_fee_category == RRratio_adj_fee_category)]\n",
    "    \n",
    "    \n",
    "            \"\"\"\n",
    "            v2.0\n",
    "                add symbol to pivot_table index.\n",
    "            \n",
    "            last confirmed at, 20240605 1106.\n",
    "            \"\"\"\n",
    "            \n",
    "            table_trade_result_pivot = table_trade_result.pivot_table(index=[table_trade_result.RRratio_adj_fee_category, 'symbol'], columns=table_trade_result.status, values=['status', 'income - commission'], aggfunc={'status': 'count', 'income - commission': 'sum'}, fill_value=0)\n",
    "            table_trade_result_pivot['frequency'] = table_trade_result_pivot[(             'status', 'SL')] + table_trade_result_pivot[(             'status', 'TP')]\n",
    "            table_trade_result_pivot['winRatio'] = table_trade_result_pivot[(             'status', 'TP')] / table_trade_result_pivot['frequency']\n",
    "            table_trade_result_pivot['incomeTotal'] = table_trade_result_pivot[('income - commission', 'SL')] + table_trade_result_pivot[('income - commission', 'TP')]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # range_winRatio = np.arange(0.3, 1.0, 0.01) # could know the minimum value for profit rightTopness. \n",
    "            \n",
    "            # threshold_winRatio = 0.82\n",
    "            \n",
    "            # threshold_frequency = 0\n",
    "            # threshold_frequency = 40\n",
    "            # threshold_frequency = 70\n",
    "            \n",
    "            # threshold_frequencyTotal = 0\n",
    "            # threshold_frequencyTotal = 50\n",
    "            # threshold_incomeTotal = 0.0 # answer should be set before!\n",
    "            \n",
    "            \n",
    "            \n",
    "            for threshold_winRatio in range_winRatio:\n",
    "                \n",
    "                # symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)].index\n",
    "                symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "                symbol_extracted = symbol_extracted.droplevel()\n",
    "                # symbol_extracted\n",
    "                symbol_extracted_len = len(symbol_extracted)\n",
    "                symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "                \n",
    "                if symbol_extracted_len > 0:  \n",
    "                    \n",
    "                    table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "                    table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                            \n",
    "                    frequencyTotal = len(table_trade_result_agg)\n",
    "            \n",
    "                    \n",
    "                    if frequencyTotal > threshold_frequencyTotal:     \n",
    "                        \n",
    "                        winRatio = len(table_trade_result_agg[table_trade_result_agg.status=='TP']) / frequencyTotal\n",
    "                        profit_pct_cumsum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy())\n",
    "                        profit_pct_sum = profit_pct_cumsum[-1]\n",
    "            \n",
    "                        frequencyMean = frequencyTotal / symbol_extracted_len\n",
    "            \n",
    "                        # sharpRatio\n",
    "                        profit = table_trade_result_agg.profit.to_numpy()            \n",
    "                        \n",
    "                        # Risk-free rate (assumed to be 0 for simplicity)\n",
    "                        risk_free_rate = 0\n",
    "                        \n",
    "                        # Calculate various metrics\n",
    "                        mean_return = np.mean(profit)\n",
    "                        std_return = np.std(profit)\n",
    "                        sharpe_ratio = (mean_return - risk_free_rate) / std_return\n",
    "                        \n",
    "                        # Calculate Sortino Ratio\n",
    "                            # focus on downside more.\n",
    "                                # safe oriented.\n",
    "                        downside_returns = profit[profit < 0]\n",
    "                        downside_deviation = np.std(downside_returns)\n",
    "                        sortino_ratio = (mean_return - risk_free_rate) / downside_deviation\n",
    "                        \n",
    "                        # Calculate Maximum Drawdown\n",
    "                        cumulative_returns = np.cumsum(profit)\n",
    "                        drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "                        max_drawdown = np.min(drawdowns)\n",
    "                        \n",
    "                        cumulative_returns_min = cumulative_returns.min()\n",
    "                        cumulative_returns_max = cumulative_returns.max()\n",
    "                        cumulative_returns_scaled = (cumulative_returns - cumulative_returns_min) / (cumulative_returns_max - cumulative_returns_min)\n",
    "                        drawdowns_scaled = cumulative_returns_scaled - np.maximum.accumulate(cumulative_returns_scaled)\n",
    "                        max_drawdown_scaled = np.min(drawdowns_scaled)\n",
    "                        # # Min-Max Normalization for a single MDD\n",
    "                        # min_mdd = drawdowns.max()  # assuming the minimum possible MDD is 0\n",
    "                        # max_mdd = drawdowns.min()  # assuming the maximum possible MDD is 1\n",
    "                        \n",
    "                        # # Normalize the Max Drawdown to the range [0, 1]\n",
    "                        # normalized_max_drawdown = (max_drawdown - min_mdd) / (max_mdd - min_mdd)\n",
    "                        \n",
    "                        # Calculate Calmar Ratio\n",
    "                        # annual_return = mean_return * 12  # Assuming monthly profit\n",
    "                        # calmar_ratio = annual_return / -max_drawdown\n",
    "                        \n",
    "                        # Calculate Profit Factor\n",
    "                        total_profit = np.sum(profit[profit > 0])\n",
    "                        total_loss = -np.sum(profit[profit < 0])\n",
    "                        profit_factor = total_profit / total_loss\n",
    "\n",
    "                        \n",
    "                        x = np.linspace(0, 1, len(cumulative_returns_scaled))\n",
    "                        # y_actual = x**2\n",
    "                        y_actual = x # v0.2 : closer concept to 'consistency'\n",
    "                        y_predicted = cumulative_returns_scaled\n",
    "                        \n",
    "                        mse = mean_squared_error(y_actual, y_predicted)                        \n",
    "                        r2 = r2_score(y_actual, y_predicted)\n",
    "                        \n",
    "\n",
    "                        timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "                        table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "                        table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "                        \n",
    "                        minutes = itv_to_number(interval)\n",
    "                        timestamp_unit = 60 * minutes # 15min. case\n",
    "                        table_trade_result_agg['timemap_entry'] /= timestamp_unit\n",
    "                        table_trade_result_agg['timemap_exit'] /= timestamp_unit\n",
    "                        \n",
    "                        \n",
    "                        map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]))\n",
    "                        for cnt, (row) in enumerate(table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy()):\n",
    "                            \n",
    "                            index_start, index_end, amount = row                            \n",
    "                            map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "                        \n",
    "                        map_amount_agg_max = map_amount_agg.max()\n",
    "                            \n",
    "            \n",
    "                        row = [\n",
    "                            interval,\n",
    "                            target_loss,\n",
    "                            target_leverage,\n",
    "                            position,\n",
    "                            RRratio_adj_fee_category,\n",
    "                            threshold_winRatio,\n",
    "                            threshold_frequency,\n",
    "                            threshold_frequencyTotal,\n",
    "                            \"{}\".format(symbol_extracted.tolist()),\n",
    "                            symbol_extracted_len,\n",
    "                            symbol_extracted_len_pct,\n",
    "                            frequencyTotal,\n",
    "                            frequencyMean,\n",
    "                            winRatio,\n",
    "                            profit_pct_sum,\n",
    "                            mean_return,\n",
    "                            std_return,\n",
    "                            max_drawdown,\n",
    "                            max_drawdown_scaled,\n",
    "                            sharpe_ratio,\n",
    "                            sortino_ratio,\n",
    "                            profit_factor,\n",
    "                            mse,\n",
    "                            r2,\n",
    "                            map_amount_agg_max,\n",
    "                        ]\n",
    "                        \n",
    "                        result_list.append(row)\n",
    "                        \n",
    "                        title = ''\n",
    "                        title += 'interval : {}\\n'.format(interval)\n",
    "                        title += 'target_loss : {}\\n'.format(target_loss)\n",
    "                        title += 'target_leverage : {}\\n'.format(target_leverage)\n",
    "                        title += 'position : {}\\n'.format(position)\n",
    "                        title += 'RRratio_adj_fee_category : {}\\n'.format(RRratio_adj_fee_category)\n",
    "                        title += 'threshold_winRatio : {}\\n'.format(threshold_winRatio)\n",
    "                        title += 'threshold_frequency : {}\\n'.format(threshold_frequency)\n",
    "                        title += 'threshold_frequencyTotal : {}\\n'.format(threshold_frequencyTotal)\n",
    "                        # title += 'symbol_extracted : {}\\n'.format(symbol_extracted)\n",
    "                        title += 'symbol_extracted_len : {}\\n'.format(symbol_extracted_len)\n",
    "                        title += 'symbol_extracted_len_pct : {:.2f}\\n'.format(symbol_extracted_len_pct)\n",
    "                        title += 'frequencyTotal : {}\\n'.format(frequencyTotal)\n",
    "                        title += 'frequencyMean : {:.2f}\\n'.format(frequencyMean)\n",
    "                        title += 'winRatio : {:.2f}\\n'.format(winRatio)\n",
    "                        title += 'profit_pct_sum : {:.2f}\\n'.format(profit_pct_sum)\n",
    "                        title += 'mean_return : {:.2f}\\n'.format(mean_return)\n",
    "                        title += 'std_return : {:.2f}\\n'.format(std_return)\n",
    "                        title += 'max_drawdown : {:.2f}\\n'.format(max_drawdown)\n",
    "                        title += 'max_drawdown_scaled : {:.2f}\\n'.format(max_drawdown_scaled)\n",
    "                        title += 'sharpe_ratio : {:.2f}\\n'.format(sharpe_ratio)\n",
    "                        title += 'sortino_ratio : {:.2f}\\n'.format(sortino_ratio)\n",
    "                        title += 'profit_factor : {:.2f}\\n'.format(profit_factor)\n",
    "                        title += 'mse : {:.2f}\\n'.format(mse)\n",
    "                        title += 'r2 : {:.2f}\\n'.format(r2)\n",
    "                        title += 'map_amount_agg_max : {:.2f}'.format(map_amount_agg_max)\n",
    "                        \n",
    "                        \n",
    "                        print(title)    \n",
    "                        clear_output()\n",
    "                        \n",
    "\n",
    "                        if show_figure:\n",
    "                            plt.figure()\n",
    "                            plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cumsum)\n",
    "                            plt.title(title, y=0., fontsize=10)\n",
    "\n",
    "                            if save_figure:\n",
    "                                plt.tight_layout()\n",
    "                                payload = '{}\t{}\t{}\t{}\t{}\t{:.2f}'.format(interval, target_loss, target_leverage, position, RRratio_adj_fee_category, threshold_winRatio, threshold_frequency, threshold_frequencyTotal).split('\\t')\n",
    "                                path_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\DC_II_cross\\image\\total\\v0.3\\{}.png\".format(payload)\n",
    "                                plt.savefig(path_save_fig)\n",
    "                            else:                            \n",
    "                                plt.show()\n",
    "                            \n",
    "        #                 break\n",
    "        #         break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ce640-52d3-4f48-ac95-26e7480c8973",
   "metadata": {},
   "source": [
    "#### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99122308-5c03-4a10-a5af-0730c0425448",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_winRatio = np.arange(0.3, 1.0, 0.01)# could know the minimum value for profit rightTopness. \n",
    "range_winRatio = [0.62] \n",
    "\n",
    "# threshold_winRatio = 0.82\n",
    "\n",
    "threshold_frequency = 0\n",
    "# threshold_frequency = 40\n",
    "# threshold_frequency = 70\n",
    "\n",
    "threshold_frequencyTotal = 0\n",
    "threshold_frequencyTotal = 50\n",
    "# threshold_incomeTotal = 0.0 # answer should be set before!\n",
    "\n",
    "\n",
    "\n",
    "for threshold_winRatio in range_winRatio:\n",
    "    \n",
    "    # symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency) & (table_trade_result_pivot.incomeTotal > threshold_incomeTotal)].index\n",
    "    symbol_extracted = table_trade_result_pivot[(table_trade_result_pivot.winRatio > threshold_winRatio) & (table_trade_result_pivot.frequency > threshold_frequency)].index\n",
    "    symbol_extracted = symbol_extracted.droplevel()\n",
    "    # symbol_extracted\n",
    "    symbol_extracted_len = len(symbol_extracted)\n",
    "    symbol_extracted_len_pct = symbol_extracted_len / len(table_trade_result_pivot) * 100\n",
    "    \n",
    "    if symbol_extracted_len > 0:  \n",
    "        \n",
    "        table_trade_result['symbol_extracted_bool'] = [symbol in symbol_extracted for symbol in table_trade_result.symbol]\n",
    "        table_trade_result_agg = table_trade_result[table_trade_result.symbol_extracted_bool].sort_values('timestamp_entry')\n",
    "                \n",
    "        frequencyTotal = len(table_trade_result_agg)\n",
    "\n",
    "        \n",
    "        if frequencyTotal > threshold_frequencyTotal:     \n",
    "            \n",
    "            winRatio = len(table_trade_result_agg[table_trade_result_agg.status=='TP']) / frequencyTotal\n",
    "            profit_pct_cumsum = np.cumsum(table_trade_result_agg['profit (%)'].to_numpy())\n",
    "            profit_pct_sum = profit_pct_cumsum[-1]\n",
    "\n",
    "            frequencyMean = frequencyTotal / symbol_extracted_len\n",
    "\n",
    "            # sharpRatio\n",
    "            profit = table_trade_result_agg.profit.to_numpy()            \n",
    "            \n",
    "            # Risk-free rate (assumed to be 0 for simplicity)\n",
    "            risk_free_rate = 0\n",
    "            \n",
    "            # Calculate various metrics\n",
    "            mean_return = np.mean(profit)\n",
    "            std_return = np.std(profit)\n",
    "            sharpe_ratio = (mean_return - risk_free_rate) / std_return\n",
    "            \n",
    "            # Calculate Sortino Ratio\n",
    "            downside_returns = profit[profit < 0]\n",
    "            downside_deviation = np.std(downside_returns)\n",
    "            sortino_ratio = (mean_return - risk_free_rate) / downside_deviation\n",
    "            \n",
    "            # Calculate Maximum Drawdown\n",
    "            cumulative_returns = np.cumsum(profit)\n",
    "            drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "            max_drawdown = np.min(drawdowns)\n",
    "            \n",
    "            # Calculate Calmar Ratio\n",
    "            # annual_return = mean_return * 12  # Assuming monthly profit\n",
    "            # calmar_ratio = annual_return / -max_drawdown\n",
    "            \n",
    "            # Calculate Profit Factor\n",
    "            total_profit = np.sum(profit[profit > 0])\n",
    "            total_loss = -np.sum(profit[profit < 0])\n",
    "            profit_factor = total_profit / total_loss\n",
    "\n",
    "            row = [\n",
    "                interval,\n",
    "                target_loss,\n",
    "                target_leverage,\n",
    "                position,\n",
    "                RRratio_adj_fee_category,\n",
    "                threshold_winRatio,\n",
    "                threshold_frequency,\n",
    "                threshold_frequencyTotal,\n",
    "                \"{}\".format(symbol_extracted.tolist()),\n",
    "                symbol_extracted_len,\n",
    "                symbol_extracted_len_pct,\n",
    "                frequencyTotal,\n",
    "                frequencyMean,\n",
    "                winRatio,\n",
    "                profit_pct_sum,\n",
    "                mean_return,\n",
    "                std_return,\n",
    "                max_drawdown,\n",
    "                sharpe_ratio,\n",
    "                sortino_ratio,\n",
    "                profit_factor\n",
    "            ]\n",
    "            \n",
    "            result_list.append(row)\n",
    "            \n",
    "            print(\"interval : {}\".format(interval)) \n",
    "            print(\"target_loss : {}\".format(target_loss)) \n",
    "            print(\"target_leverage : {}\".format(target_leverage))     \n",
    "            print(\"position : {}\".format(position))      \n",
    "            print(\"RRratio_adj_fee_category : {}\".format(RRratio_adj_fee_category))                \n",
    "            print(\"threshold_winRatio : {}\".format(threshold_winRatio))     \n",
    "            print(\"threshold_frequency : {}\".format(threshold_frequency))   \n",
    "            print(\"threshold_frequencyTotal : {}\\n\".format(threshold_frequencyTotal))               \n",
    "            print(\"symbol_extracted_len : {} ({:.2%})\".format(symbol_extracted_len, symbol_extracted_len / len(table_trade_result_pivot)))   \n",
    "            print(\"frequencyTotal : {}\".format(frequencyTotal))    \n",
    "            print(\"frequencyTotal / symbol_extracted_len : {}\".format(frequencyTotal / symbol_extracted_len))                \n",
    "            print(\"winRatio : {}\".format(winRatio))    \n",
    "            print(\"profit_pct_cumsum : {}\\n\".format(profit_pct_cumsum[-1]))  \n",
    "            print(\"Mean Return : {}\".format(mean_return))\n",
    "            print(\"Standard Deviation : {}\".format(std_return))\n",
    "            print(\"Maximum Drawdown : {}\".format(max_drawdown))\n",
    "            print(\"Sharpe Ratio (0/1/2) : {}\".format(sharpe_ratio))\n",
    "            print(\"Sortino Ratio (1/2/3) : {}\".format(sortino_ratio))\n",
    "            print(\"Profit Factor (1/1.5/2) : {}\".format(profit_factor))\n",
    "\n",
    "            \n",
    "            # plt.plot(np.cumsum(table_trade_result_agg['income - commission'].to_numpy()))\n",
    "            # plt.step(np.arange(len(table_trade_result_agg)), np.cumsum(table_trade_result_agg['income - commission'].to_numpy()))\n",
    "            plt.step(np.arange(len(table_trade_result_agg)), profit_pct_cumsum)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491eee20-d17d-43ef-ad78-db067aa48ec3",
   "metadata": {},
   "source": [
    "### check individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ce840-4fc2-496b-ab0f-d57dfdbccb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ed0f2-543b-4882-a817-145244c1505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for symbol in symbol_extracted:\n",
    "    \n",
    "    table_trade_result_target = table_trade_result[table_trade_result.symbol==symbol]\n",
    "\n",
    "    frequency = len(table_trade_result_target)\n",
    "    winRatio = len(table_trade_result_target[table_trade_result_target.status=='TP']) / frequency\n",
    "    \n",
    "    print(\"symbol : {}\".format(symbol))\n",
    "    print(\"frequency : {}\".format(frequency))\n",
    "    print(\"winRatio : {}\".format(winRatio))\n",
    "    \n",
    "    # plt.plot(np.cumsum(table_trade_result_target['income - commission'].to_numpy()))\n",
    "    plt.step(np.arange(len(table_trade_result_target)), np.cumsum(table_trade_result_target['income - commission'].to_numpy()))\n",
    "    plt.show()\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b88d1c-705c-4f45-ab5e-e37fbae2c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f952d6-4187-4119-9b3b-9e98f965a1ef",
   "metadata": {},
   "source": [
    "### get max amount (adj. leverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5909d9-b9f4-4355-a704-6a4d99a712f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_min = table_trade_result_agg['timestamp_entry'].iloc[0]\n",
    "table_trade_result_agg['timemap_entry'] = table_trade_result_agg['timestamp_entry'] - timestamp_min\n",
    "table_trade_result_agg['timemap_exit'] = table_trade_result_agg['timestamp_exit'] - timestamp_min\n",
    "\n",
    "minutes = itv_to_number(interval)\n",
    "timestamp_unit = 60 * minutes # 15min. case\n",
    "table_trade_result_agg['timemap_entry'] /= timestamp_unit\n",
    "table_trade_result_agg['timemap_exit'] /= timestamp_unit\n",
    "\n",
    "\n",
    "map_amount_agg = np.zeros(int(table_trade_result_agg['timemap_exit'].iloc[-1]))\n",
    "\n",
    "# for cnt, (_, row) in enumerate(table_trade_result_agg[['timestamp_entry', 'timestamp_exit', 'amount']].iterrows()):\n",
    "for cnt, (row) in enumerate(table_trade_result_agg[['timemap_entry', 'timemap_exit', 'amount_entry_adj_leverage']].to_numpy()):\n",
    "\n",
    "    print(cnt, end='\\r')\n",
    "    \n",
    "    index_start, index_end, amount = row\n",
    "    # print(index_start, index_end, amount)\n",
    "    \n",
    "    map_amount_agg[int(index_start):int(index_end) + 1] += amount\n",
    "    # print(map_amount_agg)\n",
    "    # break\n",
    "\n",
    "print(minutes)\n",
    "print(map_amount_agg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbf0fa-ae87-48e6-830d-23b5e1ce1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_agg.describe() #.head()\n",
    "# table_trade_result_agg #.head()\n",
    "# table_trade_result_agg['timestamp_exit'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e43579-ab62-486b-ac3a-6e0585d6a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.step(np.arange(len(map_amount_agg)), map_amount_agg)\n",
    "plt.step(np.arange(len(table_trade_result_agg.amount_entry)), table_trade_result_agg.amount_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1b37c-d652-4fd1-95fd-24d307155288",
   "metadata": {},
   "source": [
    "## save table_trade_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eeb03c-9f97-4733-9405-7a84fde6a930",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144aa5f-ba1b-4a82-a8db-1d716684e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2.0\n",
    "    modify column following to get_output_row\n",
    "\n",
    "last confirmed at, 20240704 1357.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "columns = [\n",
    "    'interval',\n",
    "    'target_loss',\n",
    "    'target_loss_pct', \n",
    "    'target_leverage',\n",
    "    'position',\n",
    "    'RRratio_adj_fee_category',\n",
    "    'threshold_winRatio',\n",
    "    'threshold_frequency',\n",
    "    'threshold_frequencyTotal',\n",
    "    'symbol_extracted',\n",
    "    'symbol_extracted_len',\n",
    "    'symbol_extracted_len_pct',\n",
    "    'frequencyTotal',\n",
    "    'frequencyMean',\n",
    "    'winRatio',\n",
    "    'assets_min_required_const',\n",
    "    'assets_max_drawdown_const',\n",
    "    'profit_pct_final',\n",
    "    'profit_pct_daily', \n",
    "    'profit_pct_monthly',\n",
    "    'profit_pct_yearly',\n",
    "    'profit_pct_final_min',\n",
    "    'profit_pct_daily_min', \n",
    "    'profit_pct_monthly_min',\n",
    "    'profit_pct_yearly_min',\n",
    "    'profit_pct_final_max',\n",
    "    'profit_pct_daily_max', \n",
    "    'profit_pct_monthly_max',\n",
    "    'profit_pct_yearly_max',\n",
    "    'mean_return',\n",
    "    'std_return',\n",
    "    'max_drawdown',\n",
    "    'max_drawdown_scaled',\n",
    "    'sharpe_ratio',\n",
    "    'sortino_ratio',\n",
    "    'profit_factor',\n",
    "    'mse',\n",
    "    'r2'\n",
    "]\n",
    "\n",
    "columns_reorder = [\n",
    "    'r2',\n",
    "    'max_drawdown_scaled',\n",
    "    'frequencyTotal',\n",
    "    'frequencyMean',\n",
    "    'symbol_extracted_len_pct',\n",
    "    'profit_pct_monthly_min',\n",
    "    'profit_pct_monthly_max',\n",
    "    'winRatio',\n",
    "    \n",
    "    'interval',\n",
    "    'target_loss',\n",
    "    'target_loss_pct', \n",
    "    'target_leverage',\n",
    "    'position',\n",
    "    'RRratio_adj_fee_category',\n",
    "    'threshold_winRatio',\n",
    "    'threshold_frequency',\n",
    "    'threshold_frequencyTotal',\n",
    "    'symbol_extracted',\n",
    "    'symbol_extracted_len',\n",
    "    'assets_min_required_const',\n",
    "    'assets_max_drawdown_const',\n",
    "    'profit_pct_final',\n",
    "    'profit_pct_daily', \n",
    "    'profit_pct_monthly',\n",
    "    'profit_pct_yearly',\n",
    "    'profit_pct_final_min',\n",
    "    'profit_pct_daily_min', \n",
    "    'profit_pct_yearly_min',\n",
    "    'profit_pct_final_max',\n",
    "    'profit_pct_daily_max', \n",
    "    'profit_pct_yearly_max',\n",
    "    'mean_return',\n",
    "    'std_return',\n",
    "    'max_drawdown',\n",
    "    'sharpe_ratio',\n",
    "    'sortino_ratio',\n",
    "    'profit_factor',\n",
    "    'mse',\n",
    "]\n",
    "\n",
    "table_trade_result_anchor =  pd.DataFrame(result_list, columns=columns) #.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fef11f-a013-4410-baa4-a9beb16d5f62",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5de5e5-c1c1-4cf5-8b9a-7cc44e1bda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        'interval',\n",
    "        'target_loss',\n",
    "        'target_loss_pct', \n",
    "        'target_leverage',\n",
    "        'position',\n",
    "        'RRratio_adj_fee_category',\n",
    "        'threshold_winRatio',\n",
    "        'threshold_frequency',\n",
    "        'threshold_frequencyTotal',\n",
    "        'symbol_extracted',\n",
    "        'symbol_extracted_len',\n",
    "        'symbol_extracted_len_pct',\n",
    "        'frequencyTotal',\n",
    "        'frequencyMean',\n",
    "        'winRatio',\n",
    "        'profit_pct_sum',\n",
    "        'mean_return',\n",
    "        'std_return',\n",
    "        'max_drawdown',\n",
    "        'max_drawdown_scaled',\n",
    "        'sharpe_ratio',\n",
    "        'sortino_ratio',\n",
    "        'profit_factor',\n",
    "        'mse',\n",
    "        'r2',\n",
    "        'map_amount_agg_max'\n",
    "    ]\n",
    "\n",
    "columns_reorder = [\n",
    "        'r2',\n",
    "        'max_drawdown_scaled',\n",
    "        'frequencyMean',\n",
    "        'symbol_extracted_len_pct',\n",
    "    \n",
    "        'interval',\n",
    "        'target_loss',\n",
    "        'target_loss_pct', \n",
    "        'target_leverage',\n",
    "        'position',\n",
    "        'RRratio_adj_fee_category',\n",
    "        'threshold_winRatio',\n",
    "        'threshold_frequency',\n",
    "        'threshold_frequencyTotal',\n",
    "        'symbol_extracted',\n",
    "        'symbol_extracted_len',\n",
    "        'frequencyTotal',\n",
    "        'winRatio',\n",
    "        'profit_pct_sum',\n",
    "        'mean_return',\n",
    "        'std_return',\n",
    "        'max_drawdown',\n",
    "        'sharpe_ratio',\n",
    "        'sortino_ratio',\n",
    "        'profit_factor',\n",
    "        'mse',\n",
    "        'map_amount_agg_max'\n",
    "    ]\n",
    "\n",
    "table_trade_result_anchor =  pd.DataFrame(result_list, columns=columns) #.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89a1e2-f71a-4d6e-944c-db1d82f735ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_trade_result_anchor#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801a1cc-090d-4337-84f6-c98cc9856a28",
   "metadata": {},
   "source": [
    "### excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc38d0d-9f22-4e74-8864-676d8f9e6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_table_trade_result_anchor = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result_anchor/{}_{}/{}\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator)\n",
    "os.makedirs(path_dir_table_trade_result_anchor, exist_ok=True)\n",
    "\n",
    "table_trade_result_anchor.to_excel(os.path.join(path_dir_table_trade_result_anchor, \"{}.xlsx\".format(datetime.now().strftime('%Y%m%d%H%M'))), index=0)#.tail()\n",
    "# table_trade_result_anchor[columns_reorder].to_excel(os.path.join(path_dir_table_trade_result_anchor, \"{}.xlsx\".format(datetime.now().strftime('%Y%m%d%H%M'))), index=0)#.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314c1b7-b703-4ca1-91de-faf5978cd21e",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad5575-7215-4320-af6b-4f1fa8aff757",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_table_trade_result_anchor = r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/{}/table_trade_result_anchor/{}_{}/{}\".format(dir_name_strategy, priceBox_value, point_value, zone_indicator)\n",
    "os.makedirs(path_dir_table_trade_result_anchor, exist_ok=True)\n",
    "\n",
    "table_trade_result_anchor.to_csv(os.path.join(path_dir_table_trade_result_anchor, \"{}.csv\".format(datetime.now().strftime('%Y%m%d%H%M'))), index=0)#.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34251ae1-9d2a-4cbd-b442-bbaf35d34bbf",
   "metadata": {},
   "source": [
    "### feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491356a-300c-49e8-8acf-0633fc47dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/{}/{}/\".format(interval, period_DC), exist_ok=True)\n",
    "table_trade_result.reset_index(drop=True).to_feather(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/{}/{}/{}_SHORT_{}.ftr\".format(interval, period_DC, bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ef009-b0b1-46a2-87aa-a45dad710df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_feather(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/table_trade_res/BANDUSDT_202406060214.ftr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509d732-1612-4972-92a6-6d3b5edef369",
   "metadata": {},
   "source": [
    "### parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497f74f-120a-4def-832b-7c083af10c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1.0\n",
    "    feather doesn't support datetimeIndex.\n",
    "\n",
    "last confirmed at, 20240606 0109.\n",
    "\"\"\"\n",
    "\n",
    "bank.df_res.to_parquet(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/df_res/{}/{}_{}.parquet\".format(interval, bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))\n",
    "pd.read_parquet(r\"D:\\\\Project\\\\SystemTrading\\\\Project\\\\JnQ\\\\anal/DC_II_cross/df_res/{}/DOTUSDT_202406060107.parquet\".format(interval, bank.symbol, datetime.now().strftime('%Y%m%d%H%M')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9293a-e487-40bb-add9-79da231cb880",
   "metadata": {},
   "source": [
    "### .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cd0a4-ec7e-4213-a2ca-2a970e2e73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_category, category in enumerate(table_trade_result_pivot_adj_threshold.index.tolist()):\n",
    "\n",
    "    table_trade_result_anal = table_trade_result[table_trade_result.RRratio_adj_fee_category == category]\n",
    "    table_trade_result_len = len(table_trade_result)\n",
    "    table_trade_result_anal_len = len(table_trade_result_anal)\n",
    "    \n",
    "    winRatio = len(table_trade_result_anal[table_trade_result_anal.status=='TP']) / table_trade_result_anal_len\n",
    "    \n",
    "    print(\"category : {}\".format(category))\n",
    "    print(\"winRatio : {}\".format(winRatio))\n",
    "    print(\"frequency_total : {}\".format(table_trade_result_len))\n",
    "    print(\"frequency : {}\".format(table_trade_result_anal_len))\n",
    "\n",
    "    title = \"symbol : {}\\n\".format(bank.symbol)\n",
    "    title += \"category : {}\\n\".format(category)\n",
    "    title += \"winRatio : {:.2f}\\n\".format(winRatio)\n",
    "    title += \"frequency_total : {}\\n\".format(table_trade_result_len)\n",
    "    title += \"frequency : {}\".format(table_trade_result_anal_len)\n",
    "    \n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.step(np.arange(len(table_trade_result_anal)), np.cumsum(table_trade_result_anal['income - commission'].to_numpy()))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # path_save_fig = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\DC_II_cross\\image\\{}_{}.png\".format(bank.symbol, index_category)\n",
    "    # plt.savefig(path_save_fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e6e93-84f8-4576-8fa8-dbd5723c447a",
   "metadata": {},
   "source": [
    "# DataScience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1650d-e408-49ad-8d56-f84a0cbc2ab7",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ce461-480b-4c0c-a800-7c7647d72df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_dir = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\database\\binance\\data_trade\"\n",
    "\n",
    "path_dir_save = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\"\n",
    "# path_dir_save = None\n",
    "\n",
    "for name_file in os.listdir(path_dir):\n",
    "    if name_file.endswith('.ftr'): \n",
    "        if path_dir_save is not None:\n",
    "            path_save_pkl = os.path.join(path_dir_save, 'dataframe', name_file.replace('.ftr', '.pkl'))\n",
    "            # path_save_fig = os.path.join(path_dir_save, 'image', name_file.replace('.ftr', '.png'))\n",
    "            path_save_fig = None\n",
    "        else:\n",
    "            path_save_pkl = None\n",
    "            path_save_fig = None\n",
    "        \n",
    "        get_steady_profitable_conditions(path_df=os.path.join(path_dir, name_file),\n",
    "                                        figsize=(5,5),\n",
    "                                        path_save_pkl=path_save_pkl,\n",
    "                                        path_save_fig=path_save_fig)\n",
    "\n",
    "        print(\"{} done.\".format(name_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907440d1-2a3f-4bf0-ae6e-61babd1c51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steady_profitable_conditions(path_df,\n",
    "                                    figsize,\n",
    "                                    path_save_pkl,\n",
    "                                    path_save_fig):\n",
    "\n",
    "    df = pd.read_feather(path_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ts_gap_max = df['ts_en'].max()\n",
    "    ts_gap_min = df['ts_ex'].min()\n",
    "    ts_gap = ts_gap_max - ts_gap_min\n",
    "    \n",
    "    ts_ratio_train = 0.5\n",
    "    ts_ratio_val = 0.8\n",
    "    \n",
    "    ts_train_last = ts_gap_min + ts_gap * ts_ratio_train\n",
    "    ts_val_last = ts_gap_min + ts_gap * ts_ratio_val\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['DataType'] = np.where(df['ts_en'] < ts_val_last, 'VAL', 'TEST')\n",
    "    df['DataType'] = np.where(df['ts_en'] < ts_train_last, 'TRAIN', df['DataType'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    unit_wrr32 = np.arange(0, 1.01, 0.01)\n",
    "    df['wrr_32_category'] = pd.cut(df['wrr_32'], unit_wrr32, precision=0, duplicates='drop').astype(str)\n",
    "    \n",
    "    \n",
    "    \n",
    "    index = ['symbol', 'position', 'wrr_32_category']\n",
    "    df_pivot = df.pivot_table(index=index, columns=['DataType'], values=['pr'], aggfunc={'symbol': 'count', 'pr': 'prod'}, fill_value=0)\n",
    "    df_pivot = df_pivot[[(    'pr',  'TRAIN'),\n",
    "                (    'pr', 'VAL'),\n",
    "                (    'pr',   'TEST'),\n",
    "                ('symbol',  'TRAIN'),\n",
    "                ('symbol', 'VAL'),\n",
    "                ('symbol',   'TEST')]]#.columns\n",
    "    \n",
    "    index_profit_criteria_passed = (np.sum(df_pivot[[(    'pr',  'TRAIN'),\n",
    "                (    'pr', 'VAL'),\n",
    "                (    'pr',   'TEST')]] > 1.02, axis=1) == 3).values #.columns\n",
    "           \n",
    "    df_pivot[index_profit_criteria_passed].reset_index().to_pickle(path_save_pkl)\n",
    "\n",
    "    \n",
    "    \n",
    "    index_key_valid = df_pivot[index_profit_criteria_passed].index.values    \n",
    "    for idx, key in enumerate(index_key_valid):   \n",
    "        df_extracted = df[np.sum(df[['symbol', 'position', 'wrr_32_category']] == key, axis=1) == 3].reset_index()\n",
    "        vline_train = np.where(df_extracted.DataType == 'TRAIN')[0][-1]\n",
    "        vline_val = np.where(df_extracted.DataType == 'VAL')[0][-1]\n",
    "    \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(df_extracted.pr.cumprod(), 'r')\n",
    "        plt.plot((df_extracted.pr - 1).cumsum() + 1, 'y')\n",
    "        plt.axvline(vline_train)\n",
    "        plt.axvline(vline_val)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.title(key, fontsize=8)\n",
    "\n",
    "        if path_save_fig is not None:\n",
    "            plt.savefig(path_save_fig.replace('.png', '_{}.png'.format(idx)))\n",
    "        else:\n",
    "            plt.show()\n",
    "        # break\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9143-aca6-4512-9790-345a978bb392",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91d1b9-cdd3-4df2-a12b-c8201e2189ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(r\"D:\\Project\\SystemTrading\\Project\\JnQ\\database\\binance\\data_trade\\1INCHUSDT.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d61648-cba7-443e-b761-d5b625e99fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_gap_max = df['ts_en'].max()\n",
    "ts_gap_min = df['ts_ex'].min()\n",
    "ts_gap = ts_gap_max - ts_gap_min\n",
    "\n",
    "ts_ratio_train = 0.5\n",
    "ts_ratio_val = 0.8\n",
    "\n",
    "ts_train_last = ts_gap_min + ts_gap * ts_ratio_train\n",
    "ts_val_last = ts_gap_min + ts_gap * ts_ratio_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082a803-de64-4fe8-a391-f786f41de301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['win/lose'] = df['pr'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0327d8d-52ee-477b-b698-f35b7f64f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DataType'] = np.where(df['ts_en'] < ts_val_last, 'VAL', 'TEST')\n",
    "df['DataType'] = np.where(df['ts_en'] < ts_train_last, 'TRAIN', df['DataType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165707d-c3e2-4d34-9bb8-5aea31549248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(['max', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97a74e-c8f5-463b-8d40-13ff0e63487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_wrr32 = np.arange(0, 1.01, 0.01)\n",
    "unit_spread = np.arange(0, 0.7, 0.01)\n",
    "unit_tr = np.arange(0, 2.8, 0.1)\n",
    "unit_wave_length = np.arange(0, 300, 50)\n",
    "\n",
    "df['wrr_32_category'] = pd.cut(df['wrr_32'], unit_wrr32, precision=0, duplicates='drop').astype(str)\n",
    "df['spread_category'] = pd.cut(df['spread'], unit_spread, precision=0, duplicates='drop').astype(str)\n",
    "df['tr_category'] = pd.cut(df['tr'], unit_tr, precision=0, duplicates='drop').astype(str)\n",
    "df['wave_length_category'] = pd.cut(df['wave_length'], unit_wave_length, precision=0, duplicates='drop').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1333ecc-6a44-4746-8a6a-02ebe10da4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['wrr_32_category']\n",
    "index = ['spread_category']\n",
    "# index = ['wave_length_category']\n",
    "\n",
    "# index = ['wrr_32_category', 'DataType']\n",
    "# index = ['wrr_32_category', 'spread_category', 'tr_category', 'DataType']\n",
    "# index = ['wrr_32_category', 'spread_category', 'wave_length_category', 'DataType']\n",
    "\n",
    "index = ['symbol', 'position', 'wrr_32_category']\n",
    "df_pivot = df.pivot_table(index=index, columns=['DataType'], values=['pr'], aggfunc={'symbol': 'count', 'pr': 'prod'}, fill_value=0)\n",
    "df_pivot = df_pivot[[(    'pr',  'TRAIN'),\n",
    "            (    'pr', 'VAL'),\n",
    "            (    'pr',   'TEST'),\n",
    "            ('symbol',  'TRAIN'),\n",
    "            ('symbol', 'VAL'),\n",
    "            ('symbol',   'TEST')]]#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c296a-6f70-44bc-a6df-b8bc1d0ea523",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_profit_criteria_passed = (np.sum(df_pivot[[(    'pr',  'TRAIN'),\n",
    "            (    'pr', 'VAL'),\n",
    "            (    'pr',   'TEST')]] > 1.02, axis=1) == 3).values #.columns\n",
    "\n",
    "index_key_valid = df_pivot[index_profit_criteria_passed].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff5d13-9362-4139-9b91-99cf5ab3e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_key_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c37bc-f70c-4e8b-9077-fde2578b0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pivot[index_profit_criteria_passed].reset_index().to_feather(r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\dataframe\\test.ftr\")\n",
    "df_pivot[index_profit_criteria_passed].reset_index().to_pickle(r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\dataframe\\test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a193b3-661e-4515-82af-1ef4df17a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd.read_pickle(r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\dataframe\\test.pkl\").index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb51e4-6190-4e8c-8756-8598e5dfe320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mabalance_availablelotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b65d1-3986-4a32-8b27-b97518df7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5,5)\n",
    "# figure = plt.figure(figsize=(5,5))\n",
    "for idx, key in enumerate(index_key_valid):  \n",
    "    df_extracted = df[np.sum(df[['symbol', 'position', 'wrr_32_category']] == key, axis=1) == 3].reset_index()\n",
    "    vline_train = np.where(df_extracted.DataType == 'TRAIN')[0][-1]\n",
    "    vline_val = np.where(df_extracted.DataType == 'VAL')[0][-1]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(df_extracted.pr.cumprod())\n",
    "    plt.axvline(vline_train)\n",
    "    plt.axvline(vline_val)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title(key, fontsize=8)\n",
    "    plt.savefig(r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\test_{}.png\".format(idx))\n",
    "    plt.show()\n",
    "\n",
    "    # figure.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e3a9c-d65d-471a-bf63-12f933c38a9e",
   "metadata": {},
   "source": [
    "## set data (make table_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f71ad-41e1-496b-8396-fb1beca89f13",
   "metadata": {},
   "source": [
    "### read label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336cda7-8a6e-46ee-8c4b-0b1e5f191ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\label.txt\"\n",
    "\n",
    "to_series_list = []\n",
    "with open(path_label, 'r') as f:\n",
    "    # print(f.readlines())\n",
    "    for line in f.readlines():\n",
    "        if len(line) > 1:\n",
    "            # symbol, idx = line.strip().split(\"\\\\\")[-1].split('.')[0].split('_')\n",
    "            # print(symbol, idx)\n",
    "            to_series_list.append(line.strip().split(\"\\\\\")[-1].split('.')[0].split('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18407b-9c4e-4643-8f63-f6a45b6b81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_series_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c475d4b-e215-48a6-a396-69bf3bbc62a8",
   "metadata": {},
   "source": [
    "### read dataframe & concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efd784-ede6-47e2-8cf8-37b10741982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_df = r\"D:\\Project\\SystemTrading\\Project\\JnQ\\anal\\WRR32_condition\\dataframe\"\n",
    "# path_dir_save = None\n",
    "\n",
    "df_list = []\n",
    "for name_file_df in os.listdir(path_dir_df):\n",
    "    df_list.append(pd.read_pickle(os.path.join(path_dir_df, name_file_df)))\n",
    "    # break\n",
    "\n",
    "df_concat = pd.concat(df_list).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169c72b-bdbe-46fa-92f5-7239fec4d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat #['index'] #.index\n",
    "df_concat.columns #['index'] #.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f669df-1bc6-49aa-86b3-7c2daf72bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_list = []\n",
    "\n",
    "for symbol, idx in to_series_list:\n",
    "    # print(np.where(df_concat.symbol == symbol)[0])#.index)\n",
    "    df_extract_by_symbol = df_concat.iloc[np.where(df_concat.symbol == symbol)[0]]\n",
    "    # print(df_extract_by_symbol[df_extract_by_symbol['index'] == int(idx)])\n",
    "    df_valid_list.append(df_extract_by_symbol[df_extract_by_symbol['index'] == int(idx)])\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89e832-ff69-4bf0-99ba-53ab0ceeaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.concat(df_valid_list).reset_index(drop=True) #inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d2320-2c0f-4cae-9082-116f33180551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid\n",
    "# df_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8e217-6638-4dac-825e-d86ab3c9216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_valid_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1794d905-62d2-44c6-a8c6-9a08bb0e72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.columns #.symbol\n",
    "# df_valid[(         'symbol',      '')]#.columns #.symbol\n",
    "\n",
    "data_valid_symbol = df_valid[(         'symbol',      '')].values\n",
    "data_valid_position = df_valid[(         'position',      '')].values\n",
    "data_valid_wrr32 = np.vstack(df_valid[('wrr_32_category',      '')].apply(lambda x : np.array(x.replace('(', '').replace(']', '').split(',')).astype(float))) #.shape#.to_numpy().reshape(-1, 2) # .astype(float) #.values\n",
    "\n",
    "\n",
    "data_valid_wrr32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45df116-4f68-4fcb-85db-8c2b08fd6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list = []\n",
    "\n",
    "for symbol, position, (wrr32_min, wrr32_max) in zip(data_valid_symbol, data_valid_position, data_valid_wrr32):\n",
    "    \n",
    "    # print(symbol, position, (wrr32_min, wrr32_max))\n",
    "    \n",
    "    data_row = row_value_default.copy()\n",
    "    data_row[0] = symbol\n",
    "    \n",
    "    if position == 'SHORT':\n",
    "        data_row[6] = wrr32_max # short max\n",
    "        data_row[8] = wrr32_min # short min\n",
    "    else:\n",
    "        data_row[7] = wrr32_max # long max\n",
    "        data_row[9] = wrr32_min # long min\n",
    "        \n",
    "    data_list.append(data_row)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0aaafc-3481-47d3-9ef0-06b131ce93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_excel(\"./data\\table\\table_condition - 복사본.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477e283-86d5-4fee-b983-7053e8361548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_load.values\n",
    "df_load.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f412e-8914-498d-b10a-17fdf6b200c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=data_list, columns=df_load.columns).to_excel(\"./data\\table\\table_condition_from_code.xlsx\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf5e4d-8e5d-4093-ad9f-764555ee318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_value_default = ['None', 'None', 'None', 5, 'None', 'None', 'None', 'None', 'None', 'None',\n",
    "                'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
    "                1, 0, 'None', 'None', 'None', 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55096030-12c4-4038-bf57-fdefccaf366d",
   "metadata": {},
   "source": [
    "# Alertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae5800-7577-4da9-8db5-cd66a02036fd",
   "metadata": {},
   "source": [
    "## Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31d568-c65c-4176-ae70-92639c734c6e",
   "metadata": {},
   "source": [
    "### II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5ba48-4eb0-4651-b348-c90bba172f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 2 # at least 2 days for 15T II value to be synced.\n",
    "end_date = None  # \"2023-01-06\" \"2021-04-12\" \"2021-03-23\"\n",
    "# end_date = \"2023-12-20\"\n",
    "intervals = ['1m']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "interval = '15m'\n",
    "limit = 1500\n",
    "\n",
    "# bank.symbol = 'THETAUSDT'\n",
    "symbols = ['BCHUSDT', 'BICOUSDT']\n",
    "symbols = ['DOTUSDT']\n",
    "# bank_exchange_info = bank.exchange_info()\n",
    "# symbols = [data['symbol'] for data in bank.exchange_info()['symbols'] if 'USDT' in data['symbol'] if '_' not in data['symbol']]\n",
    "\n",
    "while 1:\n",
    "    for bank.symbol in symbols:        \n",
    "        bank.df_res, end_date = concat_candlestick_v2(bank.symbol,\n",
    "                                                      interval,\n",
    "                                                      days,\n",
    "                                                      limit=limit,\n",
    "                                                      end_date=end_date,\n",
    "                                                      show_process=True,\n",
    "                                                      timesleep=0.2)\n",
    "\n",
    "        # 15T \n",
    "        # bank.df_res = to_htf(bank.df_res, '15T', 0)\n",
    "    \n",
    "        # signal\n",
    "            # get II\n",
    "        bank.df_res = get_II(bank.df_res)\n",
    "        display(bank.df_res.tail())\n",
    "        break\n",
    "        \n",
    "            # open\n",
    "                # cross_over.\n",
    "        if bank.df_res.iiSource[-2] > 0 > bank.df_res.iiSource[-3]:\n",
    "            bank.push_msg(bank, \"signal : {} {}\".format(bank.symbol, 'OPEN'))\n",
    "            \n",
    "            # close\n",
    "                # cross_under.\n",
    "        elif bank.df_res.iiSource[-2] < 0 < bank.df_res.iiSource[-3]:\n",
    "            bank.push_msg(bank, \"signal : {} {}\".format(bank.symbol, 'CLOSE'))    \n",
    "            \n",
    "        # time.sleep(0.1)  \n",
    "        \n",
    "    time.sleep(1)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa8126-89cf-4fe3-b198-98e53dabad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_htf(df, interval, offset):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        adj. volume : sum\n",
    "\n",
    "    last confirmed at, 20240509 2502.\n",
    "    \"\"\"\n",
    "\n",
    "    df_htf = df.resample(interval, offset=offset).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "\n",
    "    return df_htf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba036002-fee7-4242-8a57-7dbd8f8be37c",
   "metadata": {},
   "source": [
    "#### get_id_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a99d7-2fbb-4365-8a3f-335c039b56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_cols(df_chunk):\n",
    "    \n",
    "    df_chunk['idVolume'] =  df_chunk.volume.cumsum()\n",
    "    df_chunk['idRangeH'] =  df_chunk.high.cummax()\n",
    "    df_chunk['idRangeL'] =  df_chunk.low.cummin()\n",
    "\n",
    "    return df_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0685dd6-2971-4964-a19d-cc4227b7f56a",
   "metadata": {},
   "source": [
    "#### get_II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b7c8d-bc06-49ee-9319-2b32e00c4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_II(df, period=21):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        add assertion type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "\n",
    "    last confirmed at, 20240606 0732.\n",
    "    \"\"\"\n",
    "\n",
    "    assert type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "    idx_startDay = df.index.map(lambda x : '09:00:00' in str(x))\n",
    "\n",
    "    idx_startDay_arr = np.argwhere(idx_startDay)\n",
    "    idx_startDay_arr = np.insert(idx_startDay_arr, 0, 0)\n",
    "    idx_startDay_arr = np.append(idx_startDay_arr, len(df))\n",
    "    \n",
    "    df_chunks = [get_id_cols(df.iloc[idx_startDay_arr[n]:idx_startDay_arr[n + 1]]) for n in range(len(idx_startDay_arr)-1)]\n",
    "    df_res_id = pd.concat(df_chunks)\n",
    "    df_res_id_arr = df_res_id.to_numpy()\n",
    "    \n",
    "    idx_col_close = df_res_id.columns.get_loc('close')\n",
    "    idx_col_idRangeH = df_res_id.columns.get_loc('idRangeH')\n",
    "    idx_col_idRangeL = df_res_id.columns.get_loc('idRangeL')\n",
    "    idx_col_idVolume = df_res_id.columns.get_loc('idVolume')\n",
    "    \n",
    "    #  # 357 µs ± 45.8\n",
    "    # %timeit -n1 -r100 df_res_id['iiiValue'] = (2 * df_res_id['close'] - df_res_id['idRangeH'] - df_res_id['idRangeL']) / (df_res_id['idRangeH'] - df_res_id['idRangeL']) * df_res_id['idVolume']\n",
    "    # # 39.7 µs ± 13.8 µs per loop\n",
    "    # %timeit -n1 -r100 df_res_id['iiiValue'] = (2 * df_res_id_arr[:, idx_col_close] - df_res_id_arr[:, idx_col_idRangeH] - df_res_id_arr[:, idx_col_idRangeL]) / (df_res_id_arr[:, idx_col_idRangeH] - df_res_id_arr[:, idx_col_idRangeL]) * df_res_id_arr[:, idx_col_idVolume]\n",
    "    \n",
    "    # # 381 µs ± 31.7 µs per loop\n",
    "    # %timeit -n1 -r100 df_res_id['iiSource'] = df_res_id.iiiValue.rolling(21).sum().to_numpy() / df_res_id.idVolume.rolling(21).sum().to_numpy() * 100\n",
    "    # # 471 µs ± 52.8 µs per loop\n",
    "    # %timeit -n1 -r100 df_res_id['iiSource'] = df_res_id.iiiValue.rolling(21).sum() / df_res_id.idVolume.rolling(21).sum() * 100\n",
    "    \n",
    "    df_res_id['iiiValue'] = (2 * df_res_id_arr[:, idx_col_close] - df_res_id_arr[:, idx_col_idRangeH] - df_res_id_arr[:, idx_col_idRangeL]) / (df_res_id_arr[:, idx_col_idRangeH] - df_res_id_arr[:, idx_col_idRangeL]) * df_res_id_arr[:, idx_col_idVolume]\n",
    "    df_res_id['iiSource'] = df_res_id.iiiValue.rolling(period).sum().to_numpy() / df_res_id.idVolume.rolling(period).sum().to_numpy() * 100\n",
    "\n",
    "    return df_res_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859fc05-cb85-4dc2-9c69-866e6141c33d",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de2cea-367e-4248-a19a-21f275830c9b",
   "metadata": {},
   "source": [
    "## configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6055033-13c9-487d-9f75-19ea16cc4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dict = \\\n",
    "{\n",
    "  \"selection_id\": \"1\",\n",
    "  \"show_detail\": 1,\n",
    "  \"trader_set\": {\n",
    "    \"backtrade\": 0,\n",
    "    \"back_data_path\": \"D:\\\\Projects\\\\SystemTrading\\\\JnQ\\\\database\\\\binance\\\\cum\\\\2023-01-12\\\\2023-01-12 ETHUSDT_1m.ftr\",\n",
    "    \"start_datetime\": \"2022-10-05 00:00:59.999\",\n",
    "    \"ticker_list_path\": \"D:\\\\Projects\\\\SystemTrading\\\\JnQ\\\\Bank\\\\tickers\\\\binance_20240102.pkl\",\n",
    "    \"run\": 1,\n",
    "    \"df_log\": 0,\n",
    "    \"show_detail\": 0,\n",
    "    \"latest_index\": -1,\n",
    "    \"complete_index\": -2,\n",
    "    \"fee_limit\": 0.0002,\n",
    "    \"fee_market\": 0.0005,\n",
    "    \"initial_asset\": 15,\n",
    "    \"profit_mode\": \"SUM\",\n",
    "    \"income_accumulated\": 0.0,\n",
    "    \"profit_accumulated\": 0.0,\n",
    "    \"asset_changed\": 0,\n",
    "    \"messenger_on\": 1,\n",
    "    \"get_df_new_timeout\": 1,\n",
    "    \"loop_duration\": 3.6,\n",
    "    \"realtime_term\": 0.2,\n",
    "    \"api_term\": 3,\n",
    "    \"order_term\": 0.5,\n",
    "    \"market_check_term\": 5,\n",
    "    \"exec_open_check_term\": 5,\n",
    "    \"quantity_open_exec_ratio\": 0.97,\n",
    "    \"tp_exec_check_term\": 5\n",
    "  },\n",
    "    \"term\": {\n",
    "        \"get_df_new_timeout\": 1,\n",
    "        \"loop_duration\": 3.6,\n",
    "        \"realtime_term\": 0.2,\n",
    "        \"api_term\": 3,\n",
    "        \"order_term\": 0.5,\n",
    "        \"market_check_term\": 5,\n",
    "        \"exec_open_check_term\": 5,\n",
    "        \"tp_exec_check_term\": 5,            \n",
    "    },\n",
    "  \"pos_set\": {\n",
    "    \"short_inversion\": 0,\n",
    "    \"long_inversion\": 0,\n",
    "    \"short_ban\": 0,\n",
    "    \"long_ban\": 0,\n",
    "    \"short_fake\": 0,\n",
    "    \"long_fake\": 0\n",
    "  },\n",
    "  \"loc_set\": {\n",
    "    \"point1\": {\n",
    "      \"exp_itv\": \"5T\",\n",
    "      \"tf_entry\": \"15T\",\n",
    "      \"candle_pattern\": \"CDLMARUBOZU\"\n",
    "    },\n",
    "    \"point2\": {\n",
    "      \"wrr_32_min\": \"None\",\n",
    "      \"wrr_32_max\": \"None\",\n",
    "      \"csdbox_range\": 0.3,\n",
    "      \"tr_thresh_short\": \"None\",\n",
    "      \"tr_thresh_long\": \"None\",\n",
    "      \"csd_period\": \"None\"\n",
    "    },\n",
    "    \"zone1\": {\n",
    "      \"use_zone\": 0,\n",
    "      \"base_roll_period\": 50,\n",
    "      \"degree_list\": \"[]\",\n",
    "      \"dtk_itv\": \"5T\",\n",
    "      \"dt_k\": \"None\",\n",
    "      \"dc_period\": 135,\n",
    "      \"use_dtk_line\": 0,\n",
    "      \"zone_dt_k\": 0.4,\n",
    "      \"zone_dc_period\": 135\n",
    "    },\n",
    "    \"zone2\": {\n",
    "      \"use_zone\": 0\n",
    "    }\n",
    "  },\n",
    "  \"tr_set\": {\n",
    "    \"check_hlm\": 0,\n",
    "    \"wave_itv1\": \"T\",\n",
    "    \"wave_itv2\": \"T\",\n",
    "    \"wave_period1\": 20,\n",
    "    \"wave_period2\": 20,\n",
    "    \"wave_length_max_short1\": \"None\",\n",
    "    \"wave_length_max_long1\": \"None\",\n",
    "    \"wave_length_min_short1\": \"None\",\n",
    "    \"wave_length_min_long1\": \"None\",\n",
    "    \"wave_spread1\": \"None\",\n",
    "    \"wave_time_ratio1\": \"None\",\n",
    "    \"tc_period\": 20,\n",
    "    \"wave_greater1\": 0,\n",
    "    \"wave_greater2\": 0,\n",
    "    \"wave_lesser1\": 2,\n",
    "    \"wave_lesser2\": 2,\n",
    "    \"expire_k1\": 0.0,\n",
    "    \"expire_k2\": 0.0,\n",
    "    \"expire_tick\": \"None\",\n",
    "    \"p2_box_k1\": 0,\n",
    "    \"p2_box_k2\": 0,\n",
    "    \"p1p2_low\": 0.0,\n",
    "    \"tp_gap\": 0.0,\n",
    "    \"ep1_gap\": 0.7,\n",
    "    \"ep2_gap\": 0.3,\n",
    "    \"out_gap\": 0,\n",
    "    \"bias_tick\": 100\n",
    "  },\n",
    "  \"ep_set\": {\n",
    "    \"entry_type\": \"LIMIT\",\n",
    "    \"static_ep\": 1,\n",
    "    \"point2\": {\n",
    "      \"entry_type\": \"LIMIT\"\n",
    "    }\n",
    "  },\n",
    "  \"tp_set\": {\n",
    "    \"non_tp\": 0,\n",
    "    \"static_tp\": 1,\n",
    "    \"tp_onexec\": 0,\n",
    "    \"decay_term\": 60,\n",
    "    \"partial_ranges\": \"[1]\",\n",
    "    \"partial_quantity_ratio\": \"[1]\"\n",
    "  },\n",
    "  \"out_set\": {\n",
    "    \"non_out\": 0,\n",
    "    \"hl_out\": 1,\n",
    "    \"static_out\": 1,\n",
    "    \"out_onexec\": 0,\n",
    "    \"tf_exit\": \"None\",\n",
    "    \"fisher_exit\": \"None\",\n",
    "    \"rsi_exit\": 0,\n",
    "    \"cci_exit\": 0\n",
    "  },\n",
    "  \"lvrg_set\": {\n",
    "    \"static_lvrg_short\": 1,\n",
    "    \"static_lvrg_long\": 1,\n",
    "    \"limit_leverage\": \"None\",\n",
    "    \"leverage\": 10,\n",
    "    \"target_pct\": 0.5,\n",
    "    \"target_loss\": 50,\n",
    "    \"allow_float\": 0,\n",
    "    \"lvrg_rejection\": 1,\n",
    "    \"multiplier\": 1000,\n",
    "    \"log_base\": 30\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ba9f3-8537-440f-8f68-862e47d075e0",
   "metadata": {},
   "source": [
    "## Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a2288-3cf7-42df-a4e4-d265d2d66a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenBucket:\n",
    "    def __init__(self, sys_log, capacity):\n",
    "        self.capacity = capacity  # Maximum number of tokens the bucket can hold\n",
    "        self.tokens = capacity\n",
    "        self.lock = threading.Lock()\n",
    "        self.sys_log = sys_log\n",
    "        # self.last_refill_time = time.time()\n",
    "        \n",
    "    # def refill(self):\n",
    "    #     now = time.time()\n",
    "    #     # Calculate the number of minutes that have passed since the last refill\n",
    "    #     minutes_passed = (now - self.last_refill_time) // 60\n",
    "    #     if minutes_passed >= 1:\n",
    "    #         self.tokens = self.capacity\n",
    "    #         self.last_refill_time = now - (now % 60)  # Reset to the start of the current minute\n",
    "\n",
    "\n",
    "    def consume(self, tokens_used, tokens):\n",
    "        with self.lock:                \n",
    "            self.tokens = self.capacity - tokens_used\n",
    "            self.sys_log.debug(f\"tokens : {self.tokens}\")\n",
    "            \n",
    "            if self.tokens >= tokens: # enough to use.\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "    def wait_for_token_consume(self, tokens_used, tokens=10):\n",
    "        wait_time = 1\n",
    "        while not self.consume(tokens_used, tokens): # set maximium weight that can be consumed.\n",
    "            time.sleep(wait_time)\n",
    "            wait_time = min(wait_time * 2, 60)  # Max wait time of 60 seconds\n",
    "\n",
    "\n",
    "class Bank(UMFutures):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        api_key, secret_key = self.load_key(kwargs['path_api'])        \n",
    "        UMFutures.__init__(self, key=api_key, secret=secret_key, show_header=kwargs['show_header'])\n",
    "\n",
    "        self.websocket_client = UMFuturesWebsocketClient()\n",
    "        self.websocket_client.start()\n",
    "        self.price_market = {}\n",
    "\n",
    "        api_rate_limit = kwargs['api_rate_limit']\n",
    "        self.token_bucket = TokenBucket(sys_log=self.sys_log, capacity=api_rate_limit)\n",
    "\n",
    "        \n",
    "        self.path_save_log = kwargs['path_save_log']\n",
    "        self.set_logger()\n",
    "        \n",
    "        self.path_config = kwargs['path_config']\n",
    "        with open(self.path_config, 'r') as f:\n",
    "            self.config = EasyDict(json.load(f))\n",
    "\n",
    "        \n",
    "        # load_table \n",
    "        db_user = self.config.database.user\n",
    "        db_password = self.config.database.password\n",
    "        db_host = self.config.database.host\n",
    "        db_port = self.config.database.port\n",
    "        db_name = self.config.database.name\n",
    "        \n",
    "        connection_string = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "        self.engine = create_engine(connection_string, connect_args={'connect_timeout': 5})\n",
    "        \n",
    "        self.conn = psycopg2.connect(\n",
    "            dbname=self.config.database.name,\n",
    "            user=self.config.database.user, \n",
    "            password=self.config.database.password, \n",
    "            host=self.config.database.host\n",
    "        )\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "        self.table_account_name = kwargs['table_account_name']\n",
    "        self.table_condition_name = kwargs['table_condition_name']\n",
    "        self.table_trade_name = kwargs['table_trade_name']\n",
    "        self.table_log_name = kwargs['table_log_name']\n",
    "        \n",
    "        self.table_account = self.fetch_table(self.table_account_name)\n",
    "        self.table_condition = self.fetch_table(self.table_condition_name)\n",
    "        self.table_trade = self.fetch_table(self.table_trade_name)\n",
    "        self.table_log = self.fetch_table(self.table_log_name)\n",
    "\n",
    "        \n",
    "        self.path_dir_df_res = kwargs['path_dir_df_res']\n",
    "\n",
    "        \n",
    "        # add messegner\n",
    "        self.chat_id = kwargs['chat_id']\n",
    "        self.token = kwargs['token'] # \"7156517117:AAF_Qsz3pPTHSHWY-ZKb8LSKP6RyHSMTupo\"        \n",
    "        self.msg_bot = None # default.\n",
    "        self.get_messenger_bot()\n",
    "\n",
    "        \n",
    "        # income\n",
    "        self.income = 0.0\n",
    "        self.income_accumulated = self.config.trader_set.income_accumulated\n",
    "        \n",
    "        # profit\n",
    "        self.profit = 0.0\n",
    "        self.profit_accumulated = self.config.trader_set.profit_accumulated\n",
    "        \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def load_key(key_abspath):\n",
    "        with open(key_abspath, 'rb') as f:\n",
    "            return pickle.load(f)            \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_precision_by_price(price):\n",
    "        try:\n",
    "            precision = len(str(price).split('.')[1])\n",
    "        except Exception as e:\n",
    "            precision = 0\n",
    "        return precision\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_with_precision(data, precision_data, def_type='floor'):\n",
    "\n",
    "        if not pd.isna(data):\n",
    "            if precision_data > 0:\n",
    "                if def_type == 'floor':\n",
    "                    data = math.floor(data * (10 ** precision_data)) / (10 ** precision_data)\n",
    "                elif def_type == 'round':\n",
    "                    data = float(round(data, precision_data))\n",
    "                else:\n",
    "                    data = math.ceil(data * (10 ** precision_data)) / (10 ** precision_data)\n",
    "            else:\n",
    "                data = int(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def agg_trade_message_handler(self, message):\n",
    "        \"\"\"\n",
    "        1. websocket streaming method 를 이용한 get_price_realtime method.\n",
    "            a. try --> received data = None 일 경우를 대비한다.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.price_market[message['s']] = float(message['p'])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def set_logger(self,):\n",
    "\n",
    "        \"\"\"\n",
    "        v1.0\n",
    "            add RotatingFileHandler\n",
    "\n",
    "        last confirmed at, 20240520 0610.\n",
    "        \"\"\"\n",
    "        \n",
    "        simple_formatter = logging.Formatter(\"[%(name)s] %(message)s\")\n",
    "        complex_formatter = logging.Formatter(\"%(asctime)s %(levelname)s [%(name)s] [%(filename)s:%(lineno)d] - %(message)s\")\n",
    "        \n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(simple_formatter)\n",
    "        console_handler.setLevel(logging.DEBUG)\n",
    "    \n",
    "        # file_handler = logging.FileHandler(self.path_save_log)\n",
    "        file_handler = logging.handlers.RotatingFileHandler(self.path_save_log, maxBytes=10 * 1000 * 1000, backupCount=10)\n",
    "        file_handler.setFormatter(complex_formatter)\n",
    "        file_handler.setLevel(logging.DEBUG)        \n",
    "    \n",
    "        self.sys_log = logging.getLogger('Bank')\n",
    "    \n",
    "        self.sys_log.handlers.clear()\n",
    "        self.sys_log.addHandler(console_handler)\n",
    "        self.sys_log.addHandler(file_handler)\n",
    "        self.sys_log.setLevel(logging.DEBUG)      \n",
    "\n",
    "    def echo(self, update, context):    \n",
    "        self.user_text = update.message.text\n",
    "\n",
    "    def get_messenger_bot(self, ):\n",
    "\n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            use token from self directly.\n",
    "        v3.0\n",
    "            remove self.msg_bot exist condition.\n",
    "    \n",
    "        last confirmed at, 20240528 1257.\n",
    "        \"\"\"\n",
    "            \n",
    "        # init\n",
    "        self.msg_bot = telegram.Bot(token=self.token)    \n",
    "        self.user_text = None # messenger buffer.\n",
    "        \n",
    "        # get updater & set handler\n",
    "        self.updater = Updater(token=self.token, use_context=True)\n",
    "        dispatcher = self.updater.dispatcher\n",
    "        \n",
    "        echo_handler = MessageHandler(Filters.text & (~Filters.command), self.echo)\n",
    "        dispatcher.add_handler(echo_handler)\n",
    "        \n",
    "        # start_polling.\n",
    "        self.updater.start_polling()\n",
    "        \n",
    "        self.sys_log.debug(\"msg_bot {} assigned.\".format(self.token))\n",
    "    \n",
    "    def push_msg(self, msg):    \n",
    "    \n",
    "        \"\"\"\n",
    "        v1.0\n",
    "            this function has some time dely.\n",
    "    \n",
    "        last confirmed at, 20240517 1413.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            self.msg_bot.sendMessage(chat_id=self.chat_id, text=msg)\n",
    "        except Exception as e:\n",
    "            self.sys_log.error(e)\n",
    "\n",
    "    def fetch_table(self, table_name, limit=None):\n",
    "\n",
    "        \"\"\"\n",
    "        v1.1\n",
    "            using engine, much faster.\n",
    "    \n",
    "        last confirmed at, 20240705 2208.\n",
    "        \"\"\"\n",
    "    \n",
    "        # if you use self.engine, you can show table in original dtypes.\n",
    "            # %timeit -n1 -r1000 fetch_table(self.engine, 'table_log', limit=None) \n",
    "                # 1.9 ms ± 93.7 µs per loop (mean ± std. dev. of 1000 runs, 1 loop each)\n",
    "        try:\n",
    "            with self.engine.connect() as conn:\n",
    "                if limit is None:\n",
    "                    query = text(f\"SELECT * FROM {table_name};\")\n",
    "                else:\n",
    "                    query = text(f\"SELECT * FROM {table_name} LIMIT {limit};\")\n",
    "                \n",
    "                result = conn.execute(query)\n",
    "                rows = result.fetchall()\n",
    "                df = pd.DataFrame(rows, columns=result.keys())\n",
    "                return df\n",
    "    \n",
    "        except Exception as e:\n",
    "            self.sys_log.error(f\"error fetching data from {table_name}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def replace_table(self, df, table_name, send=False):\n",
    "    \n",
    "        \"\"\"\n",
    "        v1.1\n",
    "            using engine, much faster.\n",
    "        v1.2\n",
    "            using temp_table, stay as consistent state.\n",
    "            \n",
    "            v1.2.1\n",
    "                modify to psycopg2, considering latency.\n",
    "\n",
    "        last confirmed at, 20240706 1014.\n",
    "        \"\"\"  \n",
    "        \n",
    "        temp_csv = f'{table_name}.csv'\n",
    "        df.to_csv(temp_csv, index=False, header=False)\n",
    "\n",
    "        if send:\n",
    "            try:            \n",
    "                # Fetch column names and data types from the existing table            \n",
    "                self.cur.execute(sql.SQL(\"\"\"\n",
    "                    SELECT column_name, data_type\n",
    "                    FROM information_schema.columns\n",
    "                    WHERE table_name = %s\n",
    "                    ORDER BY ordinal_position\n",
    "                \"\"\"), [table_name])\n",
    "                \n",
    "                # Retrieve the results\n",
    "                columns = self.cur.fetchall()\n",
    "                \n",
    "                # Replace the table\n",
    "                self.cur.execute(f\"DROP TABLE IF EXISTS {table_name}\")            \n",
    "                \n",
    "                create_table_query = sql.SQL(\"CREATE TABLE {} ({});\").format(\n",
    "                    sql.Identifier(table_name),\n",
    "                    sql.SQL(', ').join(\n",
    "                        sql.SQL(\"{} {}\").format(\n",
    "                            sql.Identifier(column[0]),\n",
    "                            sql.SQL(column[1])\n",
    "                        ) for column in columns\n",
    "                    )\n",
    "                )\n",
    "                self.cur.execute(create_table_query)\n",
    "        \n",
    "                # Use COPY command to load data\n",
    "                with open(temp_csv, 'r') as f:\n",
    "                    self.cur.copy_expert(f\"COPY {table_name} FROM STDIN WITH CSV\", f)\n",
    "        \n",
    "                # Commit changes\n",
    "                self.conn.commit()\n",
    "            except Exception as e:\n",
    "                if self.conn:\n",
    "                    self.conn.rollback()\n",
    "                print(f\"error occurred in replace_table : {e}\")\n",
    "            # finally:\n",
    "                # # Remove temporary file\n",
    "                # os.remove(temp_csv)\n",
    "            \n",
    "    def set_leverage(self,\n",
    "                    symbol,\n",
    "                    leverage):\n",
    "\n",
    "        \"\"\"\n",
    "        v2.0\n",
    "            vivid mode.\n",
    "\n",
    "        last confirmed at, 20240702 1758.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            server_time = self.time()['serverTime']\n",
    "            self.change_leverage(symbol=symbol, \n",
    "                                leverage=leverage, \n",
    "                                recvWindow=6000, \n",
    "                                timestamp=server_time)\n",
    "        except Exception as e:\n",
    "            msg = \"error in change_initial_leverage : {}\".format(e)\n",
    "            self.sys_log.error(msg)\n",
    "            self.push_msg(msg)\n",
    "        else:\n",
    "            self.sys_log.info('leverage changed to {}'.format(leverage))\n",
    "            \n",
    "    def set_position_mode(self, \n",
    "                        dualSidePosition='true'):\n",
    "\n",
    "        \"\"\"\n",
    "        v1.0\n",
    "            pass error -4059 -4046\n",
    "\n",
    "        last confirmed at, 20240702 1801.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            server_time = self.time()['serverTime']\n",
    "            self.change_position_mode(dualSidePosition=dualSidePosition,\n",
    "                                    recvWindow=2000,\n",
    "                                    timestamp=server_time)\n",
    "        except Exception as e:\n",
    "            if '-4059' in str(e): # 'No need to change position side.'\n",
    "                return\n",
    "            msg = \"error in set_position_mode : {}\".format(e)\n",
    "            self.sys_log.error(msg)\n",
    "            self.push_msg(msg)\n",
    "        else:\n",
    "            self.sys_log.info(\"dualSidePosition is true.\")\n",
    "            \n",
    "    def set_margin_type(self, \n",
    "                    symbol,\n",
    "                    marginType='CROSSED'): # CROSSED / ISOLATED\n",
    "\n",
    "        \"\"\"\n",
    "        v1.0s\n",
    "            pass error -4046\n",
    "        v2.0\n",
    "            vivid mode.\n",
    "\n",
    "        last confirmed at, 20240702 1805.\n",
    "        \"\"\"\n",
    "\n",
    "        # margin type => \"cross or isolated\"\n",
    "        try:\n",
    "            server_time = self.time()['serverTime']\n",
    "            self.change_margin_type(symbol=symbol, \n",
    "                                    marginType=marginType, \n",
    "                                    recvWindow=6000, \n",
    "                                    timestamp=server_time)\n",
    "                \n",
    "        except Exception as e:\n",
    "            if '-4046' in str(e): # 'No need to change margin type.'\n",
    "                return\n",
    "            msg = \"error in set_margin_type : {}\".format(e)\n",
    "            self.sys_log.error(msg)\n",
    "            self.push_msg(msg)\n",
    "        else:\n",
    "            self.sys_log.info(\"margin type is {} now.\".format(marginType))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d1f52-f72a-4a93-98c9-ce3d6f30b281",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8e527-3f1d-4b94-97d2-d8536ee3e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = Bank(path_config=\"./config.json\", \n",
    "            path_api=\"../keys/binance_mademerich.pkl\", # 'r' preserve away 't, a' other vague letters.\n",
    "            path_dir_df_res =  \"./data/df_res\",\n",
    "            path_save_log=\"./logs/{}.log\".format(datetime.now().strftime('%Y%m%d%H%M%S')),\n",
    "            api_rate_limit=2400, # per minute.\n",
    "            table_account_name = 'table_account_test',\n",
    "            table_condition_name = 'table_condition_test',\n",
    "            table_trade_name = 'table_trade_test',\n",
    "            table_log_name = 'table_log_test',\n",
    "            chat_id=\"5320962614\",\n",
    "            # token=\"7156517117:AAF_Qsz3pPTHSHWY-ZKb8LSKP6RyHSMTupo\", # TheBank\n",
    "            token=\"6961110608:AAEH4_vSxmRxJ2OnGQCk0NocfmH-iujHyNs\", # BotBinance (for .ipynb)\n",
    "            # token=\"6206784409:AAE-xpIQELzgBfzbcFxhQE2Cjb6lZt6zn4s\", # BinanceMessenger (Tester)\n",
    "            receive_limit_ms=1000*3600,\n",
    "            show_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546ad48-4196-452b-bee0-0448ca0ca32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bank.table_account.dtypes)\n",
    "print(bank.table_condition.dtypes)\n",
    "print(bank.table_trade.dtypes)\n",
    "print(bank.table_log.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5f7c8-3da6-4edf-a588-1dd8671abd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bank.table_account.tail())\n",
    "display(bank.table_condition.tail())\n",
    "display(bank.table_trade.tail())\n",
    "display(bank.table_log.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b7f89-d934-4f90-ab7a-75f78535df2a",
   "metadata": {},
   "source": [
    "#### Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940484c-1720-4792-9b51-808fb817d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.token_bucket = TokenBucket(sys_log=bank.sys_log, capacity=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003523f8-a58b-4df2-bf70-344ae04fd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bank.balance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbebee7-dd83-4ec3-b065-7e3e6dbf0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response\n",
    "response['header'].get('X-MBX-USED-WEIGHT-1M')\n",
    "# response['limit_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b3c7e-25cb-4917-9d4e-72332aa6bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers.get('X-MBX-USED-WEIGHT-1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab24b54-8aa6-4f05-9147-13f5aeeb8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_rate_limit = 1200\n",
    "# bank.token_bucket = TokenBucket(capacity=api_rate_limit)\n",
    "\n",
    "print(bank.token_bucket.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7a844-b268-45d6-8563-abcca7f41d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait_time = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"datetime.now().second : {datetime.now().second}\")\n",
    "    \n",
    "    tokens_prev = bank.token_bucket.tokens\n",
    "    bank.token_bucket.wait_for_token_consume(100)\n",
    "    # while not bank_test.token_bucket.consume(1):\n",
    "    #     time.sleep(wait_time)\n",
    "    #     wait_time = min(wait_time * 2, 60)  # Max wait time of 60 seconds\n",
    "    # if bank.token_bucket.tokens > tokens_prev:\n",
    "    print(bank.token_bucket.tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167bee6-3bfe-4985-addb-114725bbda5c",
   "metadata": {},
   "source": [
    "### MainLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7c221-6e38-4fc2-a881-bae6a0a35626",
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    loop_table_condition(bank)\n",
    "    loop_table_trade(bank)\n",
    "    \n",
    "    clear_output(wait=True) # if run in ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c6c02-7d4c-477e-a958-aea88af2d634",
   "metadata": {},
   "source": [
    "#### loop_messenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86b0f1-1959-497b-9986-8af4ae085693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loop_messenger(self,):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        init\n",
    "            consider dtypes in payload (float & str)\n",
    "                default type = str.\n",
    "    v1.1\n",
    "        vivid mode.\n",
    "        \n",
    "    last confirmed at, 20240702 1610.\n",
    "    \"\"\"\n",
    "    \n",
    "    if self.user_text is not None:\n",
    "\n",
    "        # default msg = invalid payload.\n",
    "        msg = \"error in self.user_text : invalid payload.\"\n",
    "        user_text_upper_case = self.user_text.upper()\n",
    "        payload = user_text_upper_case.replace('  ', ' ').split(' ')  # allow doubled-space.\n",
    "        # payload_ = user_text_upper_case.replace('  ', ' ').split('/')  # allow doubled-space.\n",
    "\n",
    "        payload_len = len(payload)\n",
    "\n",
    "        if payload_len == 2:\n",
    "\n",
    "            # asset change\n",
    "            if 'ASSET' in user_text_upper_case:\n",
    "                self.balance_available = int(self.user_text.split(' ')[-1])\n",
    "                user_text_upper_case = 'WATCH'\n",
    "\n",
    "        # set user_data\n",
    "        elif payload_len == 6:\n",
    "            \n",
    "            symbol, side_open, price_take_profit, price_entry, price_stop_loss, leverage = payload\n",
    "            symbol += 'USDT'\n",
    "\n",
    "            self.get_tickers(self,)\n",
    "\n",
    "            # validation\n",
    "                # symbol\n",
    "            if symbol in self.tickers_available:\n",
    "                \n",
    "                # side_open\n",
    "                if side_open in ['BUY', 'SELL']:\n",
    "\n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()  \n",
    "                    table_condition_new_row = pd.DataFrame(data = np.array([np.nan] * len(self.table_condition.columns)).reshape(-1, 1).T, columns=self.table_condition.columns, dtype=object)\n",
    "                \n",
    "                    # init table_condition.\n",
    "                    table_condition_new_row.symbol = symbol \n",
    "                    table_condition_new_row.side_open = side_open \n",
    "                    table_condition_new_row.price_take_profit = float(price_take_profit)\n",
    "                    table_condition_new_row.price_entry = float(price_entry)\n",
    "                    table_condition_new_row.price_stop_loss = float(price_stop_loss)\n",
    "                    table_condition_new_row.leverage = float(leverage)\n",
    "                    \n",
    "                    # append row.\n",
    "                    self.table_condition = pd.concat([self.table_condition, table_condition_new_row]).reset_index(drop=True)        \n",
    "                    self.sys_log.debug(\"InitTableCondition : elasped time, append row : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()    \n",
    "                    self.set_tables(mode='CONDITION')\n",
    "                    self.sys_log.debug(\"InitTableCondition : elasped time, set_tables  : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")  \n",
    "                    \n",
    "                    user_text_upper_case = 'WATCH'\n",
    "                                    \n",
    "        # watch\n",
    "        if 'WATCH' in user_text_upper_case:\n",
    "            msg = \"{}\".format(self.table_condition)\n",
    "\n",
    "\n",
    "        # show message.\n",
    "        self.push_msg(msg)\n",
    "\n",
    "\n",
    "        # reset user_text.\n",
    "        self.user_text = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f67e5a-4b8b-4a52-b463-e0be98d3c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while 1:\n",
    "    # print(bank.user_text)\n",
    "    loop_messenger(bank)\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72d19a-2b82-4309-9da0-62796bed4da9",
   "metadata": {},
   "source": [
    "#### loop_table_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3d943-1a69-42bd-9d43-c53b91b9ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_table_condition(self, drop=False, debug=False):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        modify to data_table mode.\n",
    "        update with one trade in a minute.\n",
    "        add push_msg for initTableTrade.\n",
    "        modify code name to code_{} using datetime.\n",
    "        remove realtime_term for this loop\n",
    "            term already exist in get_new_df\n",
    "    v1.2\n",
    "        add drop param.\n",
    "    v1.3\n",
    "        use messenger mode.\n",
    "            add user_data. (symbol & price ...)\n",
    "        add condition\n",
    "    v1.4\n",
    "        modify to TableCondition_v0.3 verison.\n",
    "        modify drop to False. \n",
    "        remove elapsed time +,\n",
    "    v1.5\n",
    "        add column 'timestampLastUsed' in tableCondition.\n",
    "            apply remaining minutes to zero.\n",
    "        add interval_value (days)\n",
    "        \n",
    "        v1.5.1\n",
    "            apply functional idep.py.\n",
    "            add target_loss, account            \n",
    "        v1.5.2\n",
    "            apply dbms\n",
    "            \n",
    "            v1.5.2.1\n",
    "                divide send / save. \n",
    "                add debug mode.\n",
    "                api_count + 1    \n",
    "                \n",
    "        v1.5.3\n",
    "            apply TokenBucket.\n",
    "            remove loop_duration.\n",
    "        \n",
    "    last confirmed at, 20240710 1016.\n",
    "    \"\"\"\n",
    "\n",
    "    start_time_loop = time.time()\n",
    "    for idx, row in self.table_condition.iterrows(): # idx can be used, cause table_condition's index are not reset.\n",
    "\n",
    "        # init.        \n",
    "        self.table_condition_row = row # declared for using in entry_point_location. (deprecated)\n",
    "           \n",
    "        self.symbol = row.symbol\n",
    "        self.side_open = row.side_open\n",
    "        # self.price_take_profit = row.price_take_profit\n",
    "        # self.price_entry = row.price_entry\n",
    "        # self.price_stop_loss = row.price_stop_loss\n",
    "        # self.leverage = row.leverage\n",
    "        self.position = row.position\n",
    "        self.interval = row.interval\n",
    "        self.interval_value = row.interval_value\n",
    "        self.priceBox_indicator = row.priceBox_indicator\n",
    "        self.priceBox_value = row.priceBox_value\n",
    "        self.point_indicator = row.point_indicator\n",
    "        self.point_value = row.point_value\n",
    "        self.zone_indicator = row.zone_indicator\n",
    "        self.zone_value = row.zone_value\n",
    "        self.target_loss = row.target_loss\n",
    "        self.account = row.account\n",
    "        \n",
    "\n",
    "        # do not repeat it in interval.\n",
    "        interval_number = itv_to_number(self.interval)\n",
    "        timestamp_current = int(time.time())\n",
    "        if timestamp_current - int(row.timestampLastUsed) < interval_number * 60:\n",
    "            continue\n",
    "        else:\n",
    "            self.sys_log.debug(\"------------------------------------------------\")            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            timestamp_anchor = 1718236800 # 2024-06-13 9:00:00\n",
    "            timestamp_remain = (timestamp_current - timestamp_anchor) % (interval_number * 60)\n",
    "            timestamp_current -= timestamp_remain\n",
    "            self.table_condition.at[idx, 'timestampLastUsed'] =  timestamp_current     \n",
    "                \n",
    "            self.sys_log.debug(\"LoopTableCondition : elasped time, check timestampLastUsed : {:.2f}s\".format(time.time() - start_time))\n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "        \n",
    "\n",
    "        # get df_res\n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.token_bucket.wait_for_token_consume(1)        \n",
    "        self.df_res = get_df_new(self, \n",
    "                               interval=self.interval, \n",
    "                               days=self.interval_value, \n",
    "                               limit=1500, \n",
    "                               timesleep=0.0) # changed to 0.0\n",
    "                \n",
    "        self.sys_log.info(\"LoopTableCondition : check df_res last row timestamp : {}\".format(self.df_res.index[-1]))\n",
    "        self.sys_log.debug(\"LoopTableCondition : elasped time, get_df_new : {:.2f}s\".format(time.time() - start_time))\n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    " \n",
    "        if self.df_res is None:\n",
    "            continue     \n",
    "            \n",
    "        \n",
    "        # set point (3)   \n",
    "            # set side_open considered. (set priceBox_indicator automation require side_open)\n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.df_res, \\\n",
    "        cross_over, \\\n",
    "        cross_under = get_point_index(self.df_res,\n",
    "                                        row.point_mode,\n",
    "                                        row.point_indicator,\n",
    "                                        row.point_value,\n",
    "                                        row.interval,\n",
    "                                        return_bool=True)\n",
    "        \n",
    "        point_index_long = np.argwhere(cross_over).ravel() # input for get_price_arr\n",
    "        point_index_short = np.argwhere(cross_under).ravel()   \n",
    "\n",
    "        point_min_len = abs(self.config.trader_set.complete_index)\n",
    "        if len(cross_over) >= point_min_len and len(cross_under) >= point_min_len:\n",
    "            self.sys_log.debug(\"cross_over[self.config.trader_set.complete_index] : {}\".format(cross_over[self.config.trader_set.complete_index]))\n",
    "            self.sys_log.debug(\"cross_under[self.config.trader_set.complete_index] : {}\".format(cross_under[self.config.trader_set.complete_index]))\n",
    "    \n",
    "            if self.position == 'LONG':\n",
    "                if cross_over[self.config.trader_set.complete_index] and not debug: # debugging.\n",
    "                    self.side_open = 'BUY'\n",
    "            else:\n",
    "                if cross_under[self.config.trader_set.complete_index] and not debug: # debugging.\n",
    "                    self.side_open = 'SELL' \n",
    "                    \n",
    "        self.sys_log.debug(\"LoopTableCondition : elasped time, set point : %.4fs\" % (time.time() - start_time)) \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "            \n",
    "\n",
    "        \n",
    "        if not pd.isnull(self.side_open): # default = np.nan\n",
    "            \n",
    "            # set priceBox_indicator automation (2)\n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()       \n",
    "            \n",
    "            try:                \n",
    "                priceBox_upper, \\\n",
    "                priceBox_lower, \\\n",
    "                close = get_priceBox(self.df_res,\n",
    "                                     row.priceBox_indicator,\n",
    "                                     row.priceBox_value,\n",
    "                                     row.interval,\n",
    "                                     self.side_open)\n",
    "            \n",
    "                \n",
    "                # price_arr use priceBox_indicator differed by side_open.\n",
    "                price_take_profit_arr, \\\n",
    "                price_entry_arr, \\\n",
    "                price_stop_loss_arr, \\\n",
    "                index_valid_bool = get_price_arr(self.side_open, \n",
    "                                             priceBox_upper, \n",
    "                                             priceBox_lower,\n",
    "                                             close,\n",
    "                                             point_index_short,\n",
    "                                             point_index_long)\n",
    "\n",
    "                self.sys_log.debug(\"index_valid_bool : {}\".format(index_valid_bool))\n",
    "                \n",
    "                if len(index_valid_bool):    \n",
    "                    # we have save df_res, so not using conitnue.\n",
    "                        # use lastest index, -1.\n",
    "                            # cannot be debugged for price protection.\n",
    "                    if not index_valid_bool[-1]:\n",
    "                        self.side_open = np.nan                   \n",
    "                     \n",
    "                    self.price_take_profit = price_take_profit_arr[-1]\n",
    "                    self.price_entry = price_entry_arr[-1]\n",
    "                    self.price_stop_loss = price_stop_loss_arr[-1]\n",
    "    \n",
    "                    # get RRratio\n",
    "                        # currently, we are using set_price from other functions.\n",
    "                            # replace below function later.\n",
    "                    set_price_and_open_signal(self, env='BANK') # env select not to use adj_price_unit().       \n",
    "                    \n",
    "                    RRratio_adj_fee_category = self.df_res['RRratio_adj_fee_category'].to_numpy()            \n",
    "                    self.sys_log.debug(\"RRratio_adj_fee_category[self.config.trader_set.complete_index] : {}\".format(RRratio_adj_fee_category[self.config.trader_set.complete_index]))\n",
    "                    self.sys_log.debug(\"self.zone_value.split(';') : {}\".format(self.zone_value.split(';')))\n",
    "                    \n",
    "                    # debugging.\n",
    "                    if RRratio_adj_fee_category[self.config.trader_set.complete_index] not in self.zone_value.split(';') and not debug:\n",
    "                        self.side_open = np.nan                        \n",
    "                else:\n",
    "                    self.side_open = np.nan  \n",
    "                    \n",
    "                self.sys_log.debug(\"self.side_open : {}\".format(self.side_open))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                msg = \"error in get_priceBox, get_price_arr : {}\".format(e)\n",
    "                self.sys_log.error(msg)\n",
    "                # self.push_msg(msg)\n",
    "                continue \n",
    "                \n",
    "            self.sys_log.debug(\"LoopTableCondition : elasped time, get_priceBox, get_price_arr : %.4fs\" % (time.time() - start_time)) \n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # set zone (4)\n",
    "            #     # RRratio phase should be after set_price_and_open_signal.\n",
    "            # self.sys_log.debug(\"------------------------------------------------\")\n",
    "            # start_time = time.time()\n",
    "            \n",
    "            # self.sys_log.debug(\"LoopTableCondition : elasped time, set zone : %.4fs\" % (time.time() - start_time)) \n",
    "            # self.sys_log.debug(\"------------------------------------------------\")\n",
    "    \n",
    "\n",
    "            \n",
    "            if not pd.isnull(self.side_open): # default = np.nan\n",
    "    \n",
    "                # set symbol & code.\n",
    "                self.code = \"{}_{}\".format(self.symbol, datetime.now().strftime('%Y%m%d%H%M%S%f'))\n",
    "                init_table_trade(self) \n",
    "    \n",
    "                if drop:\n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()   \n",
    "                    \n",
    "                    self.table_condition.drop([idx], inplace=True)    \n",
    "                    \n",
    "                    self.sys_log.debug(\"LoopTableCondition : elasped time, drop rows  : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")  \n",
    "\n",
    "                \n",
    "        # save df_res.\n",
    "            # to use not-updated df_res in LoopTableTrade's REPLACEMENT phase.\n",
    "            # check df_res integrity.\n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()            \n",
    "        \n",
    "        self.path_df_res = \"{}\\\\{}.ftr\".format(self.path_dir_df_res, self.symbol)\n",
    "        self.df_res.reset_index(drop=False).to_feather(self.path_df_res , compression='lz4')\n",
    "        \n",
    "        self.sys_log.debug(\"LoopTableCondition : elasped time, save df_res : %.4fs\" % (time.time() - start_time)) \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        \n",
    "        # saving table takes some time, so we do not persist this phase more front.\n",
    "            # check timestampLastUsed\n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()   \n",
    "        \n",
    "        self.replace_table(self.table_condition, self.table_condition_name)\n",
    "        \n",
    "        self.sys_log.debug(\"LoopTableCondition : elasped time, replace_table  : %.4fs\" % (time.time() - start_time)) \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        \n",
    "\n",
    "\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    self.replace_table(self.table_condition, self.table_condition_name, send=True)\n",
    "    \n",
    "    self.sys_log.debug(\"LoopTableCondition : elasped time, replace_table (send=True)  : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc2152-a829-4be1-92ef-c10c10629f36",
   "metadata": {},
   "source": [
    "#### init_table_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c097b5-7f01-43e9-8203-2b155ebf29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_table_trade(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        rm OrderSide, PositionSide.\n",
    "    v2.0\n",
    "        move get_balance to the top.\n",
    "        modify to vivid input & output.\n",
    "        \n",
    "        v2.1\n",
    "            vivid mode.\n",
    "            add account & margin.\n",
    "        v2.2\n",
    "            apply dbms.\n",
    "             \n",
    "            v2.2.1\n",
    "                divide send / save. \n",
    "                api_count + 3\n",
    "        v2.3\n",
    "            apply TokenBucket.\n",
    "    \n",
    "    last confirmed at, 20240710 1019.\n",
    "    \"\"\"\n",
    "           \n",
    "    \n",
    "    self.order_motion = 0  # for consuming time without trading.\n",
    "\n",
    "    # we don't use get_price anymore...\n",
    "        # cause priceBox values are gotten already from LoopTableCondition. \n",
    "    # # get prices for order.\n",
    "    # self.sys_log.debug(\"------------------------------------------------\")\n",
    "    # start_time = time.time()\n",
    "    # self.price_entry, \\\n",
    "    # self.price_stop_loss, \\\n",
    "    # self.price_take_profit = self.get_price(self, \n",
    "    #                                       self.side_open, \n",
    "    #                                       self.df_res)\n",
    "    # self.sys_log.debug(\"InitTableTrade : elasped time, get_price : %.4fs\" % (time.time() - start_time)) \n",
    "    # self.sys_log.debug(\"------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()   \n",
    "        \n",
    "    self.side_close, \\\n",
    "    self.side_position = get_side_info(self, \n",
    "                                       self.side_open)\n",
    "        \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_side_info : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    self.price_entry = get_price_entry(self.df_res,\n",
    "                                       self.side_open,\n",
    "                                       self.price_entry)\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_price_entry : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "        \n",
    "\n",
    "    # get price_liquidation\n",
    "        # get_price_liquidation requires leverage.\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()   \n",
    "\n",
    "    # we are using target_loss_pct now, so liquidation has no more meaning.\n",
    "        # target_loss_pct max is 100.\n",
    "    self.price_liquidation = self.price_stop_loss\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_price_liquidation : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    # get price_expiration\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    self.price_expiration = self.price_take_profit # temporarily fix to price_take_profit.\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_price_expiration : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    # adj. precision_price & quantity\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()    \n",
    "    \n",
    "    self.token_bucket.wait_for_token_consume(1)   \n",
    "    \n",
    "    self.precision_price, \\\n",
    "    self.precision_quantity = get_precision(self, \n",
    "                                            self.symbol)\n",
    "    self.price_take_profit, \\\n",
    "    self.price_entry, \\\n",
    "    self.price_stop_loss, \\\n",
    "    self.price_liquidation, \\\n",
    "    self.price_expiration = [self.calc_with_precision(price_, self.precision_price) for price_ in [self.price_take_profit, \n",
    "                                                                                                    self.price_entry, \n",
    "                                                                                                    self.price_stop_loss,\n",
    "                                                                                                    self.price_liquidation,\n",
    "                                                                                                    self.price_expiration]]  # add price_expiration.\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, adj. precision_price : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "            \n",
    "    # get leverage\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    self.token_bucket.wait_for_token_consume(1)   \n",
    "    \n",
    "    self.loss, \\\n",
    "    self.leverage_limit_user, \\\n",
    "    self.leverage_limit_server, \\\n",
    "    self.leverage = get_leverage_limit(self, \n",
    "                                       self.symbol, \n",
    "                                       self.price_entry, \n",
    "                                       self.price_stop_loss, \n",
    "                                       self.config.trader_set.fee_market,\n",
    "                                       self.config.trader_set.fee_market)\n",
    "    # self.get_leverage(self)\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_leverage : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "            \n",
    "    # set leverage\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    if not self.config.trader_set.backtrade:\n",
    "        \n",
    "        self.token_bucket.wait_for_token_consume(1)   \n",
    "        \n",
    "        self.set_leverage(self.symbol,\n",
    "                          self.leverage)      \n",
    "        \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, set_leverage : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    # get quantity_open   \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    if self.target_loss:\n",
    "        self.quantity_open = self.target_loss / self.loss\n",
    "    else:\n",
    "        self.quantity_open = 15 / self.price_entry\n",
    "    self.quantity_open = self.calc_with_precision(self.quantity_open, self.precision_quantity)\n",
    "    \n",
    "    # Calculate entry and exit amounts\n",
    "        # amount_entry cannot be larger than the target_loss.\n",
    "    self.amount_entry = self.price_entry * self.quantity_open\n",
    "    self.margin = self.amount_entry / self.leverage\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get margin : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "            \n",
    "    self.sys_log.info(\"price_take_profit : {}\".format(self.price_take_profit))\n",
    "    self.sys_log.info(\"price_entry : {}\".format(self.price_entry))\n",
    "    self.sys_log.info(\"price_stop_loss : {}\".format(self.price_stop_loss))\n",
    "    self.sys_log.info(\"price_liquidation : {}\".format(self.price_liquidation))\n",
    "    self.sys_log.info(\"price_expiration : {}\".format(self.price_expiration))\n",
    "    self.sys_log.info(\"quantity_open : {}\".format(self.quantity_open))\n",
    "    self.sys_log.info(\"amount_entry : {}\".format(self.amount_entry))\n",
    "    self.sys_log.info(\"leverage : {}\".format(self.leverage))\n",
    "    self.sys_log.info(\"margin : {}\".format(self.margin))\n",
    "\n",
    "    \n",
    "    # get balance\n",
    "        # Stock 특성상, balance_min = self.price_entry 로 설정함.\n",
    "        # open_data_dict.pop 은 watch_dict 의 일회성 / 영구성과 무관하다.    \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    self.token_bucket.wait_for_token_consume(1)   \n",
    "    \n",
    "    margin_consistency = get_margin_consistency(self, \n",
    "                                                self.margin,\n",
    "                                                self.account,\n",
    "                                                mode=\"PROD\")\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, get_margin_consistency : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    if margin_consistency:    \n",
    "    \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()  \n",
    "        \n",
    "        table_trade_new_row = pd.DataFrame(data = np.array([np.nan] * len(self.table_trade.columns)).reshape(-1, 1).T, columns=self.table_trade.columns, dtype=object)\n",
    "    \n",
    "        # # save df_res.\n",
    "        self.path_df_res_open = \"{}/{}.ftr\".format(self.path_dir_df_res, self.code)\n",
    "        # self.df_res.reset_index(drop=True).to_feather(self.path_df_res , compression='lz4')\n",
    "    \n",
    "        # init table_trade.\n",
    "        table_trade_new_row.symbol = self.symbol \n",
    "        table_trade_new_row.code = self.code \n",
    "        table_trade_new_row.path_df_res_open = self.path_df_res_open \n",
    "        table_trade_new_row.order_motion = self.order_motion \n",
    "        table_trade_new_row.side_open = self.side_open \n",
    "        table_trade_new_row.side_close = self.side_close \n",
    "        table_trade_new_row.side_position = self.side_position \n",
    "        table_trade_new_row.precision_price = self.precision_price \n",
    "        table_trade_new_row.precision_quantity = self.precision_quantity \n",
    "        table_trade_new_row.price_take_profit = self.price_take_profit \n",
    "        table_trade_new_row.price_entry = self.price_entry \n",
    "        table_trade_new_row.price_stop_loss = self.price_stop_loss \n",
    "        table_trade_new_row.price_liquidation = self.price_liquidation \n",
    "        table_trade_new_row.price_expiration = self.price_expiration \n",
    "        table_trade_new_row.quantity_open = self.quantity_open \n",
    "        table_trade_new_row.amount_entry = self.amount_entry # added.\n",
    "        table_trade_new_row.leverage = self.leverage \n",
    "        table_trade_new_row.margin = self.margin             # added.\n",
    "        table_trade_new_row.account = self.account           # added. \n",
    "    \n",
    "        # self.sys_log.info(\"table_trade_new_row : \\n{}\".format(table_trade_new_row.iloc[0]))\n",
    "    \n",
    "        # append row.\n",
    "        self.table_trade = pd.concat([self.table_trade, table_trade_new_row]).reset_index(drop=True)            \n",
    "        \n",
    "        self.sys_log.debug(\"InitTableTrade : elasped time, append row : %.4fs\" % (time.time() - start_time)) \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        \n",
    "        self.push_msg(\"{} row insert into TableTrade.\".format(self.code))        \n",
    "        \n",
    "        \n",
    "    # preventing losing table_account info.\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    self.replace_table(self.table_account, self.table_account_name, send=True)\n",
    "    self.replace_table(self.table_trade, self.table_trade_name, send=True)\n",
    "    \n",
    "    self.sys_log.debug(\"InitTableTrade : elasped time, replace_table (send=True)  : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82cf6f3-7624-440e-af71-ca4a8c0f636a",
   "metadata": {},
   "source": [
    "#### loop_table_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79efb825-b6b9-485f-8f4c-4d7b7f305a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loop_table_trade(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        values come from rows should be static.\n",
    "        prevent order_market dup.\n",
    "        rm self.table_trade.at[idx, 'status'] = self.order_result['status'] in order phase.\n",
    "            considering status_prev. cannot be here, causing no diffenece before / after order_info update.\n",
    "            self.table_trade.at[idx, 'statusChangeTime'] can be replaced with order_result's updateTime\n",
    "        use loc istead of iloc for concat table_log (stay comprehension with .at)\n",
    "        secure orderId dtype\n",
    "    v1.1\n",
    "        add, if self.table_trade.at[idx, 'remove_row'] != 1: # if not trade is done,\n",
    "            if self.table_trade.at[idx, 'order_way'] == 'CLOSE':\n",
    "                if self.order_market_on:    \n",
    "        replace to feather ver (orderId type to int64)   \n",
    "        add side_open to check_stop_loss upper phase.\n",
    "        reorder statusChangeTime & OPEN CLOSE\n",
    "        modify statusChangeTime format\n",
    "        add remove_row = 1, self.error_code is not None.\n",
    "        add side_position on get_income_info().\n",
    "        modify remove from websocket_client\n",
    "            remove symbol from price_market\n",
    "        modify get_price_realtime phase. (consider price_realtime error).\n",
    "        \n",
    "        add preventing losing orderId by set set_table in this function.\n",
    "        \n",
    "        v1.1.1\n",
    "            modify to vivid input / output\n",
    "            add \\n to row : {}.\n",
    "        v1.1.2\n",
    "            vivid mode after v1.1.1\n",
    "                decide to use without self. (if self. is needless)\n",
    "        v1.1.3\n",
    "            apply dbms.\n",
    "\n",
    "            v1.1.3.1\n",
    "                divide send / server.\n",
    "                api_count + 8. (dynamic)\n",
    "        v1.1.4\n",
    "            apply TokenBucket.\n",
    "    \n",
    "    last confirmed at, 20240711 2410.\n",
    "    \"\"\" \n",
    "    \n",
    "    for idx, row in self.table_trade.iterrows(): # for save iteration, use copy().\n",
    "        \n",
    "        # init.\n",
    "        self.order_info = None\n",
    "        self.expired = 0\n",
    "        self.order_market_on = 0\n",
    "        self.table_trade.at[idx, 'order'] = 0 # default.        \n",
    "        \n",
    "        # update & clean table.\n",
    "            # some data need to be transfered to Bank's instance, some don't.\n",
    "                # 'row' means un-updated information. (by get_order_info)\n",
    "        self.code = row.code\n",
    "        self.symbol = row.symbol # we have symbol column in table already.\n",
    "        self.orderId = row.orderId\n",
    "        self.status_prev = row.status # save before updateing status.        \n",
    "        self.order_motion = row.order_motion\n",
    "        \n",
    "        self.price_expiration = row.price_expiration \n",
    "        \n",
    "        self.side_open = row.side_open\n",
    "        self.price_stop_loss = row.price_stop_loss\n",
    "        self.price_liquidation = row.price_liquidation\n",
    "                        \n",
    "        self.side_close = row.side_close\n",
    "        self.side_position = row.side_position        \n",
    "\n",
    "        self.sys_log.debug(\"row : \\n{}\".format(row))\n",
    "        self.sys_log.debug(\"row.dtypes : {}\".format(row.dtypes))\n",
    "    \n",
    "\n",
    "        # set order, order_way (OPEN) (order not exists)\n",
    "        if pd.isnull(self.orderId):\n",
    "            \n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            self.table_trade.at[idx, 'order'] = 1\n",
    "            self.table_trade.at[idx, 'order_way'] = 'OPEN'\n",
    "\n",
    "            if self.symbol not in self.price_market.keys(): # only once.\n",
    "                \n",
    "                self.token_bucket.wait_for_token_consume(2)\n",
    "                self.websocket_client.agg_trade(symbol=self.symbol, \n",
    "                                                id=1, \n",
    "                                                callback=self.agg_trade_message_handler)\n",
    "                self.set_position_mode(dualSidePosition='true')\n",
    "                self.set_margin_type(symbol=self.symbol)\n",
    "            \n",
    "            self.sys_log.debug(\"LoopTableTrade : elasped time, set order, order_way (OPEN) : %.4fs\" % (time.time() - start_time)) \n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        #  order exists.\n",
    "        else:\n",
    "        # if not pd.isnull(self.orderId): # this means, status is not None. (order in settled)\n",
    "\n",
    "            # get_order_info. (update order_info)\n",
    "                # get_order_info should have valid symbol & orderId.        \n",
    "            self.token_bucket.wait_for_token_consume(1)            \n",
    "            self.order_info = get_order_info(self, \n",
    "                                       self.symbol,\n",
    "                                       self.orderId)\n",
    "            \n",
    "            if self.order_info is not None: # order should be exist.\n",
    "                \n",
    "                # update table_trade\n",
    "                self.sys_log.debug(\"------------------------------------------------\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                for k, v in self.order_info.items():\n",
    "                    self.table_trade.at[idx, k] = v\n",
    "                    \n",
    "                self.sys_log.debug(\"LoopTableTrade : elasped time, update table_trade : %.4fs\" % (time.time() - start_time)) \n",
    "                self.sys_log.debug(\"------------------------------------------------\")\n",
    "                # display(self.table_trade)    \n",
    "                \n",
    "                # set statusChangeTime \n",
    "                    # check if status has been changed.\n",
    "                if self.status_prev != self.order_info['status']:\n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # self.table_trade.at[idx, 'statusChangeTime'] = int(time.time())\n",
    "                    self.table_trade.at[idx, 'statusChangeTime'] = datetime.now().strftime('%Y%m%d%H%M%S%f')\n",
    "                    self.push_msg(\"{} status has been changed. {} {}\".format(self.code, row.order_way, self.order_info['status']))\n",
    "                    \n",
    "                    self.sys_log.debug(\"LoopTableTrade : elasped time, set statusChangeTime : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")      \n",
    "                    # display(self.table_trade)\n",
    "                    \n",
    "                    # set remove_row. \n",
    "                        # use updated status. \n",
    "                    if (self.order_info['status'] in ['CANCELED', 'EXPIRED', 'REJECTED']) or (row.order_way == 'CLOSE' and self.order_info['status'] == 'FILLED'):\n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                        self.table_trade.at[idx, 'remove_row'] = 1\n",
    "                        \n",
    "                        self.sys_log.debug(\"LoopTableTrade : elasped time, set remove_row : %.4fs\" % (time.time() - start_time)) \n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        # display(self.table_trade)\n",
    "                    \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # logging : transfer rows to Table - log.        \n",
    "                    self.table_log = pd.concat([self.table_log, self.table_trade.loc[[idx]]]) # list input persist dataframe oubalance_availableut.\n",
    "                    self.table_log.reset_index(drop=True, inplace=True) # for indexing row by 'loc'    \n",
    "                    self.replace_table(self.table_log, self.table_log_name)\n",
    "                    \n",
    "                    self.sys_log.debug(\"LoopTableTrade : elasped time, replace_table : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")  \n",
    "                    # display(self.table_trade)\n",
    "\n",
    "                \n",
    "                # set order, order_way (CLOSE)\n",
    "                if row.order_way == 'OPEN':         \n",
    "                    if (abs(float(self.order_info['executedQty']) / float(self.order_info['origQty'])) >= self.config.trader_set.quantity_open_exec_ratio) or self.order_info['status'] == 'FILLED':           \n",
    "                        \n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()\n",
    "                        \n",
    "                        self.table_trade.at[idx, 'order'] = 1\n",
    "                        self.table_trade.at[idx, 'order_way'] = 'CLOSE'\n",
    "                        \n",
    "                        self.sys_log.debug(\"LoopTableTrade : elasped time, set order, order_way (CLOSE) : %.4fs\" % (time.time() - start_time)) \n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        # display(self.table_trade)\n",
    "                \n",
    "                \n",
    "                # check expiration for order_open.\n",
    "                    # set price_reatlime\n",
    "                        # for, open expiry & check_stop_loss\n",
    "                self.price_realtime = get_price_realtime(self, \n",
    "                                                        self.symbol)\n",
    "                self.sys_log.debug(\"self.price_realtime : {}\".format(self.price_realtime))\n",
    "\n",
    "                if not pd.isnull(self.price_realtime):                    \n",
    "                    self.table_trade.at[idx, 'price_realtime'] = self.price_realtime                    \n",
    "            \n",
    "                        # row.side_position has 2 state (LONG / SHORT) in status below 2 case.\n",
    "                    if row.order_way == 'OPEN' and self.order_info['status'] in ['NEW', 'PARTIALLY_FILLED']:\n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()  \n",
    "                                \n",
    "                        self.expired = check_expiration(self.side_position, \n",
    "                                                        self.price_realtime, \n",
    "                                                        self.price_expiration)\n",
    "                            \n",
    "                        if self.expired:\n",
    "                            \n",
    "                            self.token_bucket.wait_for_token_consume(2)   \n",
    "                            quantity_unexecuted = get_quantity_unexecuted(self, \n",
    "                                                                        self.symbol,\n",
    "                                                                        self.orderId)  \n",
    "                            \n",
    "                            self.table_account.loc[self.table_account['account'] == row.account, 'balance'] +=(quantity_unexecuted * row.price_entry / row.leverage)\n",
    "                            \n",
    "                            # Todo, messeage alertion needed ?\n",
    "                            self.push_msg(\"{} has been expired.\".format(self.code))\n",
    "                            self.user_text = 'watch'  # allowing message.\n",
    "                            \n",
    "                        self.sys_log.debug(\"LoopTableTrade : elasped time, check expiration for order_open : %.4fs\" % (time.time() - start_time)) \n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        \n",
    "                    \n",
    "                    # check stop_loss\n",
    "                        # get order_market_on\n",
    "                        # order_way == 'CLOSE' : stop_loss / liquidation condition.\n",
    "                    elif row.order_way == 'CLOSE':\n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "                        start_time = time.time()  \n",
    "                        \n",
    "                        self.order_market_on = check_stop_loss(self,\n",
    "                                                            self.side_open,\n",
    "                                                            self.price_realtime,\n",
    "                                                            self.price_liquidation,\n",
    "                                                            self.price_stop_loss)\n",
    "                        \n",
    "                        self.sys_log.debug(\"LoopTableTrade : elasped time, check_stop_loss : %.4fs\" % (time.time() - start_time)) \n",
    "                        self.sys_log.debug(\"------------------------------------------------\")\n",
    "            \n",
    "        \n",
    "        # order_limit\n",
    "        if not self.config.trader_set.backtrade and not self.order_motion:\n",
    "\n",
    "           # reflect updated row.\n",
    "           if self.table_trade.at[idx, 'order'] == 1:\n",
    "\n",
    "                self.sys_log.debug(\"------------------------------------------------\")\n",
    "                start_time = time.time()\n",
    "               \n",
    "                # public set.\n",
    "                order_type = 'LIMIT' # fixed for order_limit.\n",
    "                side_position = row.side_position\n",
    "            \n",
    "                # open condition\n",
    "                if self.table_trade.at[idx, 'order_way'] == 'OPEN':\n",
    "                \n",
    "                    # open                    \n",
    "                    side_order = row.side_open\n",
    "                    price = row.price_entry\n",
    "                    quantity = row.quantity_open\n",
    "    \n",
    "                # close condition\n",
    "                else: #  self.table_trade.at[idx, 'order_way'] == 'CLOSE': # upper phase's condition use 'order' = 1\n",
    "                            \n",
    "                    # we don't do partial like this anymore.\n",
    "                        # each price info will be adjusted order by order.\n",
    "                    \n",
    "                    # close                    \n",
    "                    side_order = row.side_close\n",
    "                    price = row.price_take_profit\n",
    "                    quantity = self.order_info['executedQty'] # OPEN's qty.\n",
    "\n",
    "            \n",
    "                self.token_bucket.wait_for_token_consume(1)   \n",
    "                self.order_result, \\\n",
    "                self.error_code = order_limit(self, \n",
    "                                            self.symbol,\n",
    "                                            side_order, \n",
    "                                            side_position, \n",
    "                                            price, \n",
    "                                            quantity)\n",
    "            \n",
    "                # KIWOOM version.\n",
    "                    # If the order price is at the upper limit, keep it until the order is possible.\n",
    "                        # Continuously perform self.price_stop_loss check.\n",
    "                        # Append only once; do not pop in close_data.\n",
    "                            # Is this also cumulative?\n",
    "               \n",
    "                # normal state : self.error_code = 0\n",
    "                if not self.error_code:\n",
    "                    # self.table_trade.at[idx, 'orderId'] = str(self.order_result['orderId']) # this is key for updating order_info (change to OPEN / CLOSE orderId)\n",
    "                    self.table_trade.at[idx, 'orderId'] = self.order_result['orderId'] # this is key for updating order_info (change to OPEN / CLOSE orderId)\n",
    "                    \n",
    "                else:\n",
    "                    self.table_trade.at[idx, 'remove_row'] = 1\n",
    "                    \n",
    "                    if self.table_trade.at[idx, 'order_way'] == 'OPEN': # if open fail, deposit withdrew margin.\n",
    "                        self.table_account.loc[self.table_account['account'] == row.account, 'balance'] += row.margin\n",
    "                    \n",
    "                self.sys_log.debug(\"LoopTableTrade : elasped time, order_limit : %.4fs\" % (time.time() - start_time)) \n",
    "                self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        \n",
    "        # order_market\n",
    "            # prevent order_market duplication.\n",
    "                # order_way == 'CLOSE' : stop_loss / liquidation condition.\n",
    "                    # repflect updated row.\n",
    "        if self.table_trade.at[idx, 'remove_row'] != 1: # if not trade is done, it has np.nan or 1.\n",
    "            if self.table_trade.at[idx, 'order_way'] == 'CLOSE':\n",
    "                if self.order_market_on:\n",
    "                    \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    self.token_bucket.wait_for_token_consume(2)                    \n",
    "                    quantity_unexecuted = get_quantity_unexecuted(self, \n",
    "                                                                self.symbol,\n",
    "                                                                self.orderId)          \n",
    "                    \n",
    "                    self.token_bucket.wait_for_token_consume(2)  \n",
    "                    self.order_result, \\\n",
    "                    self.error_code = order_market(self, \n",
    "                                                 self.symbol,\n",
    "                                                 self.side_close,\n",
    "                                                 self.side_position,\n",
    "                                                 quantity_unexecuted)\n",
    "                    \n",
    "                    # normal state : self.error_code = 0\n",
    "                    if not self.error_code:\n",
    "                        self.table_trade.at[idx, 'orderId'] = self.order_result['orderId'] # this is key for updating order_info (change to CLOSE orderId)                                \n",
    "                    self.sys_log.debug(\"LoopTableTrade : elasped time, order_market : %.4fs\" % (time.time() - start_time)) \n",
    "                    self.sys_log.debug(\"------------------------------------------------\")\n",
    "\n",
    "        \n",
    "        # drop rows\n",
    "            # this phase should be placed in the most below, else order_ will set value as np.nan in invalid rows.\n",
    "        else:\n",
    "        # if self.table_trade.at[idx, 'remove_row'] == 1:      \n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # drow remove_row = 1,\n",
    "            self.table_trade.drop([idx], inplace=True)\n",
    "            # display(self.table_trade)\n",
    "\n",
    "            # remove from websocket_client.\n",
    "            if self.symbol not in self.table_trade.symbol.values:        \n",
    "                self.websocket_client.stop_socket(\"{}@aggTrade\".format(self.symbol.lower()))\n",
    "                \n",
    "                if self.symbol in self.price_market.keys():\n",
    "                    self.price_market.pop(self.symbol)\n",
    "\n",
    "            self.sys_log.debug(\"LoopTableTrade : elasped time, drop rows : %.4fs\" % (time.time() - start_time)) \n",
    "            self.sys_log.debug(\"------------------------------------------------\")  \n",
    "\n",
    "            # except open canceld,            \n",
    "            self.sys_log.debug(\"------------------------------------------------\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            self.income, \\\n",
    "            self.income_accumulated, \\\n",
    "            self.profit, \\\n",
    "            self.profit_accumulated = get_income_info(self, \n",
    "                                                    self.table_log,\n",
    "                                                    self.code,\n",
    "                                                    row.side_position,\n",
    "                                                    row.leverage,\n",
    "                                                    self.income_accumulated,\n",
    "                                                    self.profit_accumulated,                    \n",
    "                                                    mode=\"PROD\", \n",
    "                                                    currency=\"USDT\")\n",
    "            \n",
    "            self.table_account.loc[self.table_account['account'] == row.account, 'balance'] += self.income\n",
    "            \n",
    "            self.sys_log.debug(\"LoopTableTrade : elasped time, get_income_info : %.4fs\" % (time.time() - start_time)) \n",
    "            self.sys_log.debug(\"------------------------------------------------\")  \n",
    "            # display(self.table_trade)\n",
    "\n",
    "\n",
    "        # preventing losing orderId      \n",
    "        self.sys_log.debug(\"------------------------------------------------\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.replace_table(self.table_account, self.table_account_name)\n",
    "        self.replace_table(self.table_trade, self.table_trade_name)\n",
    "        \n",
    "        self.sys_log.debug(\"LoopTableTrade : elasped time, replace_table : %.4fs\" % (time.time() - start_time)) \n",
    "        self.sys_log.debug(\"------------------------------------------------\")  \n",
    "\n",
    "        \n",
    "        # # preventing API flood.\n",
    "        # time.sleep(0.1)\n",
    "\n",
    "    # use send=True instead time.sleep for API flood.\n",
    "    self.sys_log.debug(\"------------------------------------------------\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    self.replace_table(self.table_account, self.table_account_name, send=True)\n",
    "    self.replace_table(self.table_trade, self.table_trade_name, send=True)\n",
    "    self.replace_table(self.table_log, self.table_log_name, send=True)\n",
    "    \n",
    "    self.sys_log.debug(\"LoopTableTrade : elasped time, replace_table (send=True) : %.4fs\" % (time.time() - start_time)) \n",
    "    self.sys_log.debug(\"------------------------------------------------\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6aadb0-b941-45bc-9ec2-7a82393e1b6c",
   "metadata": {},
   "source": [
    "### BankSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ead4f0-4f80-40d4-91b7-0542ee226532",
   "metadata": {},
   "source": [
    "#### echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f563ac4-9b88-479e-89a5-c4b906c115e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(self, update, context):    \n",
    "    self.user_text = update.message.text     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32532ecf-adaf-4dbc-800b-f50165890ce1",
   "metadata": {},
   "source": [
    "#### get_messenger_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83365866-fa37-4247-b569-1fdc67ea9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messenger_bot(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        use token from self directly.\n",
    "    v3.0\n",
    "        remove self.msg_bot exist condition.\n",
    "\n",
    "    last confirmed at, 20240528 1257.\n",
    "    \"\"\"\n",
    "        \n",
    "    # init\n",
    "    self.msg_bot = telegram.Bot(token=self.token)    \n",
    "    self.user_text = None # messenger buffer.\n",
    "    \n",
    "    # get updater & set handler\n",
    "    self.updater = Updater(token=self.token, use_context=True)\n",
    "    dispatcher = self.updater.dispatcher\n",
    "    \n",
    "    echo_handler = MessageHandler(Filters.text & (~Filters.command), self.echo)\n",
    "    dispatcher.add_handler(echo_handler)\n",
    "    \n",
    "    # start_polling.\n",
    "    self.updater.start_polling()\n",
    "    \n",
    "    self.sys_log.debug(\"msg_bot {} assigned.\".format(self.token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61e362-f022-4d16-af2e-24bb448a62c8",
   "metadata": {},
   "source": [
    "#### push_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57936f-8771-448e-b333-3fd2844f68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_msg(self, msg):    \n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        this function has some time dely.\n",
    "\n",
    "    last confirmed at, 20240517 1413.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        self.msg_bot.sendMessage(chat_id=self.chat_id, text=msg)\n",
    "    except Exception as e:\n",
    "        self.sys_log.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3889e-fb35-4d3e-870d-d5381dffc559",
   "metadata": {},
   "source": [
    "#### read_and_write_config (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48bbac-1817-471b-93e7-baca7c64420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_write_config(self, mode='r', config_edited=None):\n",
    "    \n",
    "    try:\n",
    "        file_config = open(self.path_config, mode)\n",
    "\n",
    "        if mode == 'r':\n",
    "            self.config = EasyDict(json.load(file_config))\n",
    "            \n",
    "        elif mode == 'w':\n",
    "            assert config_edited is not None, \"assert config_edited is not None\"\n",
    "            json.dump(config_edited, file_config, indent=2)\n",
    "        else:\n",
    "            assert mode in ['r', 'w'], \"assert mode in ['r', 'w']\"\n",
    "\n",
    "        # 1. opened files should be closed.\n",
    "        file_config.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        msg = \"error in read_and_write_config : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(self, msg)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918a71d-0402-4648-ad9a-8cffe4b27782",
   "metadata": {},
   "source": [
    "#### fetch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e781e9-13e5-4aee-acd4-0fb64df233f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_table(self, table_name, limit=None):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        using engine, much faster.\n",
    "\n",
    "    last confirmed at, 20240705 2208.\n",
    "    \"\"\"\n",
    "\n",
    "    # if you use self.engine, you can show table in original dtypes.\n",
    "        # %timeit -n1 -r1000 fetch_table(self.engine, 'table_log', limit=None) \n",
    "            # 1.9 ms ± 93.7 µs per loop (mean ± std. dev. of 1000 runs, 1 loop each)\n",
    "    try:\n",
    "        with self.engine.connect() as conn:\n",
    "            if limit is None:\n",
    "                query = text(f\"SELECT * FROM {table_name};\")\n",
    "            else:\n",
    "                query = text(f\"SELECT * FROM {table_name} LIMIT {limit};\")\n",
    "            \n",
    "            result = conn.execute(query)\n",
    "            rows = result.fetchall()\n",
    "            df = pd.DataFrame(rows, columns=result.keys())\n",
    "            return df\n",
    "\n",
    "    except Exception as e:\n",
    "        self.sys_log.error(f\"error fetching data from {table_name}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b53174-df52-41dc-8db2-ad7fda5754b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection details\n",
    "bank.db_user = 'bank'\n",
    "bank.db_password = '8974'\n",
    "bank.db_host = 'localhost'\n",
    "bank.db_port = '5432'\n",
    "bank.db_name = 'postgres'\n",
    "\n",
    "bank.engine = create_engine(f'postgresql://{bank.db_user}:{bank.db_password}@{bank.db_host}:{bank.db_port}/{bank.db_name}')\n",
    "\n",
    "\n",
    "bank.table_account = fetch_table(bank, bank.table_account_name)\n",
    "bank.table_condition = fetch_table(bank, bank.table_condition_name)\n",
    "bank.table_trade = fetch_table(bank, bank.table_trade_name)\n",
    "bank.table_log = fetch_table(bank, bank.table_log_name)\n",
    "\n",
    "# bank.engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1730e-897d-4364-89c8-e05bc6ce548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bank.table_account)\n",
    "display(bank.table_condition)\n",
    "display(bank.table_trade)\n",
    "display(bank.table_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df3f58-f873-4123-ad1f-978bc7cf368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.table_account_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65de92e-8bfa-4dfc-b62e-cce3ff2f5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.fetch_table(bank.table_account_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb7869-7b74-40ab-8a89-486c38535378",
   "metadata": {},
   "source": [
    "#### replace_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f385f-9ce8-4176-a4c1-9c31edf1fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_table(self, df, table_name, send=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.1\n",
    "        using engine, much faster.\n",
    "    v1.2\n",
    "        using temp_table, stay as consistent state.\n",
    "        \n",
    "        v1.2.1\n",
    "            modify to psycopg2, considering latency.\n",
    "\n",
    "    last confirmed at, 20240706 1014.\n",
    "    \"\"\"  \n",
    "    \n",
    "    temp_csv = f'{table_name}.csv'\n",
    "    df.to_csv(temp_csv, index=False, header=False)\n",
    "\n",
    "    if send:\n",
    "        try:            \n",
    "            # Fetch column names and data types from the existing table            \n",
    "            self.cur.execute(sql.SQL(\"\"\"\n",
    "                SELECT column_name, data_type\n",
    "                FROM information_schema.columns\n",
    "                WHERE table_name = %s\n",
    "                ORDER BY ordinal_position\n",
    "            \"\"\"), [table_name])\n",
    "            \n",
    "            # Retrieve the results\n",
    "            columns = self.cur.fetchall()\n",
    "            \n",
    "            # Replace the table\n",
    "            self.cur.execute(f\"DROP TABLE IF EXISTS {table_name}\")            \n",
    "            \n",
    "            create_table_query = sql.SQL(\"CREATE TABLE {} ({});\").format(\n",
    "                sql.Identifier(table_name),\n",
    "                sql.SQL(', ').join(\n",
    "                    sql.SQL(\"{} {}\").format(\n",
    "                        sql.Identifier(column[0]),\n",
    "                        sql.SQL(column[1])\n",
    "                    ) for column in columns\n",
    "                )\n",
    "            )\n",
    "            self.cur.execute(create_table_query)\n",
    "    \n",
    "            # Use COPY command to load data\n",
    "            with open(temp_csv, 'r') as f:\n",
    "                self.cur.copy_expert(f\"COPY {table_name} FROM STDIN WITH CSV\", f)\n",
    "    \n",
    "            # Commit changes\n",
    "            self.conn.commit()\n",
    "        except Exception as e:\n",
    "            if self.conn:\n",
    "                self.conn.rollback()\n",
    "            print(f\"error occurred in replace_table : {e}\")\n",
    "        # finally:\n",
    "            # # Remove temporary file\n",
    "            # os.remove(temp_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083f727-d1c2-4135-9520-778abf336120",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_table(bank, bank.table_account, bank.table_account_name, send=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687a4ff-edc6-415d-be51-46bca958bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.replace_table(bank.table_log, 'table_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74e2ef-6a03-4ffc-af69-9fc2642b9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "close(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beee932-8441-40f3-8ac3-cec28d90cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def connect(self):\n",
    "#     \"\"\" Connect to the database. \"\"\"\n",
    "#     self.conn = psycopg2.connect(\n",
    "#         dbname=self.config.database.name,\n",
    "#         user=self.config.database.user, \n",
    "#         password=self.config.database.password, \n",
    "#         host=self.config.database.host\n",
    "#     )\n",
    "#     self.cur = self.conn.cursor()\n",
    "\n",
    "# def close(self):\n",
    "#     \"\"\" Close the database connection. \"\"\"\n",
    "#     if self.cur:\n",
    "#         self.cur.close()\n",
    "#     if self.conn:\n",
    "#         self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb1db-1f7c-4d4d-bfcb-7878cfd6dbf4",
   "metadata": {},
   "source": [
    "#### load_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bcf21a-6eb2-429d-8d8e-5673a53257d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(self, file_path, file_type='excel'):\n",
    "    \"\"\"\n",
    "    Load a table from the specified file path. If it fails, try to load from a backup file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the primary file.\n",
    "    - file_type: str, type of the file ('excel' or 'pickle').\n",
    "\n",
    "    Returns:\n",
    "    - Loaded table as a DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_type == 'excel':\n",
    "            return pd.read_excel(file_path)\n",
    "        elif file_type == 'pickle':\n",
    "            return pd.read_pickle(file_path)\n",
    "    except:\n",
    "        if file_type == 'excel':\n",
    "            return pd.read_excel(file_path.replace(\".xlsx\", \"_bk.xlsx\"))\n",
    "        elif file_type == 'pickle':\n",
    "            return pd.read_pickle(file_path.replace(\".pkl\", \"_bk.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a9358-db70-43a7-8bde-9d38559076ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.path_table_account = \"data/table/table_account.xlsx\"\n",
    "bank.path_table_condition = \"./data/table/table_condition.xlsx\"\n",
    "bank.path_table_trade = \"./data/table/table_trade.xlsx\"\n",
    "bank.path_table_log = \"./data/table/table_log.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5cc8c-e816-43bf-b4e5-c3eea60a1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.table_account = load_table(bank, bank.path_table_account, 'excel')\n",
    "bank.table_condition = load_table(bank, bank.path_table_condition, 'excel')\n",
    "# bank.table_trade = load_table(bank, bank.path_table_trade, 'pickle')\n",
    "bank.table_trade = load_table(bank, bank.path_table_trade, 'excel')\n",
    "bank.table_log = load_table(bank, bank.path_table_log, 'excel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41352f48-7862-438f-a223-a3ee04174f76",
   "metadata": {},
   "source": [
    "#### get_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094b8d2-211b-4de3-bd92-a6a7cd8f172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        we need this func. only once (program start, loading saved data.)\n",
    "        replace csv to excel : preserving dtypes.\n",
    "    v2.0\n",
    "        path_table_trade replace to feather.\n",
    "        add restoration logic.\n",
    "        \n",
    "    last confirmed at, 20240518 2355.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.table_condition = pd.read_excel(self.path_table_condition)\n",
    "    # self.table_trade = pd.read_feather(self.path_table_trade)\n",
    "    self.table_trade = pd.read_pickle(self.path_table_trade)\n",
    "    try:\n",
    "        self.table_log = pd.read_excel(self.path_table_log)\n",
    "    except:\n",
    "        self.table_log = pd.read_excel(self.path_table_log.replace(\".xlsx\", \"_bk.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c57da-ce93-4847-8390-a9716fdd87f3",
   "metadata": {},
   "source": [
    "#### set_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8c3aa-5eea-4c32-88b5-cb897ee3f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tables(self, mode='ALL'):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        we need this func. only once (program start, loading saved data.)\n",
    "        replace csv to excel : preserving dtypes.\n",
    "    v2.0\n",
    "        path_table_trade replace to feather.\n",
    "    v2.1\n",
    "        divide save target.\n",
    "        save as pickle\n",
    "            table_trade\n",
    "                feather doesn't support 'something'.\n",
    "    v2.3\n",
    "        save as excel\n",
    "            table condition, log\n",
    "                for user interfacing.\n",
    "        v2.3.1\n",
    "            add table_account.\n",
    "\n",
    "    last confirmed at, 20240701 1257.\n",
    "    \"\"\"\n",
    "\n",
    "    if mode in ['ALL', 'ACCOUNT']:\n",
    "        self.table_account.to_excel(self.path_table_account, index=False)\n",
    "        self.table_account.to_excel(self.path_table_account.replace(\".xlsx\", \"_bk.xlsx\"), index=False)\n",
    "\n",
    "    if mode in ['ALL', 'CONDITION']:\n",
    "        self.table_condition.to_excel(self.path_table_condition, index=False)\n",
    "        self.table_condition.to_excel(self.path_table_condition.replace(\".xlsx\", \"_bk.xlsx\"), index=False)\n",
    "\n",
    "    if mode in ['ALL', 'TRADE']: # table_trade's idx should be reset. (using .at in loop)\n",
    "        # self.table_trade.reset_index(drop=True).to_pickle(self.path_table_trade)\n",
    "        # self.table_trade.reset_index(drop=True).to_pickle(self.path_table_trade.replace(\".pkl\", \"_bk.pkl\"))\n",
    "        self.table_trade.reset_index(drop=True).to_excel(self.path_table_trade, index=False)\n",
    "        self.table_trade.reset_index(drop=True).to_excel(self.path_table_trade.replace(\".xlsx\", \"_bk.xlsx\"), index=False)\n",
    "\n",
    "    if mode in ['ALL', 'LOG']:\n",
    "        self.table_log.to_excel(self.path_table_log, index=False)\n",
    "        self.table_log.to_excel(self.path_table_log.replace(\".xlsx\", \"_bk.xlsx\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f673488-99ca-431f-868b-d6475a488ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.set_tables()\n",
    "# bank.table_account\n",
    "# bank.path_table_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cac652-582b-4f30-ae85-225d3d6b2876",
   "metadata": {},
   "source": [
    "### LoopMessenger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe1f1e-4243-40cb-ab3f-124177c32dc9",
   "metadata": {},
   "source": [
    "#### get_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775965e0-30aa-4db3-9ba4-360edb904aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers(self, ):    \n",
    "    self.tickers_available = [info['symbol'] for info in self.exchange_info()['symbols']]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482e6ae-5770-4619-ac7b-815fa9700b35",
   "metadata": {},
   "source": [
    "### LoopTableCondition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fa706-592e-443d-907c-bb9d035ea4eb",
   "metadata": {},
   "source": [
    "#### get_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87756636-71e8-47bb-a70d-1d672f98ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamer(self):\n",
    "    \n",
    "    row_list = literal_eval(self.config.trader_set.row_list)\n",
    "    itv_list = literal_eval(self.config.trader_set.itv_list)\n",
    "    rec_row_list = literal_eval(self.config.trader_set.rec_row_list)\n",
    "    use_rows, days = calc_rows_and_days(itv_list, row_list, rec_row_list)\n",
    "\n",
    "    back_df = pd.read_feather(self.config.trader_set.back_data_path, columns=None, use_threads=True).set_index(\"index\")\n",
    "\n",
    "    if self.config.trader_set.start_datetime != \"None\":\n",
    "        target_datetime = pd.to_datetime(self.config.trader_set.start_datetime)\n",
    "        if target_datetime in back_df.index:\n",
    "            start_idx = np.argwhere(back_df.index == target_datetime).item()\n",
    "        else:\n",
    "            start_idx = use_rows\n",
    "    else:\n",
    "        start_idx = use_rows\n",
    "\n",
    "    # 시작하는 idx 는 필요로하는 rows 보다 커야함.\n",
    "    assert start_idx >= use_rows, \"more dataframe rows required\"\n",
    "\n",
    "    for i in range(start_idx + 1, len(back_df)):  # +1 for i inclusion\n",
    "        yield back_df.iloc[i - use_rows:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864a5b0-253f-4e9e-8f15-0779c58158b8",
   "metadata": {},
   "source": [
    "#### get_df_new_by_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11caedf4-abd0-4979-9187-d42b0e1cfc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_new_by_streamer(self, ):\n",
    "    \n",
    "    try:\n",
    "        self.df_res = next(self.streamer)  # Todo, 무결성 검증 미진행\n",
    "    except Exception as e:\n",
    "        msg = \"error in get_df_new_by_streamer : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(self, msg)\n",
    "        # self.kill_proc()  # error 처리할 필요없이, backtrader 프로그램 종료\n",
    "        # return None, None   # oubalance_availableut len 유지\n",
    "    # else:\n",
    "    #     return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988524b-1a4c-41ca-8a87-4e100a4ce719",
   "metadata": {},
   "source": [
    "#### get_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb71e64-ec62-471f-85a1-bd3feafc7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_df_new(self, interval='1m', days=2, end_date=None, limit=1500, timesleep=None):\n",
    "\n",
    "    limit_kline = 1500\n",
    "    assert limit <= limit_kline, f\"assert limit < limit_kline ({limit_kline})\"\n",
    "\n",
    "    while True:\n",
    "        if end_date is None:\n",
    "            end_date = str(datetime.now()).split(' ')[0]\n",
    "\n",
    "        timestamp_end = int(datetime.strptime(end_date, '%Y-%m-%d').replace(hour=23, minute=59, second=59).timestamp() * 1000)\n",
    "        timestamp_start = timestamp_end - days * 24 * 60 * 60 * 1000\n",
    "        timestamp_unit = itv_to_number(interval) * 60 * 1000 * limit\n",
    "\n",
    "        time_arr_start = np.arange(timestamp_start, timestamp_end, timestamp_unit)\n",
    "        time_arr_end = time_arr_start + timestamp_unit\n",
    "\n",
    "        df_list = []\n",
    "\n",
    "        for time_start, time_end in zip(time_arr_start, time_arr_end):\n",
    "            try:                \n",
    "                response = self.klines(\n",
    "                    symbol=self.symbol,\n",
    "                    interval=interval,\n",
    "                    startTime=int(time_start),\n",
    "                    endTime=int(time_end),\n",
    "                    limit=limit\n",
    "                )\n",
    "                \n",
    "                tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "                self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "\n",
    "                response = response['data'] # replace response.\n",
    "\n",
    "                if not response:\n",
    "                    if df_list: # if df_list lose middle df, occur error.\n",
    "                        return None, ''\n",
    "                    time.sleep(timesleep)\n",
    "                    continue\n",
    "\n",
    "                df = pd.DataFrame(np.array(response)).set_index(0).iloc[:, :5]\n",
    "                df.index = list(map(lambda x: datetime.fromtimestamp(int(x) / 1000), df.index)) # modify to datetime format.\n",
    "                df.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                df = df.astype(float)\n",
    "\n",
    "                if True:  # Always show process for debugging\n",
    "                    self.sys_log.debug(f\"{self.symbol} {df.index[0]} --> {df.index[-1]}\")\n",
    "\n",
    "                df_list.append(df)\n",
    "                \n",
    "            except Exception as e:\n",
    "                msg = f\"error in klines : {str(e)}\"\n",
    "                self.sys_log.error(msg)\n",
    "                if 'sum_df' not in msg:\n",
    "                    self.push_msg(msg)\n",
    "                time.sleep(self.config.trader_set.api_term)\n",
    "                \n",
    "            else:\n",
    "                if timesleep:\n",
    "                    time.sleep(timesleep)\n",
    "\n",
    "        if df_list:\n",
    "            sum_df = pd.concat(df_list)\n",
    "\n",
    "            return sum_df[~sum_df.index.duplicated(keep='last')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53266cbd-c934-416a-a5fc-a2d1d0b7a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.get_df_new(bank, interval='15m', days=3, limit=1500, timesleep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b898b-9491-4a4f-868d-01d84100c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "\n",
    "bank.df_res = get_df_new(bank, \n",
    "                       interval='15m', \n",
    "                       days=3, \n",
    "                       limit=1500, \n",
    "                       timesleep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5dbeb-1556-4693-8bdf-f507d9c18683",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d43a32-59e3-4732-a538-91e29efde014",
   "metadata": {},
   "source": [
    "#### set_price_and_open_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d4242-441f-4a43-8f6c-6e6a084601b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_price_and_open_signal(self, mode='OPEN', env='BANK'):\n",
    "    \n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        Class mode.\n",
    "    \t\tuse self, as parameter.\n",
    "            modulize self.short_open_res1 *= phase.\n",
    "            include np.timeidx\n",
    "    v3.0\n",
    "        turn off adj_wave_point. (messenger version)\n",
    "        modify 'IDEP' to 'IDEP'\n",
    "        \n",
    "        v3.1\n",
    "            modify to TableCondition_v0.3\n",
    "        v3.2\n",
    "            vivid mode.\n",
    "    \n",
    "    last confirmed at, 20240702 1342.\n",
    "    \"\"\"\n",
    "    \n",
    "    self.len_df = len(self.df_res)\n",
    "    self.np_timeidx = np.array([intmin_np(date_) for date_ in self.df_res.index.to_numpy()])     \n",
    "    close = self.df_res['close'].to_numpy()\n",
    "    \n",
    "    set_price_box(self, )\n",
    "    set_price(self, close)       \n",
    "    get_reward_risk_ratio(self, ) # default\n",
    "    \n",
    "    if env == 'IDEP':\n",
    "        adj_price_unit(self,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f5e62-9211-4795-845d-b67d4a5d2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.side_open = 'BUY'\n",
    "bank.price_take_profit = 0.3157\n",
    "bank.price_entry = 0.3092\n",
    "bank.price_stop_loss = 0.3040\n",
    "          \n",
    "\n",
    "# bank.get_df_mtf(bank) # function usage format maintenance\n",
    "# bank.get_wave_info(bank)\n",
    "set_price_and_open_signal(bank, mode='OPEN', env='BANK') # env select not to use adj_price_unit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbd71f-9aed-4e55-b916-ad20c1723a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123da904-5568-4c58-8bbe-624d5aa06000",
   "metadata": {},
   "source": [
    "##### set_price_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d2e9d-1cb1-4785-aa21-74fb3ad54857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_price_box(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        use table_condition & messenger.\n",
    "\n",
    "    last confirmed at, 20240529 0929.\n",
    "    \"\"\"  \n",
    "    \n",
    "    self.df_res['short_tp_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['short_tp_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "    self.df_res['long_tp_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['long_tp_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "\n",
    "    self.df_res['short_ep1_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['short_ep1_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "    self.df_res['long_ep1_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['long_ep1_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "\n",
    "    # --> p2's self.price_entry use p1's self.price_entry\n",
    "    self.df_res['short_ep2_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['short_ep2_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "    self.df_res['long_ep2_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['long_ep2_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "\n",
    "    # --> self.price_stop_loss use p1's low, (allow prev_low as self.price_stop_loss for p1_hhm only)\n",
    "    self.df_res['short_out_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['short_out_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "    self.df_res['long_out_1_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['long_out_0_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "\n",
    "    \n",
    "    # gap\n",
    "    self.df_res['short_tp_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_tp_1_{}'.format(self.config.selection_id)] - self.df_res['short_tp_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_tp_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_tp_1_{}'.format(self.config.selection_id)] - self.df_res['long_tp_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['short_ep1_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_ep1_1_{}'.format(self.config.selection_id)] - self.df_res['short_ep1_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_ep1_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_ep1_1_{}'.format(self.config.selection_id)] - self.df_res['long_ep1_0_{}'.format(self.config.selection_id)])\n",
    "\n",
    "    self.df_res['short_out_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_out_1_{}'.format(self.config.selection_id)] - self.df_res['short_out_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_out_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_out_1_{}'.format(self.config.selection_id)] - self.df_res['long_out_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['short_ep2_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_ep2_1_{}'.format(self.config.selection_id)] - self.df_res['short_ep2_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_ep2_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_ep2_1_{}'.format(self.config.selection_id)] - self.df_res['long_ep2_0_{}'.format(self.config.selection_id)])\n",
    "\n",
    "    \n",
    "    # gap\n",
    "    self.df_res['short_tp_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_tp_1_{}'.format(self.config.selection_id)] - self.df_res['short_tp_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_tp_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_tp_1_{}'.format(self.config.selection_id)] - self.df_res['long_tp_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['short_ep1_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_ep1_1_{}'.format(self.config.selection_id)] - self.df_res['short_ep1_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_ep1_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_ep1_1_{}'.format(self.config.selection_id)] - self.df_res['long_ep1_0_{}'.format(self.config.selection_id)])\n",
    "\n",
    "    self.df_res['short_out_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_out_1_{}'.format(self.config.selection_id)] - self.df_res['short_out_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_out_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_out_1_{}'.format(self.config.selection_id)] - self.df_res['long_out_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['short_ep2_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['short_ep2_1_{}'.format(self.config.selection_id)] - self.df_res['short_ep2_0_{}'.format(self.config.selection_id)])\n",
    "    self.df_res['long_ep2_gap_{}'.format(self.config.selection_id)] = abs(self.df_res['long_ep2_1_{}'.format(self.config.selection_id)] - self.df_res['long_ep2_0_{}'.format(self.config.selection_id)])\n",
    "\n",
    "    \n",
    "    # spread\n",
    "    self.df_res['short_spread_{}'.format(self.config.selection_id)] = (self.df_res['short_tp_0_{}'.format(self.config.selection_id)].to_numpy() / self.df_res['short_tp_1_{}'.format(self.config.selection_id)].to_numpy() - 1) / 2\n",
    "    self.df_res['long_spread_{}'.format(self.config.selection_id)] = (self.df_res['long_tp_1_{}'.format(self.config.selection_id)].to_numpy() / self.df_res['long_tp_0_{}'.format(self.config.selection_id)].to_numpy() - 1) / 2\n",
    "\n",
    "    \n",
    "    # # lvrg_needed is used in get_price v2.0\n",
    "    # if not pd.isnull(self.table_condition_row.lvrg_k):        \n",
    "    #     self.df_res['short_lvrg_needed_{}'.format(self.config.selection_id)] = (1 / self.df_res['short_spread_{}'.format(self.config.selection_id)]) * self.table_condition_row.lvrg_k\n",
    "    #     self.df_res['long_lvrg_needed_{}'.format(self.config.selection_id)] = (1 / self.df_res['long_spread_{}'.format(self.config.selection_id)]) * self.table_condition_row.lvrg_k\n",
    "\n",
    "    #     if not pd.isnull(self.table_condition_row.lvrg_ceiling):            \n",
    "    #         if self.table_condition_row.lvrg_ceiling:                \n",
    "    #             self.df_res['short_lvrg_needed_{}'.format(self.config.selection_id)][self.df_res['short_lvrg_needed_{}'.format(self.config.selection_id)] > self.table_condition_row.lvrg_max_short] = self.table_condition_row.lvrg_max_short\n",
    "    #             self.df_res['long_lvrg_needed_{}'.format(self.config.selection_id)][self.df_res['long_lvrg_needed_{}'.format(self.config.selection_id)] > self.table_condition_row.lvrg_max_long] = self.table_condition_row.lvrg_max_long\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c6b52-bff2-445c-9b77-c2f50e0e8cf1",
   "metadata": {},
   "source": [
    "##### set_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302a241-8884-44c9-a510-1ee2302c6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_price(self, close):    \n",
    "    \n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        use table_condition & messenger.\n",
    "\n",
    "    last confirmed at, 20240528 1422.\n",
    "    \"\"\"        \n",
    "    \n",
    "    # price_take_profit \n",
    "        # i. 기준 : balance_available_1, gap : balance_available_box\n",
    "    self.df_res['short_tp_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "    self.df_res['long_tp_{}'.format(self.config.selection_id)] = self.price_take_profit\n",
    "\n",
    "    \n",
    "    # price_entry\n",
    "        # limit\n",
    "    if self.config.ep_set.entry_type == \"LIMIT\": \n",
    "            # 1. 기준 : ep1_0, gap : ep1_box\n",
    "        self.df_res['short_ep1_{}'.format(self.config.selection_id)] = self.price_entry\n",
    "        self.df_res['long_ep1_{}'.format(self.config.selection_id)] = self.price_entry\n",
    "        \n",
    "        # market\n",
    "    else:\n",
    "        self.df_res['short_ep1_{}'.format(self.config.selection_id)] = close\n",
    "        self.df_res['long_ep1_{}'.format(self.config.selection_id)] = close    \n",
    "    \n",
    "    \n",
    "    # price_entry2\n",
    "        # limit\n",
    "    if self.config.ep_set.point2.entry_type == \"LIMIT\":\n",
    "            # 1. 기준 : ep2_0, gap : ep2_box\n",
    "        self.df_res['short_ep2_{}'.format(self.config.selection_id)] = self.df_res['short_ep2_1_{}'.format(self.config.selection_id)].to_numpy() + self.df_res['short_ep2_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.ep2_gap\n",
    "        self.df_res['long_ep2_{}'.format(self.config.selection_id)] = self.df_res['long_ep2_1_{}'.format(self.config.selection_id)].to_numpy() - self.df_res['long_ep2_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.ep2_gap        \n",
    "        \n",
    "        # market\n",
    "    else:\n",
    "        self.df_res['short_ep2_{}'.format(self.config.selection_id)] = close\n",
    "        self.df_res['long_ep2_{}'.format(self.config.selection_id)] = close\n",
    "\n",
    "    \n",
    "    # price_stop_loss\n",
    "    if self.config.tr_set.check_hlm == 0:\n",
    "        # ii. 기준 : out_0, gap : out_box\n",
    "        self.df_res['short_out_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "        self.df_res['long_out_{}'.format(self.config.selection_id)] = self.price_stop_loss\n",
    "\n",
    "    elif self.config.tr_set.check_hlm == 1:\n",
    "        self.df_res['short_out_{}'.format(self.config.selection_id)] = self.df_res['short_ep1_0_{}'.format(self.config.selection_id)].to_numpy() + self.df_res['short_ep1_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.out_gap  \n",
    "        self.df_res['long_out_{}'.format(self.config.selection_id)] = self.df_res['long_ep1_0_{}'.format(self.config.selection_id)].to_numpy() - self.df_res['long_ep1_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.out_gap  \n",
    "\n",
    "    else:  # p2_hlm\n",
    "        # ii. 기준 : ep2_0, gap : ep2_box\n",
    "        self.df_res['short_out_{}'.format(self.config.selection_id)] = self.df_res['short_ep2_1_{}'.format(self.config.selection_id)].to_numpy() + self.df_res['short_ep2_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.ep2_gap  # * 5\n",
    "        self.df_res['long_out_{}'.format(self.config.selection_id)] = self.df_res['long_ep2_1_{}'.format(self.config.selection_id)].to_numpy() - self.df_res['long_ep2_gap_{}'.format(self.config.selection_id)].to_numpy() * self.config.tr_set.ep2_gap  # * 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbaf99b-e72c-4870-b68d-60749c0befca",
   "metadata": {},
   "source": [
    "##### get_reward_risk_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fb551-2be0-4370-b843-13ef509d1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_reward_risk_ratio(self, unit_RRratio_adj_fee=np.arange(0, 2, 0.1)):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        modify to RRratio.\n",
    "            apply updated formula.\n",
    "        no more position_tp / ep1 / out _{}\n",
    "\n",
    "    last confirmed at, 20240610 1552.\n",
    "    \"\"\"\n",
    "\n",
    "    fee_entry = self.config.trader_set.fee_market # can be replaced later.\n",
    "    fee_exit = self.config.trader_set.fee_market\n",
    "    \n",
    "    self.df_res['RRratio'] = abs(self.price_take_profit - self.price_entry) / abs(self.price_entry - self.price_stop_loss)\n",
    "    self.df_res['RRratio_adj_fee'] = (abs(self.price_take_profit - self.price_entry) - (self.price_entry * fee_entry + self.price_take_profit * fee_exit)) / (abs(self.price_entry - self.price_stop_loss) + (self.price_entry * fee_entry + self.price_stop_loss * fee_exit))\n",
    "        \n",
    "    # unit_RRratio_adj_fee = np.arange(0, 1, 0.1)\n",
    "    self.df_res['RRratio_adj_fee_category'] = pd.cut(self.df_res['RRratio_adj_fee'], unit_RRratio_adj_fee, precision=0, duplicates='drop').astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0b5fb-04b5-4292-83c8-66db0eb99c6b",
   "metadata": {},
   "source": [
    "##### adj_price_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56c9d5-48b8-4ca1-bcaf-646a4c7cb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_price_unit(self):   \n",
    "    \n",
    "    calc_with_hoga_unit_vecto = np.vectorize(calc_with_precision)\n",
    "    self.df_res['short_tp_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['short_tp_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['long_tp_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['long_tp_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['short_ep1_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['short_ep1_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['long_ep1_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['long_ep1_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['short_ep2_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['short_ep2_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['long_ep2_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['long_ep2_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['short_out_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['short_out_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    self.df_res['long_out_{}'.format(self.config.selection_id)] = calc_with_hoga_unit_vecto(self.df_res['long_out_{}'.format(self.config.selection_id)].to_numpy(), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e250c616-d1a9-40bc-ba85-0aed05adb610",
   "metadata": {},
   "source": [
    "### InitTableTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a086888-34f7-4863-b952-05735acd29c0",
   "metadata": {},
   "source": [
    "#### get_side_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483398fe-4b81-4cbd-9e9b-a44be2a4a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side_info(self, side_open):\n",
    "    \n",
    "    if side_open == 'BUY':\n",
    "        side_close = 'SELL'\n",
    "        side_position = 'LONG'\n",
    "        # if self.config.pos_set.long_fake:\n",
    "        #     self.order_motion = 1\n",
    "    else:\n",
    "        side_close = 'BUY'\n",
    "        side_position = 'SHORT'\n",
    "        # if self.config.pos_set.short_fake:\n",
    "        #     self.order_motion = 1\n",
    "\n",
    "    return side_close, side_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953ae1f-3193-46ea-87e9-f43ec4958694",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.side_open = 'BUY'\n",
    "\n",
    "get_side_info(bank, \n",
    "              bank.side_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baffcd54-6def-4767-ba28-6b5cb4fbc54c",
   "metadata": {},
   "source": [
    "#### get_price_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eecf27-396d-4c95-b361-7775d5c72d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_entry(self,\n",
    "                    df_res,\n",
    "                    side_open,\n",
    "                    price_entry):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        validate if price_entry has been replaced with price_open.\n",
    "\n",
    "    last confirmed at, 20240710 0850.\n",
    "    \"\"\"\n",
    "    \n",
    "    price_open = df_res['open'].to_numpy()[-1]  # price_open uses latest_index.\n",
    "\n",
    "    if side_open == 'BUY':\n",
    "        price_entry = min(price_open, price_entry)\n",
    "    else:\n",
    "        price_entry = max(price_open, price_entry)\n",
    "\n",
    "    return price_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaff4a9-5bee-42d5-bd1f-7cf513a529db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.df_res = get_df_new(bank, \n",
    "                       interval='15m', \n",
    "                       days=1, \n",
    "                       limit=1500, \n",
    "                       timesleep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0008c-6158-4317-b11f-2cc3deec5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.df_res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a182640-cf03-4704-9125-16ed25d5c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.price_entry = 1.0522\n",
    "\n",
    "price_entry = get_price_entry(bank,\n",
    "                              bank.df_res,\n",
    "                              bank.side_open,\n",
    "                              bank.price_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306c2e9-8f52-4fb4-bc5d-e06f7f734319",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bbe1d-9b4f-4f05-9877-5a6f77a465da",
   "metadata": {},
   "source": [
    "#### get_balance_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6472053-425d-479c-aafe-01720a193dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance_available(self, \n",
    "                          asset_type='USDT'):\n",
    "    \n",
    "    try:      \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.balance(recvWindow=6000, timestamp=server_time)\n",
    "\n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = \"error in get_balance() : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "    else:\n",
    "        available_asset = float([res['availableBalance'] for res in response['data'] if res['asset'] == asset_type][0])\n",
    "        balance_available = self.calc_with_precision(available_asset, 2) # default for Binance\n",
    "\n",
    "        return balance_available\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f5b88-446c-4fad-8ebb-10bfb60d386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_balance_available(bank, \n",
    "                    asset_type='USDT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4e487-ceed-4041-85df-a5b8e8ced8ae",
   "metadata": {},
   "source": [
    "#### get_margin_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26730ca5-afde-441c-9dfd-d42d6268e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_margin_consistency(self, \n",
    "                         margin,\n",
    "                         account,\n",
    "                         # balance_account,\n",
    "                         # balance_min, \n",
    "                         mode=\"PROD\"):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        derived after get_balance_info v2.0\n",
    "        modify to vivid mode.\n",
    "            compare margin & TableAccount.\n",
    "            Class mode remain, cause we are using core (public) object.\n",
    "                like sys_log, tables, etc...\n",
    "\n",
    "    last confirmed at, 20240701 0829.\n",
    "    \"\"\"\n",
    "\n",
    "    # init.\n",
    "    consistency = True\n",
    "\n",
    "    # update self.table_account.balance_insufficient\n",
    "    self.table_account.balance_insufficient = self.table_account.balance < self.table_account.balance_min  \n",
    "    self.sys_log.debug(\"self.table_account : \\n{}\".format(self.table_account))  \n",
    "\n",
    "    # get balance_available\n",
    "    # check balance_available.\n",
    "    balance_account_total = self.table_account.balance.sum()\n",
    "    balance_available = get_balance_available(self)\n",
    "    self.sys_log.info('balance_account_total : {:.2f}'.format(balance_account_total))\n",
    "    self.sys_log.info('balance_available : {:.2f}'.format(balance_available))\n",
    "    \n",
    "    # reject balance_account_total over.\n",
    "    if balance_available <= balance_account_total:\n",
    "        self.sys_log.warning(\"over balance : balance_available {:.2f} <= balance_account_total {:.2f}\".format(balance_available, balance_account_total))\n",
    "        consistency = False\n",
    "\n",
    "    \n",
    "    # get a row by account.\n",
    "    table_account_row = self.table_account[self.table_account['account'] == account]\n",
    "    self.sys_log.debug(\"table_account_row : \\n{}\".format(table_account_row))\n",
    "\n",
    "    if not table_account_row.empty:    \n",
    "        # check min balance.\n",
    "        if table_account_row.balance_insufficient.values[0]:\n",
    "            self.sys_log.warning(\"table_account_row.balance_insufficient = True.\")\n",
    "            consistency = False\n",
    "        \n",
    "        # check balance < asset. \n",
    "        if table_account_row.balance.values[0] < margin:\n",
    "            self.sys_log.warning(\"table_account_row.balance < margin {:.2f}\".format(margin))\n",
    "            consistency = False\n",
    "    else:\n",
    "        self.sys_log.warning(\"table_account_row is empty.\")\n",
    "        consistency = False\n",
    "\n",
    "    if consistency:        \n",
    "        self.table_account.loc[self.table_account['account'] == account, 'balance'] -= margin   \n",
    "\n",
    "    return consistency\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c0cff-0b0f-4edb-8c55-14f5316dcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.table_account = pd.read_excel(\"./data\\table\\table_account.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867bcae-4685-4884-b69b-1d47cab84281",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 15\n",
    "account = 'A'\n",
    "\n",
    "get_margin_consistency(bank, \n",
    "                         margin,\n",
    "                         account,\n",
    "                         mode=\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea482e68-669e-40a9-a1fd-e12f50e550d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.table_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e82b5a-9cab-4556-9486-2aef2910497b",
   "metadata": {},
   "source": [
    "#### get_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51701be8-c486-49f5-912b-bf0cca934074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_precision(self, \n",
    "                  symbol):\n",
    "    \n",
    "    try:        \n",
    "        response = self.exchange_info()\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = \"error in get_precision : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "\n",
    "        # time.sleep(self.config.trader_set.api_term)\n",
    "    else:\n",
    "        precision_price, precision_quantity = [[data['pricePrecision'], data['quantityPrecision']] \n",
    "                                                         for data in response['data']['symbols'] if data['symbol'] == symbol][0]\n",
    "\n",
    "        return precision_price, precision_quantity\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb202d5-abb3-4904-8e98-298c53e536d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_precision(bank, \n",
    "              bank.symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedb077-d270-4d30-886c-15ff7ed20b91",
   "metadata": {},
   "source": [
    "#### get_leverage_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0197f90-9a93-485e-aaf9-01dac606ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leverage_limit(self, \n",
    "                       symbol, \n",
    "                       price_entry, \n",
    "                       price_stop_loss,\n",
    "                       fee_entry, \n",
    "                       fee_exit):\n",
    "    \n",
    "    # leverage_limit (server)\n",
    "    server_time = self.time()['data']['serverTime']\n",
    "    response = self.leverage_brackets(symbol=symbol, recvWindow=6000, timestamp=server_time)\n",
    "    \n",
    "    tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "    self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "\n",
    "    \n",
    "    leverage_limit_server = response['data'][0]['brackets'][0]['initialLeverage']    \n",
    "    \n",
    "    loss = abs(price_entry - price_stop_loss) + (price_entry * fee_entry + price_stop_loss * fee_exit)\n",
    "    loss_pct = loss / price_entry * 100\n",
    "    leverage_limit_user = np.maximum(1, np.floor(100 / loss_pct).astype(int))\n",
    "\n",
    "    leverage_limit = min(leverage_limit_user, leverage_limit_server)\n",
    "\n",
    "    return loss, leverage_limit_user, leverage_limit_server, leverage_limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c31817-3fd4-44cb-88cc-9ed786ea9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.price_entry = 0.3\n",
    "bank.price_stop_loss = 0.4\n",
    "\n",
    "get_leverage_limit(bank, \n",
    "                     bank.symbol, \n",
    "                     bank.price_entry, \n",
    "                     bank.price_stop_loss, \n",
    "                     bank.config.trader_set.fee_market, \n",
    "                     bank.config.trader_set.fee_market)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ec324-00d2-4879-8a20-51e253fea21a",
   "metadata": {},
   "source": [
    "#### get_leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfc28e-517e-4595-83fd-7449883471de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leverage(self, mode_round='floor'):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0 --> v2_1\n",
    "        math.ceil self.leverage.\n",
    "    v2_1 --> v2_2\n",
    "        target_pct pointed at self.price_take_profit. (origin --> self.price_stop_loss)\n",
    "        adj. get_pr_v8\n",
    "    v3.0\n",
    "        Class mode\n",
    "            add self,\n",
    "                temporarily not removing origin parameter.\n",
    "                \n",
    "            replace balance_available_ with self.price_stop_loss.\n",
    "    v3.1\n",
    "        calibrate target_pct.\n",
    "        add checking pd.isnull(self.leverage) for messenger mode.\n",
    "\n",
    "    last confirmed at, 20240528 1539.\n",
    "    \"\"\"\n",
    "    \n",
    "    # init.\n",
    "    price_fluc = None\n",
    "    fee_sum = self.config.trader_set.fee_market + self.config.trader_set.fee_market # conservative.\n",
    "    if pd.isnull(self.leverage):\n",
    "        self.leverage = self.config.lvrg_set.leverage\n",
    "    \n",
    "    # calculate leverage.\n",
    "        # target_pct is based on price_take_profit.\n",
    "    if not pd.isnull(self.price_take_profit):\n",
    "        if not self.config.lvrg_set.static_lvrg_short:\n",
    "            if self.side_open == 'SELL':\n",
    "                price_fluc = self.price_entry / (self.price_take_profit - (self.price_take_profit + self.price_entry) * fee_sum)\n",
    "\n",
    "        if not self.config.lvrg_set.static_lvrg_long:\n",
    "            if self.side_open == 'BUY':\n",
    "                price_fluc = (self.price_take_profit - (self.price_take_profit + self.price_entry) * fee_sum) / self.price_entry\n",
    "\n",
    "        if price_fluc is not None:\n",
    "            self.leverage = self.config.lvrg_set.target_pct / abs(price_fluc - 1)\n",
    "\n",
    "    # make as an integer.\n",
    "    if not self.config.lvrg_set.allow_float:\n",
    "        if mode_round == 'floor':            \n",
    "            self.leverage = math.floor(self.leverage)\n",
    "        else:\n",
    "            self.leverage = math.ceil(self.leverage)\n",
    "    \n",
    "    # leverage rejection.\n",
    "        # if calculated leverage is smaller than 1, consider rejection.\n",
    "    if self.config.lvrg_set.lvrg_rejection:\n",
    "        if self.leverage < 1:\n",
    "            self.leverage = None\n",
    "\n",
    "    # limit leverage\n",
    "    self.leverage = min(self.leverage_limit, max(self.leverage, 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989727ee-9503-4d44-91c9-24ffea89d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.price_expiration = get_price_expiration(bank.df_res, \n",
    "                                             bank.side_open, \n",
    "                                             bank.config.selection_id, \n",
    "                                             bank.config.trader_set.complete_index, \n",
    "                                             bank.config.tr_set.expire_k1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cf9ae-588e-4cd7-88e4-f11fbe395e82",
   "metadata": {},
   "source": [
    "#### get_price_expiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff463f-8877-47e6-bd4d-f9563ae91399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_price_expiration(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0 --> v3.0\n",
    "        self.expired variable added.\n",
    "    v4\n",
    "        Class mode.\n",
    "            rename function to get_price_expiration.\n",
    "\n",
    "    last confirmed at, 20240428 1904.\n",
    "    \"\"\"\n",
    "\n",
    "    # if self.config.tr_set.expire_tick != \"None\":\n",
    "    #     if time.time() - datetime.timestamp(self.df_res.index[self.config.trader_set.latest_index]) >= self.config.tr_set.expire_tick * 60:\n",
    "    #         self.expired = 1    \n",
    "        \n",
    "    if self.side_open == OrderSide.SELL:\n",
    "        short_tp_ = self.df_res['short_tp_{}'.format(self.config.selection_id)].to_numpy()\n",
    "        short_tp_gap_ = self.df_res['short_tp_gap_{}'.format(self.config.selection_id)].to_numpy()        \n",
    "        self.price_expiration = short_tp_[self.config.trader_set.complete_index] + short_tp_gap_[self.config.trader_set.complete_index] * self.config.tr_set.expire_k1    \n",
    "    else:\n",
    "        long_tp_ = self.df_res['long_tp_{}'.format(self.config.selection_id)].to_numpy()  # iloc 5.34 ms, to_numpy() 3.94 ms\n",
    "        long_tp_gap_ = self.df_res['long_tp_gap_{}'.format(self.config.selection_id)].to_numpy()        \n",
    "        self.price_expiration = long_tp_[self.config.trader_set.complete_index] - long_tp_gap_[self.config.trader_set.complete_index] * self.config.tr_set.expire_k1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fa46c-74ab-49e1-b552-e697e6de7580",
   "metadata": {},
   "source": [
    "#### get_price_liquidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a09bd-8f18-4628-8a32-1bbc061673e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_liquidation(side_open, price_entry, fee_limit, fee_market, leverage):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        consider vivide input & output.\n",
    "\n",
    "    last confirmed at, 20240613 1223. \n",
    "    \"\"\"\n",
    "    \n",
    "    if side_open == 'SELL':\n",
    "        price_liquidation = price_entry / (1 + fee_limit + fee_market - 1 / leverage)\n",
    "    else:\n",
    "        price_liquidation = price_entry * (1 + fee_limit + fee_market - 1 / leverage)\n",
    "\n",
    "    return price_liquidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd79323-655c-46e2-a630-c60bfed88140",
   "metadata": {},
   "source": [
    "#### set_leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16da95-c6f0-4d22-8f9f-a646dd17047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_leverage(self,\n",
    "                 symbol,\n",
    "                 leverage):\n",
    "\n",
    "    try:        \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.change_leverage(symbol=symbol, \n",
    "                             leverage=leverage, \n",
    "                             recvWindow=6000, \n",
    "                             timestamp=server_time)        \n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = \"error in change_initial_leverage : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "    else:\n",
    "        self.sys_log.info('leverage changed to {}'.format(leverage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933535d9-85dc-413e-88d9-6e99401e5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.leverage = 1\n",
    "\n",
    "set_leverage(bank,\n",
    "                 bank.symbol,\n",
    "                 bank.leverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af8d5a-5edd-4909-85a3-9d1b5cba552f",
   "metadata": {},
   "source": [
    "#### set_position_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5603e0d-0552-4189-bd66-0664bfc86a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_position_mode(self, \n",
    "                      dualSidePosition='true'):    \n",
    "\n",
    "    try:\n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.change_position_mode(dualSidePosition=dualSidePosition,\n",
    "                                  recvWindow=2000,\n",
    "                                  timestamp=server_time)\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "    except Exception as e:\n",
    "        if '-4059' in str(e): # 'No need to change position side.'\n",
    "            return\n",
    "        msg = \"error in set_position_mode : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "    else:\n",
    "        self.sys_log.info(\"dualSidePosition is true.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c23310-1601-4f2c-bd95-f17055c14533",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_position_mode(bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e31c6-c4a8-419c-9a55-ed3d76504efa",
   "metadata": {},
   "source": [
    "#### set_margin_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a39355-52f2-4e4a-91b3-196f7aaf54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_margin_type(self, \n",
    "                symbol,\n",
    "                marginType='CROSSED'): # CROSSED / ISOLATED\n",
    "\n",
    "    # margin type => \"cross or isolated\"\n",
    "    try:            \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.change_margin_type(symbol=symbol, \n",
    "                                marginType=marginType, \n",
    "                                recvWindow=6000, \n",
    "                                timestamp=server_time)\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "            \n",
    "    except Exception as e:\n",
    "        if '-4046' in str(e): # 'No need to change margin type.'\n",
    "            return\n",
    "        msg = \"error in set_margin_type : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "    else:\n",
    "        self.sys_log.info(\"margin type is {} now.\".format(marginType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73602e6-9e21-45ed-9314-c99f8dbb5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_margin_type(bank, \n",
    "                bank.symbol,\n",
    "                marginType='CROSSED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d252d-71b7-4840-90ac-df784c7324d5",
   "metadata": {},
   "source": [
    "### LoopTableTrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91ec52-fd76-4f8c-a4b2-1a985adf4d4d",
   "metadata": {},
   "source": [
    "#### get_order_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a795f55-bf7d-4399-b40f-63d650aa9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_info(self, \n",
    "                   symbol,\n",
    "                   orderId):\n",
    " \n",
    "    try:                \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.query_order(symbol=symbol, \n",
    "                                      orderId=orderId, \n",
    "                                      recvWindow=2000, \n",
    "                                      timestamp=server_time)\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "        return response['data']\n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = f\"error in get_order_info : {e}, tokens : {self.token_bucket.tokens}\"\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa53c56-1466-43ae-95c7-e639194501c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.orderId = '12489258743'\n",
    "\n",
    "order_info = get_order_info(bank, \n",
    "                           bank.symbol,\n",
    "                           bank.orderId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de03dbe-066b-4c67-bbf7-c470acfc308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f96dedf-2a33-4a3d-9e49-bab7d4d7dab7",
   "metadata": {},
   "source": [
    "#### get_price_realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c6497-2c19-45ba-bb71-c4171f0fe837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_price_realtime(self, symbol):\n",
    "    \n",
    "    \"\"\"\n",
    "    access to self.price_market by symbol.\n",
    "        we don't need token for it.        \n",
    "    \"\"\"\n",
    "        \n",
    "    try:\n",
    "        price_realtime =  self.price_market[symbol]\n",
    "    except Exception as e:\n",
    "        price_realtime = np.nan   \n",
    "        \n",
    "        if symbol not in self.price_market.keys():\n",
    "            self.websocket_client.agg_trade(symbol=symbol, id=1, callback=self.agg_trade_message_handler)\n",
    "            msg = \"error in get_price_realtime : {} added to websocket_client.agg_trade\".format(symbol)\n",
    "        else:                \n",
    "            msg = \"error in get_price_realtime : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "    \n",
    "    return price_realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e2290-08fc-4dbc-829f-77c1188b0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "\n",
    "price_realtime = get_price_realtime(bank, \n",
    "                                   bank.symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c603905-2b82-4e2f-9c85-089385c5813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(price_realtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d270632-59a4-40cd-9d3e-4cf281148c16",
   "metadata": {},
   "source": [
    "#### check_order_expiration_onbarclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbc14f-5974-4ac5-ae7f-075210296d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_order_expiration_onbarclose(self,):  # for point2\n",
    "\n",
    "    \"\"\"\n",
    "    v4.0\n",
    "        Class mode\n",
    "    \n",
    "    last confirmed at, 20240418 2459.\n",
    "    \"\"\"\n",
    "\n",
    "    selection_id = self.config.selection_id\n",
    "\n",
    "    if self.config.tr_set.expire_tick != \"None\":\n",
    "        if datetime.timestamp(self.df_res.index[-1]) - datetime.timestamp(self.df_res.index[self.config.trader_set.latest_index]) \\\n",
    "                >= self.config.tr_set.expire_tick * 60:\n",
    "            self.expired = 1\n",
    "\n",
    "    if self.config.tr_set.expire_k1 != \"None\":  # Todo - onbarclose 에서는, self.df_res 으로 open_index 의 self.price_take_profit 정보를 사용\n",
    "        if self.side_open == OrderSide.SELL:\n",
    "            low = self.df_res['low'].to_numpy()\n",
    "            short_tp_ = self.df_res['short_tp_{}'.format(selection_id)].to_numpy()  # id 에 따라 dynamic 변수라 이곳에서 numpy 화 진행\n",
    "            short_tp_gap_ = self.df_res['short_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if low[self.config.trader_set.complete_index] <= short_tp_[self.config.trader_set.complete_index] + short_tp_gap_[self.config.trader_set.complete_index] * self.config.tr_set.expire_k1:\n",
    "                self.expired = 1\n",
    "        else:\n",
    "            high = self.df_res['high'].to_numpy()\n",
    "            long_tp_ = self.df_res['long_tp_{}'.format(selection_id)].to_numpy()  # iloc 이 빠를까, to_numpy() 가 빠를까  # 3.94 ms --> 5.34 ms (iloc)\n",
    "            long_tp_gap_ = self.df_res['long_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if high[self.config.trader_set.complete_index] >= long_tp_[self.config.trader_set.complete_index] - long_tp_gap_[self.config.trader_set.complete_index] * self.config.tr_set.expire_k1:\n",
    "                self.expired = 1\n",
    "\n",
    "    # if self.expired:\n",
    "    #     self.sys_log.warning(\"cancel order_open by ei_k\\n\")\n",
    "\n",
    "    # return self.expired\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c44f43-ab55-4643-8f2b-dee52c3eea7a",
   "metadata": {},
   "source": [
    "#### check_expiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34294924-dcf9-4a09-9a80-70426b7ce8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_expiration(side_position,\n",
    "                    price_realtime, \n",
    "                    price_expiration):    \n",
    "    \"\"\"\n",
    "    Checks if the position has expired based on the real-time price and the expiration price.\n",
    "\n",
    "    Parameters:\n",
    "    - price_realtime: float, the current real-time price.\n",
    "    - price_expiration: float, the price at which the position expires.\n",
    "    - side_position: str, the position side, either 'SHORT' or 'LONG'.\n",
    "\n",
    "    Returns:\n",
    "    - expired: int, 1 if the position has expired, 0 otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    expired = 0\n",
    "    if side_position == 'SHORT':\n",
    "        if price_realtime <= price_expiration:\n",
    "            expired = 1\n",
    "    else:  # side_position == 'LONG'\n",
    "        if price_realtime >= price_expiration:\n",
    "            expired = 1\n",
    "    return expired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe07c0e-f11b-43af-99f2-0de778904973",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_position = 'LONG'\n",
    "price_realtime = 1\n",
    "price_expiration = 2\n",
    "\n",
    "check_expiration(side_position, \n",
    "                 price_realtime, \n",
    "                 price_expiration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3962aa-6e36-49f1-9fe2-611cceb4d685",
   "metadata": {},
   "source": [
    "#### check_stop_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655907d-fe09-4e41-9582-93b1c247ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_stop_loss(self,\n",
    "                    side_open,\n",
    "                    price_realtime,\n",
    "                    price_liquidation,\n",
    "                    price_stop_loss):\n",
    "\n",
    "    order_market_on = False\n",
    "            \n",
    "    if side_open == 'SELL':\n",
    "        if price_realtime >= price_stop_loss:\n",
    "            order_market_on = True\n",
    "            self.sys_log.info(\"price_realtime {} >= price_stop_loss {}\".format(price_realtime, price_stop_loss))\n",
    "    else:\n",
    "        if price_realtime <= price_stop_loss:\n",
    "            order_market_on = True\n",
    "            self.sys_log.info(\"price_realtime {} <= price_stop_loss {}\".format(price_realtime, price_stop_loss))\n",
    "\n",
    "    self.sys_log.info(\"order_market_on : {}\".format(order_market_on))\n",
    "\n",
    "    return order_market_on\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb588e6e-3249-44cc-bada-eee1d110bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.side_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf418ea-4aa8-47c2-a5fa-2e3a3083b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.price_realtime = 7\n",
    "bank.price_liquidation = 8\n",
    "bank.price_stop_loss = 9\n",
    "\n",
    "\n",
    "bank.order_market_on = check_stop_loss(bank,\n",
    "                bank.side_open,\n",
    "                bank.price_realtime,\n",
    "                bank.price_liquidation,\n",
    "                bank.price_stop_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1478763-79f9-40f0-b682-4f77dc1d804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.order_market_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c82074-43f6-4f76-bf8e-1da374476867",
   "metadata": {},
   "source": [
    "#### check_stop_loss_onbarclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8b812-23b3-4edc-a33d-94beec5d77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_stop_loss_onbarclose(self,):\n",
    "\n",
    "    \"\"\"\n",
    "    v1 --> v2.0\n",
    "        1. add liquidation platform.\n",
    "        2. add self.log_out\n",
    "        3. add non_out\n",
    "    \"\"\"\n",
    "\n",
    "    self.log_out = None\n",
    "\n",
    "    high = self.df_res['high'].to_numpy()[self.config.trader_set.complete_index]\n",
    "    low = self.df_res['low'].to_numpy()[self.config.trader_set.complete_index]\n",
    "    close = self.df_res['close'].to_numpy()[self.config.trader_set.complete_index]\n",
    "\n",
    "    # ------ 1. liquidation default check ------ #\n",
    "    if self.side_open == OrderSide.SELL:\n",
    "        const_str = \"high >= self.price_liquidation\"\n",
    "        if eval(const_str):\n",
    "            self.order_market_on = True\n",
    "            self.log_out = self.price_liquidation\n",
    "            self.sys_log.info(\"{} : {} {}\".format(const_str, high, self.price_liquidation))\n",
    "    else:\n",
    "        const_str = \"low <= self.price_liquidation\"\n",
    "        if eval(const_str):\n",
    "            self.order_market_on = True\n",
    "            self.log_out = self.price_liquidation\n",
    "            self.sys_log.info(\"{} : {} {}\".format(const_str, low, self.price_liquidation))\n",
    "\n",
    "    if not self.config.out_set.non_out:\n",
    "\n",
    "        # ------ 2. hl_out ------ #\n",
    "        if self.config.out_set.hl_out:\n",
    "            if self.side_open == OrderSide.SELL:\n",
    "                const_str = \"high >= self.price_stop_loss\"\n",
    "                if eval(const_str):\n",
    "                    self.order_market_on = True\n",
    "                    self.log_out = self.price_stop_loss\n",
    "                    self.sys_log.info(\"{} : {} {}\".format(const_str, high, self.price_stop_loss))\n",
    "            else:\n",
    "                const_str = \"low <= self.price_stop_loss\"\n",
    "                if eval(const_str):\n",
    "                    self.order_market_on = True\n",
    "                    self.log_out = self.price_stop_loss\n",
    "                    self.sys_log.info(\"{} : {} {}\".format(const_str, low, self.price_stop_loss))\n",
    "\n",
    "        # ------ 3. close_out ------ #\n",
    "        else:\n",
    "            if self.side_open == OrderSide.SELL:\n",
    "                if close >= self.price_stop_loss:\n",
    "                    self.order_market_on = True\n",
    "                    self.log_out = close\n",
    "                    self.sys_log.info(\"{} : {} {}\".format(\"close >= self.price_stop_loss\", self.log_out, self.price_stop_loss))\n",
    "            else:\n",
    "                if close <= self.price_stop_loss:\n",
    "                    self.order_market_on = True\n",
    "                    self.log_out = close\n",
    "                    self.sys_log.info(\"{} : {} {}\".format(\"close <= self.price_stop_loss\", self.log_out, self.price_stop_loss))\n",
    "\n",
    "    # return self.order_market_on, self.log_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a3008-7ac5-41b5-a7de-1bf526883d40",
   "metadata": {},
   "source": [
    "#### check_stop_loss_by_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bababe2-daa4-4766-9230-161e126e7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_stop_loss_by_signal(self, ):\n",
    "\n",
    "    \"\"\"\n",
    "    v3 --> v4.0\n",
    "        1. add fisher_exit.\n",
    "        2. add self.np_timeidx\n",
    "    \"\"\"\n",
    "\n",
    "    self.log_out = None\n",
    "\n",
    "    close = self.df_res['close'].to_numpy()[self.config.trader_set.complete_index]\n",
    "\n",
    "    # 1. timestamp\n",
    "    # if self.config.out_set.tf_exit != \"None\":\n",
    "    #     if self.np_timeidx[i] % self.config.out_set.tf_exit == self.config.out_set.tf_exit - 1 and i != open_i:\n",
    "    #         self.order_market_on = True\n",
    "\n",
    "    # 2. fisher\n",
    "    # if self.config.out_set.fisher_exit:\n",
    "\n",
    "    #     itv_num = itv_to_number(self.table_condition_row.tf_entry)\n",
    "\n",
    "    #     if self.np_timeidx[self.config.trader_set.complete_index] % itv_num == itv_num - 1:\n",
    "\n",
    "    #         fisher_ = self.df_res['fisher_{}30'.format(self.table_condition_row.tf_entry)].to_numpy()\n",
    "    #         fisher_band = self.config.out_set.fisher_band\n",
    "    #         fisher_band2 = self.config.out_set.fisher_band2\n",
    "\n",
    "    #         if self.side_open == OrderSide.SELL:\n",
    "    #             if (fisher_[self.config.trader_set.complete_index - itv_num] > -fisher_band) & (fisher_[self.config.trader_set.complete_index] <= -fisher_band):\n",
    "    #                 self.order_market_on = True\n",
    "    #             elif (fisher_[self.config.trader_set.complete_index - itv_num] < fisher_band2) & (fisher_[self.config.trader_set.complete_index] >= fisher_band2):\n",
    "    #                 self.order_market_on = True\n",
    "    #         else:\n",
    "    #             if (fisher_[self.config.trader_set.complete_index - itv_num] < fisher_band) & (fisher_[self.config.trader_set.complete_index] >= fisher_band):\n",
    "    #                 self.order_market_on = True\n",
    "    #             elif (fisher_[self.config.trader_set.complete_index - itv_num] > fisher_band2) & (fisher_[self.config.trader_set.complete_index] <= fisher_band2):\n",
    "    #                 self.order_market_on = True\n",
    "\n",
    "    # 3. rsi_exit\n",
    "    if self.config.out_set.rsi_exit:\n",
    "        rsi_ = self.df_res['rsi_%s' % self.config.loc_set.point.exp_itv].to_numpy()\n",
    "        osc_band = self.config.loc_set.point.osc_band\n",
    "\n",
    "        if self.side_open == OrderSide.SELL:\n",
    "            if (rsi_[self.config.trader_set.complete_index - 1] >= 50 - osc_band) & (rsi_[self.config.trader_set.complete_index] < 50 - osc_band):\n",
    "                self.order_market_on = True\n",
    "        else:\n",
    "            if (rsi_[self.config.trader_set.complete_index - 1] <= 50 + osc_band) & (rsi_[self.config.trader_set.complete_index] > 50 + osc_band):\n",
    "                self.order_market_on = True\n",
    "\n",
    "    # 4. cci_exit\n",
    "    #           a. deprecated.\n",
    "    # if self.config.out_set.cci_exit:\n",
    "    #     wave_itv1 = self.config.tr_set.wave_itv1\n",
    "    #     wave_period1 = self.config.tr_set.wave_period1\n",
    "    #\n",
    "    #     if self.side_open == OrderSide.SELL:\n",
    "    #         wave_co_ = self.df_res['wave_co_{}{}'.format(wave_itv1, wave_period1)].to_numpy()[self.config.trader_set.complete_index]\n",
    "    #         if wave_co_:\n",
    "    #             self.order_market_on = True\n",
    "    #     else:\n",
    "    #         wave_cu_ = self.df_res['wave_cu_{}{}'.format(wave_itv1, wave_period1)].to_numpy()[self.config.trader_set.complete_index]\n",
    "    #         if wave_cu_:\n",
    "    #             self.order_market_on = True\n",
    "\n",
    "    # if self.order_market_on:\n",
    "    #     self.log_out = close\n",
    "    #     self.sys_log.info(\"signal self.price_stop_loss : {}\".format(self.log_out))\n",
    "\n",
    "    # return self.order_market_on, self.log_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70212aae-a522-4197-a9f3-5fcae45b7c2d",
   "metadata": {},
   "source": [
    "#### get_price_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f932b9f-8fab-4170-a2ea-65edb5e920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_replacement(self, order_info_old, idx):\n",
    "\n",
    "    \"\"\"\n",
    "    v2.0\n",
    "        modify to vivid in-out\n",
    "\n",
    "    last confirmed at, 20240617 1507.\n",
    "    \"\"\"\n",
    "\n",
    "    self.price_replacement = 0\n",
    "\n",
    "    # price_TP / SL replacement version.\n",
    "    # self.df_res = pd.read_feather(order_info_old.path_df_res)\n",
    "    self.df_res = pd.read_feather(\"{}\\\\{}.ftr\".format(self.path_dir_df_res, self.symbol)) # temporary.\n",
    "    \n",
    "    # temporarily, modify side_open for getting updated stop_loss.\n",
    "    self.side_open = order_info_old.side_close\n",
    "    # self.get_price(self)\n",
    "    \n",
    "    self.price_entry, \\\n",
    "    self.price_stop_loss, \\\n",
    "    self.price_take_profit = self.get_price(self, \n",
    "                                          self.side_open, \n",
    "                                          self.df_res)\n",
    "    self.table_trade.at[idx, 'price_stop_loss'] = self.price_take_profit\n",
    "    \n",
    "    if self.side_open == 'BUY':        \n",
    "        if self.price_stop_loss < order_info_old.price_stop_loss:\n",
    "            self.price_replacement = 1\n",
    "    else:\n",
    "        if self.price_stop_loss > order_info_old.price_stop_loss: \n",
    "            self.price_replacement = 1\n",
    "\n",
    "    # return it.\n",
    "    self.side_open = order_info_old.side_open\n",
    "    # self.get_price(self)\n",
    "    \n",
    "    self.price_entry, \\\n",
    "    self.price_stop_loss, \\\n",
    "    self.price_take_profit = self.get_price(self, \n",
    "                                          self.side_open, \n",
    "                                          self.df_res)\n",
    "    self.table_trade.at[idx, 'price_take_profit'] = self.price_take_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de9760-ee50-4bba-86a6-999bc18eaa9f",
   "metadata": {},
   "source": [
    "#### order_cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b50a56-325c-48c5-b19c-7359a122a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_cancel(self, \n",
    "                symbol,\n",
    "                orderId):    \n",
    "    try:     \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.cancel_order(symbol=symbol, \n",
    "                              orderId=orderId, \n",
    "                              timestamp=server_time)\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "        \n",
    "    except Exception as e:        \n",
    "        msg = \"error in order_cancel : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        self.push_msg(msg)\n",
    "    else:\n",
    "        self.sys_log.info(\"{} {} canceled.\".format(symbol, orderId))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7323db27-6e03-4ac4-8bc2-5a2e9d08fa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Bank] error in order_cancel : (400, -2011, 'Unknown order sent.', {'Content-Type': 'application/json', 'Content-Length': '42', 'Connection': 'keep-alive', 'Date': 'Thu, 11 Jul 2024 00:05:46 GMT', 'Server': 'Tengine', 'x-mbx-used-weight-1m': '749', 'x-response-time': '5ms', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS', 'X-Cache': 'Error from cloudfront', 'Via': '1.1 cd1475e8dfc127af2db8d7d52ea9ef40.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'ICN54-C2', 'X-Amz-Cf-Id': 't1ecqyNJUuqBmqGzmuXuU9-Z_8nQW3OFUaX5FxjimWm_ztItSFdm9w=='})\n"
     ]
    }
   ],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.orderId = 12534875366\n",
    "\n",
    "order_cancel(bank, \n",
    "            bank.symbol,\n",
    "            bank.orderId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d474afe-1402-412e-be31-1e321089b2eb",
   "metadata": {},
   "source": [
    "#### get_quantity_unexecuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5738f-0ef0-4c8a-bb22-0648b050a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quantity_unexecuted(self, \n",
    "                            symbol,\n",
    "                            orderId):\n",
    "\n",
    "    \"\"\"    \n",
    "    use order_cancel + get_precision.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    order_cancel(self, \n",
    "                symbol,\n",
    "                orderId)\n",
    "    \n",
    "    self.order_info = get_order_info(self, \n",
    "                                    symbol,\n",
    "                                    orderId)\n",
    "        \n",
    "    quantity_unexecuted = abs(float(self.order_info['origQty'])) - abs(float(self.order_info['executedQty']))\n",
    "    \n",
    "        # get price, volume updated precision\n",
    "    precision_price, \\\n",
    "    precision_quantity = get_precision(self, \n",
    "                                            symbol)\n",
    "    self.sys_log.info('precision_quantity : {}'.format(precision_quantity))\n",
    "    \n",
    "    quantity_unexecuted = self.calc_with_precision(quantity_unexecuted, precision_quantity)\n",
    "    self.sys_log.info('quantity_unexecuted : {}'.format(quantity_unexecuted))\n",
    "    self.sys_log.info('quantity_unexecuted (adj. precision) : {}'.format(quantity_unexecuted))\n",
    "\n",
    "    return quantity_unexecuted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3c6b4-4ed3-49ba-8cf5-3a11fe3d30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.orderId = 12489258743\n",
    "\n",
    "# order_cancel(bank, \n",
    "#             bank.symbol,\n",
    "#             bank.orderId)\n",
    "quantity_unexecuted = get_quantity_unexecuted(bank, \n",
    "                                        bank.symbol,\n",
    "                                        bank.orderId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9675c3b-5e89-4e4f-b6e6-f2a6a7074f1f",
   "metadata": {},
   "source": [
    "#### order_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a771dad-2f75-43f3-81a2-06d634fc0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_limit(self, \n",
    "                symbol,\n",
    "                side_order, \n",
    "                side_position, \n",
    "                price, \n",
    "                quantity):\n",
    "        \n",
    "    # init.  \n",
    "    order_result = None\n",
    "    error_code = 0\n",
    "    \n",
    "    try:     \n",
    "        server_time = self.time()['data']['serverTime']\n",
    "        response = self.new_order(timeInForce=TimeInForce.GTC,\n",
    "                                        symbol=symbol,\n",
    "                                        side=side_order,\n",
    "                                        positionSide=side_position,\n",
    "                                        type=OrderType.LIMIT,\n",
    "                                        quantity=str(quantity),\n",
    "                                        price=str(price),\n",
    "                                        timestamp=server_time)\n",
    "        \n",
    "        tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "        self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "\n",
    "        order_result = response['data']        \n",
    "        self.sys_log.info(\"order_limit succeed. order_result : {}\".format(order_result))\n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = \"error in order_limit : {}\".format(e)\n",
    "        self.sys_log.error(msg)\n",
    "        # self.push_msg(msg)\n",
    "\n",
    "        # error casing. (later)\n",
    "\n",
    "        # 1. order_limit() 에서 해결할 수 없는 error 일 경우, return\n",
    "        #       a. -4003 : quantity less than zero\n",
    "        # if \"-4003\" in str(e):\n",
    "        #     error_code = -4003\n",
    "        error_code = -4003\n",
    "\n",
    "    return order_result, error_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "616a5840-e503-4354-8dc0-dca382433cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Bank] tokens : 2399\n",
      "[Bank] tokens : 2401\n",
      "[Bank] order_limit succeed. order_result : {'orderId': 12534875366, 'symbol': 'BANDUSDT', 'status': 'NEW', 'clientOrderId': '4SdFtlkYT87muFFKicFqjm', 'price': '1.0500', 'avgPrice': '0.00', 'origQty': '5.0', 'executedQty': '0.0', 'cumQty': '0.0', 'cumQuote': '0.00000', 'timeInForce': 'GTC', 'type': 'LIMIT', 'reduceOnly': False, 'closePosition': False, 'side': 'BUY', 'positionSide': 'LONG', 'stopPrice': '0.0000', 'workingType': 'CONTRACT_PRICE', 'priceProtect': False, 'origType': 'LIMIT', 'priceMatch': 'NONE', 'selfTradePreventionMode': 'NONE', 'goodTillDate': 0, 'updateTime': 1720656277839}\n"
     ]
    }
   ],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.side_order = 'BUY'\n",
    "bank.side_position = 'LONG'\n",
    "bank.price = 1.05\n",
    "bank.quantity = 5\n",
    "\n",
    "order_result, \\\n",
    "error_code = order_limit(bank, \n",
    "            bank.symbol,\n",
    "            bank.side_order, \n",
    "            bank.side_position, \n",
    "            bank.price, \n",
    "            bank.quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92524d7-d40c-4451-aae2-88a8c0c3f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(order_result)\n",
    "print(error_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9b98e-10de-422c-b3fb-462e6bb122d8",
   "metadata": {},
   "source": [
    "#### order_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b3f0f-4c98-4f75-84ea-ddd7be4ae438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_market(self, \n",
    "                 symbol,\n",
    "                 side_order,\n",
    "                 side_position,\n",
    "                 quantity):\n",
    "\n",
    "    while 1:\n",
    "\n",
    "        # quantity_unexecuted = get_quantity_unexecuted(self, \n",
    "        #                                             symbol,\n",
    "        #                                             orderId)\n",
    "\n",
    "        # order_market\n",
    "        order_result = None\n",
    "        error_code = 0\n",
    "        \n",
    "        # while 1:\n",
    "        try:\n",
    "            server_time = self.time()['data']['serverTime']\n",
    "            response = self.new_order(symbol=symbol,\n",
    "                                        side=side_order,\n",
    "                                        positionSide=side_position,\n",
    "                                        type=OrderType.MARKET,\n",
    "                                        quantity=str(quantity),\n",
    "                                        timestamp=server_time)\n",
    "            \n",
    "            tokens_used = int(response['header'].get('X-MBX-USED-WEIGHT-1M'))\n",
    "            self.token_bucket.wait_for_token_consume(tokens_used) \n",
    "\n",
    "            order_result = response['data']            \n",
    "            self.sys_log.info(\"order_market succeed. : {}\".format(order_result))\n",
    "            \n",
    "        except Exception as e:\n",
    "            msg = \"error in order_market : {}\".format(e)\n",
    "            self.sys_log.error(msg)\n",
    "            self.push_msg(msg)                \n",
    "            time.sleep(self.config.trader_set.order_term)\n",
    "            continue\n",
    "\n",
    "            # # -2022 ReduceOnly Order is rejected\n",
    "            # if '-2022' in str(e):\n",
    "            #     error_code = '-2022'\n",
    "            #     break\n",
    "\n",
    "            # # -4003 quantity less than zero\n",
    "            # if '-4003' in str(e):\n",
    "            #     error_code = '-4003'\n",
    "            #     break\n",
    "                \n",
    "            # # -1111 : Precision is over the maximum defined for this asset\n",
    "            #     # = quantity precision error\n",
    "\n",
    "\n",
    "        # 4. term for quantity consumption.\n",
    "        time.sleep(1)\n",
    "\n",
    "        if order_result:\n",
    "\n",
    "            # order_result doesn't update executedQty. (remain at zero)\n",
    "            \n",
    "            # symbol = order_result['symbol'] # we have symbol column in table already.\n",
    "            # orderId = order_result['orderId']        \n",
    "            \n",
    "            self.order_info = get_order_info(self, \n",
    "                                           order_result['symbol'],\n",
    "                                           order_result['orderId'])\n",
    "        \n",
    "            if self.order_info['status'] == 'FILLED':\n",
    "                self.sys_log.info(\"order_market filled.\")\n",
    "                return order_result, error_code\n",
    "            else:\n",
    "                self.sys_log.info(\"order_market failed.\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e80ade-a2fe-4334-a6fb-34e7241d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.order_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53af9aa6-c539-4946-b261-9ee73220e331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Bank] tokens : 2401\n",
      "[Bank] order_market succeed. : {'orderId': 12534879212, 'symbol': 'BANDUSDT', 'status': 'NEW', 'clientOrderId': 'Pq9n2YFlRtyfWctXNCM9hT', 'price': '0.0000', 'avgPrice': '0.00', 'origQty': '5.0', 'executedQty': '0.0', 'cumQty': '0.0', 'cumQuote': '0.00000', 'timeInForce': 'GTC', 'type': 'MARKET', 'reduceOnly': False, 'closePosition': False, 'side': 'BUY', 'positionSide': 'LONG', 'stopPrice': '0.0000', 'workingType': 'CONTRACT_PRICE', 'priceProtect': False, 'origType': 'MARKET', 'priceMatch': 'NONE', 'selfTradePreventionMode': 'NONE', 'goodTillDate': 0, 'updateTime': 1720656376832}\n",
      "[Bank] tokens : 2122\n",
      "[Bank] order_market filled.\n"
     ]
    }
   ],
   "source": [
    "bank.symbol = 'BANDUSDT'\n",
    "bank.side_order = 'BUY'\n",
    "bank.side_position = 'LONG'\n",
    "# bank.price = 1.09\n",
    "bank.quantity = 5\n",
    "\n",
    "\n",
    "order_result, \\\n",
    "error_code = order_market(bank, \n",
    "                         bank.symbol,\n",
    "                         bank.side_order,\n",
    "                         bank.side_position,\n",
    "                         bank.quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab45b4-f639-4d02-8379-69ac3ca258af",
   "metadata": {},
   "source": [
    "#### get_income_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07958e1a-f545-40d1-85cd-7fb2d5c0896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_income_info(self, \n",
    "                    table_log,\n",
    "                    code,\n",
    "                    side_position,\n",
    "                    leverage,\n",
    "                    income_accumulated,\n",
    "                    profit_accumulated,\n",
    "                    mode=\"PROD\", \n",
    "                    currency=\"USDT\"):\n",
    "\n",
    "    table_log = table_log.astype({'cumQuote' : 'float'})\n",
    "    table_log_valid = table_log[(table_log.code == code) & (table_log.cumQuote != 0)]\n",
    "    table_log_valid['fee_ratio'] = np.where(table_log_valid.type == 'LIMIT', self.config.trader_set.fee_limit, self.config.trader_set.fee_market)\n",
    "    table_log_valid['fee'] = table_log_valid.cumQuote * table_log_valid.fee_ratio\n",
    "    \n",
    "    # if PARTIALLY_FILLED & FILLED exist both, use FILLED only.\n",
    "    table_log_valid_open = table_log_valid[table_log_valid.order_way == 'OPEN']\n",
    "    table_log_valid_close = table_log_valid[table_log_valid.order_way == 'CLOSE']\n",
    "    \n",
    "    if len(table_log_valid_open) > 0 and len(table_log_valid_close) > 0:\n",
    "        cumQuote_open = table_log_valid_open.iloc[-1].cumQuote\n",
    "        cumQuote_close = table_log_valid_close.iloc[-1].cumQuote\n",
    "        fee_open = table_log_valid_open.iloc[-1].fee\n",
    "        fee_close = table_log_valid_close.iloc[-1].fee\n",
    "    else:\n",
    "        self.sys_log.info(\"table_log_valid length insufficient : {}\".format(table_log_valid))\n",
    "        return 0, income_accumulated, 0, profit_accumulated\n",
    "        \n",
    "    self.sys_log.info(\"cumQuote_open : {}\".format(cumQuote_open))\n",
    "    self.sys_log.info(\"cumQuote_close : {}\".format(cumQuote_close))\n",
    "    self.sys_log.info(\"fee_open : {}\".format(fee_open))\n",
    "    self.sys_log.info(\"fee_close : {}\".format(fee_close))\n",
    "\n",
    "    \n",
    "    if side_position == 'LONG':\n",
    "        income = cumQuote_close - cumQuote_open\n",
    "    else:\n",
    "        income = cumQuote_open - cumQuote_close\n",
    "    income -= (fee_open + fee_close)\n",
    "        \n",
    "    income_accumulated += income\n",
    "    self.sys_log.info(\"income : {:.4f} {}\".format(income, currency))\n",
    "    self.sys_log.info(\"income_accumulated : {:.4f} {}\".format(income_accumulated, currency))\n",
    "\n",
    "    \n",
    "    # reject manual trade intervention.\n",
    "    if cumQuote_open == 0:\n",
    "        profit = 0.0\n",
    "    else:\n",
    "        profit = income / cumQuote_open * leverage\n",
    "    profit_accumulated += profit\n",
    "    self.sys_log.info(\"profit : {:.4f}\".format(profit))\n",
    "\n",
    "\n",
    "    # set to outer scope using output vars. later.\n",
    "    # if self.config.trader_set.profit_mode == \"PROD\":\n",
    "    #     # add your income.\n",
    "    #     balance_available += income\n",
    "        \n",
    "    #     # update config.\n",
    "    #     self.config.trader_set.initial_asset = balance_available\n",
    "\n",
    "    #     with open(self.path_config, 'w') as cfg:\n",
    "    #         json.dump(self.config, cfg, indent=2)   \n",
    "    \n",
    "            \n",
    "    msg = (\"cumQuote_open : {:.4f}\\n\" + \n",
    "            \"cumQuote_close : {:.4f}\\n\" + \n",
    "            \"fee_open : {:.4f}\\n\" + \n",
    "            \"fee_close : {:.4f}\\n\" + \n",
    "            \"income : {:.4f}\\n\" + \n",
    "            \"income_accumulated : {:.4f}\\n\" + \n",
    "            \"profit : {:.4f}\\n\" + \n",
    "            \"profit_accumulated : {:.4f}\\n\")\\\n",
    "            .format(cumQuote_open,\n",
    "                    cumQuote_close,\n",
    "                    fee_open,\n",
    "                    fee_close,\n",
    "                    income,\n",
    "                    income_accumulated,\n",
    "                    profit,\n",
    "                    profit_accumulated)\n",
    "\n",
    "    self.push_msg(msg)\n",
    "\n",
    "    return income, income_accumulated, profit, profit_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e33903a2-1eef-4ec9-8095-452bb411d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Bank] table_log_valid length insufficient : Empty DataFrame\n",
      "Columns: [code, orderId, order, remove_row, order_way, status, statusChangeTime, cumQuote, type, path_df_res_open, order_motion, side_open, side_close, side_position, precision_price, precision_quantity, price_take_profit, price_entry, price_stop_loss, price_liquidation, price_expiration, price_realtime, quantity_open, amount_entry, leverage, margin, account, symbol, clientOrderId, price, avgPrice, origQty, executedQty, cumQty, timeInForce, reduceOnly, closePosition, side, positionSide, stopPrice, workingType, priceProtect, origType, priceMatch, selfTradePreventionMode, goodTillDate, time, updateTime, fee_ratio, fee]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.0, 0, 0.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_income_info(bank,\n",
    "# bank.profit_accumulated = 0\n",
    "get_income_info(bank, \n",
    "                    bank.table_log,\n",
    "                    'QTUMUSDT_20240613164112088652',\n",
    "                    'SHORT',\n",
    "                    31,\n",
    "                    bank.income_accumulated,\n",
    "                    bank.profit_accumulated,                    \n",
    "                    mode=\"PROD\", \n",
    "                    currency=\"USDT\")               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a4823-3816-4551-a3e2-1fff2cee0de8",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e26c0-388a-486b-97b7-c7a4d63a2d31",
   "metadata": {},
   "source": [
    "## expiry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b207b-c897-453b-973b-2042ba649d4b",
   "metadata": {},
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cf2a8-c987-4a8b-937d-067962bf79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expiry_tp(df_res, config, op_idx, e_j, balance_available_j, np_datas, side_open):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        expiration criteria : balance_available_1 with balance_available_gap. \n",
    "    v1.1\n",
    "        expiration criteria : self.price_take_profit with balance_available_gap. \n",
    "    \n",
    "    last confirmed at, 20240412 2031\n",
    "    \"\"\"\n",
    "    \n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "\n",
    "    if config.tr_set.expire_tick != \"None\":\n",
    "        if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "            expire = 1\n",
    "\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if side_open == OrderSide.SELL:\n",
    "            short_tp_ = df_res['short_tp_{}'.format(selection_id)].to_numpy()  # id 에 따라 dynamic 변수라 이곳에서 numpy 화 진행\n",
    "            short_tp_gap_ = df_res['short_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if low[e_j] <= short_tp_[balance_available_j] + short_tp_gap_[balance_available_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "        else:\n",
    "            long_tp_ = df_res['long_tp_{}'.format(\n",
    "                selection_id)].to_numpy()  # iloc 이 빠를까, to_numpy() 가 빠를까  # 3.94 ms --> 5.34 ms (iloc)\n",
    "            long_tp_gap_ = df_res['long_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if high[e_j] >= long_tp_[balance_available_j] - long_tp_gap_[balance_available_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71c3ba-c568-44bf-83e6-6aa067f48e68",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bb745-a17a-4201-82b2-db92fcca4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expiry(df_res, config, op_idx, e_j, balance_available_j, np_datas, side_open):\n",
    "\n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        expiration criteria : balance_available_1 with balance_available_gap. \n",
    "    \n",
    "    last confirmed at, 20240412 2030\n",
    "    \"\"\"\n",
    "    \n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "\n",
    "    if config.tr_set.expire_tick != \"None\":\n",
    "        if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "            expire = 1\n",
    "\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if side_open == OrderSide.SELL:\n",
    "            short_tp_1_ = df_res['short_tp_1_{}'.format(selection_id)].to_numpy()  # id 에 따라 dynamic 변수라 이곳에서 numpy 화 진행\n",
    "            short_tp_gap_ = df_res['short_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if low[e_j] <= short_tp_1_[balance_available_j] - short_tp_gap_[balance_available_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "        else:\n",
    "            long_tp_1_ = df_res['long_tp_1_{}'.format(\n",
    "                selection_id)].to_numpy()  # iloc 이 빠를까, to_numpy() 가 빠를까  # 3.94 ms --> 5.34 ms (iloc)\n",
    "            long_tp_gap_ = df_res['long_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if high[e_j] >= long_tp_1_[balance_available_j] + long_tp_gap_[balance_available_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261d0f1-1219-4b22-9220-f86f43362c3d",
   "metadata": {},
   "source": [
    "## expiry_between"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b897f-e61d-434f-b1ef-b5353df7ce3c",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced05e5-6898-42b2-92ef-b56fe9c2e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expiry_between(df_res, config, op_idx1, op_idx2, balance_available1, balance_available0, balance_available_gap, np_datas, side_open):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1.0\n",
    "        expiration survey between op_idx1 & op_idx2.\n",
    "    \n",
    "    last confirmed at, 20240412 2035\n",
    "    \"\"\"\n",
    "\n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "    touch_idx = None\n",
    "\n",
    "    # if config.tr_set.expire_tick != \"None\":\n",
    "    #     if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "    #         expire = 1\n",
    "\n",
    "    # Todo, p1's balance_available1, 0 cannot be vectorized\n",
    "    #   a. expiration 의 조건은 wave1, 0 의 broken\n",
    "    idx_range = np.arange(op_idx1, op_idx2)\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if side_open == OrderSide.SELL:\n",
    "            touch_idx = np.where((low[op_idx1:op_idx2] <= balance_available1 + balance_available_gap * config.tr_set.expire_k1) | \\\n",
    "                                 (high[op_idx1:op_idx2] >= balance_available0 - balance_available_gap * config.tr_set.expire_k1),\n",
    "                                 idx_range, np.nan)\n",
    "            # if op_idx1 >= 16353:\n",
    "            #   print(\"high[16353], balance_available0 :\", high[16353], balance_available0)\n",
    "            if np.sum(~np.isnan(touch_idx)) > 0:  # touch 가 존재하면,\n",
    "                # if low[op_idx1:op_idx2].min() <= balance_available1 + balance_available_gap * config.tr_set.expire_k1 or \\\n",
    "                # high[op_idx1:op_idx2].max() >= balance_available0 - balance_available_gap * config.tr_set.expire_k1:   # p2_box loc. 이 있어서, op_idx2 + 1 안함\n",
    "                expire = 1\n",
    "        else:\n",
    "            touch_idx = np.where((high[op_idx1:op_idx2] >= balance_available1 - balance_available_gap * config.tr_set.expire_k1) | \\\n",
    "                                 (low[op_idx1:op_idx2] <= balance_available0 + balance_available_gap * config.tr_set.expire_k1),\n",
    "                                 idx_range, np.nan)\n",
    "            if np.sum(~np.isnan(touch_idx)) > 0:\n",
    "                # if high[op_idx1:op_idx2].max() >= balance_available1 - balance_available_gap * config.tr_set.expire_k1 or \\\n",
    "                # low[op_idx1:op_idx2].min() <= balance_available0 + balance_available_gap * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire, np.nanmin(touch_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
