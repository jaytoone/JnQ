{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a450b4-727b-4db1-b63d-a59862bd67fa",
   "metadata": {
    "id": "8uqYv5StTazo"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937b153-9733-4c8e-a894-3aa82dcff611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41909,
     "status": "ok",
     "timestamp": 1666567834950,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "6rmQpzEGXfCw",
    "outputId": "6e7fec9e-910c-4f49-bc35-5e99ac69bfd8"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "pkg_path = 'D:\\\\Projects\\\\System_Trading\\\\JnQ\\\\'\n",
    "\n",
    "os.chdir(pkg_path)\n",
    "\n",
    "# mpl_finance_path = 'D:\\\\python\\\\python38_1\\\\projects\\\\JnQ\\\\mpl_finance'\n",
    "# ta_lib_path = 'D:\\\\python\\\\python38_1\\\\projects\\\\JnQ\\\\ta_lib'\n",
    "funcs_path = pkg_path + 'funcs'\n",
    "\n",
    "if funcs_path not in sys.path:\n",
    "\n",
    "  try:\n",
    "    # sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/JnQ')\n",
    "    sys.path.insert(0, pkg_path + 'Bank')\n",
    "    sys.path.insert(0, funcs_path)\n",
    "    # sys.path.insert(0, mpl_finance_path)\n",
    "    # sys.path.insert(0, ta_lib_path)\n",
    "    \n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357cb99-1f22-47c1-857b-e20ab54a921f",
   "metadata": {
    "executionInfo": {
     "elapsed": 20652,
     "status": "ok",
     "timestamp": 1666567855597,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "9qGt60DKTZmf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import talib\n",
    "from funcs.public.idep import *\n",
    "from funcs.public.plot_check import *\n",
    "from funcs.public.en_ex_pairing import *\n",
    "from funcs.public.indicator import *\n",
    "from funcs.public.broker import *\n",
    "from funcs.public.ds import *\n",
    "from ast import literal_eval\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# import bz2\n",
    "import pickle\n",
    "# import _pickle as cPickle\n",
    "import shutil\n",
    "import json\n",
    "from easydict import EasyDict\n",
    "import copy\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "# import warnings\n",
    "\n",
    "from IPython.display import clear_output\n",
    "# warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "np.seterr(invalid=\"ignore\")\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(linewidth=2000) \n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a5021-e287-43a2-a9c5-a09c0967f36c",
   "metadata": {},
   "source": [
    "# Telegramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a39df9-ae8a-4adc-97a4-77436c6f96d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import telegram\n",
    "from telegram.ext import Updater\n",
    "from telegram.ext import MessageHandler, Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf403b-a7e7-41e8-b43e-1b22724a3677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def echo(self, update, context):\n",
    "    self.user_text = update.message.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864b975-577c-4e86-b605-c1f9c23fe786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#       i. Telegram logger\n",
    "#               1. chat_id 는 env 동일.\n",
    "token = \"6717940201:AAFc62YReeED3mJKw5drHnT7jp6dzXy0rPE\"\n",
    "msg_bot = telegram.Bot(token=token)\n",
    "chat_id = \"5320962614\"\n",
    "\n",
    "#       ii. Telegram messenger\n",
    "#           1. init.\n",
    "user_text = None\n",
    "\n",
    "updater = Updater(token=token, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "echo_handler = MessageHandler(Filters.text & (~Filters.command), echo)\n",
    "dispatcher.add_handler(echo_handler)\n",
    "\n",
    "#           2. polling for messenger.\n",
    "updater.start_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf02e61-080f-4ad3-9514-4a321a11aac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msg = \"ping telegramer\"\n",
    "\n",
    "try:\n",
    "    msg_bot.sendMessage(chat_id=chat_id, text=msg)\n",
    "except Exception as e:\n",
    "    print(\"error in msg_bot : {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a376c02-9be1-43d5-8f72-6b3c9de62130",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a80464-94bb-4c6f-8ff8-9625f195905a",
   "metadata": {},
   "source": [
    "## Upbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6bac3-d1ac-4718-8d91-bf9d6d3102db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fluc_arr = np.array(list(fluc_dict.items()))\n",
    "\n",
    "fluc_arr_krw = np.array([v_ for v_ in fluc_arr if 'krw'.upper() in v_[0]])\n",
    "fluc_arr_krw = fluc_arr_krw[fluc_arr_krw[:, 1].astype(float).argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b3eb-3428-4955-856b-31f1b87470cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(fluc_arr_krw).set_index(0).to_excel(\"signal/upbit_fluc_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b106d93-19b8-428f-8f5a-bd7e482d9b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from funcs.upbit.concat_candlestick_ftr_v2 import concat_candlestick\n",
    "from pyupbit import get_tickers\n",
    "\n",
    "\"\"\"\n",
    "1. upbit 에서 당일 기준 이전 데이터를 조회할지라도 None 은 성립하지 않는다. --> end_date = today 로 변경 요구.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "days = 1  # 330 3\n",
    "\n",
    "end_date = None  # None 2023-07-04 # \"2023-01-06\" \"2021-04-12\" \"2021-03-23\"\n",
    "    \n",
    "intervals = [ 'D']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "intervals = ['30m', '1h', '2h']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "intervals = ['1d']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "\n",
    "time_schedule = {'4h': [21, 17, 13, 9, 5, 1], '1d': [9]}\n",
    "    \n",
    "show_process = False\n",
    "show_process = True\n",
    "\n",
    "\n",
    "\n",
    "with open(\"signal/upbit_fluc_max.pkl\", 'rb') as f:\n",
    "    fluc_dict = pickle.load(f)\n",
    "    \n",
    "# hour_prev = None    \n",
    "symbol_list = get_tickers()\n",
    "\n",
    "while 1:\n",
    "\n",
    "    time.sleep(1)  # term for small fan sound.\n",
    "    \n",
    "    target_symbol_total = []\n",
    "    for interval in intervals:\n",
    "        \n",
    "        timestamp = datetime.now().timestamp()\n",
    "        hour_current = datetime.fromtimestamp(datetime.now().timestamp()).hour\n",
    "        hour_prev = datetime.fromtimestamp(datetime.now().timestamp() - 10).hour  # 10 seconds before.\n",
    "        \n",
    "        # print(\"hour_current :\", hour_current)\n",
    "        # print(\"hour_prev :\", hour_prev)\n",
    "        # print(\"time_schedule[interval] :\", time_schedule[interval])\n",
    "        \n",
    "        if not ((hour_current in time_schedule[interval]) and hour_current != hour_prev):\n",
    "            continue\n",
    "\n",
    "        target_symbol = []\n",
    "        for s_i, symbol in enumerate(symbol_list):\n",
    "\n",
    "            print(s_i)\n",
    "\n",
    "            if 'KRW' not in symbol:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                concated_df, end_date = concat_candlestick(symbol, \n",
    "                                                           interval, \n",
    "                                                           days, \n",
    "                                                           limit=limit_by_itv(interval),\n",
    "                                                           end_date=end_date, \n",
    "                                                           show_process=show_process, \n",
    "                                                           timesleep=0.1)\n",
    "\n",
    "\n",
    "                concated_df2 = fisher_v2(concated_df, 30, itv=interval)    \n",
    "                # display(concated_df2.tail())\n",
    "                # break\n",
    "\n",
    "                target_data = concated_df2.iloc[-2:, -1].to_numpy()\n",
    "\n",
    "                \"\"\"\n",
    "                condition\n",
    "                \"\"\"\n",
    "                # 1. fisher band\n",
    "                fisher_lower = -1.5\n",
    "                if target_data[0] < fisher_lower < target_data[1]:\n",
    "                    target_symbol.append(symbol)\n",
    "\n",
    "                clear_output(wait=True)          \n",
    "\n",
    "\n",
    "\n",
    "                # break\n",
    "                # save_path = os.path.join(save_dir, save_name)\n",
    "                # concated_df.reset_index().to_feather(save_path, compression='lz4')\n",
    "                # print(save_path, \"saved.\\n\")\n",
    "            except Exception as e:\n",
    "                print(\"error in save to_feather :\", e)\n",
    "                continue\n",
    "\n",
    "        target_symbol_total = np.array([[s_.replace('KRW-', ''), fluc_dict[s_]] for s_ in target_symbol])\n",
    "        if len(target_symbol_total) > 0:\n",
    "            target_symbol_total = target_symbol_total[target_symbol_total[:, 1].astype(float).argsort()[::-1]]\n",
    "            print(\"target_symbol_total :\", target_symbol_total)\n",
    "\n",
    "            msg = \"target_symbol_total : {} {}\".format(interval, target_symbol_total)\n",
    "            try:\n",
    "                msg_bot.sendMessage(chat_id=chat_id, text=msg)\n",
    "            except Exception as e:\n",
    "                print(\"error in msg_bot : {}\".format(e))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247bb74-fc13-45d9-877c-8341a644d03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(index=intervals, data=target_symbol_total)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c026e1-db2e-4490-8cc2-c0ae0289f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_excel(\"signal/upbit_res.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba34d96-f6b9-4d4e-8c25-c9321240ecf4",
   "metadata": {},
   "source": [
    "### get max price in whole range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b5e23-da62-45ad-b0ce-c199aee13abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "days = 365 * 10  # 330 3\n",
    "end_date = str(datetime.now()).split(' ')[0]    \n",
    "count = int((days * 60 * 24) / itv_to_number(interval))\n",
    "timesleep = 0.1\n",
    "print(\"count :\", count)\n",
    "\n",
    "\n",
    "fluc_dict = {}\n",
    "for s_i, symbol in enumerate(get_tickers()):\n",
    "    \n",
    "    print(s_i, symbol)\n",
    "    \n",
    "    df = pyupbit.get_ohlcv(\"{}\".format(symbol),\n",
    "                                       interval=itv_binance_to_upbit(interval),\n",
    "                                       count=count,\n",
    "                                       period=timesleep,\n",
    "                                       to=end_date) \n",
    "\n",
    "    print(df.index[0], end=\" --> \")\n",
    "    print(df.index[-1])\n",
    "\n",
    "    fluc_max = df.high.max() / df.close.iloc[-1]\n",
    "    fluc_dict[symbol] = fluc_max\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787610c-8dd4-40dc-86cc-2b14f2f6a091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"signal/upbit_fluc_max.pkl\", 'wb') as f:\n",
    "    pickle.dump(fluc_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21903bfe-88a8-4160-8b2e-b0996a84bb31",
   "metadata": {},
   "source": [
    "## Binance_Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfea807-5066-4f6f-b5d0-34c0819a34e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(r\"D:\\Projects\\System_Trading\\JnQ\\Bank\\tickers\\binance_20240102.pkl\", 'wb') as f:\n",
    "#     pickle.dump(symbol_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07628a3b-ce5a-4fb9-a977-ed2409598c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from binance.um_futures import UMFutures\n",
    "from funcs.binance.futures_concat_candlestick_ftr_v2 import *\n",
    "# break\n",
    "\n",
    "\n",
    "days = 5  # 330 3\n",
    "\n",
    "end_date = None  # None 2023-07-04 # \"2023-01-06\" \"2021-04-12\" \"2021-03-23\"\n",
    "    \n",
    "intervals = ['4h', '1d']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "intervals = ['15m', '30m', '1h', '4h', '1d']  # ['1m', '3m', '5m', '15m', '30m', '1h', '4h'] - old\n",
    "\n",
    "limit = 1500\n",
    "    \n",
    "show_process = False\n",
    "show_process = True\n",
    "\n",
    "\n",
    " \n",
    "symbol_list = [s_['symbol'] for s_ in um_futures_client.exchange_info()['symbols']]\n",
    "\n",
    "\n",
    "\n",
    "target_symbol_total = []\n",
    "for interval in intervals:\n",
    "    \n",
    "    target_symbol = []\n",
    "    for s_i, symbol in enumerate(symbol_list):\n",
    "        \n",
    "        print(s_i)\n",
    "        \n",
    "        # if 'KRW' not in symbol:\n",
    "        #     continue\n",
    "        \n",
    "        try:\n",
    "            concated_df, end_date = concat_candlestick_v2(symbol, \n",
    "                                                          interval, \n",
    "                                                          days,\n",
    "                                                          limit=limit,\n",
    "                                                          end_date=end_date,\n",
    "                                                          show_process=True,\n",
    "                                                          timesleep=0.4)\n",
    "            \n",
    "            \n",
    "            concated_df2 = fisher_v2(concated_df, 30, itv=interval.upper())      \n",
    "            # display(concated_df2.tail())\n",
    "            # break\n",
    "            \n",
    "            target_data = concated_df2.iloc[-2:, -1].to_numpy()\n",
    "            \n",
    "            \"\"\"\n",
    "            condition\n",
    "            \"\"\"\n",
    "            # 1. fisher band\n",
    "            fisher_lower = -1.5\n",
    "            if target_data[0] < fisher_lower < target_data[1]:\n",
    "                target_symbol.append(symbol)\n",
    "                \n",
    "            clear_output(wait=True)          \n",
    "            \n",
    "            \n",
    "            \n",
    "            # break\n",
    "            # save_path = os.path.join(save_dir, save_name)\n",
    "            # concated_df.reset_index().to_feather(save_path, compression='lz4')\n",
    "            # print(save_path, \"saved.\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"error in save to_feather :\", e)\n",
    "            continue\n",
    "     \n",
    "    target_symbol_total.append([s_ + '.P' for s_ in target_symbol])\n",
    "    # print(\"target_symbol_total :\", target_symbol_total)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7711e-58e1-4077-93cd-3dd58039d437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(index=intervals, data=target_symbol_total)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5653356-d9eb-4323-9900-fe282394526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_excel(\"signal/binance_futures_res.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
