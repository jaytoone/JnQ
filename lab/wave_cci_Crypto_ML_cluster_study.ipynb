{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uqYv5StTazo"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41909,
     "status": "ok",
     "timestamp": 1666567834950,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "6rmQpzEGXfCw",
    "outputId": "6e7fec9e-910c-4f49-bc35-5e99ac69bfd8"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "pkg_path = 'D:\\\\Projects\\\\System_Trading\\\\JnQ\\\\'\n",
    "\n",
    "os.chdir(pkg_path)\n",
    "\n",
    "# mpl_finance_path = 'D:\\\\python\\\\python38_1\\\\projects\\\\JnQ\\\\mpl_finance'\n",
    "# ta_lib_path = 'D:\\\\python\\\\python38_1\\\\projects\\\\JnQ\\\\ta_lib'\n",
    "funcs_path = pkg_path + 'funcs'\n",
    "\n",
    "if funcs_path not in sys.path:\n",
    "\n",
    "  try:\n",
    "    # sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/JnQ')\n",
    "    sys.path.insert(0, pkg_path + 'Bank')\n",
    "    sys.path.insert(0, funcs_path)\n",
    "    # sys.path.insert(0, mpl_finance_path)\n",
    "    # sys.path.insert(0, ta_lib_path)\n",
    "    \n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 20652,
     "status": "ok",
     "timestamp": 1666567855597,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "9qGt60DKTZmf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import talib\n",
    "from funcs.public.idep import *\n",
    "from funcs.public.plot_check import *\n",
    "from funcs.public.en_ex_pairing import *\n",
    "from funcs.public.indicator import *\n",
    "from funcs.public.broker import *\n",
    "from ast import literal_eval\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "import json\n",
    "from easydict import EasyDict\n",
    "import copy\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "# import warnings\n",
    "\n",
    "# warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "np.seterr(invalid=\"ignore\")\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(linewidth=2000) \n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic1mfmwWCIBu",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Database work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUSBU7T8Suzi",
    "tags": []
   },
   "source": [
    "## Data sync_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmhLikYlSuzi"
   },
   "outputs": [],
   "source": [
    "def sync_check_make(df):\n",
    "\n",
    "    make_itv_list = ['3T', '5T', '15T', '30T', 'H', '4H', 'D']\n",
    "    offset_list = ['1h', '1h', '1h', '1h', '1h', '1h', '9h']\n",
    "\n",
    "    assert len(make_itv_list) == len(offset_list), \"length of itv & offset_list should be equal\"\n",
    "        \n",
    "    htf_df_list = [to_htf(df, itv=itv_, offset=offset_) for itv_, offset_ in zip(make_itv_list, offset_list)]\n",
    "\n",
    "    df_3T, df_5T, df_15T, df_30T, df_H, df_4H, df_D = htf_df_list\n",
    "\n",
    "    for htf_df in htf_df_list:\n",
    "      print(\"{} -> \".format(pd.infer_freq(htf_df.index)), htf_df.tail(1))\n",
    "\n",
    "    # heikinashi_v2(res_df_)\n",
    "    \n",
    "    # h_candle_v3(df, df_5T, '5T')\n",
    "    \n",
    "    # df = h_candle_v4(df, df_5T)\n",
    "    # df = h_candle_v4(df, df_15T)\n",
    "    # df = h_candle_v4(df, df_30T)\n",
    "    # df = h_candle_v4(df, df_45T)\n",
    "    # df = h_candle_v4(df, df_H)\n",
    "    # df = h_candle_v4(df, df_4H)\n",
    "    # df = h_candle_v4(df, 'D')\n",
    "\n",
    "    # df = candle_pattern_pkg(df, df_5T)\n",
    "    # df = candle_pattern_pkg(df, df_30T)\n",
    "    # df = candle_pattern_pkg(df, df_H)\n",
    "    # df = candle_pattern_pkg(df, df_4H)\n",
    "    \n",
    "    # --------------- stochastic --------------- #\n",
    "    # df = stoch_v2(df)\n",
    "    # df_5T['stoch'] = stoch(df_5T, 13, 3, 3)\n",
    "    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf_v2(df, df_5T, [-1], backing_i=-1), columns=['stoch_5m']))\n",
    "\n",
    "    # print(\"stoch phase done\")\n",
    "    \n",
    "    # --------------- supertrend --------------- #\n",
    "#     df = st_price_line(df, df_15T)\n",
    "#     df = st_level(df, '15T', 1)\n",
    "    \n",
    "#     df = st_price_line(df, df_4H)\n",
    "#     df = st_level(df, '4H', 1)\n",
    "\n",
    "#     print(\"supertrend phase done\")\n",
    "\n",
    "    # --------------- ma --------------- #  \n",
    "    # df = ma(df, 60)\n",
    "    # print(\"ma phase done\")\n",
    "\n",
    "    # df = macd_hist(df, 5, 35, 15)\n",
    "    # print(\"macd_hist phase done\")\n",
    "    \n",
    "    # df = enough_space(df, '15T', 1)\n",
    "    \n",
    "    # --------------- dc --------------- #  \n",
    "    dc_period = 500\n",
    "    # df = donchian_channel_v4(df, dc_period)\n",
    "    # df = dc_line(df, df_5T, '5T')  # join 사용시에만 return df 허용함\n",
    "    # df = dc_line(df, df_15T, '15T')\n",
    "    # df = dc_line_v2(df, df_H, 'H', dc_period=5)\n",
    "\n",
    "    # df = dc_line_v4(df, df, dc_period=10)\n",
    "    # df = dc_line_v4(df, df, dc_period=20)\n",
    "    # df = dc_line_v4(df, df, dc_period=100)\n",
    "    # df = dc_line_v4(df, df_5T, dc_period=20)\n",
    "    # df = dc_line_v4(df, df_15T, dc_period=20)\n",
    "    # df = dc_line_v4(df, df_H, dc_period=20)\n",
    "    # df = dc_line_v4(df, df_4H, dc_period=20)\n",
    "    # print(\"dc phase done\")\n",
    "\n",
    "    # --------------- bb --------------- #  \n",
    "    bb_period = 200\n",
    "\n",
    "    # upper, base, lower = talib.BBANDS(res_df_.close, timeperiod=20, nbdevup=1, nbdevdn=1, matype=0)\n",
    "        \n",
    "#     df = bb_width_v3(df, period=bb_period, multiple=1, itv='T')\n",
    "#     df = bb_level_v2(df, 'T', bb_period)\n",
    "        \n",
    "#     # 1. Stock 을 위한 bb setting 아직 정립되지 않음. to_lower_tf 라든지.\n",
    "#     # df = bb_line_v3(df, df_15T, 20)    \n",
    "#     # df = bb_line_v3(df, df, bb_period)\n",
    "#     print(\"bb phase done\")\n",
    "\n",
    "    c_itv = '5T'\n",
    "\n",
    "    # df =  wick_ratio(df, c_itv)\n",
    "    # df =  wick_ratio(df, c_itv)\n",
    "\n",
    "    bb_itv= 'T'\n",
    "\n",
    "    # df = candle_range_ratio(df, c_itv, bb_itv, bb_period)\n",
    "    # # candle_pumping_ratio(df, c_itv, bb_itv, bb_period)\n",
    "\n",
    "    dc_itv= '15T'\n",
    "    dc_period = 4\n",
    "    # df = candle_pumping_ratio_v2(df, c_itv, dc_itv, dc_period)\n",
    "    # print(\"candle_pumping_ratio_v2 phase done\")\n",
    "\n",
    "    # df = dc_over_body_ratio(df, c_itv, dc_itv, dc_period)\n",
    "    # print(\"dc_over_body_ratio phase done\")\n",
    "\n",
    "    # df = body_rel_ratio(df, c_itv)\n",
    "    # print(\"body_rel_ratio phase done\")\n",
    "\n",
    "    # --------------- cbline --------------- #    \n",
    "    # cloud_bline(df_3T, 20)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_3T, [-1]), how='inner')\n",
    "    # # cloud_bline(df_5T, 20)\n",
    "    # # df = df.join(to_lower_tf_v2(df, df_5T, [-1]), how='inner')\n",
    "    # cloud_bline(df_15T, 20)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_15T, [-1]), how='inner')\n",
    "    # cloud_bline(df_30T, 20)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_30T, [-1]), how='inner')\n",
    "    # cloud_bline(df_H, 20)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_H, [-1]), how='inner')\n",
    "    # cloud_bline(df_4H, 20)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_4H, [-1]), how='inner')\n",
    "\n",
    "    # print(\"cbline phase done\")\n",
    "\n",
    "\n",
    "\n",
    "    # --------------- sd_dc --------------- #\n",
    "    # df = sd_dc(df, 20, 40)\n",
    "    # df = sd_dc(df, 20, 20)\n",
    "    # df = sd_dc(df_5T, 20, 40, df)\n",
    "    # df = sd_dc(df_H, 20, 40, df)\n",
    "\n",
    "    # print(\"sd_dc phase done\")\n",
    "\n",
    "    # --------------- imb_ratio --------------- #\n",
    "    # imb_ratio(df, '5T')\n",
    "    # imb_ratio_v3(df, \"5T\")\n",
    "    # imb_ratio_v4(df, \"5T\")\n",
    "\n",
    "    # imb_ratio(df, 'H')\n",
    "    # imb_ratio_v2(df, '5T')\n",
    "    \n",
    "    # print(\"imb_ratio phase done\")\n",
    "\n",
    "    # --------------- rel_abs_ratio --------------- #\n",
    "    # rel_abs_ratio(df, '5T', norm_period=120)\n",
    "\n",
    "    # --------------- normalize data --------------- #\n",
    "    # itv = 'T'\n",
    "    # lb_period = 15\n",
    "    # target_col = 'close_{}{}'.format(itv, lb_period)\n",
    "    # target_data = df['close'].diff(lb_period).to_numpy()\n",
    "    # norm_data(df, target_data, target_col)    \n",
    "    # print(\"normalize data phase done !\")\n",
    "\n",
    "    # --------------- lucid sar --------------- #\n",
    "    # lucid_sar_v2(df)\n",
    "    # lucid_sar_v2(df_3T)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_3T, [-2, -1]), how='inner')\n",
    "    # lucid_sar_v2(df_5T)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_5T, [-2, -1]), how='inner')\n",
    "    # lucid_sar_v2(df_15T)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_15T, [-2, -1]), how='inner')\n",
    "    # lucid_sar_v2(df_30T)\n",
    "    # df = df.join(to_lower_tf_v2(df, df_30T, [-2, -1]), how='inner')       \n",
    "\n",
    "    # print(\"sar phase done\")\n",
    "\n",
    "\n",
    "    # --------------- rsi --------------- #  \n",
    "    # df['rsi_1m'] = rsi(df, 14)    \n",
    "    # df_5T['rsi_5m'] = rsi(df_5T, 14)\n",
    "    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf_v2(df, df_5T, [-1]), columns=['rsi_5m']))\n",
    "    \n",
    "    # print(\"rsi phase done\")\n",
    "\n",
    "\n",
    "    # --------------- cci --------------- #  \n",
    "    # df['cci_1m'] = cci(df, 20)\n",
    "\n",
    "    # print(\"cci phase done\")\n",
    "\n",
    "    # --------------- ema --------------- #      \n",
    "    # df_5T['ema_5m'] = ema(df_5T['close'], 195)\n",
    "    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf_v2(df, df_5T, [-1]), columns=['ema_5m']))\n",
    "    \n",
    "    # print(\"ema phase done\")        \n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "executionInfo": {
     "elapsed": 3099,
     "status": "ok",
     "timestamp": 1662020383911,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "odqVwQHpYo1M",
    "outputId": "a847fe3a-8ef4-42ef-8f5b-42a30e227a8c"
   },
   "outputs": [],
   "source": [
    "res_df_ = sync_check_make(res_df_)  # suffix duplication 유의\n",
    "res_df_.tail().iloc[:, -10:]\n",
    "# res_df_.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SKglsQCj5_x"
   },
   "outputs": [],
   "source": [
    "# test_df_ = sync_check_make(res_df_.iloc[-4000:])  # suffix duplication 유의\n",
    "# test_df_.tail().iloc[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOQxwYqK0jCS"
   },
   "outputs": [],
   "source": [
    "# ------ validation ------ #\n",
    "# res_df_.cppr_15T.describe()\n",
    "print((res_df_.open_15T.to_numpy() - res_df_.close_15T.to_numpy())[-10:])\n",
    "print((res_df_.dc_upper_15T4.to_numpy() - res_df_.dc_lower_15T4.to_numpy())[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmiB5VU5DN6B"
   },
   "outputs": [],
   "source": [
    "# np.where(res_df_.CDL3LINESTRIKE_15T) #.iloc[-1000:,]\n",
    "\n",
    "# CDL3LINESTRIKE = talib.CDL3LINESTRIKE(df_15T.open, df_15T.high, df_15T.low, df_15T.close)\n",
    "for col in talib.get_function_groups()['Pattern Recognition']:  \n",
    "  print(np.unique(res_df_[col + '_15T'].to_numpy(), return_counts=True))\n",
    "\n",
    "# CDLCLOSINGMARUBOZU = talib.CDLCLOSINGMARUBOZU(df_15T.open, df_15T.high, df_15T.low, df_15T.close)\n",
    "# print(np.unique(CDLCLOSINGMARUBOZU.to_numpy(), return_counts=True))\n",
    "# print(CDLCLOSINGMARUBOZU.tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2407,
     "status": "ok",
     "timestamp": 1662020394112,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "XrgJPQRuisCa",
    "outputId": "b136b481-cf11-40ed-9bcc-1c12bad3129d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save current res_df \n",
    "\"\"\"\n",
    "\n",
    "res_df_.reset_index().to_feather(data_path, compression='lz4')  # key 잘 확인하고 저장\n",
    "print(data_path, 'saved !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTN3M842Suzl",
    "tags": []
   },
   "source": [
    "## Data concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVAKq3i8Suzm",
    "tags": []
   },
   "source": [
    "### Row concatenation (Feather version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'database/binance/'\n",
    "\n",
    "ticker = \"BTCUSDT_1m.ftr\"\n",
    "\n",
    "old_dir = 'non_cum'\n",
    "old_date = '2021-03-23'  # earlier\n",
    "\n",
    "new_dir = 'non_cum'\n",
    "new_date = '2023-02-21'  # latest\n",
    "\n",
    "old_path = os.path.join(pkg_path, db_path,  old_dir, old_date, \" \".join([cum_date, ticker]))\n",
    "new_path = os.path.join(pkg_path, db_path, new_dir, new_date, \" \".join([non_cum_date, ticker]))\n",
    "\n",
    "old_df = pd.read_feather(old_path, columns=None, use_threads=True).set_index(\"index\")   # key 에 new_date 담겨있음\n",
    "new_df = pd.read_feather(new_path, columns=None, use_threads=True).set_index(\"index\")\n",
    "\n",
    "sum_df = pd.concat([old_df, new_df])\n",
    "sum_df = sum_df[~sum_df.index.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), sum_df.index)))\n",
    "ideal_ts_gap = 60 # * itv_num\n",
    "\n",
    "for ts_i in range(len(np_idx_ts)):\n",
    "\n",
    "  if ts_i != 0:\n",
    "    ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n",
    "    \n",
    "    if ts_gap > ideal_ts_gap or ts_gap < ideal_ts_gap:\n",
    "    # if ts_gap == ideal_ts_gap:  # logic 정상성 확인을 위함.\n",
    "        \n",
    "      print(\"unideal ts_gap : {} {}\".format(sum_df.index[ts_i - 1], sum_df.index[ts_i]))\n",
    "\n",
    "print(\"continuity check done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir_save_path = os.path.join(pkg_path, db_path,  \"cum\", new_date)\n",
    "os.makedirs(database_dir_save_path, exist_ok=True)\n",
    "\n",
    "data_save_path = os.path.join(database_dir_save_path, \" \".join([new_date, ticker]))\n",
    "sum_df.reset_index().to_feather(data_save_path, compression='lz4')\n",
    "\n",
    "print(\"{} saved\".format(data_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### on multiple ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_concate(db_path, ticker, old_dir, new_dir, old_date, new_date):    \n",
    "    \n",
    "    old_path = os.path.join(pkg_path, db_path,  old_dir, old_date, \" \".join([old_date, ticker]))\n",
    "    new_path = os.path.join(pkg_path, db_path, new_dir, new_date, \" \".join([new_date, ticker]))\n",
    "\n",
    "    try:\n",
    "        old_df = pd.read_feather(old_path, columns=None, use_threads=True).set_index(\"index\")   # key 에 new_date 담겨있음\n",
    "        new_df = pd.read_feather(new_path, columns=None, use_threads=True).set_index(\"index\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    sum_df = pd.concat([old_df, new_df])\n",
    "    sum_df = sum_df[~sum_df.index.duplicated(keep='last')]\n",
    "    \n",
    "    np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), sum_df.index)))\n",
    "    ideal_ts_gap = 60 # * itv_num\n",
    "\n",
    "    for ts_i in range(len(np_idx_ts)):\n",
    "\n",
    "      if ts_i != 0:\n",
    "        ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n",
    "\n",
    "        if ts_gap > ideal_ts_gap or ts_gap < ideal_ts_gap:\n",
    "        # if ts_gap == ideal_ts_gap:  # logic 정상성 확인을 위함.\n",
    "\n",
    "          print(\"unideal ts_gap : {} {}\".format(sum_df.index[ts_i - 1], sum_df.index[ts_i]))\n",
    "\n",
    "    print(\"continuity check done\")\n",
    "    \n",
    "    database_dir_save_path = os.path.join(pkg_path, db_path,  \"cum\", new_date)\n",
    "    os.makedirs(database_dir_save_path, exist_ok=True)\n",
    "\n",
    "    data_save_path = os.path.join(database_dir_save_path, \" \".join([new_date, ticker]))\n",
    "    sum_df.reset_index().to_feather(data_save_path, compression='lz4')\n",
    "\n",
    "    print(\"{} saved\".format(data_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'database/binance/'\n",
    "\n",
    "old_dir = 'non_cum'\n",
    "old_date = '2021-03-23'  # earlier\n",
    "\n",
    "new_dir = 'non_cum'\n",
    "new_date = '2023-02-21'  # latest\n",
    "\n",
    "ticker_list = [ticker_.split(\" \")[-1] for ticker_ in os.listdir(os.path.join(pkg_path, db_path,  old_dir, old_date))]\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    row_concate(db_path, ticker, old_dir, new_dir, old_date, new_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUs4fjVHSuzl",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Column concatenation (Feather version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cu-Y82iSuzl"
   },
   "outputs": [],
   "source": [
    "new_dir_path = \"st3m_backi2\"\n",
    "base_dir_path = \"bb1d_backi2\"\n",
    "\n",
    "# new_date = \"2021-11-17\"\n",
    "new_date = \"2022-01-10\"\n",
    "\n",
    "#     save to (new) concat dir    #\n",
    "#      1. if dir. not exists, makedir\n",
    "save_path = './candlestick_concated/res_df/'\n",
    "save_path = os.path.join(save_path, new_dir_path, \"concat/cum\", new_date)   \n",
    "# save_path = os.path.join(save_path, new_dir_path, \"concat/non_cum\", new_date)   # row col 하려면 concat 맞음, noncum 사용\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "#     load ftr list    #\n",
    "# ftr_list = [s for s in os.listdir(os.path.join(save_path, new_dir_path)) if \"ftr\" in s]\n",
    "\n",
    "noncat_path = save_path.replace(\"concat/\", \"noncat/\")\n",
    "ftr_list = [s for s in os.listdir(noncat_path) if \"ftr\" in s]\n",
    "print(ftr_list)\n",
    "# break\n",
    "\n",
    "\n",
    "for key in ftr_list:\n",
    "\n",
    "  if new_date not in key:\n",
    "    continue\n",
    "\n",
    "  try:\n",
    "\n",
    "    #       read from base postfix's directory    #\n",
    "    base_df = pd.read_feather(os.path.join(save_path.replace(new_dir_path, base_dir_path), key), columns=None, use_threads=True).set_index(\"index\")\n",
    "    res_df = pd.read_feather(os.path.join(noncat_path, key), columns=None, use_threads=True).set_index(\"index\")\n",
    "\n",
    "    # print(base_df.head())\n",
    "    # print(res_df.head())\n",
    "    # break\n",
    "\n",
    "    new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n",
    "    # new_res_df.head()\n",
    "\n",
    "    droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n",
    "    # droped_new_res_df.head()\n",
    "    # break\n",
    "\n",
    "    droped_new_res_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n",
    "\n",
    "    # res_df_dict[key] = res_df\n",
    "    # res_df_dict[key] = droped_new_res_df\n",
    "    print(os.path.join(save_path, key), \"saved !\")\n",
    "  \n",
    "  except Exception as e:\n",
    "    print(\"error occured ! :\", e)\n",
    "  \n",
    "\n",
    "  # sample_cnt -= 1\n",
    "\n",
    "  # if sample_cnt <= 0:\n",
    "  #   break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7l5CTJfSuzn",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Check continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-5jn9opBl73"
   },
   "outputs": [],
   "source": [
    "droped_new_res_df = res_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGzMGyC3Suzn"
   },
   "outputs": [],
   "source": [
    "# print(droped_new_res_df.columns)\n",
    "\n",
    "print(droped_new_res_df.iloc[[0, -1]])\n",
    "\n",
    "np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), droped_new_res_df.index)))\n",
    "\n",
    "print(np_idx_ts[:10])\n",
    "for ts_i in range(len(np_idx_ts)):\n",
    "  \n",
    "  if ts_i != 0:\n",
    "    ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n",
    "\n",
    "    if ts_gap > 60 or ts_gap < 60:\n",
    "\n",
    "      print(\"invalid ts_gap found !\")\n",
    "    # if ts_gap == 60:\n",
    "      print(droped_new_res_df.index[ts_i - 1])\n",
    "      print(droped_new_res_df.index[ts_i])\n",
    "      # print(ts_gap)\n",
    "      print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_XGJqBi8Jex",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Check length of front missing value & middle_data non_missing validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14chOHeXh6JD",
    "tags": []
   },
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O87s8_EUakqS",
    "tags": []
   },
   "source": [
    "### instant indi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fg4JnLY6i99D"
   },
   "outputs": [],
   "source": [
    "def get_wave_time_ratio(res_df, wave_itv1, wave_period1):\n",
    "\n",
    "  wave_cu_post_idx_fill_ = res_df['wave_cu_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(int)\n",
    "  wave_co_post_idx_fill_ = res_df['wave_co_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(int)\n",
    "\n",
    "  wave_cu_idx_fill_ = res_df['wave_cu_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(int)\n",
    "  wave_co_idx_fill_ = res_df['wave_co_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(int)\n",
    "\n",
    "  wave_valid_cu_post_idx_fill_ = np.where(wave_cu_post_idx_fill_ < 0, 0, wave_cu_post_idx_fill_)\n",
    "  wave_valid_co_post_idx_fill_ = np.where(wave_co_post_idx_fill_ < 0, 0, wave_co_post_idx_fill_)\n",
    "\n",
    "  wave_valid_cu_idx_fill_ = np.where(wave_cu_idx_fill_ < 0, 0, wave_cu_idx_fill_)\n",
    "  wave_valid_co_idx_fill_ = np.where(wave_co_idx_fill_ < 0, 0, wave_co_idx_fill_)\n",
    "\n",
    "  res_df['short_wave_time_ratio_{}{}'.format(wave_itv1, wave_period1)] = (wave_valid_co_post_idx_fill_ - wave_valid_cu_post_idx_fill_[wave_valid_co_post_idx_fill_[wave_valid_cu_idx_fill_]]) / (wave_valid_cu_idx_fill_ - wave_valid_co_post_idx_fill_)\n",
    "  res_df['long_wave_time_ratio_{}{}'.format(wave_itv1, wave_period1)] = (wave_valid_cu_post_idx_fill_ - wave_valid_co_post_idx_fill_[wave_valid_cu_post_idx_fill_[wave_valid_co_idx_fill_]]) / (wave_valid_co_idx_fill_ - wave_valid_cu_post_idx_fill_)\n",
    "\n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkrbzNFKZhl0"
   },
   "outputs": [],
   "source": [
    "def wave_range_cci_v4_1(t_df, wave_period):\n",
    "    t_df = cci_v2(t_df, wave_period)\n",
    "    itv = pd.infer_freq(t_df.index)\n",
    "\n",
    "    cci_ = t_df['cci_{}{}'.format(itv, wave_period)].to_numpy()\n",
    "    b1_cci_ = t_df['cci_{}{}'.format(itv, wave_period)].shift(1).to_numpy()\n",
    "\n",
    "    baseline = 0\n",
    "    band_width = 100\n",
    "    upper_band = baseline + band_width\n",
    "    lower_band = baseline - band_width\n",
    "\n",
    "    data_cols = ['open', 'high', 'low', 'close']\n",
    "    ohlc_list = [t_df[col_].to_numpy() for col_ in data_cols]\n",
    "    open, high, low, close = ohlc_list\n",
    "\n",
    "    # ============ modules ============ #\n",
    "    # ------ define co, cu ------ # <- point missing 과 관련해 정교해아함\n",
    "    cu_bool = (b1_cci_ > upper_band) & (upper_band > cci_)\n",
    "    co_bool = (b1_cci_ < lower_band) & (lower_band < cci_)\n",
    "\n",
    "    return wave_publics_v2(t_df, cu_bool, co_bool, ohlc_list, wave_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdDkSxbaX4AI"
   },
   "outputs": [],
   "source": [
    "def wave_publics_v2(t_df, cu_bool, co_bool, ohlc_list, wave_period):\n",
    "    itv = pd.infer_freq(t_df.index)\n",
    "\n",
    "    len_df = len(t_df)\n",
    "    len_df_range = np.arange(len_df).astype(int)\n",
    "\n",
    "    cu_idx = get_index_bybool(cu_bool, len_df_range)\n",
    "    co_idx = get_index_bybool(co_bool, len_df_range)\n",
    "\n",
    "    open, high, low, close = ohlc_list\n",
    "\n",
    "    cu_fill_idx, co_fill_idx, cu_prime_idx, co_prime_idx, cu_prime_fill_idx, co_prime_fill_idx, valid_cu_bool, valid_co_bool = get_terms_info_v4(\n",
    "        cu_idx, co_idx, len_df, len_df_range)\n",
    "    # cu_fill_idx, co_fill_idx, cu_prime_idx, co_prime_idx, cu_prime_fill_idx, co_prime_fill_idx, \\\n",
    "    #   cu_post_idx, co_post_idx, cu_post_fill_idx, co_post_fill_idx, valid_cu_bool, valid_co_bool = get_terms_info_v5(cu_idx, co_idx, len_df, len_df_range)\n",
    "\n",
    "    # ------ get post_terms ------ #\n",
    "    high_post_terms = np.vstack((co_fill_idx[valid_cu_bool], cu_idx[valid_cu_bool])).T.astype(int)\n",
    "    low_post_terms = np.vstack((cu_fill_idx[valid_co_bool], co_idx[valid_co_bool])).T.astype(int)\n",
    "\n",
    "    high_post_terms_cnt = high_post_terms[:, 1] - high_post_terms[:, 0]\n",
    "    low_post_terms_cnt = low_post_terms[:, 1] - low_post_terms[:, 0]\n",
    "\n",
    "    # ------ get post_idx ------ #\n",
    "    paired_cu_post_idx = high_post_terms[:, 1]  # Todo, 여기는 cross_idx (위에서 vstack 으로 cross_idx 입력함)\n",
    "    paired_co_post_idx = low_post_terms[:, 1]\n",
    "\n",
    "    cu_post_idx = np.full(len_df, np.nan)  # --> Todo, unavailable : not cross_idx\n",
    "    co_post_idx = np.full(len_df, np.nan)\n",
    "\n",
    "    cu_post_idx[paired_cu_post_idx] = paired_cu_post_idx\n",
    "    co_post_idx[paired_co_post_idx] = paired_co_post_idx\n",
    "\n",
    "    cu_post_fill_idx = fill_arr(cu_post_idx)\n",
    "    co_post_fill_idx = fill_arr(co_post_idx)\n",
    "\n",
    "    # ------ get prime_terms ------ # # 기본은 아래 logic 으로 수행하고, update_hl 도 해당 term 구간의 hl 이 더 작거나 클경우 적용 가능할 것\n",
    "    # high_prime_terms = np.vstack((co_prime_fill_idx[valid_cu_bool], cu_idx[valid_cu_bool])).T.astype(int)\n",
    "    # low_prime_terms = np.vstack((cu_prime_fill_idx[valid_co_bool], co_idx[valid_co_bool])).T.astype(int)\n",
    "\n",
    "    # high_prime_terms_cnt = high_prime_terms[:, 1] - high_prime_terms[:, 0]\n",
    "    # low_prime_terms_cnt = low_prime_terms[:, 1] - low_prime_terms[:, 0]\n",
    "\n",
    "    # paired_prime_cu_idx = high_prime_terms[:, 1]\n",
    "    # paired_prime_co_idx = low_prime_terms[:, 1]\n",
    "\n",
    "    # ====== get wave_hl & terms ====== #\n",
    "    wave_high_ = np.full(len_df, np.nan)\n",
    "    wave_low_ = np.full(len_df, np.nan)\n",
    "\n",
    "    wave_highs = np.array([high[iin:iout + 1].max() for iin, iout in high_post_terms])\n",
    "    wave_lows = np.array([low[iin:iout + 1].min() for iin, iout in low_post_terms])\n",
    "\n",
    "    wave_high_[paired_cu_post_idx] = wave_highs\n",
    "    wave_low_[paired_co_post_idx] = wave_lows\n",
    "\n",
    "    wave_high_fill_ = fill_arr(wave_high_)\n",
    "    wave_low_fill_ = fill_arr(wave_low_)\n",
    "\n",
    "    # ------ Todo, update_hl 에 대해서, post_terms_hl 적용 ------ #\n",
    "    wave_high_terms_low_ = np.full(len_df, np.nan)\n",
    "    wave_low_terms_high_ = np.full(len_df, np.nan)\n",
    "\n",
    "    wave_high_terms_lows = np.array([low[iin:iout + 1].min() for iin, iout in high_post_terms])  # for point rejection, Todo, min_max 설정 항상 주의\n",
    "    wave_low_terms_highs = np.array([high[iin:iout + 1].max() for iin, iout in low_post_terms])\n",
    "\n",
    "    wave_high_terms_low_[paired_cu_post_idx] = wave_high_terms_lows\n",
    "    wave_low_terms_high_[paired_co_post_idx] = wave_low_terms_highs\n",
    "\n",
    "    update_low_cu_bool = wave_high_terms_low_ < wave_low_fill_\n",
    "    update_high_co_bool = wave_low_terms_high_ > wave_high_fill_\n",
    "\n",
    "    # ------ term cnt ------ #\n",
    "    wave_high_terms_cnt_ = np.full(len_df, np.nan)\n",
    "    wave_low_terms_cnt_ = np.full(len_df, np.nan)\n",
    "\n",
    "    wave_high_terms_cnt_[paired_cu_post_idx] = high_post_terms_cnt\n",
    "    wave_low_terms_cnt_[paired_co_post_idx] = low_post_terms_cnt\n",
    "\n",
    "    wave_high_terms_cnt_fill_ = fill_arr(wave_high_terms_cnt_)\n",
    "    wave_low_terms_cnt_fill_ = fill_arr(wave_low_terms_cnt_)\n",
    "\n",
    "    # ------ hl_fill 의 prime_idx 를 찾아야함 ------ #\n",
    "    # b1_wave_high_fill_ = pd.Series(wave_high_fill_).shift(1).to_numpy()\n",
    "    # b1_wave_low_fill_ = pd.Series(wave_low_fill_).shift(1).to_numpy()\n",
    "    # wave_high_prime_idx = np.where((wave_high_fill_ != b1_wave_high_fill_) & ~np.isnan(wave_high_fill_), len_df_range, np.nan)\n",
    "    # wave_low_prime_idx = np.where((wave_low_fill_ != b1_wave_low_fill_) & ~np.isnan(wave_low_fill_), len_df_range, np.nan)\n",
    "    #\n",
    "    # high_prime_idx_fill_ = fill_arr(wave_high_prime_idx)\n",
    "    # low_prime_idx_fill_ = fill_arr(wave_low_prime_idx)\n",
    "\n",
    "    # ============ enlist to df_cols ============ #\n",
    "    t_df['wave_high_fill_{}{}'.format(itv, wave_period)] = wave_high_fill_\n",
    "    t_df['wave_low_fill_{}{}'.format(itv, wave_period)] = wave_low_fill_\n",
    "    t_df['wave_high_terms_cnt_fill_{}{}'.format(itv, wave_period)] = wave_high_terms_cnt_fill_\n",
    "    t_df['wave_low_terms_cnt_fill_{}{}'.format(itv, wave_period)] = wave_low_terms_cnt_fill_\n",
    "\n",
    "    t_df['wave_update_low_cu_bool_{}{}'.format(itv, wave_period)] = update_low_cu_bool  # temporary, for plot_check\n",
    "    t_df['wave_update_high_co_bool_{}{}'.format(itv, wave_period)] = update_high_co_bool\n",
    "\n",
    "    t_df['wave_cu_{}{}'.format(itv, wave_period)] = cu_bool  # * ~update_low_cu_bool\n",
    "    t_df['wave_co_{}{}'.format(itv, wave_period)] = co_bool  # * ~update_high_co_bool\n",
    "    \n",
    "    t_df['wave_cu_idx_fill_{}{}'.format(itv, wave_period)] = cu_fill_idx\n",
    "    t_df['wave_co_idx_fill_{}{}'.format(itv, wave_period)] = co_fill_idx\n",
    "\n",
    "    t_df['wave_co_post_idx_{}{}'.format(itv, wave_period)] = co_post_idx  # paired_\n",
    "    t_df['wave_cu_post_idx_{}{}'.format(itv, wave_period)] = cu_post_idx  # paired_\n",
    "    t_df['wave_co_post_idx_fill_{}{}'.format(itv, wave_period)] = co_post_fill_idx\n",
    "    t_df['wave_cu_post_idx_fill_{}{}'.format(itv, wave_period)] = cu_post_fill_idx\n",
    "\n",
    "    # Todo, idx 저장은 sync. 가 맞는 tf_df 에 대하여 적용하여야함\n",
    "    # ------ for roll prev_hl ------ #\n",
    "    # high_post_idx 를 위해 co_prime_idx 입력 = 뜻 : high_term's prime co_idx (high_prime_idx = wave_high 를 만들기 위한 가장 앞단의 co_idx)\n",
    "    t_df['wave_co_prime_idx_{}{}'.format(itv,\n",
    "                                         wave_period)] = co_prime_idx  # co_prime_idx wave_high_prime_idx  # high 갱신을 고려해, prev_hl 는 prime_idx 기준으로 진행\n",
    "    t_df['wave_cu_prime_idx_{}{}'.format(itv,\n",
    "                                         wave_period)] = cu_prime_idx  # cu_prime_idx wave_low_prime_idx  # cu_prime_idx's low 를 사용하겠다라는 의미, 즉 roll_prev 임\n",
    "    t_df['wave_co_prime_idx_fill_{}{}'.format(itv, wave_period)] = co_prime_fill_idx  # co_prime_fill_idx high_prime_idx_fill_\n",
    "    t_df['wave_cu_prime_idx_fill_{}{}'.format(itv, wave_period)] = cu_prime_fill_idx  # cu_prime_fill_idx low_prime_idx_fill_\n",
    "\n",
    "    # ------ for plot_checking ------ #\n",
    "    t_df['wave_cu_marker_{}{}'.format(itv, wave_period)] = get_line(cu_idx, close)\n",
    "    t_df['wave_co_marker_{}{}'.format(itv, wave_period)] = get_line(co_idx, close)\n",
    "\n",
    "    return t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyGnAMvLYvOZ",
    "tags": []
   },
   "source": [
    "### wave_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1uu9vQnY5dn",
    "tags": []
   },
   "source": [
    "#### plot_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqBXjVPzdccC"
   },
   "outputs": [],
   "source": [
    "i = random.randint(0, len(res_df_))\n",
    "# i = 235290, 512385\n",
    "# i = 74470\n",
    "# i = 82533\n",
    "# i = 387103\n",
    "# i = 370055\n",
    "# i = 687581\n",
    "\n",
    "data_size = 300 # 1500 150\n",
    "assert i > data_size\n",
    "# t_df = res_df.iloc[i - data_size:i + data_size]\n",
    "# t_df = res_df.iloc[i - data_size:i].astype(float)\n",
    "t_df = res_df_.iloc[i - data_size:i].astype(float)\n",
    "a_data = t_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgaNnempXRd_"
   },
   "outputs": [],
   "source": [
    "# wave_itv1, wave_period1 = '15T', 20\n",
    "wave_itv1, wave_period1 = 'T', 20\n",
    "roll_hl_cnt = 3\n",
    "\n",
    "if wave_itv1 != 'T':\n",
    "    offset = '1h' if wave_itv1 != 'D' else '9h'\n",
    "    htf_df_ = to_htf(t_df, wave_itv1, offset=offset)  # to_htf 는 ohlc, 4개의 col 만 존재 (현재까지)\n",
    "    htf_df = htf_df_[~pd.isnull(htf_df_.close)]\n",
    "    \n",
    "    # htf_df = wave_range_bb_v1(htf_df, wave_period1, itv=wave_itv1)\n",
    "    htf_df = wave_range_cci_v4_1(htf_df, wave_period1)\n",
    "    # htf_df = wave_range_cci_v3(htf_df, wave_period1)\n",
    "    # htf_df = wave_range_dc_envel_v1(htf_df, wave_period1)\n",
    "    \n",
    "    cols = list(htf_df.columns[4:])  # 15T_ohlc 를 제외한 wave_range_cci_v4 로 추가된 cols, 다 넣어버리기 (추후 혼란 방지)\n",
    "    \n",
    "    valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(htf_df, wave_itv1, wave_period1,\n",
    "                                                                                                           roll_hl_cnt=roll_hl_cnt)\n",
    "    \n",
    "    \"\"\" \n",
    "    1. wave_bb 의 경우 roll_hl 의 기준이 co <-> cu 변경됨 (cci 와 비교)\n",
    "    2. wave_bb : high_fill_ -> cu_prime_idx 사용\n",
    "    \"\"\"\n",
    "    htf_df = get_roll_wave_data_v2(htf_df, valid_co_prime_idx, roll_co_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1),\n",
    "                                   roll_hl_cnt)\n",
    "    cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "    htf_df = get_roll_wave_data_v2(htf_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "    cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "    htf_df = wave_range_ratio_v4_2(htf_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "    \n",
    "    cols += list(htf_df.columns[-4:])\n",
    "    \n",
    "#     cols = list(htf_df.columns)  # 그냥 다 넣어버리기 (추후 혼란 방지)\n",
    "\n",
    "#     valid_high_prime_idx, valid_low_prime_idx, roll_prev_high_idx_arr, roll_prev_low_idx_arr = roll_wave_hl_idx_v5(htf_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "#     htf_df = get_roll_wave_data_v2(htf_df, valid_high_prime_idx, roll_prev_high_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "#     cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "#     htf_df = get_roll_wave_data_v2(htf_df, valid_low_prime_idx, roll_prev_low_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "#     cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "#     htf_df = wave_range_ratio_v4_2(htf_df, wave_itv1, wave_period1, roll_hl_cnt=3)\n",
    "#     cols += list(htf_df.columns[-4:])  # wrr 은 4개의 cols\n",
    "\n",
    "    # ------ 필요한 cols 만 join (htf's idx 정보는 ltf 와 sync. 가 맞지 않음 - join 불가함) ------ #\n",
    "    t_df.drop(cols, inplace=True, axis=1, errors='ignore')    \n",
    "    t_df = t_df.join(to_lower_tf_v3(t_df, htf_df, cols, backing_i=0, ltf_itv='T').loc[t_df.index], how='inner')\n",
    "    \n",
    "    \n",
    "\n",
    "else:  \n",
    "    # t_df = wave_range_bb_v1(t_df, wave_period1, itv=wave_itv1)\n",
    "    t_df = wave_range_cci_v4_1(t_df, wave_period1, itv=wave_itv1)\n",
    "    # t_df = wave_range_stoch_v1(t_df, wave_period1)\n",
    "    # t_df = wave_range_dc_envel_v1(t_df, wave_period1)\n",
    "\n",
    "    \"\"\" \n",
    "    1. wave_bb 의 경우 roll_hl 의 기준이 co <-> cu 변경됨 (cci 와 비교)\n",
    "    2. wave_bb : high_fill_ -> cu_prime_idx 사용\n",
    "    \"\"\"\n",
    "    valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(t_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "    t_df = get_roll_wave_data_v2(t_df, valid_co_prime_idx, roll_co_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "    t_df = get_roll_wave_data_v2(t_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "\n",
    "    t_df = wave_range_ratio_v4_2(t_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "# t_df = wave_range_v11(t_df, config)\n",
    "# t_df = wave_range_v11_2(t_df, config)\n",
    "# t_df = wave_range_dcbase_v11_3(t_df, config, over_period=2)\n",
    "# t_df = wave_range_cci_v1(t_df, wave_itv1, wave_period1)\n",
    "# t_df = wave_range_v12(t_df, config, ltf_df=None)\n",
    "# t_df = wave_range_v13(t_df, config, ltf_df=None, term_thresh=1)\n",
    "# t_df = wave_range_v14(t_df, config, ltf_df=None, term_thresh1=1, term_thresh2=3)\n",
    "# t_df = wave_range_v15(t_df, config, term_thresh1=2, term_thresh2=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "executionInfo": {
     "elapsed": 2482,
     "status": "ok",
     "timestamp": 1660482394219,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "-Dr_tTk9csFm",
    "outputId": "cbbc017d-db06-458d-ce7d-d3ad9d67a7ad"
   },
   "outputs": [],
   "source": [
    "col_idx_dict = \\\n",
    "{\n",
    "  \"ohlc_col_idxs\": get_col_idxs(t_df, ['open', 'high', 'low', 'close']),\n",
    "}   \n",
    "\n",
    "\n",
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(15, 15), dpi=65)\n",
    "nrows, ncols = 2, 1\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                        ncols=ncols,\n",
    "                        height_ratios=[3, 1]\n",
    "                        )\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "\n",
    "# ------ candles ------ #\n",
    "# candle_plot(a_data[:, col_idx_dict['ohlc_col_idxs']], ax, alpha=1.0, wickwidth=1.0)\n",
    "# candle_plot(a_data[:, col_idx_dict['ohlc_col_idxs']], ax, alpha=1.0)\n",
    "candle_plot_v2(ax, a_data[:, col_idx_dict['ohlc_col_idxs']], alpha=1.0, wickwidth=1.0)\n",
    "# _ = [step_col_plot(a_data[:, params[0]], *params[1:]) for params in col_idx_dict['step_col_info']]\n",
    "\n",
    "len_df = len(t_df)   \n",
    "len_df_range = np.arange(len_df).astype(int)\n",
    "\n",
    "# ============ ============ ============ #\n",
    "plot_size = 100\n",
    "plot_size = len_df\n",
    "# ============ ============ ============ #\n",
    "\n",
    "wave_high_fill_ = t_df['wave_high_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_low_fill_ = t_df['wave_low_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_high_terms_cnt_fill_ = t_df['wave_high_terms_cnt_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_low_terms_cnt_fill_ = t_df['wave_low_terms_cnt_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "wave_cu_idx_ = get_index_bybool(t_df['wave_cu_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "wave_co_idx_ = get_index_bybool(t_df['wave_co_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "# wave_cu_bool_idx_ = get_index_bybool(t_df['wave_cu_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "# wave_co_bool_idx_ = get_index_bybool(t_df['wave_co_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "wave_update_low_cu_bool_idx_ = get_index_bybool(t_df['wave_update_low_cu_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "wave_update_high_co_bool_idx_ = get_index_bybool(t_df['wave_update_high_co_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy(), len_df_range)\n",
    "\n",
    "wave_cu_prime_idx_ = t_df['wave_cu_prime_idx_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_co_prime_idx_ = t_df['wave_co_prime_idx_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_cu_prime_idx_fill_ = t_df['wave_cu_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_co_prime_idx_fill_ = t_df['wave_co_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "wave_cu_post_idx_ = t_df['wave_cu_post_idx_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_co_post_idx_ = t_df['wave_co_post_idx_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_cu_post_idx_fill_ = t_df['wave_cu_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_co_post_idx_fill_ = t_df['wave_co_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "wave_cu_marker_ = t_df['wave_cu_marker_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "wave_co_marker_ = t_df['wave_co_marker_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "# ============ plot_check ============ #\n",
    "# dc_base_ = t_df['dc_base_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "# plt.step(len_df_range, dc_base_, alpha=1.0, color='cyan', linewidth=1)\n",
    "\n",
    "plt.step(len_df_range, wave_cu_marker_, \"o\", alpha=1.0, color='#ff00ff', markersize=5)\n",
    "plt.step(len_df_range, wave_co_marker_, \"o\", alpha=1.0, color='#00ff00', markersize=5)\n",
    "\n",
    "# plt.step(len_df_range, t_df['dc_upper_{}{}'.format(wave_itv1, wave_period1)], color='#ffeb3b')\n",
    "# plt.step(len_df_range, t_df['dc_lower_{}{}'.format(wave_itv1, wave_period1)], color='#ffeb3b')\n",
    "\n",
    "# plt.step(len_df_range, t_df['bb_upper_{}{}'.format(wave_itv1, wave_period1)], color='#ffeb3b')\n",
    "# plt.step(len_df_range, t_df['bb_lower_{}{}'.format(wave_itv1, wave_period1)], color='#ffeb3b')\n",
    "\n",
    "# [plt.axvline(int(idx_), color=\"#ff0000\") for idx_ in wave_cu_bool_idx_ if not np.isnan(idx_)]\n",
    "# [plt.axvline(int(idx_), color=\"#0000ff\") for idx_ in wave_co_bool_idx_ if not np.isnan(idx_)]\n",
    "[plt.axvline(int(idx_), color=\"#ff0000\") for idx_ in wave_update_low_cu_bool_idx_ if not np.isnan(idx_)]\n",
    "[plt.axvline(int(idx_), color=\"#0000ff\") for idx_ in wave_update_high_co_bool_idx_ if not np.isnan(idx_)]\n",
    "\n",
    "# [plt.axvline(int(idx_), color=\"#ff00ff\") for idx_ in wave_cu_idx_ if not np.isnan(idx_)]\n",
    "# [plt.axvline(int(idx_), color=\"#00ff00\") for idx_ in wave_co_idx_ if not np.isnan(idx_)]\n",
    "\n",
    "[plt.axvline(int(idx_), color=\"#00ff00\") for idx_ in wave_co_prime_idx_ if not np.isnan(idx_)]\n",
    "[plt.axvline(int(idx_), color=\"#ff00ff\") for idx_ in wave_cu_prime_idx_ if not np.isnan(idx_)]\n",
    "\n",
    "plt.step(len_df_range, wave_high_fill_, \"*\", alpha=1.0, color='#00ff00', markersize=6)\n",
    "plt.step(len_df_range, wave_low_fill_, \"*\", alpha=1.0, color='#ff00ff', markersize=6)\n",
    "\n",
    "# ------ data check in gs[0] ------ #\n",
    "# plt.axvline(wave_cu_post_idx_fill_[230], color='r')\n",
    "# plt.axvline(wave_cu_prime_idx_fill_[230])\n",
    "window_idx = 182\n",
    "plt.axvline(window_idx)\n",
    "\n",
    "plt.xlim(0, plot_size)\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "\n",
    "# --- cci --- #\n",
    "cci_ = t_df['cci_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "plt.step(len_df_range, cci_, alpha=1.0, color='yellow', linewidth=2)\n",
    "plt.axhline(100, color=\"#ffffff\")\n",
    "plt.axhline(-100, color=\"#ffffff\")\n",
    "\n",
    "# --- stoch --- #\n",
    "# stoch_ = t_df['stoch_{}{}33'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "# plt.step(len_df_range, stoch_, alpha=1.0, color='yellow', linewidth=2)\n",
    "# plt.axhline(67, color=\"#ffffff\")\n",
    "# plt.axhline(33, color=\"#ffffff\")\n",
    "\n",
    "[plt.axvline(int(idx_), color=\"#ff00ff\") for idx_ in wave_cu_idx_ if not np.isnan(idx_)]\n",
    "[plt.axvline(int(idx_), color=\"#00ff00\") for idx_ in wave_co_idx_ if not np.isnan(idx_)]   # long 이라서 초록색임\n",
    "\n",
    "# plt.step(len_df_range, wave_high_terms_cnt_fill_, alpha=1.0, color='yellow', linewidth=2)\n",
    "# plt.step(len_df_range, wave_low_terms_cnt_fill_, alpha=1.0, color='yellow', linewidth=2)\n",
    "# plt.step(len_df_range, wave_high_terms_cnt_fill_, \"*\", alpha=1.0, color='#00ff00', markersize=6)\n",
    "# plt.step(len_df_range, wave_low_terms_cnt_fill_, \"*\", alpha=1.0, color='#ff00ff', markersize=6)\n",
    "\n",
    "\n",
    "plt.xlim(0, plot_size)  # for sync. with gs[0]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2yVTn1tnxMn",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### data_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(window_idx)\n",
    "print(t_df['wave_high_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 1)][window_idx])\n",
    "print(t_df['wave_high_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 2)][window_idx])\n",
    "print(t_df['wave_high_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 3)][window_idx])\n",
    "print(t_df['wave_low_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 1)][window_idx])\n",
    "print(t_df['wave_low_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 2)][window_idx])\n",
    "print(t_df['wave_low_fill_{}{}_-{}'.format(wave_itv1, wave_period1, 3)][window_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(t_df, wave_itv1, wave_period1,\n",
    "#                                                                                                            roll_hl_cnt=roll_hl_cnt)\n",
    "        \n",
    "# t_df = get_roll_wave_data_v2(t_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1),\n",
    "#                                roll_hl_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_co_prime_idx_[~pd.isnull(wave_co_prime_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_co_prime_idx\n",
    "roll_co_idx_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1660483201485,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "6bra-Br3lq1h",
    "outputId": "8c90e368-24c7-439e-9733-567d4848859a"
   },
   "outputs": [],
   "source": [
    "# print(valid_high_prime_idx)  # = valid_co_prime_idx\n",
    "# print(roll_prev_high_idx_arr)   # = roll_prev_co_idx_arr\n",
    "print(valid_low_prime_idx)  # = valid_co_prime_idx\n",
    "print(roll_prev_low_idx_arr)   # = roll_prev_co_idx_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1660484147094,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "0DgdFydfB1f-",
    "outputId": "1677cb32-6a71-4292-b49a-204f7da8ed20"
   },
   "outputs": [],
   "source": [
    "idx = 239\n",
    "# print(wave_cu_post_idx_fill_[idx])\n",
    "# print(wave_co_prime_idx_fill_[idx - 1])\n",
    "# print(wave_co_post_idx_fill_[idx - 1])\n",
    "# print(wave_co_prime_idx_fill_[idx])\n",
    "print(wave_co_post_idx_fill_[int(wave_cu_post_idx_fill_[idx])])\n",
    "print(wave_co_idx_[idx])\n",
    "\n",
    "# print(len(t_df))\n",
    "# len(wave_co_prime_idx_fill_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MNVIExLULhJ",
    "tags": []
   },
   "source": [
    "### legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpyP5t8Ht_pE",
    "tags": []
   },
   "source": [
    "#### calc recursive indi's min_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1Hbm4OA4Tkk"
   },
   "outputs": [],
   "source": [
    "ticker_prcn = get_precision_by_price(res_df.close.iloc[-1]) + 2\n",
    "\n",
    "target_len = 300000\n",
    "slice_len_list = list(range(50, 10000, 100))\n",
    "slice_len_list.insert(0, target_len)\n",
    "\n",
    "start_0 = time.time()\n",
    "# prev_int_, prev_pnts_ = None, None\n",
    "offset = 1\n",
    "\n",
    "for sl_idx, sample_len in enumerate(slice_len_list):\n",
    "\n",
    "  sample_df = res_df.iloc[-sample_len -offset:-offset]\n",
    "  sample_len2 = sample_len\n",
    "\n",
    "  # --------- input using indi.s --------- #\n",
    "  # res = ema_v0(sample_df['close'], 190)\n",
    "  res = rsi(sample_df, 14)\n",
    "\n",
    "    #    to_htf()    #\n",
    "  # df_5T = to_htf(sample_df, itv_='5T', offset='1h')\n",
    "  # sample_len2 = len(df_5T)\n",
    "\n",
    "  # # --------- input using htf_indi. --------- #\n",
    "  # res = ema(df_5T['close'], 195)\n",
    "  # -------------------------------------- #\n",
    "\n",
    "  res_last_row = res.iloc[-1]\n",
    "  if pd.isnull(res_last_row):\n",
    "    continue\n",
    "\n",
    "  # print(res_last_row)\n",
    "  # break\n",
    "\n",
    "  # sample_df = sample_df.join(to_lower_tf_v2(sample_df, df_5T, [-1]), how='inner')\n",
    "\n",
    "\n",
    "  #   자리수 분할 계산    #\n",
    "  int_, points_ = str(res_last_row).split('.')\n",
    "  pnts_ = points_[:ticker_prcn]\n",
    "\n",
    "  if sl_idx == 0:\n",
    "    target_int_ = int_\n",
    "    target_pnts_ = pnts_\n",
    "    print(\"target {} ({}) -> {} {}\".format(sample_len, sample_len2, int_, points_))\n",
    "\n",
    "  else:\n",
    "    if target_int_ == int_ and target_pnts_ == pnts_:\n",
    "      # print(sample_len, \"({})\".format(sample_len2), '->', int_, pnts_, end='\\n\\n')\n",
    "      print(\"{} ({}) -> {} {}\\n\".format(sample_len, sample_len2, int_, points_))\n",
    "      break\n",
    "\n",
    "print(time.time() - start_0)  # (1301)(1361)(1301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOXQbXixiQcK",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### volume_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pFuazxpgx9B"
   },
   "outputs": [],
   "source": [
    "session_df = res_df_.iloc[-1440:] # 0.159 -> 0.024 (14400 -> 1440)\n",
    "volume = session_df['volume'].to_numpy()\n",
    "close = session_df['close'].to_numpy()\n",
    "# px.histogram(session_df, x='volume', y='close', nbins=150, orientation='h').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoPJkiyKiXLM"
   },
   "outputs": [],
   "source": [
    "kde_factor = 0.05\n",
    "num_samples = 100\n",
    "\n",
    "start_0 = time.time()\n",
    "kde = stats.gaussian_kde(close,weights=volume,bw_method=kde_factor)\n",
    "kdx = np.linspace(close.min(),close.max(),num_samples)\n",
    "kdy = kde(kdx)\n",
    "ticks_per_sample = (kdx.max() - kdx.min()) / num_samples\n",
    "print(\"ticks_per_sample :\", ticks_per_sample)  # sample 당 가격\n",
    "print(\"kdy elapsed_time :\", time.time() - start_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mK2jBddAxJ14"
   },
   "outputs": [],
   "source": [
    "peaks,_ = signal.find_peaks(kdy)\n",
    "pkx = kdx[peaks]\n",
    "pky = kdy[peaks]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "# plt.hist(close, bins=num_samples, weights=volume, alpha=.8, color='#1592e6')\n",
    "# plt.plot(kdx, kdy, color='white')\n",
    "# plt.plot(pkx, pky, 'bo', color='yellow')\n",
    "plt.plot(kdy, kdx, color='white')\n",
    "plt.plot(pky, pkx, 'bo', color='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8tpQZCy0SO1"
   },
   "outputs": [],
   "source": [
    "pkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfA946s8UgS0"
   },
   "outputs": [],
   "source": [
    "# ------ vp 의 indi. 화가 필요함 -> point 설정 ------ #\n",
    "# 1. 4 level 은 미리 만들어놓는게 맞는걸로 보임 -> 추종하는 function 이 많음 (utils_tr, ep_out ...)\n",
    "#   a. 4 level 에 국한하는게 아니라, 모든 peaks 에 대해 levels 설정\n",
    "#   b. 각 session 별로 peak_list 가 주어질 것\n",
    "#     i. prev_data 사용해야하는점 주의 (session vp 는 future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3T-9FwWFXR4f",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### prominence_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqj944n-WzyZ"
   },
   "outputs": [],
   "source": [
    "# peaks  # ndarray\n",
    "# kdx  # ndarray\n",
    "# kdy  # ndarray\n",
    "# kdx.min()\n",
    "left_base * ticks_per_sample\n",
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rvqv0RGojo9h"
   },
   "outputs": [],
   "source": [
    "print(peak_y)\n",
    "print(peak_props['prominences'])\n",
    "peak_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2729DJ6h720",
    "tags": []
   },
   "source": [
    "#### imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rucj-iepiR_-"
   },
   "outputs": [],
   "source": [
    "t_df = res_df_.iloc[-120:-100]\n",
    "a_data = t_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktm1aB-Bh7GH"
   },
   "outputs": [],
   "source": [
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "nrows, ncols = 1, 1\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                        ncols=ncols\n",
    "                        # height_ratios=[3, 1]\n",
    "                        )\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "\n",
    "# ------ candles ------ #\n",
    "candle_plot(a_data[:, col_idx_dict['ohlc_col_idxs']], ax, alpha=1.0, wickwidth=1.0)\n",
    "_ = [step_col_plot(a_data[:, params[0]], *params[1:]) for params in col_idx_dict['step_col_info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMQBhQ1Ljt5Y"
   },
   "outputs": [],
   "source": [
    "def imb_ratio_v4(df, itv):\n",
    "\n",
    "  itv_num = itv_to_number(itv)\n",
    "\n",
    "  close = df['close_{}'.format(itv)].to_numpy()\n",
    "  open = df['open_{}'.format(itv)].to_numpy()\n",
    "\n",
    "  b1_close = df['close_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_open = df['open_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_high = df['high_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_low = df['low_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "\n",
    "  body_range = abs(close - open)\n",
    "  b1_body_range = abs(b1_close - b1_open)\n",
    "\n",
    "  df['body_rel_ratio_{}'.format(itv)] = body_range / b1_body_range\n",
    "\n",
    "  short_body_range = np.where(close <= b1_low, body_range, b1_body_range)\n",
    "  long_body_range = np.where(close >= b1_high, body_range, b1_body_range)\n",
    "\n",
    "  # 추후에 통계 측정해야함 -> bir 에 따른 개별 trader 의 epout / tpep 이라던가 => short 에 양봉은 취급안함 (why use np.nan)\n",
    "  df['short_ir_{}'.format(itv)] = np.where(close < open, (b1_low - close) / short_body_range, np.nan) # close < open & close < b1_low\n",
    "  df['long_ir_{}'.format(itv)] = np.where(close > open, (close - b1_high) / long_body_range, np.nan) # close > open & close > b1_high\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1Vq_BiKpY3P"
   },
   "outputs": [],
   "source": [
    "def imb_ratio_v3(df, itv):\n",
    "\n",
    "  itv_num = itv_to_number(itv)\n",
    "\n",
    "  # high = df['high_{}'.format(itv)].to_numpy()\n",
    "  # low = df['low_{}'.format(itv)].to_numpy()\n",
    "  # candle_range = high - low\n",
    "\n",
    "  close = df['close_{}'.format(itv)].to_numpy()\n",
    "  open = df['open_{}'.format(itv)].to_numpy()\n",
    "\n",
    "  b1_close = df['close_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_open = df['open_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_high = df['high_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "  b1_low = df['low_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "\n",
    "  body_range = abs(close - open)\n",
    "  b1_body_range = abs(b1_close - b1_open)\n",
    "\n",
    "  df['body_rel_ratio_{}'.format(itv)] = body_range / b1_body_range\n",
    "\n",
    "  short_body_ratio = np.where(close <= b1_low, body_range, b1_body_range)\n",
    "  long_body_range = np.where(close >= b1_high, body_range, b1_body_range)\n",
    "\n",
    "  # 추후에 통계 측정해야함 -> bir 에 따른 개별 trader 의 epout / tpep 이라던가 => short 에 양봉은 취급안함 (why use np.nan)\n",
    "  df['short_ir_{}'.format(itv)] = np.where(close < open, (b1_low - close) / body_range, np.nan) # close < open & close < b1_low\n",
    "  df['long_ir_{}'.format(itv)] = np.where(close > open, (close - b1_high) / body_range, np.nan) # close > open & close > b1_high\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtnMUkhwkdrE"
   },
   "outputs": [],
   "source": [
    "imb_ratio(t_df, \"5T\")\n",
    "# imb_ratio_v3(t_df, \"5T\")\n",
    "# imb_ratio_v4(t_df, \"5T\")\n",
    "\n",
    "t_df.tail(100).short_ir_5T  # .461871\n",
    "# t_df.iloc[:, -10:]\n",
    "# t_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVUs1YE_pgBI"
   },
   "outputs": [],
   "source": [
    "# imb_ratio(t_df, \"5T\")\n",
    "# imb_ratio_v3(t_df, \"5T\")\n",
    "imb_ratio_v4(t_df, \"5T\")\n",
    "\n",
    "t_df.tail(100).short_ir_5T  # .461871\n",
    "# t_df.iloc[:, -10:]\n",
    "# t_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bieHiKjBkuFL"
   },
   "outputs": [],
   "source": [
    "# ------ rtc 1, 0 개념 ------ #\n",
    "# short_rtc_1 = close\n",
    "# short_rtc_0 = b1_low\n",
    "\n",
    "# long_rtc_1 = close\n",
    "# long_rtc_0 = b1_high\n",
    "\n",
    "# rtc 로 활용하려면, col 로 추가해야할 것 -> 추가할만한 col_name 은 아님\n",
    "# 1. h_candle 인 경우 -> ?\n",
    "#   a. h_candle_v3 먹이고, open_{}.shift(num_itv).to_numpy() 진행 -> ex. res_df['close_{}'.format(hc_itv)].shift(itv_num).to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X6bMXJIjPYy"
   },
   "outputs": [],
   "source": [
    "# 1. 현재 종가 - 이전 고가 = imb_range (long)\n",
    "long_imb_range = t_df.close - t_df.high.shift(1)\n",
    "# 2. 이전 저가 - 현재 종가 - imb_range (short)\n",
    "short_imb_range = t_df.low.shift(1) - t_df.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsyPhNR8yP1c",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1nEA19v7Qpj"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "\n",
    "def _calc_dev(base_price, price):\n",
    "    return 100 * (price - base_price) / base_price\n",
    "\n",
    "\n",
    "def zigzag(highs, lows, depth=10, dev_threshold=5):\n",
    "    def pivots(src_raw, length, isHigh):\n",
    "        src = list(reversed(src_raw))\n",
    "        bar_index = list(range(len(src)))\n",
    "        for start in range(0, len(src)):\n",
    "            if start + 2 * length + 1 > len(src) - 1:\n",
    "                return\n",
    "            p = 0\n",
    "            if length < len(src) - start:\n",
    "                p = src[start + length]\n",
    "            if length == 0:\n",
    "                yield 0, p\n",
    "            else:\n",
    "                isFound = True\n",
    "                for i in range(start, start + length):\n",
    "                    if isHigh and src[i] > p:\n",
    "                        isFound = False\n",
    "                    if not isHigh and src[i] < p:\n",
    "                        isFound = False\n",
    "                for i in range(start + length + 1, start + 2 * length + 1):\n",
    "                    if isHigh and src[i] >= p:\n",
    "                        isFound = False\n",
    "                    c = not isHigh and src[i] <= p\n",
    "                    if c:\n",
    "                        isFound = False\n",
    "                if isFound:\n",
    "                    yield (bar_index[start + length], p)\n",
    "                else:\n",
    "                    yield None, None\n",
    "\n",
    "    data_highs = [x for x in pivots(highs, floor(depth / 2), True) if x[0]]\n",
    "    data_lows = [x for x in pivots(lows, floor(depth / 2), False) if x[0]]\n",
    "\n",
    "    raw_pairs = []\n",
    "\n",
    "    for i, (ind, p) in enumerate(data_highs):\n",
    "        lows_d = sorted([(ind_l, p_l) for ind_l, p_l in data_lows if ind > ind_l], key=lambda x: x[0])\n",
    "        if lows_d:\n",
    "            lows = lows_d[-1]\n",
    "\n",
    "            if abs(_calc_dev(lows[1], p)) >= dev_threshold:\n",
    "                raw_pairs.append(\n",
    "                    ((ind, p),\n",
    "                     (lows[0], lows[1]))\n",
    "                )\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for (i_h, p_h),(i_l, p_l) in raw_pairs:\n",
    "        if not result:\n",
    "            result.append(((i_h, p_h),(i_l, p_l)))\n",
    "            continue\n",
    "\n",
    "        if i_l == result[-1][1][0]:\n",
    "            if p_h > result[-1][0][1]:\n",
    "                result = result[:-1]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        result.append(((i_h, p_h),(i_l, p_l)))\n",
    "\n",
    "    return result\n",
    "\n",
    "# highs, lows = t_df.high.to_numpy(), t_df.low.to_numpy()\n",
    "# zigzag(highs, lows, depth=5, dev_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGlmdyb97j4Q"
   },
   "outputs": [],
   "source": [
    "t_df = res_df_.iloc[-120:]\n",
    "a_data = t_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ropzIp0wUPAA"
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "def get_dist_plot(c, v, kx, ky):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(name='Vol Profile', x=c, y=v, nbinsx=150, \n",
    "                               histfunc='sum', histnorm='probability density',\n",
    "                               marker_color='#B0C4DE'))\n",
    "    fig.add_trace(go.Scatter(name='KDE', x=kx, y=ky, mode='lines', marker_color='#D2691E'))    \n",
    "\n",
    "    peaks,_ = signal.find_peaks(kdy)\n",
    "    pkx = kdx[peaks]\n",
    "    pky = kdy[peaks]\n",
    "    pk_marker_args=dict(size=10, color='black')\n",
    "    fig.add_trace(go.Scatter(name=\"Peaks\", x=pkx, y=pky, mode='markers', marker=pk_marker_args))\n",
    "    fig.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLWAP1Cl2Hvu"
   },
   "outputs": [],
   "source": [
    "def wave_range_ratio(res_df, config, bb_itv, bb_period):\n",
    "\n",
    "  wave_itv = pd.infer_freq(res_df.index)\n",
    "  wave_period = config.tr_set.wave_period\n",
    "\n",
    "  bb_upper_ = res_df['bb_upper_{}{}'.format(bb_itv, bb_period)].to_numpy()\n",
    "  bb_lower_ = res_df['bb_lower_{}{}'.format(bb_itv, bb_period)].to_numpy()\n",
    "  \n",
    "  cu_prime_idx_fill_ = res_df['wave_cu_prime_idx_fill_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "  co_prime_idx_fill_ = res_df['wave_co_prime_idx_fill_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "\n",
    "  cu_bb_range = get_line(co_prime_idx_fill_, bb_upper_) - get_line(co_prime_idx_fill_, bb_lower_)  # cu 에서 co_prime 의 bb_range 사용\n",
    "  co_bb_range = get_line(cu_prime_idx_fill_, bb_upper_) - get_line(cu_prime_idx_fill_, bb_lower_)\n",
    "\n",
    "  wave_range = res_df['wave_high_fill_{}{}'.format(wave_itv, wave_period)].to_numpy() - res_df['wave_low_fill_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "  \n",
    "  res_df['cu_wrr_{}{}'.format(wave_itv, wave_period)] = wave_range / cu_bb_range   # for cu (currently, long)\n",
    "  res_df['co_wrr_{}{}'.format(wave_itv, wave_period)] = wave_range / co_bb_range\n",
    "\n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_zPYIshbZgP"
   },
   "outputs": [],
   "source": [
    "# Todo, future_data\n",
    "def enough_space(res_df, itv, period):\n",
    "\n",
    "  dc_upper_ = res_df['dc_upper_{}{}'.format(itv, period)].to_numpy()\n",
    "  dc_base_ = res_df['dc_base_{}{}'.format(itv, period)].to_numpy()\n",
    "  dc_lower_ = res_df['dc_lower_{}{}'.format(itv, period)].to_numpy()  \n",
    "  high_ = res_df['high_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "  low_ = res_df['low_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "\n",
    "  half_dc_gap = dc_upper_ - dc_base_\n",
    "\n",
    "  res_df['cu_es_{}{}'.format(itv, period)] = (low_ - dc_lower_) / half_dc_gap\n",
    "  res_df['co_es_{}{}'.format(itv, period)] = (dc_upper_ - high_) / half_dc_gap\n",
    "\n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3IUBc59VR5D"
   },
   "outputs": [],
   "source": [
    "# Todo, future_data\n",
    "def candle_range_ratio(res_df, c_itv, bb_itv, bb_period):\n",
    "\n",
    "  itv_num = itv_to_number(c_itv)\n",
    "\n",
    "  b1_bb_upper_ = res_df['bb_upper_{}{}'.format(bb_itv, bb_period)].shift(itv_num).to_numpy()\n",
    "  b1_bb_lower_ = res_df['bb_lower_{}{}'.format(bb_itv, bb_period)].shift(itv_num).to_numpy()\n",
    "  bb_range = b1_bb_upper_ - b1_bb_lower_   # <-- h_candle's open_idx 의 bb_gap 사용\n",
    "\n",
    "  high_ = res_df['high_{}'.format(c_itv)].to_numpy()\n",
    "  low_ = res_df['low_{}'.format(c_itv)].to_numpy()\n",
    "  candle_range = high_ - low_  # 부호로 양 / 음봉 구분 (양봉 > 0)\n",
    "  \n",
    "  res_df['crr_{}'.format(c_itv)] = candle_range / bb_range\n",
    "\n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3yFd8Dcok5m"
   },
   "outputs": [],
   "source": [
    "def body_rel_ratio(res_df, c_itv):\n",
    "\n",
    "  itv_num = itv_to_number(c_itv)\n",
    "  \n",
    "  b1_close_ = res_df['close_{}'.format(c_itv)].shift(itv_num).to_numpy()\n",
    "  b1_open_ = res_df['open_{}'.format(c_itv)].shift(itv_num).to_numpy()\n",
    "  b1_body_range = abs(b1_close_ - b1_open_)\n",
    "\n",
    "  close_ = res_df['close_{}'.format(c_itv)].to_numpy()\n",
    "  open_ = res_df['open_{}'.format(c_itv)].to_numpy()\n",
    "  body_range = abs(close_ - open_)\n",
    "  \n",
    "  res_df['body_rel_ratio_{}'.format(c_itv)] = body_range / b1_body_range\n",
    "\n",
    "  return res_df\n",
    "\n",
    "def dc_over_body_ratio(res_df, c_itv, dc_itv, dc_period):\n",
    "  close_ = res_df['close_{}'.format(c_itv)].to_numpy()\n",
    "  open_ = res_df['open_{}'.format(c_itv)].to_numpy()\n",
    "  body_range = abs(close_ - open_)\n",
    "  \n",
    "  dc_upper_ = res_df['dc_upper_{}{}'.format(dc_itv, dc_period)].to_numpy()\n",
    "  dc_lower_ = res_df['dc_lower_{}{}'.format(dc_itv, dc_period)].to_numpy() \n",
    "\n",
    "  res_df['dc_upper_{}{}_br'.format(dc_itv, dc_period)] = (close_ - dc_upper_) / body_range\n",
    "  res_df['dc_lower_{}{}_br'.format(dc_itv, dc_period)] = (dc_lower_ - close_) / body_range\n",
    "\n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWj02LLGbnji"
   },
   "outputs": [],
   "source": [
    "def candle_pumping_ratio_v2(res_df, c_itv, dc_itv, period):\n",
    "\n",
    "  res_df = dc_line_v3(res_df, dc_itv, dc_period=period)\n",
    "\n",
    "  dc_upper_ = res_df['dc_upper_{}{}'.format(dc_itv, period)].to_numpy()\n",
    "  dc_lower_ = res_df['dc_lower_{}{}'.format(dc_itv, period)].to_numpy()\n",
    "  dc_range = dc_upper_ - dc_lower_\n",
    " \n",
    "  open_ = res_df['open_{}'.format(c_itv)].to_numpy()\n",
    "  close_ = res_df['close_{}'.format(c_itv)].to_numpy()\n",
    "  body = close_ - open_  # 부호로 양 / 음봉 구분 (양봉 > 0)\n",
    "  \n",
    "  res_df['cppr_{}'.format(c_itv)] = body / dc_range\n",
    "\n",
    "  return res_df\n",
    "\n",
    "\n",
    "# Todo, future_data\n",
    "def candle_pumping_ratio(res_df, c_itv, bb_itv, period):\n",
    "\n",
    "  itv_num = itv_to_number(c_itv)\n",
    "\n",
    "  # 여기에도 v2 처럼 bb_indi. 추가 (자동화)\n",
    "\n",
    "  b1_bb_upper_ = res_df['bb_upper_{}{}'.format(bb_itv, period)].shift(itv_num).to_numpy()\n",
    "  b1_bb_lower_ = res_df['bb_lower_{}{}'.format(bb_itv, period)].shift(itv_num).to_numpy()\n",
    "  bb_range = b1_bb_upper_ - b1_bb_lower_\n",
    "\n",
    "  open_ = res_df['open_{}'.format(c_itv)].to_numpy()\n",
    "  close_ = res_df['close_{}'.format(c_itv)].to_numpy()\n",
    "  body = close_ - open_  # 부호로 양 / 음봉 구분 (양봉 > 0)\n",
    "  \n",
    "  res_df['cppr_{}'.format(c_itv)] = body / bb_range\n",
    "\n",
    "  return res_df\n",
    "\n",
    "\n",
    "def pumping_ratio(res_df, config, itv, period1, period2):\n",
    "\n",
    "  bb_lower_5T = res_df['bb_lower_5T'].to_numpy()\n",
    "  bb_upper_5T = res_df['bb_upper_5T'].to_numpy()\n",
    "  bb_range = bb_upper_5T - bb_lower_5T\n",
    "\n",
    "  selection_id = config.selection_id\n",
    "  \n",
    "  res_df['short_ppr_{}'.format(selection_id)] = res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() / get_line(res_df['short_wave_high_idx_{}{}{}'.format(itv, period1, period2)].to_numpy(), bb_range)\n",
    "  res_df['long_ppr_{}'.format(selection_id)] = res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() / get_line(res_df['long_wave_low_idx_{}{}{}'.format(itv, period1, period2)].to_numpy(), bb_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpkclLSzazZ-"
   },
   "outputs": [],
   "source": [
    "def wave_body_ratio(res_df_, itv, period):\n",
    "  dc_upper_ = res_df_['dc_upper_{}{}'.format(itv, period)].to_numpy()\n",
    "  dc_lower_ = res_df_['dc_lower_{}{}'.format(itv, period)].to_numpy()\n",
    "  close_ = res_df_['close_{}'.format(itv)].to_numpy()\n",
    "  open_ = res_df_['open_{}'.format(itv)].to_numpy()\n",
    "\n",
    "  dc_range = dc_upper_ - dc_lower_\n",
    "  body_range = abs(close_ - open_)\n",
    "\n",
    "  res_df_['wave_body_ratio'] = body_range / dc_range\n",
    "  res_df_['dc_upper_body_ratio'] = (np.maximum(close_, open_) - dc_upper_) / body_range\n",
    "  res_df_['dc_lower_body_ratio'] = (dc_lower_) - np.minimum(close_, open_) / body_range\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-zzitQRbnz8"
   },
   "outputs": [],
   "source": [
    "# res_df_['wave_body_ratio'].tail(200)\n",
    "\n",
    "itv = 'H'\n",
    "period = 5\n",
    "wave_body_ratio(res_df_, itv, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_second(index_row):\n",
    "    splited_time = str(index_row).split(':') # [-2:] = '59.999000'\n",
    "    splited_time[-1] = '59.999000'\n",
    "    return pd.to_datetime(':'.join(splited_time))\n",
    "\n",
    "print(res_df_.index[0])\n",
    "print(change_second(res_df_.index[0]))\n",
    "res_df_.index = list(map(change_second, res_df_.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.infer_freq(to_htf(res_df_, '15T', '1h').index)) # --> None 인 이유는, 폐장 시간 때문에 (중간에 공백기간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(res_df_.head())\n",
    "\n",
    "# print(pd.to_datetime(res_df_.index)) #, format='%Y-%M-%D'))\n",
    "# Todo, int64Index -> timeIndex 로 변환하는 작업이 먼저 필요할 것\n",
    "# to_htf(res_df_, itv_='30T', offset='1H')\n",
    "str_index = res_df_.index.astype(str)\n",
    "type(str_index[0])\n",
    "str_index\n",
    "\n",
    "def str_to_date(str_date):\n",
    "    year = str_date[:4]\n",
    "    month = str_date[4:6]\n",
    "    day = str_date[6:8]\n",
    "    hour = str_date[8:10]\n",
    "    min_ = str_date[10:12]\n",
    "    \n",
    "    new_str_date = \"%s-%s-%s %s:%s:59.999000\".format(year, month, day, hour, min_)\n",
    "    new_str_date = \"%s-%s-%s %s:%s:59\" % (year, month, day, hour, min_)\n",
    "    \n",
    "    # return new_str_date\n",
    "    return datetime.strptime(new_str_date, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    \n",
    "    \n",
    "list(map(lambda x: str_to_date(x), str_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSUY4nnku3s9",
    "tags": []
   },
   "source": [
    "## legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEKyVbHWSuzi",
    "tags": []
   },
   "source": [
    "### Database utility (file extension conversion & else)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bw5JibDKSuzj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### xlsx to feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VA-_gcA7Suzj"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "exist_list = os.listdir(save_path)\n",
    "\n",
    "\n",
    "a_day = 3600 * 24\n",
    "\n",
    "for i in tqdm(range(len(file_list))):\n",
    "\n",
    "  keys = [file_list[i]]\n",
    "\n",
    "  # if 'neo'.upper() not in file_list[i]:\n",
    "    # continue\n",
    "\n",
    "  # if '2021-04-30'.upper() not in file_list[i]:\n",
    "  # if '2021-07-01'.upper() not in file_list[i]:\n",
    "  if '2021-10-10'.upper() not in file_list[i]:\n",
    "    continue\n",
    "\n",
    "\n",
    "  for key in keys:      \n",
    "\n",
    "    # if 'eth'.upper() not in key:\n",
    "    #   continue\n",
    "\n",
    "    feather_name = key.replace(\".xlsx\", \".ftr\")\n",
    "    # feather_path = save_path + feather_name\n",
    "\n",
    "    if feather_name in exist_list:\n",
    "      print(feather_name, \"already exist !\")\n",
    "      continue\n",
    "    \n",
    "    open_indexes = []\n",
    "    \n",
    "    df = pd.read_excel(date_path + key, index_col=0)\n",
    "    second_df = pd.read_excel(date_path2 + key, index_col=0)\n",
    "    third_df = pd.read_excel(date_path3 + key, index_col=0)\n",
    "    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n",
    "    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n",
    "    \n",
    "    print(df.index[[0, -1]])\n",
    "    print(second_df.index[[0, -1]])\n",
    "    print(third_df.index[[0, -1]])\n",
    "    print(fourth_df.index[[0, -1]])\n",
    "    print(fifth_df.index[[0, -1]])\n",
    "\n",
    "    open_indexes.append(df.index[0])\n",
    "    open_indexes.append(second_df.index[0])\n",
    "    open_indexes.append(third_df.index[0])\n",
    "    open_indexes.append(fourth_df.index[0])\n",
    "    open_indexes.append(fifth_df.index[0])\n",
    "    \n",
    "    try:\n",
    "      #     Todo    #\n",
    "      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n",
    "      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n",
    "      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n",
    "      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n",
    "      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n",
    "      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n",
    "      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n",
    "\n",
    "      print(sixth_df.index[[0, -1]])\n",
    "      print(seventh_df.index[[0, -1]])\n",
    "      print()\n",
    "\n",
    "      open_indexes.append(sixth_df.index[0])\n",
    "      open_indexes.append(seventh_df.index[0])\n",
    "\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n",
    "\n",
    "    df.reset_index().to_feather(date_path + feather_name, compression='lz4')\n",
    "    second_df.reset_index().to_feather(date_path2 + feather_name, compression='lz4')\n",
    "    third_df.reset_index().to_feather(date_path3 + feather_name, compression='lz4')\n",
    "    fourth_df.reset_index().to_feather(date_path4 + feather_name, compression='lz4')\n",
    "    fifth_df.reset_index().to_feather(date_path5 + feather_name, compression='lz4')\n",
    "    sixth_df.reset_index().to_feather(date_path6 + feather_name, compression='lz4')\n",
    "    seventh_df.reset_index().to_feather(date_path7 + feather_name, compression='lz4')\n",
    "\n",
    "    print(\"xlsx converted to feather !\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0QpnORSuzk",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### add itv_name to ftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-gl30KxSuzk"
   },
   "outputs": [],
   "source": [
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "# dir_path = \"bbdc3m_backi2\"\n",
    "# date = '2021-10-10'\n",
    "date = '2021-07-01'\n",
    "\n",
    "db_path = './candlestick_concated/database_bn/non_cum/%s/' % date\n",
    "os.makedirs(os.path.join(db_path), exist_ok=True)\n",
    "\n",
    "# exist_list = os.listdir(os.path.join(save_path, dir_path))\n",
    "# break\n",
    "\n",
    "\n",
    "a_day = 3600 * 24\n",
    "\n",
    "for i in tqdm(range(len(file_list))):\n",
    "\n",
    "  keys = [file_list[i]]\n",
    "\n",
    "  # if 'neo'.upper() not in file_list[i]:\n",
    "    # continue\n",
    "\n",
    "  if date not in file_list[i]:\n",
    "    continue\n",
    "\n",
    "\n",
    "  for key in keys:      \n",
    "\n",
    "    # if 'eth'.upper() not in key:\n",
    "    #   continue\n",
    "    # print(key)\n",
    "    \n",
    "    if \".ftr\" not in key:\n",
    "      continue\n",
    "        \n",
    "    df = shutil.copy(date_path + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval))\n",
    "    second_df = shutil.copy(date_path2 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval2))\n",
    "    third_df = shutil.copy(date_path3 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval3))\n",
    "    fourth_df = shutil.copy(date_path4 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval4))\n",
    "    fifth_df = shutil.copy(date_path5 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval5))\n",
    "    sixth_df = shutil.copy(date_path6 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval6))\n",
    "    seventh_df = shutil.copy(date_path7 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval7))\n",
    "\n",
    "    print(\"copied to\" + db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oZ1ohTtSuzk"
   },
   "source": [
    "#### feather ver. (database to res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgVHpnUsSuzk"
   },
   "outputs": [],
   "source": [
    "# db_path = './candlestick_concated/database_ub/' # upbit\n",
    "db_path = './candlestick_concated/database_bn/'   # binance\n",
    "\n",
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "save_dir_path = \"bb1d_backi2\"\n",
    "date = '2022-02-17'\n",
    "\n",
    "# concat_path = 'noncat' # 새로운 cols 를 기존 cum/concat 에 붙이려는 경우\n",
    "concat_path = 'concat'\n",
    "cum_path = \"cum\"\n",
    "# cum_path = \"non_cum\"  # non_cum 으로 진행하는 경우, row concat 용도이기 때문에 noncat -> concat 으로 변경 (base cols 를 모두 담고 있음)\n",
    "\n",
    "load_path = os.path.join(db_path, cum_path, date)\n",
    "save_path = os.path.join(save_path, save_dir_path, concat_path, cum_path, date)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "file_list = os.listdir(load_path)\n",
    "exist_list = os.listdir(save_path)\n",
    "# break\n",
    "\n",
    "a_day = 3600 * 24\n",
    "\n",
    "for i in tqdm(range(len(file_list))):\n",
    "\n",
    "  keys = [file_list[i]]\n",
    "\n",
    "  # if 'neo'.upper() not in file_list[i]:\n",
    "    # continue\n",
    "\n",
    "  if date not in file_list[i]:\n",
    "    continue\n",
    "\n",
    "\n",
    "  for key in keys:      \n",
    "\n",
    "    # if 'eth'.upper() not in key:\n",
    "    #   continue\n",
    "    # print(key)\n",
    "    \n",
    "    if \".ftr\" not in key:\n",
    "      continue\n",
    "\n",
    "    if \"_1m\" not in key:\n",
    "      continue\n",
    "\n",
    "    # feather_name = key.replace(\".ftr\", \"_%.ftr\" % save_dir_path)\n",
    "    feather_name = key.replace(\"_1m\", \"\")\n",
    "    feather_path = os.path.join(save_path, feather_name)\n",
    "\n",
    "    if feather_name in exist_list:\n",
    "      print(feather_name, \"already exist !\")\n",
    "      continue\n",
    "    \n",
    "    df = pd.read_feather(os.path.join(load_path, key), columns=None, use_threads=True).set_index(\"index\")\n",
    "\n",
    "    res_df = sync_check_make(df)\n",
    "\n",
    "    res_df.reset_index().to_feather(feather_path, compression='lz4')\n",
    "    print(feather_path, \"saved succesfully !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0n53hflJbnp",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### htf candle check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xW0yugCWvGz"
   },
   "outputs": [],
   "source": [
    "itv_list = ['3T', '5T', '15T', '30T', '1H', '4H']\n",
    "comp_df_list = [second_df, third_df, fourth_df, fifth_df, sixth_df, seventh_df]\n",
    "offset_list = ['1h', '2min', '2min', '2min', '2min', '2min']\n",
    "# itv_list = ['4H']\n",
    "# comp_df_list = [seventh_df]\n",
    "\n",
    "slice_len = 100\n",
    "for itv_, comp_df_, offset in zip(itv_list, comp_df_list, offset_list):\n",
    "\n",
    "  print(\"itv_ :\", itv_)\n",
    "\n",
    "  # df = h_candle_v2(df, '3T')\n",
    "  # end_ts = \n",
    "  h_res_df = df.resample(itv_, offset=offset).agg({\n",
    "          'open': 'first',\n",
    "          'high': 'max',\n",
    "          'low': 'min',\n",
    "          'close': 'last'\n",
    "      })\n",
    "\n",
    "  #   앞은 길이가 다르고, 뒤에서부터 잘라서 비교    #\n",
    "  #   last_row 빼고는 동일, 4h 제외\n",
    "  # print(df.tail())\n",
    "  print(h_res_df.tail())\n",
    "  print(comp_df_.tail())\n",
    "  # # print(h_res_df.head())\n",
    "  # # print(second_df.head())\n",
    "\n",
    "  # print(len(h_res_df))\n",
    "  # print(len(second_df))\n",
    "\n",
    "  # print(h_res_df.values[-slice_len:])\n",
    "  # print(second_df.iloc[:, :4].values[-slice_len:])\n",
    "  # print(np.argwhere(h_res_df.values[-slice_len:] != comp_df_.iloc[:, :4].values[-slice_len:]))\n",
    "  # print()\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRNwqVeAu8X8"
   },
   "outputs": [],
   "source": [
    "#       1. new_date 의 시작 timeidx 와 base_date end timeidx 의 최소 days' gap     #\n",
    "#       2. new_date 의 시작 부분 indi. value 는 np.nan 으로 채워질 거기 때문에 계산해야함    #\n",
    "\n",
    "df_count = droped_new_res_df.count()\n",
    "len_missing = df_count.max() - df_count.min()\n",
    "print(len_missing / 1440)\n",
    "\n",
    "#       3. \n",
    "missing_sliced_df = droped_new_res_df.iloc[len_missing:]\n",
    "df_count2 = missing_sliced_df.count()\n",
    "# print(df_count2)\n",
    "print((df_count2.max() - df_count2.min()))    # this value should be zero !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AY7E2_hTBsyM"
   },
   "outputs": [],
   "source": [
    "# df_count2.index[df_count2.argmin()]\n",
    "# missing_sliced_df.head(5)\n",
    "\n",
    "stay_missed = np.sum(pd.isnull(missing_sliced_df), axis=0)\n",
    "print(stay_missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9yqewOw9g33"
   },
   "outputs": [],
   "source": [
    "stay_missed_cols = stay_missed[stay_missed != 0].index\n",
    "\n",
    "for sm_col in stay_missed_cols:\n",
    "  \n",
    "  row_idx = np.argwhere(pd.isnull(missing_sliced_df[sm_col].values))\n",
    "\n",
    "  plt.figure(figsize=(3,3))\n",
    "  plt.plot(row_idx)\n",
    "  plt.ylim(0, len(missing_sliced_df))\n",
    "  plt.title(sm_col)\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## olds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old data sync_check : mtf to T df (very old..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khKb9nhlSuzj"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "exist_list = os.listdir(save_path)\n",
    "\n",
    "\n",
    "a_day = 3600 * 24\n",
    "\n",
    "for i in tqdm(range(len(file_list))):\n",
    "\n",
    "  keys = [file_list[i]]\n",
    "\n",
    "  # if 'neo'.upper() not in file_list[i]:\n",
    "    # continue\n",
    "\n",
    "  # if '2021-04-30'.upper() not in file_list[i]:\n",
    "  if '2021-07-01'.upper() not in file_list[i]:\n",
    "  # if '2021-10-10'.upper() not in file_list[i]:\n",
    "    continue\n",
    "\n",
    "\n",
    "  for key in keys:      \n",
    "\n",
    "    # if 'eth'.upper() not in key:\n",
    "    #   continue\n",
    "\n",
    "    excel_name = key.replace(\".xlsx\", \"_st1h_backi2.xlsx\")\n",
    "    excel_path = save_path + excel_name\n",
    "\n",
    "    if excel_name in exist_list:\n",
    "      print(excel_name, \"already exist !\")\n",
    "      continue\n",
    "    \n",
    "    open_indexes = []\n",
    "    \n",
    "    df = pd.read_excel(date_path + key, index_col=0)\n",
    "    second_df = pd.read_excel(date_path2 + key, index_col=0)\n",
    "    third_df = pd.read_excel(date_path3 + key, index_col=0)\n",
    "    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n",
    "    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n",
    "    \n",
    "    print(df.index[[0, -1]])\n",
    "    print(second_df.index[[0, -1]])\n",
    "    print(third_df.index[[0, -1]])\n",
    "    print(fourth_df.index[[0, -1]])\n",
    "    print(fifth_df.index[[0, -1]])\n",
    "\n",
    "    open_indexes.append(df.index[0])\n",
    "    open_indexes.append(second_df.index[0])\n",
    "    open_indexes.append(third_df.index[0])\n",
    "    open_indexes.append(fourth_df.index[0])\n",
    "    open_indexes.append(fifth_df.index[0])\n",
    "    \n",
    "    try:\n",
    "      #     Todo    #\n",
    "      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n",
    "      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n",
    "      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n",
    "      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n",
    "      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n",
    "      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n",
    "      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n",
    "\n",
    "      print(sixth_df.index[[0, -1]])\n",
    "      print(seventh_df.index[[0, -1]])\n",
    "      print()\n",
    "\n",
    "      open_indexes.append(sixth_df.index[0])\n",
    "      open_indexes.append(seventh_df.index[0])\n",
    "\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n",
    "    latest_open_index = sorted(open_indexes)[-1]\n",
    "    \n",
    "    open_ts = datetime.timestamp(latest_open_index)\n",
    "    latest_open_index_1m = datetime.fromtimestamp(open_ts + a_day)\n",
    "\n",
    "    #   str 로 만들어 접근하면 불가함  #\n",
    "    end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 08:59:59.999000\")\n",
    "    # break\n",
    "\n",
    "    sliced_df = df.loc[latest_open_index_1m:end_index] # to_lower_tf 의 기준 ltf\n",
    "    sliced_second_df = second_df.loc[latest_open_index:end_index]\n",
    "    sliced_third_df = third_df.loc[latest_open_index:end_index]\n",
    "    sliced_fourth_df = fourth_df.loc[latest_open_index:end_index]\n",
    "    sliced_fifth_df = fifth_df.loc[latest_open_index:end_index]\n",
    "\n",
    "    print(\"sliced index\")\n",
    "    print(sliced_df.index[[0, -1]])\n",
    "    print(sliced_second_df.index[[0, -1]])\n",
    "    print(sliced_third_df.index[[0, -1]])\n",
    "    print(sliced_fourth_df.index[[0, -1]])\n",
    "    print(sliced_fifth_df.index[[0, -1]])\n",
    "\n",
    "    try:\n",
    "      sliced_sixth_df = sixth_df.loc[latest_open_index:end_index]\n",
    "      sliced_seventh_df = seventh_df.loc[latest_open_index:end_index]\n",
    "\n",
    "      print(sliced_sixth_df.index[[0, -1]])\n",
    "      print(sliced_seventh_df.index[[0, -1]])\n",
    "\n",
    "      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df, sliced_sixth_df, sliced_seventh_df)\n",
    "    \n",
    "    except:\n",
    "      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df)\n",
    "\n",
    "\n",
    "\n",
    "    res_df.to_excel(excel_path)\n",
    "    print(excel_name, \"saved succesfully !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### row concatenation (excel version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-3QkfbFSuzl"
   },
   "outputs": [],
   "source": [
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "dict_name = \"2021-07-01 ETHUSDT_bb15m_backi2_res_dfs.pkl\"\n",
    "\n",
    "#     load with pickle    #\n",
    "with open(save_path + dict_name, 'rb') as f:\n",
    "  saved_res_df_dict = pickle.load(f)\n",
    "\n",
    "print(dict_name, \"loaded !\")\n",
    "res_df_files = os.listdir(save_path)\n",
    "res_df_files.reverse()\n",
    "\n",
    "print(res_df_files)\n",
    "\n",
    "res_df_dict = {}\n",
    "\n",
    "base_postfix = '_bb15m_backi2.xlsx'\n",
    "new_postfix = '_st1h_backi2.xlsx'\n",
    "\n",
    "max_cnt = 10\n",
    "sample_cnt = max_cnt\n",
    "\n",
    "for k_i, key in enumerate(res_df_files):\n",
    "\n",
    "  if '2021-07-01'.upper() not in key:\n",
    "  # if '2021-10-10'.upper() not in key:\n",
    "    continue\n",
    "\n",
    "  # if \"link\".upper() not in key:\n",
    "  # if \"btc\".upper() not in key:\n",
    "  #   continue\n",
    "\n",
    "  if new_postfix not in key:\n",
    "    continue\n",
    "\n",
    "  # if key in \n",
    "\n",
    "  if sample_cnt == max_cnt:\n",
    "    dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n",
    "    print(\"dict_name :\", dict_name)\n",
    "\n",
    "  base_df = saved_res_df_dict[key.replace(new_postfix, base_postfix)]\n",
    "  # base_df = pd.read_excel(save_path + key.replace(new_postfix, base_postfix), index_col=0)  \n",
    "  res_df = pd.read_excel(save_path + key, index_col=0)  \n",
    "\n",
    "  # print(base_df.head())\n",
    "  # print(res_df.head())\n",
    "  # break\n",
    "\n",
    "  new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n",
    "  # new_res_df.head()\n",
    "\n",
    "  droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n",
    "  droped_new_res_df.head()\n",
    "  # break\n",
    "\n",
    "  # res_df_dict[key] = res_df\n",
    "  res_df_dict[key] = droped_new_res_df\n",
    "  print(key, \"saved to dict !\")\n",
    "\n",
    "  #     save with pickle    #\n",
    "  with open(save_path + dict_name, 'wb') as f:\n",
    "    pickle.dump(res_df_dict, f)\n",
    "\n",
    "  sample_cnt -= 1\n",
    "\n",
    "  if sample_cnt <= 0:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XG2p9OhhSuzm"
   },
   "outputs": [],
   "source": [
    "# save_path = './candlestick_concated/res_df/'        # cols 추가된 cum db 에 new_row's cols 기준으로 합치는 경우\n",
    "save_path = './candlestick_concated/database_bn/'   # ohlcv cum db 만들 경우\n",
    "\n",
    "base_date = '2022-04-25'\n",
    "# new_date = '2022-02-17'\n",
    "new_date = '2022-04-27'\n",
    "\n",
    "# ------ load ftr list ------ #\n",
    "if \"database\" in save_path:\n",
    "  base_dir_path = \"\"\n",
    "  new_dir_path = \"\"\n",
    "  concat_dir = \"\"\n",
    "else:\n",
    "  base_dir_path = \"sar_backi2\"\n",
    "  new_dir_path = \"bb4h_backi2\"  # dir_path 가 base / new 서로 달라질 수 있어서 분할함\n",
    "  concat_dir = \"concat\"\n",
    "\n",
    "base_date_path = os.path.join(save_path, base_dir_path, concat_dir, \"cum\", base_date)      # 기존 cum db 와 new_date db 를 cum 진행\n",
    "# base_date_path = os.path.join(save_path, base_dir_path, concat_dir, \"non_cum\", base_date)    # non_cum db 와 new_date db 를 cum 진행\n",
    "\n",
    "# new_date_path = os.path.join(save_path, new_dir_path, concat_dir, \"cum\", new_date)      # 상황별로 직접 선택해야할 듯\n",
    "new_date_path = os.path.join(save_path, new_dir_path, concat_dir, \"non_cum\", new_date)\n",
    "\n",
    "\n",
    "\n",
    "# ------ save to (new) concat dir ------ #\n",
    "#      1. if dir. not exists, makedir\n",
    "save_path = new_date_path.replace(\"non_cum\", \"cum\")   # non_cum 아니여도 무관\n",
    "os.makedirs(save_path, exist_ok=True)   # noncat / concat 두가지 경우 존재가능할 것\n",
    "# os.makedirs(os.path.join(save_path, dir_path, \"noncat/cum\", new_date), exist_ok=True)\n",
    "\n",
    "\n",
    "ftr_list = [s for s in os.listdir(new_date_path) if \"ftr\" in s]\n",
    "exist_list = os.listdir(save_path)\n",
    "print(ftr_list)\n",
    "# break\n",
    "\n",
    "\n",
    "for key in ftr_list:\n",
    "\n",
    "  if new_date not in key:   # date rejection\n",
    "    continue\n",
    "  if '1m' not in key:  # itv rejection\n",
    "    continue\n",
    "\n",
    "  # if key in exist_list:\n",
    "  #   print(key, \"already exist !\")\n",
    "  #   continue\n",
    "\n",
    "  #       read from base postfix's directory    #\n",
    "  base_df = pd.read_feather(os.path.join(base_date_path, key.replace(new_date, base_date)), columns=None, use_threads=True).set_index(\"index\")   # key 에 new_date 담겨있음\n",
    "  res_df = pd.read_feather(os.path.join(new_date_path, key), columns=None, use_threads=True).set_index(\"index\")\n",
    "\n",
    "  # print(base_df.head())\n",
    "  # print(res_df.head())\n",
    "  # break\n",
    "\n",
    "  new_res_df = pd.concat([base_df, res_df], axis=0) # df_tot.drop_duplicates()\n",
    "  # new_res_df.head()\n",
    "\n",
    "  intersection_cols = res_df.columns.intersection(base_df.columns)\n",
    "\n",
    "  droped_new_res_df = new_res_df.loc[~new_res_df.index.duplicated(keep='last'),intersection_cols]\n",
    "  # droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n",
    "  # droped_new_res_df = new_res_df.loc[:,~new_res_df.index.duplicated(keep='last')]\n",
    "  # droped_new_res_df.head()\n",
    "  # break  \n",
    "  \n",
    "  print(droped_new_res_df.iloc[[0, -1]])  \n",
    "\n",
    "  # ------------- verify df continuity directly itv by itv ------------- #\n",
    "  true_continue = True\n",
    "  if \"_\" in key:\n",
    "\n",
    "    # interval = key.split(\".\")[0].split(\"_\")[-1] \n",
    "    # itv_num = itv_to_number(interval)\n",
    "\n",
    "    # verified_df = consecutive_df(droped_new_res_df, itv_to_number(interval))\n",
    "    # verified_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n",
    "\n",
    "    # res_df_dict[key] = res_df\n",
    "    # res_df_dict[key] = droped_new_res_df  \n",
    "\n",
    "    np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), droped_new_res_df.index)))\n",
    "    ideal_ts_gap = 60 # * itv_num\n",
    "\n",
    "    for ts_i in range(len(np_idx_ts)):\n",
    "      \n",
    "      if ts_i != 0:\n",
    "        ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n",
    "        if ts_gap > ideal_ts_gap or ts_gap < ideal_ts_gap:\n",
    "        # if ts_gap == ideal_ts_gap:\n",
    "          print(droped_new_res_df.index[ts_i - 1])\n",
    "          print(droped_new_res_df.index[ts_i])\n",
    "          # print(ts_gap)\n",
    "          print(\"------------------ unideal ts_gap ------------------\")\n",
    "          true_continue = False\n",
    "\n",
    "    print(\"continuity checked !\")\n",
    "\n",
    "  if true_continue:\n",
    "    droped_new_res_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n",
    "\n",
    "  print(os.path.join(save_path, key), \"saved !\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1E_eAyPSuzm",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### new col to latest feather (1m_indi. only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyI5NrM7Suzm"
   },
   "outputs": [],
   "source": [
    "save_path = './candlestick_concated/res_df/'\n",
    "\n",
    "cum_dir = \"cum\"\n",
    "\n",
    "new_dir_path = \"rsi_backi2\"\n",
    "base_dir_path = \"bbdc3m_backi2\"\n",
    "\n",
    "new_date = '2021-11-17'\n",
    "\n",
    "\n",
    "\n",
    "#     load ftr list    #\n",
    "base_save_path = os.path.join(save_path, base_dir_path, \"concat/cum\", new_date)\n",
    "new_save_path = base_save_path.replace(base_dir_path, new_dir_path)\n",
    "\n",
    "#     save to (new) cum dir    #\n",
    "#      1. if dir. not exists, makedir\n",
    "os.makedirs(new_save_path, exist_ok=True)\n",
    "\n",
    "ftr_list = [s for s in os.listdir(base_save_path) if \"ftr\" in s]\n",
    "print(ftr_list)\n",
    "# break\n",
    "\n",
    "\n",
    "max_cnt = 10\n",
    "sample_cnt = max_cnt\n",
    "\n",
    "for key in ftr_list:\n",
    "\n",
    "  if new_date not in key:\n",
    "    continue\n",
    "\n",
    "\n",
    "  #       read from base postfix's directory    #\n",
    "  base_df = pd.read_feather(os.path.join(base_save_path, key), columns=None, use_threads=True).set_index(\"index\")\n",
    "  # print(base_df.head())\n",
    "  # print(res_df.head())\n",
    "  # break\n",
    "\n",
    "  droped_new_res_df = sync_check(base_df)\n",
    "\n",
    "  # new_res_df = pd.concat([base_df, res_df], axis=0) # df_tot.drop_duplicates()\n",
    "  # # new_res_df.head()\n",
    "\n",
    "  # intersection_cols = res_df.columns.intersection(base_df.columns)\n",
    "\n",
    "  # droped_new_res_df = new_res_df.loc[~new_res_df.index.duplicated(keep='last'),intersection_cols]\n",
    "  # droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n",
    "  # droped_new_res_df = new_res_df.loc[:,~new_res_df.index.duplicated(keep='last')]\n",
    "  # droped_new_res_df.head()\n",
    "  # break\n",
    "\n",
    "  droped_new_res_df.reset_index().to_feather(os.path.join(new_save_path, key), compression='lz4')\n",
    "\n",
    "  print(os.path.join(new_save_path, key), \"saved !\")\n",
    "\n",
    "  # sample_cnt -= 1\n",
    "\n",
    "  # if sample_cnt <= 0:\n",
    "  #   break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epgS5Dksu-HX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### mv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJcVpEdrslA5"
   },
   "outputs": [],
   "source": [
    "df_path = './candlestick_concated/survey_df_v2'\n",
    "files_ = os.listdir(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEKyEYkotFDy"
   },
   "outputs": [],
   "source": [
    "dirs = [file_ for file_ in files_ if not file_.endswith('.ftr')]\n",
    "files = [file_ for file_ in files_ if file_.endswith('.ftr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgM79tcxtPVZ"
   },
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M767iRtwtRQP"
   },
   "outputs": [],
   "source": [
    "def move_fn(dir_, file_):\n",
    "  src_path = os.path.join(df_path, file_)\n",
    "  dst_path = os.path.join(df_path, dir_, file_)\n",
    "  shutil.move(src_path, dst_path)\n",
    "  print(\"moved to {}\".format(dst_path))\n",
    "\n",
    "_ = [move_fn('2022-01-10 ETHUSDT_all', file_) for file_ in files if 'eth'.upper() in file_]\n",
    "# sols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy76iO7gztne",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### move legacy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMRht32Czwry"
   },
   "outputs": [],
   "source": [
    "# print()\n",
    "cur_dir_list = os.listdir('.')\n",
    "for f in cur_dir_list:\n",
    "  if 'legacy' in f :\n",
    "    # print(f)\n",
    "    if os.path.isdir(pkg_path + f,):\n",
    "      continue\n",
    "\n",
    "    shutil.move(pkg_path + f, pkg_path + 'legacy/' + f)\n",
    "    print(\"moved to\" + pkg_path + 'legacy/' +  f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5duWn8t4BRyv",
    "tags": []
   },
   "source": [
    "# IDEP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrIGjmUzqU-D",
    "tags": []
   },
   "source": [
    "## Load utils & config paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bank.traders.trader_v1_4 import *\n",
    "\n",
    "# ------- input params ------- #\n",
    "paper_name = \"wave_cci_wrr32_spread\"\n",
    "bank_id_list = [1]\n",
    "\n",
    "bank = Trader(paper_name=paper_name, id_list=bank_id_list, config_type=\"realtrade\", mode=\"IDEP\")\n",
    "\n",
    "id_arr = np.array(bank_id_list)\n",
    "utils_arr = np.array(bank.utils_list)\n",
    "config_arr = np.array(bank.config_list)  # Todo, 이거 사용하려면, bank.__init__ 에서 read_write_config 한번해야할 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leSQlImg4_9L"
   },
   "source": [
    "### utils paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1666570072396,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "CB2yZdQ95Cdg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from funcs.public.broker import itv_to_number\n",
    "from datetime import datetime\n",
    "\n",
    "sys_log = logging.getLogger()\n",
    "\n",
    "\n",
    "def enlist_tr(res_df, config, np_timeidx, mode='OPEN', env='BANK', show_detail=True):\n",
    "    selection_id = config.selection_id\n",
    "\n",
    "    len_df = len(res_df)\n",
    "    len_df_range = np.arange(len_df)\n",
    "\n",
    "    # if config.tr_set.check_hlm == 2:  # 동일한 param 으로도 p2_hlm 시도를 충분히 할 수 있음 (csdbox 와 같은)\n",
    "    #   assert not (wave_itv1 == wave_itv2 and wave_period1 == wave_period2)\n",
    "\n",
    "    \"\"\"\n",
    "    1. get data for tr_set\n",
    "    \"\"\"\n",
    "    wave_itv1 = config.tr_set.wave_itv1\n",
    "    wave_period1 = config.tr_set.wave_period1\n",
    "    wave_itv2 = config.tr_set.wave_itv2\n",
    "    wave_period2 = config.tr_set.wave_period2\n",
    "    tc_period = config.tr_set.tc_period\n",
    "    roll_hl_cnt = 3\n",
    "\n",
    "    roll_highs1 = [res_df['wave_high_fill_{}{}_-{}'.format(wave_itv1, wave_period1, cnt_ + 1)].to_numpy() for cnt_ in reversed(range(roll_hl_cnt))]\n",
    "    roll_lows1 = [res_df['wave_low_fill_{}{}_-{}'.format(wave_itv1, wave_period1, cnt_ + 1)].to_numpy() for cnt_ in reversed(range(roll_hl_cnt))]\n",
    "\n",
    "    wave_high_fill1_ = res_df['wave_high_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "    wave_low_fill1_ = res_df['wave_low_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "    #     roll_highs2 = [res_df['wave_high_fill_{}{}_-{}'.format(wave_itv2, wave_period2, cnt_ + 1)].to_numpy() for cnt_ in reversed(range(roll_hl_cnt))]\n",
    "    #     roll_lows2 = [res_df['wave_low_fill_{}{}_-{}'.format(wave_itv2, wave_period2, cnt_ + 1)].to_numpy() for cnt_ in reversed(range(roll_hl_cnt))]\n",
    "\n",
    "    #     wave_high_fill2_ = res_df['wave_high_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "    #     wave_low_fill2_ = res_df['wave_low_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "\n",
    "    # res_df['short_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)] = roll_highs1[-1] / wave_low_fill1_\n",
    "    # res_df['long_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)] = wave_high_fill1_ / roll_lows1[-1]\n",
    "    # res_df['short_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)] = wave_high_fill1_ / wave_low_fill1_\n",
    "    # res_df['long_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)] = wave_high_fill1_ / wave_low_fill1_\n",
    "\n",
    "    # itvnum = itv_to_number(wave_itv1)\n",
    "    # itvnum2 = itvnum * 2\n",
    "\n",
    "    # high_ = res_df['high_{}'.format(wave_itv1)].to_numpy()\n",
    "    # low_ = res_df['low_{}'.format(wave_itv1)].to_numpy()\n",
    "\n",
    "    # b1_close_ = res_df['close_{}'.format(wave_itv1)].shift(itvnum).to_numpy()\n",
    "    # b1_open_ = res_df['open_{}'.format(wave_itv1)].shift(itvnum).to_numpy()\n",
    "    # b1_high_ = res_df['high_{}'.format(wave_itv1)].shift(itvnum).to_numpy()\n",
    "    # b1_low_ = res_df['low_{}'.format(wave_itv1)].shift(itvnum).to_numpy()\n",
    "    # b2_high_ = res_df['high_{}'.format(wave_itv1)].shift(itvnum2).to_numpy()\n",
    "    # b2_low_ = res_df['low_{}'.format(wave_itv1)].shift(itvnum2).to_numpy()\n",
    "\n",
    "    # max_high_ = np.maximum(b1_high_, b2_high_)\n",
    "    # min_low_ = np.minimum(b1_low_, b2_low_)\n",
    "\n",
    "    # res_df['b1_close_{}'.format(wave_itv1)] = b1_close_\n",
    "    # res_df['b1_open_{}'.format(wave_itv1)] = b1_open_\n",
    "    # res_df['b1_high_{}'.format(wave_itv1)] = b1_high_\n",
    "    # res_df['b1_low_{}'.format(wave_itv1)] = b1_low_\n",
    "    # res_df['b2_high_{}'.format(wave_itv1)] = b2_high_\n",
    "    # res_df['b2_low_{}'.format(wave_itv1)] = b2_low_\n",
    "    # res_df['max_high_{}'.format(wave_itv1)] = max_high_\n",
    "    # res_df['min_low_{}'.format(wave_itv1)] = min_low_\n",
    "\n",
    "    \"\"\"\n",
    "    2. set tr_set's 1, 0 & spread\n",
    "    \"\"\"\n",
    "    # cu's roll_high_[:, -1] = prev_high & cu's roll_low_[:, -1] = current_low\n",
    "    # co's roll_low_[:, -1] = prev_low & co's roll_high_[:, -1] = current_high\n",
    "    # 2 사용하는 이유 : tp_1 을 p2_box 기준으로 설정하가 위함 --> enex_pairing_v4 function 과 호환되지 않음\n",
    "    res_df['short_tp_1_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill1_ b2_low_5T\n",
    "    res_df['short_tp_0_{}'.format(selection_id)] = roll_highs1[-1]  # roll_highs1[-1] wave_high_fill1_\n",
    "    res_df['long_tp_1_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill1_ b2_high_5T\n",
    "    res_df['long_tp_0_{}'.format(selection_id)] = roll_lows1[-1]  # roll_lows1[-1]  wave_low_fill1_\n",
    "\n",
    "    res_df['short_ep1_1_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill1_   # b2_low_5T\n",
    "    res_df['short_ep1_0_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill1_\n",
    "    res_df['long_ep1_1_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill1_   # b2_high_5T\n",
    "    res_df['long_ep1_0_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill1_\n",
    "\n",
    "    # --> p2's ep use p1's ep\n",
    "    res_df['short_ep2_1_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill2_   # b2_low_5T\n",
    "    res_df['short_ep2_0_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill2_\n",
    "    res_df['long_ep2_1_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill2_   # b2_high_5T\n",
    "    res_df['long_ep2_0_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill2_\n",
    "\n",
    "    # --> out use p1's low, (allow prev_low as out for p1_hhm only)\n",
    "    res_df['short_out_1_{}'.format(selection_id)] = wave_low_fill1_  # wave_low_fill1_   # wave_low_fill2_   # b2_low_5T\n",
    "    res_df['short_out_0_{}'.format(selection_id)] = roll_highs1[-1]  # roll_highs1[-1] if not config.tr_set.check_hlm else wave_high_fill1_   # roll_highs2[-1]  # roll_high_[:, -2]\n",
    "    res_df['long_out_1_{}'.format(selection_id)] = wave_high_fill1_  # wave_high_fill1_   # wave_high_fill2_   # b2_high_5T\n",
    "    res_df['long_out_0_{}'.format(selection_id)] = roll_lows1[-1]  # roll_lows1[-1] if not config.tr_set.check_hlm else wave_low_fill1_   # roll_lows2[-1]\n",
    "\n",
    "    res_df['short_tp_gap_{}'.format(selection_id)] = abs(res_df['short_tp_1_{}'.format(selection_id)] - res_df['short_tp_0_{}'.format(selection_id)])\n",
    "    res_df['long_tp_gap_{}'.format(selection_id)] = abs(res_df['long_tp_1_{}'.format(selection_id)] - res_df['long_tp_0_{}'.format(selection_id)])\n",
    "    res_df['short_ep1_gap_{}'.format(selection_id)] = abs(res_df['short_ep1_1_{}'.format(selection_id)] - res_df['short_ep1_0_{}'.format(selection_id)])\n",
    "    res_df['long_ep1_gap_{}'.format(selection_id)] = abs(res_df['long_ep1_1_{}'.format(selection_id)] - res_df['long_ep1_0_{}'.format(selection_id)])\n",
    "\n",
    "    res_df['short_out_gap_{}'.format(selection_id)] = abs(res_df['short_out_1_{}'.format(selection_id)] - res_df['short_out_0_{}'.format(selection_id)])\n",
    "    res_df['long_out_gap_{}'.format(selection_id)] = abs(res_df['long_out_1_{}'.format(selection_id)] - res_df['long_out_0_{}'.format(selection_id)])\n",
    "    res_df['short_ep2_gap_{}'.format(selection_id)] = abs(res_df['short_ep2_1_{}'.format(selection_id)] - res_df['short_ep2_0_{}'.format(selection_id)])\n",
    "    res_df['long_ep2_gap_{}'.format(selection_id)] = abs(res_df['long_ep2_1_{}'.format(selection_id)] - res_df['long_ep2_0_{}'.format(selection_id)])\n",
    "\n",
    "    res_df['short_spread_{}'.format(selection_id)] = 1 + (res_df['short_tp_0_{}'.format(selection_id)].to_numpy() / res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - 1) / 2\n",
    "    res_df['long_spread_{}'.format(selection_id)] = 1 + (res_df['long_tp_1_{}'.format(selection_id)].to_numpy() / res_df['long_tp_0_{}'.format(selection_id)].to_numpy() - 1) / 2\n",
    "\n",
    "    # Todo - public_indi 이전에 해야할지도 모름 # 'close', 'haopen', 'hahigh', 'halow', 'haclose'\n",
    "    open, high, low, close = [res_df[col_].to_numpy() for col_ in ['open', 'high', 'low', 'close']]\n",
    "\n",
    "    \"\"\"\n",
    "    3. set tp / ep / out\n",
    "    \"\"\"\n",
    "\n",
    "    #     a. tp\n",
    "    tpg = config.tr_set.tp_gap\n",
    "\n",
    "    #         i. magnetic level\n",
    "    #     cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "    #     co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "    #     short_magnetic_tpg = np.vectorize(get_next_wave_level)(cu_wrr_32_, 'tp')\n",
    "    #     long_magnetic_tpg = np.vectorize(get_next_wave_level)(co_wrr_32_, 'tp')\n",
    "\n",
    "    #     res_df['short_tp_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * short_magnetic_tpg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "    #     res_df['long_tp_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * long_magnetic_tpg\n",
    "\n",
    "    #         ii. 기준 : tp_1, gap : tp_box\n",
    "    res_df['short_tp_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * tpg\n",
    "    res_df['long_tp_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * tpg\n",
    "\n",
    "    # res_df['short_tp_{}'.format(selection_id)] = res_df['short_out_1_{}'.format(selection_id)].to_numpy() - res_df[\n",
    "    #     'short_out_gap_{}'.format(selection_id)].to_numpy() * tpg\n",
    "    # res_df['long_tp_{}'.format(selection_id)] = res_df['long_out_1_{}'.format(selection_id)].to_numpy() + res_df[\n",
    "    #     'long_out_gap_{}'.format(selection_id)].to_numpy() * tpg\n",
    "\n",
    "    # res_df['short_tp_{}'.format(selection_id)] = short_tp_1 - short_epout_gap * tpg\n",
    "    # res_df['long_tp_{}'.format(selection_id)] = long_tp_1 + long_epout_gap * tpg\n",
    "\n",
    "    #     b. ep\n",
    "    #             i. limit_ep1\n",
    "    if config.ep_set.entry_type == \"LIMIT\":\n",
    "        epg1 = config.tr_set.ep1_gap\n",
    "\n",
    "        #              1. magnetic level\n",
    "        # cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        # co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        #         short_magnetic_outg = np.vectorize(get_next_wave_level)(cu_wrr_32_)\n",
    "        #         long_magnetic_outg = np.vectorize(get_next_wave_level)(co_wrr_32_)\n",
    "\n",
    "        #         res_df['short_ep1_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * short_magnetic_outg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "        #         res_df['long_ep1_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * long_magnetic_outg\n",
    "\n",
    "        #              2. 기준 : ep1_0, gap : ep1_box\n",
    "        res_df['short_ep1_{}'.format(selection_id)] = res_df['short_ep1_1_{}'.format(selection_id)].to_numpy() + res_df['short_ep1_gap_{}'.format(selection_id)].to_numpy() * epg1\n",
    "        res_df['long_ep1_{}'.format(selection_id)] = res_df['long_ep1_1_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_gap_{}'.format(selection_id)].to_numpy() * epg1\n",
    "\n",
    "        #              3. 기준 : ep1_0, gap : tp_box\n",
    "        # p1_hlm 을 위해선, tp_0 를 기준할 수 없음 --> ep1 & ep2 를 기준으로 진행\n",
    "        # res_df['short_ep1_{}'.format(selection_id)] = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * epg1  # fibonacci 고려하면, tp / out gap 기준이 맞지 않을까\n",
    "        # res_df['long_ep1_{}'.format(selection_id)] = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * epg1\n",
    "\n",
    "        #              4. 기준 : tp_1, gap : tp_box [ fibo_ep ]\n",
    "        # res_df['short_ep1_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * epg1  # fibonacci 고려하면, tp / out gap 기준이 맞지 않을까\n",
    "        # res_df['long_ep1_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * epg1\n",
    "\n",
    "\n",
    "    #             ii. market_ep1\n",
    "    else:\n",
    "        res_df['short_ep1_{}'.format(selection_id)] = close\n",
    "        res_df['long_ep1_{}'.format(selection_id)] = close\n",
    "\n",
    "    #             iii. limit_ep2\n",
    "    if config.ep_set.point2.entry_type == \"LIMIT\":\n",
    "        epg2 = config.tr_set.ep2_gap\n",
    "\n",
    "        #              1. magnetic level\n",
    "        # cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        # co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        #         short_magnetic_outg = np.vectorize(get_next_wave_level)(cu_wrr_32_)\n",
    "        #         long_magnetic_outg = np.vectorize(get_next_wave_level)(co_wrr_32_)\n",
    "\n",
    "        #         res_df['short_ep2_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * short_magnetic_outg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "        #         res_df['long_ep2_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * long_magnetic_outg\n",
    "\n",
    "        #              2. 기준 : ep2_0, gap : ep2_box\n",
    "        res_df['short_ep2_{}'.format(selection_id)] = res_df['short_ep2_1_{}'.format(selection_id)].to_numpy() + res_df['short_ep2_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "        res_df['long_ep2_{}'.format(selection_id)] = res_df['long_ep2_1_{}'.format(selection_id)].to_numpy() - res_df['long_ep2_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "\n",
    "        #              3. 기준 : ep2_0, gap : out_box\n",
    "        # res_df['short_ep2_{}'.format(selection_id)] = res_df['short_ep2_0_{}'.format(selection_id)].to_numpy() + res_df['short_out_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "        # res_df['long_ep2_{}'.format(selection_id)] = res_df['long_ep2_0_{}'.format(selection_id)].to_numpy() - res_df['long_out_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "\n",
    "        #              4. 기준 : tp_1, gap : tp_box [ fibo_ep ]\n",
    "        # res_df['short_ep2_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * epg2  # fibonacci 고려하면, tp / out gap 기준이 맞지 않을까\n",
    "        # res_df['long_ep2_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "\n",
    "        #              5. 기준 : out_0, gap : out_box [ fibo_ep ]\n",
    "        # res_df['short_ep2_{}'.format(selection_id)] = res_df['short_out_0_{}'.format(selection_id)].to_numpy() + res_df[\n",
    "        #     'short_out_gap_{}'.format(selection_id)].to_numpy() * epg2  # fibonacci 고려하면, tp / out gap 기준이 맞지 않을까\n",
    "        # res_df['long_ep2_{}'.format(selection_id)] = res_df['long_out_0_{}'.format(selection_id)].to_numpy() - res_df[\n",
    "        #     'long_out_gap_{}'.format(selection_id)].to_numpy() * epg2\n",
    "\n",
    "\n",
    "    #             iv. market_ep2\n",
    "    else:\n",
    "        res_df['short_ep2_{}'.format(selection_id)] = close\n",
    "        res_df['long_ep2_{}'.format(selection_id)] = close\n",
    "\n",
    "    #     c. out\n",
    "    outg = config.tr_set.out_gap\n",
    "    # res_df['short_out_{}'.format(selection_id)] = short_tp_0 + short_tp_gap * outg            # 1. for hhm check -> 규칙성과 wave_range 기반 거래 기준의 hhm 확인\n",
    "    # res_df['long_out_{}'.format(selection_id)] = long_tp_0 - long_tp_gap * outg\n",
    "\n",
    "    if config.tr_set.check_hlm == 0:\n",
    "\n",
    "        # cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        # co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        #     i. magnetic level\n",
    "        #         short_magnetic_outg = np.vectorize(get_next_wave_level)(cu_wrr_32_, 'out')\n",
    "        #         long_magnetic_outg = np.vectorize(get_next_wave_level)(co_wrr_32_, 'out')\n",
    "\n",
    "        #         res_df['short_out_{}'.format(selection_id)] = res_df['short_tp_1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * short_magnetic_outg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "        #         res_df['long_out_{}'.format(selection_id)] = res_df['long_tp_1_{}'.format(selection_id)].to_numpy() + res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * long_magnetic_outg\n",
    "\n",
    "        #     ii. 기준 : out_0, gap : out_box\n",
    "        res_df['short_out_{}'.format(selection_id)] = res_df['short_out_0_{}'.format(selection_id)].to_numpy() + res_df['short_out_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        res_df['long_out_{}'.format(selection_id)] = res_df['long_out_0_{}'.format(selection_id)].to_numpy() - res_df['long_out_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        #     iii. 기준 : tp_0, gap : tp_box\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_tp_0_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_tp_0_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        #     iv. 기준 : ep1_0, gap : ep1_box\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy() + res_df['short_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_1_{}'.format(selection_id)].to_numpy() + res_df['short_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_1_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        #     v. 기준 : temporary refix for flexible p1_hhm\n",
    "        # res_df['short_tp_0_{}'.format(selection_id)] = res_df['short_out_{}'.format(selection_id)]\n",
    "        # res_df['long_tp_0_{}'.format(selection_id)] = res_df['long_out_{}'.format(selection_id)]\n",
    "\n",
    "\n",
    "    elif config.tr_set.check_hlm == 1:  # for p1_hlm\n",
    "        # ------ ep1box as outg ------ #\n",
    "        res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy() + res_df['short_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        # ------ 1_tr - ep1box as outg ------ #\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy() + res_df['short_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        # ------ 1_tr - auto_calculation by ep1 ------ #\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_{}'.format(selection_id)] + (res_df['short_ep1_{}'.format(selection_id)].to_numpy() - res_df['short_tp_{}'.format(selection_id)].to_numpy())\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_{}'.format(selection_id)].to_numpy() - (res_df['long_tp_{}'.format(selection_id)].to_numpy() - res_df['long_ep1_{}'.format(selection_id)].to_numpy())\n",
    "\n",
    "        # ------ tpbox as outg ------ #\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * outg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        # ------ [fibo_out] = 기준 : tp_0, gap = tp_box ------ #\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_tp_0_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * outg  # ep 와 마찬가지로, tpg 기준 가능\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_tp_0_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "    else:  # p2_hlm\n",
    "        #     i. 기준 : out_0, gap : out_box\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_out_0_{}'.format(selection_id)].to_numpy() + res_df['short_out_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_out_0_{}'.format(selection_id)].to_numpy() - res_df['long_out_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        #     ii. 기준 : ep2_0, gap : ep2_box\n",
    "        res_df['short_out_{}'.format(selection_id)] = res_df['short_ep2_1_{}'.format(selection_id)].to_numpy() + res_df['short_ep2_gap_{}'.format(selection_id)].to_numpy() * epg2 # * 5\n",
    "        res_df['long_out_{}'.format(selection_id)] = res_df['long_ep2_1_{}'.format(selection_id)].to_numpy() - res_df['long_ep2_gap_{}'.format(selection_id)].to_numpy() * epg2 # * 5\n",
    "\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_tp_0_{}'.format(selection_id)].to_numpy() + res_df['short_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_tp_0_{}'.format(selection_id)].to_numpy() - res_df['long_tp_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        #     iii. ep2box as out\n",
    "        # res_df['short_out_{}'.format(selection_id)] = res_df['short_ep2_0_{}'.format(selection_id)].to_numpy() + res_df['short_ep2_gap_{}'.format(selection_id)].to_numpy() * outg   # p2's ep_box 를 out 으로 사용한다?\n",
    "        # res_df['long_out_{}'.format(selection_id)] = res_df['long_ep2_0_{}'.format(selection_id)].to_numpy() - res_df['long_ep2_gap_{}'.format(selection_id)].to_numpy() * outg\n",
    "\n",
    "        \n",
    "    if env == 'IDEP':\n",
    "        calc_with_hoga_unit_vecto = np.vectorize(calc_with_precision)\n",
    "        res_df['short_tp_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['short_tp_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['long_tp_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['long_tp_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['short_ep1_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['short_ep1_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['long_ep1_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['long_ep1_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['short_ep2_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['short_ep2_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['long_ep2_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['long_ep2_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['short_out_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['short_out_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        res_df['long_out_{}'.format(selection_id)] = calc_with_hoga_unit_vecto(res_df['long_out_{}'.format(selection_id)].to_numpy(), 2)\n",
    "        \n",
    "        \n",
    "    if mode == \"OPEN\":\n",
    "\n",
    "        #    a. init open_res\n",
    "        short_open_res1 = np.ones(len_df)  # .astype(object)\n",
    "        long_open_res1 = np.ones(len_df)  # .astype(object)\n",
    "        short_open_res2 = np.ones(len_df)  # .astype(object)\n",
    "        long_open_res2 = np.ones(len_df)  # .astype(object)\n",
    "\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"init open_res\")\n",
    "            sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "            sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        #    b. bars in a hour.\n",
    "#         timestamp_index = np.array(list(map(lambda x: int(datetime.timestamp(x)), pd.Series(res_df.index))))\n",
    "#         timestamp_index_shifted = np.array(list(map(lambda x: int(datetime.timestamp(x)) if not pd.isnull(x) else 0, pd.Series(res_df.index).shift(60))))\n",
    "#         bars_in_hour = timestamp_index - timestamp_index_shifted < 4800\n",
    "\n",
    "#         short_open_res1 *= bars_in_hour\n",
    "#         long_open_res1 *= bars_in_hour\n",
    "\n",
    "#         if show_detail:\n",
    "#             sys_log.warning(\"bars in a hour\")\n",
    "#             sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "#             sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        \"\"\"\n",
    "        4. wave points\n",
    "        \"\"\"\n",
    "        #    a. wave_point\n",
    "        # notnan_short_tc = ~pd.isnull(res_df['short_tc_{}{}'.format(wave_itv1, wave_period1)].to_numpy())  # isnull for object\n",
    "        # notnan_long_tc = ~pd.isnull(res_df['long_tc_{}{}'.format(wave_itv1, wave_period1)].to_numpy())  # isnull for object\n",
    "\n",
    "        notnan_cu = ~pd.isnull(res_df['wave_cu_{}{}'.format(wave_itv1, wave_period1)].to_numpy())  # isnull for object\n",
    "        notnan_co = ~pd.isnull(res_df['wave_co_{}{}'.format(wave_itv1, wave_period1)].to_numpy())\n",
    "        # notnan_cu2 = ~pd.isnull(res_df['wave_cu_{}{}'.format(wave_itv2, wave_period2)].to_numpy())  # isnull for object\n",
    "        # notnan_co2 = ~pd.isnull(res_df['wave_co_{}{}'.format(wave_itv2, wave_period2)].to_numpy())\n",
    "\n",
    "        short_open_res1 *= res_df['wave_cu_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool) * notnan_cu  # object로 변환되는 경우에 대응해, bool 로 재정의\n",
    "        long_open_res1 *= res_df['wave_co_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool) * notnan_co  # np.nan = bool type 으로 True 임..\n",
    "        # short_open_res1 *= res_df['short_tc_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool) * notnan_short_tc\n",
    "        # long_open_res1 *= res_df['long_tc_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool) * notnan_long_tc\n",
    "\n",
    "        # short_open_res2 *= res_df['wave_cu_{}{}'.format(wave_itv2, wave_period2)].to_numpy().astype(bool) * notnan_cu2  # object로 변환되는 경우에 대응해, bool 로 재정의\n",
    "        # long_open_res2 *= res_df['wave_co_{}{}'.format(wave_itv2, wave_period2)].to_numpy().astype(bool) * notnan_co2  # np.nan = bool type 으로 True 임..\n",
    "        # short_open_res2 *= res_df['short_tc_{}{}'.format(wave_itv2, tc_period)].to_numpy()\n",
    "        # long_open_res2 *= res_df['long_tc_{}{}'.format(wave_itv2, tc_period)].to_numpy()\n",
    "\n",
    "        # sys_log.warning => for pretty logging, 개행 문자를 추가하지 않고 이쁘게 log_file 에만 write 하는 법.\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"wave_point\")\n",
    "            sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "            sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "            # sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "            # sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "\n",
    "        #     b. reject wave_update_hl\n",
    "        notnan_update_low_cu = ~pd.isnull(res_df['wave_update_low_cu_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy())\n",
    "        notnan_update_high_co = ~pd.isnull(res_df['wave_update_high_co_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy())\n",
    "        # notnan_update_low_cu2 = ~pd.isnull(res_df['wave_update_low_cu_bool_{}{}'.format(wave_itv2, wave_period2)].to_numpy())\n",
    "        # notnan_update_high_co2 = ~pd.isnull(res_df['wave_update_high_co_bool_{}{}'.format(wave_itv2, wave_period2)].to_numpy())\n",
    "\n",
    "        short_open_res1 *= ~(res_df['wave_update_low_cu_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool)) * notnan_update_low_cu\n",
    "        long_open_res1 *= ~(res_df['wave_update_high_co_bool_{}{}'.format(wave_itv1, wave_period1)].to_numpy().astype(bool)) * notnan_update_high_co\n",
    "        # short_open_res2 *= ~(res_df['wave_update_low_cu_bool_{}{}'.format(wave_itv2, wave_period2)].to_numpy().astype(bool)) * notnan_update_low_cu2\n",
    "        # long_open_res2 *= ~(res_df['wave_update_high_co_bool_{}{}'.format(wave_itv2, wave_period2)].to_numpy().astype(bool)) * notnan_update_high_co2\n",
    "\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"reject update_hl\")\n",
    "            sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "            sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "        #     sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "        #     sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "\n",
    "        #     c. wave_itv\n",
    "        if wave_itv1 != 'T':\n",
    "            wave_itv1_num = itv_to_number(wave_itv1)\n",
    "            short_open_res1 *= np_timeidx % wave_itv1_num == (wave_itv1_num - 1)\n",
    "            long_open_res1 *= np_timeidx % wave_itv1_num == (wave_itv1_num - 1)\n",
    "\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_itv1\")\n",
    "                sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "                sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        if wave_itv2 != 'T':\n",
    "            wave_itv2_num = itv_to_number(wave_itv2)\n",
    "            short_open_res2 *= np_timeidx % wave_itv2_num == (wave_itv2_num - 1)\n",
    "            long_open_res2 *= np_timeidx % wave_itv2_num == (wave_itv2_num - 1)\n",
    "\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_itv2\")\n",
    "                sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "                sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "\n",
    "        #     d. wave_mm\n",
    "        wave_high_terms_cnt_fill1_ = res_df['wave_high_terms_cnt_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        wave_low_terms_cnt_fill1_ = res_df['wave_low_terms_cnt_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        short_open_res1 *= (wave_high_terms_cnt_fill1_ > config.tr_set.wave_greater2) & (\n",
    "                wave_low_terms_cnt_fill1_ > config.tr_set.wave_greater1)\n",
    "        long_open_res1 *= (wave_low_terms_cnt_fill1_ > config.tr_set.wave_greater2) & (\n",
    "                wave_high_terms_cnt_fill1_ > config.tr_set.wave_greater1)\n",
    "\n",
    "        # wave_high_terms_cnt_fill2_ = res_df['wave_high_terms_cnt_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "        # wave_low_terms_cnt_fill2_ = res_df['wave_low_terms_cnt_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "\n",
    "        # short_open_res2 *= (wave_high_terms_cnt_fill2_ > config.tr_set.wave_greater2) & (wave_low_terms_cnt_fill2_ > config.tr_set.wave_greater1)\n",
    "        # long_open_res2 *= (wave_low_terms_cnt_fill2_ > config.tr_set.wave_greater2) & (wave_high_terms_cnt_fill2_ > config.tr_set.wave_greater1)\n",
    "\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"wave_mm\")\n",
    "            sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "            sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "            # sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "            # sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "\n",
    "        #     e. wave_length\n",
    "        if config.tr_set.wave_length_min_short1 != \"None\":\n",
    "            short_wave_length_fill_ = res_df['short_wave_length_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            short_open_res1 *= short_wave_length_fill_ >= config.tr_set.wave_length_min_short1\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_length_min_short1\")\n",
    "                sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "                \n",
    "        if config.tr_set.wave_length_max_short1 != \"None\":\n",
    "            short_wave_length_fill_ = res_df['short_wave_length_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            short_open_res1 *= short_wave_length_fill_ <= config.tr_set.wave_length_max_short1\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_length_max_short1\")\n",
    "                sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "                \n",
    "        if config.tr_set.wave_length_min_long1 != \"None\":\n",
    "            long_wave_length_fill_ = res_df['long_wave_length_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            long_open_res1 *= long_wave_length_fill_ >= config.tr_set.wave_length_min_long1\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_length_min_long1\")\n",
    "                sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))                \n",
    "       \n",
    "        if config.tr_set.wave_length_max_long1 != \"None\":     \n",
    "            long_wave_length_fill_ = res_df['long_wave_length_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            long_open_res1 *= long_wave_length_fill_ <= config.tr_set.wave_length_max_long1\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"wave_length_max_long1\")\n",
    "                sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        #     #     f. wave_spread\n",
    "        #     if config.tr_set.wave_spread1 != \"None\":\n",
    "        #       short_wave_spread_fill = res_df['short_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        #       long_wave_spread_fill = res_df['long_wave_spread_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        #       short_open_res1 *= short_wave_spread_fill >= config.tr_set.wave_spread1\n",
    "        #       long_open_res1 *= long_wave_spread_fill >= config.tr_set.wave_spread1\n",
    "\n",
    "        #       if show_detail:\n",
    "        #         sys_log.warning(\"wave_spread\")\n",
    "        #         sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "        #         sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        #     #     g. wave_time_ratio\n",
    "        #     if config.tr_set.wave_time_ratio1 != \"None\":\n",
    "        #       short_wave_time_ratio = res_df['short_wave_time_ratio_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        #       long_wave_time_ratio = res_df['long_wave_time_ratio_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        #       short_open_res1 *= short_wave_time_ratio >= config.tr_set.wave_time_ratio1\n",
    "        #       long_open_res1 *= long_wave_time_ratio >= config.tr_set.wave_time_ratio1\n",
    "\n",
    "        #       if show_detail:\n",
    "        #         sys_log.warning(\"wave_time_ratio\")\n",
    "        #         sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "        #         sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        \"\"\"\n",
    "        5. bb points\n",
    "        \"\"\"\n",
    "        #     a. wave prime_idx : 연속된 wave_point 에 대해서 prime_idx 만 허용함 (wave_bb 에서 파생됨)\n",
    "        #     short_open_res1 *= res_df['wave_cu_idx_{}{}'.format(wave_itv1, wave_period1)] == res_df['wave_cu_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)]\n",
    "        #     long_open_res1 *= res_df['wave_co_idx_{}{}'.format(wave_itv1, wave_period1)] == res_df['wave_co_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)]\n",
    "\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\"wave prime_idx\")\n",
    "        #         sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "        #         sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        #     b. inner_triangle\n",
    "        #     # short_open_res1 *= (roll_highs1[-2] > roll_highs1[-1]) & (roll_lows1[-2] < roll_lows1[-1])\n",
    "        #     # long_open_res1 *= (roll_lows1[-2] < roll_lows1[-1]) & (roll_highs1[-2] > roll_highs1[-1])\n",
    "        #     short_open_res1 *= (roll_highs1[-2] > roll_highs1[-1])\n",
    "        #     long_open_res1 *= (roll_lows1[-2] < roll_lows1[-1])\n",
    "        #     # short_open_res1 *= (roll_lows1[-2] < roll_lows1[-1])\n",
    "        #     # long_open_res1 *= (roll_highs1[-2] > roll_highs1[-1])\n",
    "\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\"inner_triangle\")\n",
    "        #         sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "        #         sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "        \"\"\"\n",
    "        6. point validation\n",
    "        \"\"\"\n",
    "        short_tp_ = res_df['short_tp_{}'.format(selection_id)].to_numpy()\n",
    "        short_ep1_ = res_df['short_ep1_{}'.format(selection_id)].to_numpy()\n",
    "        short_ep2_ = res_df['short_ep2_{}'.format(selection_id)].to_numpy()\n",
    "        short_out_ = res_df['short_out_{}'.format(selection_id)].to_numpy()\n",
    "\n",
    "        long_tp_ = res_df['long_tp_{}'.format(selection_id)].to_numpy()\n",
    "        long_ep1_ = res_df['long_ep1_{}'.format(selection_id)].to_numpy()\n",
    "        long_ep2_ = res_df['long_ep2_{}'.format(selection_id)].to_numpy()\n",
    "        long_out_ = res_df['long_out_{}'.format(selection_id)].to_numpy()\n",
    "\n",
    "        #     a. p1 point_validation\n",
    "        #             i. tr_set validation reject nan data\n",
    "        #             ii. 정상 거래 위한 tp > ep\n",
    "        short_open_res1 *= (short_tp_ < short_ep1_) & (short_ep1_ < short_out_)\n",
    "        #             iii. reject hl_out open_execution -> close always < ep1_0 at wave_p1\n",
    "        short_open_res1 *= close < short_out_  # res_df['short_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "        # short_open_res1 *= close < short_ep1_   # reject entry open_execution\n",
    "        # short_out_  res_df['short_tp_0_{}'.format(selection_id)].to_numpy() res_df['short_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "\n",
    "        long_open_res1 *= (long_tp_ > long_ep1_) & (long_ep1_ > long_out_)  # (long_tp_ > long_ep_)\n",
    "        long_open_res1 *= close > long_out_  # res_df['long_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "        # long_open_res1 *= close > long_ep1_  # reject entry open_execution\n",
    "        # long_out_ res_df['long_tp_0_{}'.format(selection_id)].to_numpy() res_df['long_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "\n",
    "        #     b. p2 point_validation => deprecated => now, executed in en_ex_pairing() function.\n",
    "        # short_open_res2 *= (short_ep2_ < short_out_) # tr_set validation (short_tp_ < short_ep_) # --> p2_box location (cannot be vectorized)\n",
    "        # short_open_res2 *= close < short_out_    # reject hl_out open_execution\n",
    "        # long_open_res2 *= (long_ep2_ > long_out_)  # tr_set validation (long_tp_ > long_ep_) &   # p2's ep & out cannot be vectorized\n",
    "        # long_open_res2 *= close > long_out_    # reject hl_out open_execution\n",
    "\n",
    "        res_df['short_open1_{}'.format(selection_id)] = short_open_res1 * (not config.pos_set.short_ban)\n",
    "        res_df['long_open1_{}'.format(selection_id)] = long_open_res1 * (not config.pos_set.long_ban)\n",
    "\n",
    "        res_df['short_open2_{}'.format(selection_id)] = short_open_res2\n",
    "        res_df['long_open2_{}'.format(selection_id)] = long_open_res2\n",
    "\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"point validation\")\n",
    "            sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "            sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "            # sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "            # sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "\n",
    "        #     c. tr\n",
    "        if config.tr_set.check_hlm == 2:\n",
    "            res_df['short_tr_{}'.format(selection_id)] = np.nan\n",
    "            res_df['long_tr_{}'.format(selection_id)] = np.nan\n",
    "        else:\n",
    "            res_df['short_tr_{}'.format(selection_id)] = abs((short_ep1_ / short_tp_ - config.trader_set.limit_fee - 1) / (short_ep1_ / short_out_ - config.trader_set.market_fee - 1))\n",
    "            res_df['long_tr_{}'.format(selection_id)] = abs((long_tp_ / long_ep1_ - config.trader_set.limit_fee - 1) / (long_out_ / long_ep1_ - config.trader_set.market_fee - 1))\n",
    "\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuCb0phoPN83",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DNPumVZi0xs"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # ------ wave_point 분리 ------ #\n",
    "    # cci_ = res_df['cci_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "    # b1_cci_ = res_df['cci_{}{}'.format(wave_itv1, wave_period1)].shift(1).to_numpy()        \n",
    "    \n",
    "    # band_width = 100\n",
    "    # upper_band = band_width\n",
    "    # lower_band = -band_width\n",
    "\n",
    "    # update_low_cu_bool = res_df['update_low_cu_bool_{}{}'.format(wave_itv1, wave_period1)]\n",
    "    # update_high_co_bool = res_df['update_high_co_bool_{}{}'.format(wave_itv1, wave_period1)]\n",
    "\n",
    "    # short_open_res1 *= (b1_cci_ > upper_band) & (upper_band > cci_) & ~update_low_cu_bool\n",
    "    # long_open_res1 *= (b1_cci_ < lower_band) & (lower_band < cci_) & ~update_high_co_bool   \n",
    "\n",
    "    \n",
    "# ------------ csd ------------ #\n",
    "    # ------ dc ------ #\n",
    "    # dc_upper_ = res_df['dc_upper_T30'].to_numpy()    \n",
    "    # dc_lower_ = res_df['dc_lower_T30'].to_numpy()    \n",
    "\n",
    "    # # Todo, post_cu ~ co 의 dc_lower == low (=touched) 여부 조사\n",
    "    # short_open_idx1 = get_index_bybool(short_open_res1, len_df_range)\n",
    "    # long_open_idx1 = get_index_bybool(long_open_res1, len_df_range)\n",
    "    # wave_co_post_idx_fill_ = res_df['wave_co_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "    # wave_cu_post_idx_fill_ = res_df['wave_cu_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()   # co_prime_idx (wave_high 정보를 지정하기 위한 front co_idx 지정)\n",
    "\n",
    "    # # 1. dc_lower == low 여부 조사, np.nan 덕분에 vectorize 불가하다고 봄\n",
    "    # short_valid_idx_bool = ~(pd.isnull(wave_co_post_idx_fill_) | pd.isnull(short_open_idx1)) # get_index_bybool\n",
    "    # dc_upper_touch = dc_upper_ <= high\n",
    "    # dc_upper_touch_span = np.full(len_df, np.nan)\n",
    "    # dc_upper_touch_span[short_valid_idx_bool] = [dc_upper_touch[int(iin):int(iout) + 1].sum() for iin, iout in zip(wave_co_post_idx_fill_, short_open_idx1) if not pd.isnull(iin) if not pd.isnull(iout)]\n",
    "\n",
    "    # long_valid_idx_bool = ~(pd.isnull(wave_cu_post_idx_fill_) | pd.isnull(long_open_idx1)) # get_index_bybool\n",
    "    # dc_lower_touch = dc_lower_ >= low\n",
    "    # dc_lower_touch_span = np.full(len_df, np.nan)\n",
    "    # dc_lower_touch_span[long_valid_idx_bool] = [dc_lower_touch[int(iin):int(iout) + 1].sum() for iin, iout in zip(wave_cu_post_idx_fill_, long_open_idx1) if not pd.isnull(iin) if not pd.isnull(iout)]\n",
    "\n",
    "    # short_open_res1 *= dc_upper_touch_span == 0\n",
    "    # long_open_res1 *= dc_lower_touch_span == 0\n",
    "\n",
    "    # if show_detail:\n",
    "    #   sys_log.warning(\"csd - dc\")\n",
    "    #   sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "    #   sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "    #   # sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "    #   # sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))   \n",
    "    \n",
    "    # ================== pattern depiction ================== #  \n",
    "    # bb_upper_ = res_df['bb_upper_{}{}'.format('T', 60)].to_numpy()\n",
    "    # bb_lower_ = res_df['bb_lower_{}{}'.format('T', 60)].to_numpy()\n",
    "    # bb_upper2_ = res_df['bb_upper2_{}{}'.format('T', 60)].to_numpy()\n",
    "    # bb_lower2_ = res_df['bb_lower2_{}{}'.format('T', 60)].to_numpy()\n",
    "    # bb_upper3_ = res_df['bb_upper3_{}{}'.format('T', 60)].to_numpy()\n",
    "    # bb_lower3_ = res_df['bb_lower3_{}{}'.format('T', 60)].to_numpy()\n",
    "    \n",
    "    # ------ 양 / 음봉 (long) ------ #\n",
    "    # short_open_res1 *= close < open\n",
    "    # long_open_res1 *= close > open\n",
    "\n",
    "    # if show_detail:\n",
    "    #   sys_log.warning(\"close > open\")\n",
    "    #   sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "    #   sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "    \n",
    "    # # ------ even_break, hhhl (long) ------ #        \n",
    "    # # cu's roll_high_[:, -1] = prev_high & cu's roll_low_[:, -1] = current_low\n",
    "    # # co's roll_low_[:, -1] = prev_low & co's roll_high_[:, -1] = current_high\n",
    "    # short_open_res1 *= (roll_low_[:, -2] > roll_low_[:, -1]) # & (roll_high_[:, -2] > roll_high_[:, -1])\n",
    "    # long_open_res1 *= (roll_high_[:, -2] < roll_high_[:, -1]) # & (roll_low_[:, -2] < roll_low_[:, -1])\n",
    "\n",
    "    # if show_detail:\n",
    "    #   sys_log.warning(\"even_break\")\n",
    "    #   sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "    #   sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "    # # ------ roll_high < bb_upper2 (long) ------ #\n",
    "    # short_open_res1 *= (roll_low_[:, -4] > roll_low_bb_lower2_[:, -4])\n",
    "    # short_open_res1 *= (roll_low_[:, -3] > roll_low_bb_lower2_[:, -3])\n",
    "    # short_open_res1 *= (roll_low_[:, -2] > roll_low_bb_lower2_[:, -2])\n",
    "    # short_open_res1 *= (roll_low_[:, -1] > roll_low_bb_lower2_[:, -1])\n",
    "\n",
    "    # long_open_res1 *= (roll_high_[:, -4] < roll_high_bb_upper2_[:, -4])\n",
    "    # long_open_res1 *= (roll_high_[:, -3] < roll_high_bb_upper2_[:, -3])\n",
    "    # long_open_res1 *= (roll_high_[:, -2] < roll_high_bb_upper2_[:, -2])\n",
    "    # long_open_res1 *= (roll_high_[:, -1] < roll_high_bb_upper2_[:, -1])\n",
    "    \n",
    "    # if show_detail:\n",
    "    #   sys_log.warning(\"roll_high < bb_upper2\")\n",
    "    #   sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "    #   sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "\n",
    "\n",
    "    # ------ get candle_lastidx ------ #        \n",
    "    # tf_entry = itv_to_number(config.loc_set.point.tf_entry)\n",
    "    # b1_shift = np_timeidx % tf_entry + 1  # dynamic\n",
    "    # b1_candle_lastidx = (len_df_range - b1_shift).astype(float)\n",
    "    # b2_candle_lastidx = (len_df_range - (b1_shift + tf_entry)).astype(float)\n",
    "    # b3_candle_lastidx = (len_df_range - (b1_shift + 2 * tf_entry)).astype(float)\n",
    "    # b1_candle_lastidx[b1_candle_lastidx < 0] = np.nan\n",
    "    # b2_candle_lastidx[b2_candle_lastidx < 0] = np.nan\n",
    "    # b3_candle_lastidx[b3_candle_lastidx < 0] = np.nan\n",
    "\n",
    "    # high_5T = res_df['high_5T'].to_numpy()\n",
    "    # low_5T = res_df['low_5T'].to_numpy()\n",
    "\n",
    "    # b2_high_5T = get_line(b2_candle_lastidx, high_5T)\n",
    "    # b2_low_5T = get_line(b2_candle_lastidx, low_5T)\n",
    "    \n",
    "        # # ------ bb_stream ------ #        \n",
    "        # roll_high_bb_upper_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_upper_, roll_hl_cnt)\n",
    "        # roll_low_bb_upper_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_upper_, roll_hl_cnt)\n",
    "        # roll_high_bb_upper2_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_upper2_, roll_hl_cnt)\n",
    "        # roll_low_bb_upper2_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_upper2_, roll_hl_cnt)\n",
    "\n",
    "        # roll_high_bb_lower_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_lower_, roll_hl_cnt)\n",
    "        # roll_low_bb_lower_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_lower_, roll_hl_cnt)\n",
    "        # roll_high_bb_lower2_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_lower2_, roll_hl_cnt)\n",
    "        # roll_low_bb_lower2_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_lower2_, roll_hl_cnt)\n",
    "\n",
    "        # wave_base_ = res_df['dc_base_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "\n",
    "        # roll_high_wave_base_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, wave_base_, roll_hl_cnt)\n",
    "        # roll_low_wave_base_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, wave_base_, roll_hl_cnt)\n",
    "\n",
    "        # short_open_res *= (roll_high_bb_lower_[:, -2] > roll_high_wave_base_[:, -2]) & (roll_high_wave_base_[:, -2] > roll_high_bb_lower2_[:, -2])\n",
    "        # short_open_res *= (roll_low_bb_lower_[:, -1] > roll_low_wave_base_[:, -1]) & (roll_low_wave_base_[:, -1] > roll_low_bb_lower2_[:, -1])\n",
    "        # short_open_res *= (roll_high_bb_lower_[:, -1] > roll_high_wave_base_[:, -1]) & (roll_high_wave_base_[:, -1] > roll_high_bb_lower2_[:, -1])\n",
    "\n",
    "        # long_open_res *= (roll_low_bb_upper_[:, -2] < roll_low_wave_base_[:, -2]) & (roll_low_wave_base_[:, -2] < roll_low_bb_upper2_[:, -2])\n",
    "        # long_open_res *= (roll_high_bb_upper_[:, -1] < roll_high_wave_base_[:, -1]) & (roll_high_wave_base_[:, -1] < roll_high_bb_upper2_[:, -1])\n",
    "        # long_open_res *= (roll_low_bb_upper_[:, -1] < roll_low_wave_base_[:, -1]) & (roll_low_wave_base_[:, -1] < roll_low_bb_upper2_[:, -1])\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"bb_stream\")\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))  \n",
    "\n",
    "        # ------ candle_pattern  ------ #   \n",
    "        # b3_bb_upper_ = get_line(b3_candle_lastidx, bb_upper_)\n",
    "        # b3_bb_lower_ = get_line(b3_candle_lastidx, bb_lower_)\n",
    "        # b3_bb_upper2_ = get_line(b3_candle_lastidx, bb_upper2_)\n",
    "        # b3_bb_lower2_ = get_line(b3_candle_lastidx, bb_lower2_)\n",
    "        # b3_close = get_line(b3_candle_lastidx, close)\n",
    "\n",
    "        # b2_bb_upper2_ = get_line(b2_candle_lastidx, bb_upper2_)\n",
    "        # b2_bb_lower2_ = get_line(b2_candle_lastidx, bb_lower2_)\n",
    "        # b2_bb_upper3_ = get_line(b2_candle_lastidx, bb_upper3_)\n",
    "        # b2_bb_lower3_ = get_line(b2_candle_lastidx, bb_lower3_)\n",
    "        # b2_close = get_line(b2_candle_lastidx, close)\n",
    "\n",
    "        # b1_bb_upper_ = get_line(b1_candle_lastidx, bb_upper_)\n",
    "        # b1_bb_lower_ = get_line(b1_candle_lastidx, bb_lower_)\n",
    "        # b1_bb_upper2_ = get_line(b1_candle_lastidx, bb_upper2_)\n",
    "        # b1_bb_lower2_ = get_line(b1_candle_lastidx, bb_lower2_)\n",
    "        # b1_close = get_line(b1_candle_lastidx, close)\n",
    "        # b1_high_5T = get_line(b1_candle_lastidx, high_5T)\n",
    "        # b1_low_5T = get_line(b1_candle_lastidx, low_5T)\n",
    "\n",
    "        # short_open_res *= (b3_bb_lower_ > b3_close) & (b3_close > b3_bb_lower2_)\n",
    "        # short_open_res *= (b2_bb_lower2_ > b2_close) & (b2_close > b2_bb_lower3_)\n",
    "        # short_open_res *= (b1_bb_lower_ > b1_close) & (b1_close > b1_bb_lower2_)\n",
    "\n",
    "        # long_open_res *= (b3_bb_upper_ < b3_close) & (b3_close < b3_bb_upper2_)\n",
    "        # long_open_res *= (b2_bb_upper2_ < b2_close) & (b2_close < b2_bb_upper3_)\n",
    "        # long_open_res *= (b1_bb_upper_ < b1_close) & (b1_close < b1_bb_upper2_)\n",
    "\n",
    "        # # short_open_res *= (b2_low_5T < b1_low_5T) & (b2_close < b1_close)\n",
    "        # # long_open_res *= (b2_high_5T > b1_high_5T) & (b2_close > b1_close)\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"candle_pattern\")\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1))) \n",
    "\n",
    "\n",
    "        # ------ low_confirm ------ #\n",
    "        # short_open_res *= b1_high_5T > wave_high_fill_\n",
    "        # long_open_res *= b1_low_5T < wave_low_fill_\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"low_confirm\")\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1))) \n",
    "        \n",
    "        # ------ candle_ratio ------ #\n",
    "        # b2_candle_range_5T = b2_high_5T - b2_low_5T\n",
    "        # b1_candle_range_5T = b1_high_5T - b1_low_5T\n",
    "        \n",
    "        # short_open_res *= b1_candle_range_5T / b2_candle_range_5T < config.loc_set.point.crr\n",
    "        # long_open_res *= b1_candle_range_5T / b2_candle_range_5T < config.loc_set.point.crr\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"candle_ratio\")\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1))) \n",
    "\n",
    "        # ------ wick_ratio ------ #\n",
    "        # upper_wick_ratio_ = res_df['upper_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].to_numpy()\n",
    "        # lower_wick_ratio_ = res_df['lower_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].to_numpy()\n",
    "        # b2_upper_wick_ratio_ = get_line(b2_candle_lastidx, upper_wick_ratio_)\n",
    "        # b2_lower_wick_ratio_ = get_line(b2_candle_lastidx, lower_wick_ratio_)\n",
    "\n",
    "        # short_open_res *= b2_upper_wick_ratio_ < config.loc_set.point.short_wick_ratio\n",
    "        # long_open_res *= b2_upper_wick_ratio_ < config.loc_set.point.long_wick_ratio\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"wick_ratio\")\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1))) \n",
    "\n",
    "        # ------ large wave1_range ------ #          \n",
    "        # roll_bb_upper_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_upper_, roll_hl_cnt)\n",
    "        # roll_bb_lower_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_lower_, roll_hl_cnt)\n",
    "        # roll_bb_upper3_ = get_roll_wave_data(valid_high_prime_idx, roll_high_idx_arr, len_df, bb_upper3_, roll_hl_cnt)\n",
    "        # roll_bb_lower3_ = get_roll_wave_data(valid_low_prime_idx, roll_low_idx_arr, len_df, bb_lower3_, roll_hl_cnt)\n",
    "\n",
    "        # short_open_res *= (roll_bb_upper_[:, -2] < roll_high_[:, -2]) & (roll_low_[:, -1] < roll_bb_lower_[:, -1]) & (roll_low_[:, -1] > roll_bb_lower3_[:, -1])\n",
    "        # long_open_res *= (roll_bb_upper_[:, -1] < roll_high_[:, -1]) & (roll_low_[:, -2] < roll_bb_lower_[:, -2]) & (roll_high_[:, -1] < roll_bb_upper3_[:, -1])\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "        \n",
    "        # ------ low in bb_level3 ------ #  Todo, idx sync 맞춰야할 것\n",
    "        # short_open_res *= (bb_upper2_ < wave_high_fill_) & (wave_high_fill_ < bb_upper3_)\n",
    "        # long_open_res *= (bb_lower3_ < wave_low_fill_) & (wave_low_fill_ < bb_lower2_)\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ first_high ------ #        \n",
    "        # wave_high_prime_idx_fill_= res_df['wave_high_prime_idx_fill_{}{}'.format(itv, period1)].to_numpy()\n",
    "        # wave_low_prime_idx_fill_= res_df['wave_low_prime_idx_fill_{}{}'.format(itv, period1)].to_numpy()\n",
    "        # cu_prime_wave_base = get_line(cu_prime_idx_fill_, wave_base_)\n",
    "        # co_prime_wave_base = get_line(co_prime_idx_fill_, wave_base_)\n",
    "\n",
    "        # # short_open_res *= (co_roll_high_[:, -1] > dc_base_) & (dc_base_ > co_roll_low_[:, -1])\n",
    "        # # long_open_res *= (cu_roll_low_[:, -1] < dc_base_) & (dc_base_ < cu_roll_high_[:, -1])\n",
    "\n",
    "        # short_open_res *= (cu_prime_wave_base > dc_base_) & (dc_base_ > co_prime_wave_base)\n",
    "        # long_open_res *= (co_prime_wave_base < dc_base_) & (dc_base_ < cu_prime_wave_base)\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # cu_prime_dc_base = get_line(cu_prime_idx_fill_, dc_base_)        \n",
    "        # co_prime_dc_base = get_line(co_prime_idx_fill_, dc_base_)\n",
    "        \n",
    "        # shift_size = itv_to_number(p1_itv1)\n",
    "        # b1_dc_base_ = res_df['dc_base_{}{}'.format(p1_itv1, p1_period1)].shift(shift_size).to_numpy()\n",
    "\n",
    "        # short_open_res *= (b1_dc_base_ < dc_base_)\n",
    "        # long_open_res *= (b1_dc_base_ > dc_base_)\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ b1_base_15T < wave_high ------ #\n",
    "        # short_open_res *= (b1_dc_base_ > co_roll_low_[:, -1])\n",
    "        # long_open_res *= (b1_dc_base_ < cu_roll_high_[:, -1])\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))   \n",
    "        \n",
    "        \n",
    "    # b1_itv_num = itv_to_number(config.tr_set.p2_itv0)\n",
    "    # b2_itv_num = itv_to_number(config.tr_set.p2_itv0) * 2  # multi 2 for imb_v2\n",
    "\n",
    "    # res_df[short_tp_1_] = res_df['dc_lower_{}{}'.format(itv, period1)]\n",
    "    # res_df[short_tp_0_] = res_df['dc_upper_{}{}'.format(itv, period2)]\n",
    "    # # res_df[short_tp_0_] = res_df['dc_upper_15T4']\n",
    "    # res_df[long_tp_1_] = res_df['dc_upper_{}{}'.format(itv, period1)]\n",
    "    # res_df[long_tp_0_] = res_df['dc_lower_{}{}'.format(itv, period2)]\n",
    "    # # res_df[long_tp_0_] = res_df['dc_lower_15T4']\n",
    "    \n",
    "        # ------ base_cc ------ #\n",
    "        dc_base_ = res_df['dc_base_{}{}'.format(p1_itv1, p1_period1)].to_numpy()\n",
    "\n",
    "        # close_ = res_df['close_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "        # b1_dc_base_ = res_df['dc_base_{}{}'.format(p1_itv1, p1_period1)].shift(tf_entry).to_numpy()\n",
    "        # b1_close_ = res_df['close_{}'.format(config.loc_set.point.tf_entry)].shift(tf_entry).to_numpy()\n",
    "\n",
    "        # short_open_res *= ((b1_close_ > dc_base_) & (dc_base_ > close_)) | ((b1_close_ > b1_dc_base_) & (dc_base_ > close_))\n",
    "        # long_open_res *= ((b1_close_ < dc_base_) & (dc_base_ < close_)) | ((b1_close_ < b1_dc_base_) & (dc_base_ < close_))\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "        \n",
    "        # ------ tf_entry ------ #\n",
    "        # tf_entry = itv_to_number(config.loc_set.point.tf_entry)\n",
    "        \n",
    "        # short_open_res *= np_timeidx % tf_entry == (tf_entry - 1)\n",
    "        # long_open_res *= np_timeidx % tf_entry == (tf_entry - 1) \n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "    \n",
    "        # ------ cppr 로 양음봉 check ------ # \n",
    "        # tf_entry = itv_to_number(config.loc_set.point.tf_entry)\n",
    "\n",
    "        # res_df['b1_cppr_{}'.format(config.loc_set.point.tf_entry)] = res_df['cppr_{}'.format(config.loc_set.point.tf_entry)].shift(tf_entry)\n",
    "        # b1_cppr_ = res_df['b1_cppr_{}'.format(config.loc_set.point.tf_entry)].to_numpy()  # check b1's cppr in ep_loc\n",
    "        # cppr_ = res_df['cppr_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "        # short_open_res *= (b1_cppr_ > 0) & (cppr_ < 0)\n",
    "        # long_open_res *= (b1_cppr_ < 0) & (cppr_ > 0)\n",
    "\n",
    "        # res_df['b1_updbr'] = res_df['dc_upper_15T4_br'].shift(tf_entry).to_numpy()\n",
    "        # res_df['b1_lwdbr'] = res_df['dc_lower_15T4_br'].shift(tf_entry).to_numpy()\n",
    "        \n",
    "        # res_df['b1_updbr_cppr'] = b1_cppr_ * res_df['b1_updbr'].to_numpy()\n",
    "        # res_df['b1_lwdbr_cppr'] = b1_cppr_ * res_df['b1_lwdbr'].to_numpy()\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ dc_cross ------ #\n",
    "        # b1_dc_upper_15T4 = res_df['dc_upper_15T4'].shift(tf_entry).to_numpy()\n",
    "        # b1_dc_lower_15T4 = res_df['dc_lower_15T4'].shift(tf_entry).to_numpy()\n",
    "        # b1_high_ = res_df['high_{}'.format(config.loc_set.point.tf_entry)].shift(tf_entry).to_numpy()\n",
    "        # b1_low_ = res_df['low_{}'.format(config.loc_set.point.tf_entry)].shift(tf_entry).to_numpy()\n",
    "        # short_open_res *= b1_high_ > b1_dc_upper_15T4\n",
    "        # long_open_res *= b1_low_ < b1_dc_lower_15T4\n",
    "        \n",
    "        # ------ dc_cc ------ #\n",
    "        # b1_close_ = res_df['close_{}'.format(config.loc_set.point.tf_entry)].shift(tf_entry).to_numpy()\n",
    "        # short_open_res *= b1_close_ > b1_dc_upper_15T4\n",
    "        # long_open_res *= b1_close_ < b1_dc_lower_15T4\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ empty_space ------ #       \n",
    "        # dc_upper_15T4 = res_df['dc_upper_15T4'].to_numpy()\n",
    "        # dc_lower_15T4 = res_df['dc_lower_15T4'].to_numpy() \n",
    "        # high_ = res_df['high_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "        # low_ = res_df['low_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "        # short_open_res *= high_ < dc_upper_15T4\n",
    "        # long_open_res *= low_ > dc_lower_15T4\n",
    "        \n",
    "        # ------ candle_pattern ------ #  \n",
    "        # pattern_column = \"{}_{}\".format(config.loc_set.point.candle_pattern, config.loc_set.point.tf_entry)\n",
    "        # short_open_res *= res_df[pattern_column].to_numpy() < 0\n",
    "        # long_open_res *= res_df[pattern_column].to_numpy() > 0\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "\n",
    "        # ------ lower_touch > upper_touch (long) ------ #\n",
    "        # short_open_res *= res_df['short_upper_touch_idx_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy() > res_df['short_lower_touch_idx_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy()\n",
    "        # long_open_res *= res_df['long_lower_touch_idx_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy() > res_df['long_upper_touch_idx_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy()\n",
    "\n",
    "        # ------ base_3T cross ------ #\n",
    "        # dc_base_3T = res_df['dc_base_3T'].to_numpy()\n",
    "        # b1_close = res_df['close'].shift(1).to_numpy()\n",
    "        # short_open_res *= (b1_close > dc_base_3T) & (dc_base_3T > close)\n",
    "        # long_open_res *= (b1_close < dc_base_3T) & (dc_base_3T < close)\n",
    "\n",
    "        # ------ wave_low < base_5T (long) ------ #\n",
    "        # dc_base_5T = res_df['dc_base_5T'].to_numpy()        \n",
    "        # short_open_res *= res_df['short_upper_touch_line_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy() > dc_base_5T\n",
    "        # long_open_res *= res_df['long_lower_touch_line_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy() < dc_base_5T      \n",
    "\n",
    "        # ------ ppr ------ #\n",
    "        # pumping_ratio(res_df, config, p1_itv1, p1_period1, p1_period2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTV4h3LjTZBp",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc49JPmoTaPQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    csd_period = 40\n",
    "    res_df = dc_line_v4(res_df, res_df, dc_period=csd_period)\n",
    "    \n",
    "    dc_upper_ = res_df['dc_upper_T{}'.format(csd_period)].to_numpy()    \n",
    "    dc_lower_ = res_df['dc_lower_T{}'.format(csd_period)].to_numpy()  \n",
    "\n",
    "    short_open_res2 *= dc_upper_touch_span == 0\n",
    "    long_open_res2 *= dc_lower_touch_span == 0\n",
    "\n",
    "    # ------ csdbox ------ # --> 결국 dc's upper & lower\n",
    "    if show_detail:\n",
    "      sys_log.warning(\"csdbox\")\n",
    "      # sys_log.warning(\"np.sum(short_open_res1 == 1) : {}\".format(np.sum(short_open_res1 == 1)))\n",
    "      # sys_log.warning(\"np.sum(long_open_res1 == 1) : {}\".format(np.sum(long_open_res1 == 1)))\n",
    "      sys_log.warning(\"np.sum(short_open_res2 == 1) : {}\".format(np.sum(short_open_res2 == 1)))\n",
    "      sys_log.warning(\"np.sum(long_open_res2 == 1) : {}\".format(np.sum(long_open_res2 == 1)))\n",
    "      \n",
    "    # olds,\n",
    "    # np.nan - np.nan = np.nan -> vectorize 가능할 것 => xx\n",
    "    # 1. wave_high_prime_idx_ ~ long_open_idx1 의 valid(not_non) 한 idx 를 max_dc_lower 와 min_low 의 비교값으로 채워넣음\n",
    "    # valid_idx = ~(pd.isnull(wave_cu_post_idx_fill_) | pd.isnull(long_open_idx1))\n",
    "    # max_dc_lower_ = [dc_lower_[int(iin):int(iout)].max() for iin, iout in zip(wave_cu_post_idx_fill_, long_open_idx1) if not pd.isnull(iin) if not pd.isnull(iout)]\n",
    "    # min_low = [low[int(iin):int(iout)].min() for iin, iout in zip(wave_high_prime_idx_, long_open_idx1) if not pd.isnull(iin) if not pd.isnull(iout)]\n",
    "    \n",
    "    short_tp_1_, long_tp_1_ = 'short_tp_1_{}'.format(selection_id), 'long_tp_1_{}'.format(selection_id)\n",
    "    short_tp_0_, long_tp_0_ = 'short_tp_0_{}'.format(selection_id), 'long_tp_0_{}'.format(selection_id)\n",
    "    short_tp_gap_, long_tp_gap_ = 'short_tp_gap_{}'.format(selection_id), 'long_tp_gap_{}'.format(selection_id)\n",
    "\n",
    "    short_ep_1_, long_ep_1_ = 'short_ep_1_{}'.format(selection_id), 'long_ep_1_{}'.format(selection_id)\n",
    "    short_ep_0_, long_ep_0_ = 'short_ep_0_{}'.format(selection_id), 'long_ep_0_{}'.format(selection_id)\n",
    "    short_ep_gap_, long_ep_gap_ = 'short_ep_gap_{}'.format(selection_id), 'long_ep_gap_{}'.format(selection_id)\n",
    "\n",
    "    short_epout_1_, long_epout_1_ = 'short_epout_1_{}'.format(selection_id), 'long_epout_1_{}'.format(selection_id)\n",
    "    short_epout_0_, long_epout_0_ = 'short_epout_0_{}'.format(selection_id), 'long_epout_0_{}'.format(selection_id)\n",
    "    short_epout_gap_, long_epout_gap_ = 'short_epout_gap_{}'.format(selection_id), 'long_epout_gap_{}'.format(selection_id)\n",
    "    \n",
    "    # ================== convert unit -> numpy ================== #   \n",
    "    # tp_cols = [short_tp_1_, short_tp_0_, short_tp_gap_, long_tp_1_, long_tp_0_, long_tp_gap_]\n",
    "    # epout_cols = [short_epout_1_, short_epout_0_, short_epout_gap_, long_epout_1_, long_epout_0_, long_epout_gap_]\n",
    "\n",
    "    # short_tp_1, short_tp_0, short_tp_gap, long_tp_1, long_tp_0, long_tp_gap = [res_df[col_].to_numpy() for col_ in tp_cols]\n",
    "    # short_epout_1, short_epout_0, short_epout_gap, long_epout_1, long_epout_0, long_epout_gap = [res_df[col_].to_numpy() for col_ in epout_cols]\n",
    "\n",
    "    if p2_itv1 != \"None\":  # vectorized point2\n",
    "        short_point1_on2_idx = pd.Series(\n",
    "            np.where(res_df['short_wave_point_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)], len_df_range, np.nan)).rolling(point1_to2_period,\n",
    "                                                                                                                                    min_periods=1).max().to_numpy()  # period 내의 max_point1_idx\n",
    "        long_point1_on2_idx = pd.Series(\n",
    "            np.where(res_df['long_wave_point_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)], len_df_range, np.nan)).rolling(point1_to2_period,\n",
    "                                                                                                                                   min_periods=1).max().to_numpy()\n",
    "\n",
    "        short_point2_idx = pd.Series(\n",
    "            np.where(res_df['short_wave_point_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)], len_df_range, np.nan)).to_numpy()\n",
    "        long_point2_idx = pd.Series(\n",
    "            np.where(res_df['long_wave_point_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)], len_df_range, np.nan)).to_numpy()\n",
    "\n",
    "        res_df['short_point_idxgap_{}'.format(selection_id)] = short_point2_idx - short_point1_on2_idx\n",
    "        res_df['long_point_idxgap_{}'.format(selection_id)] = long_point2_idx - long_point1_on2_idx\n",
    "\n",
    "        # ------ p1 & p2 ------ #\n",
    "        short_open_res *= ~np.isnan(res_df['short_point_idxgap_{}'.format(selection_id)].to_numpy())\n",
    "        long_open_res *= ~np.isnan(res_df['long_point_idxgap_{}'.format(selection_id)].to_numpy())\n",
    "\n",
    "        if show_detail:\n",
    "          sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "          sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ p2 amax > p1_idx (long) ------ #\n",
    "        short_open_res *= res_df['short_upper_touch_idx_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)].to_numpy() > short_point1_on2_idx\n",
    "        long_open_res *= res_df['long_lower_touch_idx_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)].to_numpy() > long_point1_on2_idx\n",
    "\n",
    "        if show_detail:\n",
    "          sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "          sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ higher low (long) ------ #\n",
    "        # short_a_line1_on2_ = get_line(short_point1_on2_idx, res_df['short_a_line_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy())\n",
    "        # long_a_line1_on2_ = get_line(long_point1_on2_idx, res_df['long_a_line_{}{}{}'.format(p1_itv1, p1_period1, p1_period2)].to_numpy())\n",
    "\n",
    "        # short_a_line2_ = res_df['short_a_line_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)].to_numpy()\n",
    "        # long_a_line2_ = res_df['long_a_line_{}{}{}'.format(p2_itv1, p2_period1, p2_period2)].to_numpy()\n",
    "\n",
    "        # short_open_res *= short_a_line1_on2_ >= short_a_line2_\n",
    "        # long_open_res *= long_a_line1_on2_ <= long_a_line2_\n",
    "\n",
    "        # print(np.sum(long_open_res == 1))\n",
    "\n",
    "        # ------ higher high (long) ------ #\n",
    "        # short_open_res *= co_roll_low_[:, -2] > co_roll_low_[:, -1]\n",
    "        # long_open_res *= cu_roll_high_[:, -2] < cu_roll_high_[:, -1]\n",
    "\n",
    "        # short_open_res *= co_roll_low_[:, -3] > co_roll_low_[:, -2]\n",
    "        # long_open_res *= cu_roll_high_[:, -3] < cu_roll_high_[:, -2]\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))\n",
    "\n",
    "        # ------ higher low (long) ------ # \n",
    "        # short_open_res *= co_roll_high_[:, -2] > co_roll_high_[:, -1]\n",
    "        # long_open_res *= cu_roll_low_[:, -2] < cu_roll_low_[:, -1]\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))  \n",
    "\n",
    "        # ------ tf2_base < wave_low ------ #\n",
    "        # short_open_res *= (dc_base_ > co_roll_high_[:, -1])\n",
    "        # long_open_res *= (dc_base_ < cu_roll_low_[:, -1])\n",
    "\n",
    "        # if show_detail:\n",
    "        #   sys_log.warning(\"np.sum(short_open_res == 1) : {}\".format(np.sum(short_open_res == 1)))\n",
    "        #   sys_log.warning(\"np.sum(long_open_res == 1) : {}\".format(np.sum(long_open_res == 1)))  \n",
    "\n",
    "        # short_open_res *= (cu_prime_wave_base > cu_prime_dc_base) & (dc_base_ > co_prime_wave_base)\n",
    "        # long_open_res *= (co_prime_wave_base < co_prime_dc_base) & (dc_base_ < cu_prime_wave_base)\n",
    "\n",
    "        short_open_res *= (co_prime_dc_base < co_roll_low_[:, -2])\n",
    "        long_open_res *= (cu_prime_dc_base > cu_roll_high_[:, -2])  #  b1_cu_prime_idx’s tf2_base > b1_high -> b1 이 아님 (error)\n",
    "\n",
    "\n",
    "        res_df[short_epout_1_] = res_df['short_wave_low_{}{}{}'.format(itv, period1, period2)]\n",
    "        res_df[short_epout_0_] = res_df['short_new_wave_high_{}{}{}'.format(itv, period1, period2)]\n",
    "        res_df[long_epout_1_] = res_df['long_wave_high_{}{}{}'.format(itv, period1, period2)]\n",
    "        res_df[long_epout_0_] = res_df['long_new_wave_low_{}{}{}'.format(itv, period1, period2)]\n",
    "        \n",
    "        # ------ get candle_lastidx ------ #        \n",
    "        tf_entry = itv_to_number(config.loc_set.point.tf_entry)\n",
    "        b1_candle_shift = np_timeidx % tf_entry + 1\n",
    "        b2_candle_shift = b1_candle_shift + tf_entry\n",
    "        b3_candle_shift = b1_candle_shift + 2 * tf_entry\n",
    "\n",
    "        print(b3_candle_shift)\n",
    "\n",
    "        # bb_upper_ = res_df['bb_upper_{}{}'.format('T', 60)].to_numpy()\n",
    "        # bb_lower_ = res_df['bb_lower_{}{}'.format('T', 60)].to_numpy()\n",
    "        # bb_upper2_ = res_df['bb_upper2_{}{}'.format('T', 60)].to_numpy()\n",
    "        # bb_lower2_ = res_df['bb_lower2_{}{}'.format('T', 60)].to_numpy()\n",
    "        # bb_upper3_ = res_df['bb_upper3_{}{}'.format('T', 60)].to_numpy()\n",
    "        # bb_lower3_ = res_df['bb_lower3_{}{}'.format('T', 60)].to_numpy()\n",
    "\n",
    "        # ------ compare by back_idx  ------ #   \n",
    "        b3_bb_upper_ = res_df['bb_upper_{}{}'.format('T', 60)].shift(b3_candle_shift).to_numpy()\n",
    "        b3_bb_lower_ = res_df['bb_lower_{}{}'.format('T', 60)].shift(b3_candle_shift).to_numpy()\n",
    "        b3_bb_upper2_ = res_df['bb_upper2_{}{}'.format('T', 60)].shift(b3_candle_shift).to_numpy()\n",
    "        b3_bb_lower2_ = res_df['bb_lower2_{}{}'.format('T', 60)].shift(b3_candle_shift).to_numpy()\n",
    "        b3_close = res_df['close'].shift(b3_candle_shift).to_numpy()\n",
    "\n",
    "        b2_bb_upper2_ = res_df['bb_upper2_{}{}'.format('T', 60)].shift(b2_candle_shift).to_numpy()\n",
    "        b2_bb_lower2_ = res_df['bb_lower2_{}{}'.format('T', 60)].shift(b2_candle_shift).to_numpy()\n",
    "        b2_bb_upper3_ = res_df['bb_upper3_{}{}'.format('T', 60)].shift(b2_candle_shift).to_numpy()\n",
    "        b2_bb_lower3_ = res_df['bb_lower3_{}{}'.format('T', 60)].shift(b2_candle_shift).to_numpy()\n",
    "        b2_close = res_df['close'].shift(b2_candle_shift).to_numpy()\n",
    "\n",
    "        b1_bb_upper_ = res_df['bb_upper_{}{}'.format('T', 60)].shift(b1_candle_shift).to_numpy()\n",
    "        b1_bb_lower_ = res_df['bb_lower_{}{}'.format('T', 60)].shift(b1_candle_shift).to_numpy()\n",
    "        b1_bb_upper2_ = res_df['bb_upper2_{}{}'.format('T', 60)].shift(b1_candle_shift).to_numpy()\n",
    "        b1_bb_lower2_ = res_df['bb_lower2_{}{}'.format('T', 60)].shift(b1_candle_shift).to_numpy()\n",
    "        b1_close = res_df['close'].shift(b1_candle_shift).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKdUKKl-483N",
    "tags": []
   },
   "source": [
    "### public paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1666567971345,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "nzOYWA2kqZ0d"
   },
   "outputs": [],
   "source": [
    "from funcs.public.indicator import *\n",
    "from funcs.public.broker import *\n",
    "from funcs.public.constant import *\n",
    "import logging\n",
    "from ast import literal_eval\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "sys_log = logging.getLogger()\n",
    "\n",
    "\n",
    "def lvrg_liqd_set_v2(res_df, config, open_side, ep_, out_, fee, limit_leverage=50):\n",
    "    \n",
    "    selection_id = config.selection_id\n",
    "    leverage = config.lvrg_set.leverage\n",
    "    loss = None\n",
    "    \n",
    "    if not pd.isnull(out_):\n",
    "        if not config.lvrg_set.static_lvrg_short:\n",
    "        # 이 phase 가 정석, 윗 phase 는 결과가 수익 극대화라 사용함\n",
    "            if open_side == OrderSide.SELL:\n",
    "                loss = ep_ / out_\n",
    "            \n",
    "        if not config.lvrg_set.static_lvrg_long:\n",
    "            if open_side == OrderSide.BUY:\n",
    "                loss = out_ / ep_\n",
    "\n",
    "        if loss is not None:\n",
    "            leverage = config.lvrg_set.target_pct / abs(loss - 1 - (fee + config.trader_set.market_fee))\n",
    "\n",
    "    # ------------ leverage rejection ------------ #\n",
    "    # 감당하기 힘든 fluc. 의 경우 진입하지 않음 - dynamic_lvrg 사용 경우\n",
    "    if leverage < 1 and config.lvrg_set.lvrg_rejection:\n",
    "        # if config.lvrg_set.leverage >= 1 and config.lvrg_set.lvrg_rejection:\n",
    "        return None, None\n",
    "\n",
    "    if not config.lvrg_set.allow_float:\n",
    "        leverage = int(leverage)\n",
    "\n",
    "    leverage = min(limit_leverage, max(leverage, 1))\n",
    "\n",
    "    if open_side == OrderSide.SELL:\n",
    "        liqd_p = ep_ / (1 + fee + config.trader_set.market_fee - 1 / leverage)\n",
    "    else:\n",
    "        liqd_p = ep_ * (1 + fee + config.trader_set.market_fee - 1 / leverage)\n",
    "\n",
    "    return leverage, liqd_p\n",
    "\n",
    "\n",
    "def lvrg_liqd_set(res_df, config, open_side, ep_, out_, fee, limit_leverage=50):\n",
    "    selection_id = config.selection_id\n",
    "    leverage = config.lvrg_set.leverage\n",
    "\n",
    "    if not pd.isnull(out_) and not config.lvrg_set.static_lvrg:\n",
    "        # 이 phase 가 정석, 윗 phase 는 결과가 수익 극대화라 사용함\n",
    "        if open_side == OrderSide.SELL:\n",
    "            loss = ep_ / out_\n",
    "        else:\n",
    "            loss = out_ / ep_\n",
    "\n",
    "        leverage = config.lvrg_set.target_pct / abs(loss - 1 - (fee + config.trader_set.market_fee))\n",
    "\n",
    "    # ------------ leverage rejection ------------ #\n",
    "    # 감당하기 힘든 fluc. 의 경우 진입하지 않음 - dynamic_lvrg 사용 경우\n",
    "    if leverage < 1 and config.lvrg_set.lvrg_rejection:\n",
    "        # if config.lvrg_set.leverage >= 1 and config.lvrg_set.lvrg_rejection:\n",
    "        return None, None\n",
    "\n",
    "    if not config.lvrg_set.allow_float:\n",
    "        leverage = int(leverage)\n",
    "\n",
    "    leverage = min(limit_leverage, max(leverage, 1))\n",
    "\n",
    "    if open_side == OrderSide.SELL:\n",
    "        liqd_p = ep_ / (1 + fee + config.trader_set.market_fee - 1 / leverage)\n",
    "    else:\n",
    "        liqd_p = ep_ * (1 + fee + config.trader_set.market_fee - 1 / leverage)\n",
    "\n",
    "    return leverage, liqd_p\n",
    "\n",
    "\n",
    "def sync_check(df_, config, mode=\"OPEN\", row_slice=True):\n",
    "    try:\n",
    "        make_itv_list = [m_itv.replace('m', 'T') for m_itv in literal_eval(config.trader_set.itv_list)]\n",
    "        row_list = literal_eval(config.trader_set.row_list)\n",
    "        rec_row_list = literal_eval(config.trader_set.rec_row_list)\n",
    "        offset_list = literal_eval(config.trader_set.offset_list)\n",
    "\n",
    "        assert len(make_itv_list) == len(offset_list), \"length of itv & offset_list should be equal\"\n",
    "        htf_df_list = [to_htf(df_, itv=itv_, offset=offset_) for itv_idx, (itv_, offset_)\n",
    "                       in enumerate(zip(make_itv_list, offset_list)) if itv_idx != 0]  #\n",
    "        htf_df_list.insert(0, df_)\n",
    "\n",
    "        # for htf_df_ in htf_df_list:\n",
    "        #     print(htf_df_.tail())\n",
    "\n",
    "        #       Todo        #\n",
    "        #        1. row_list calc.\n",
    "        #           a. indi. 를 만들기 위한 최소 period 가 존재하고, 그 indi. 를 사용한 lb_period 가 존재함\n",
    "        #           b. => default_period + lb_period\n",
    "        #               i. from sync_check, public_indi, ep_point2, ep_dur 의 tf 별 max lb_period check\n",
    "        #                   1. default_period + max lb_period check\n",
    "        #                       a. 현재까지 lb_period_list\n",
    "        #                           h_prev_idx (open / close) 60\n",
    "        #                           dc_period 135\n",
    "        #                           zone_dc_period 135\n",
    "\n",
    "        # --------- slicing (in trader phase only) --------- #\n",
    "        #               --> latency 영향도가 높은 곳은 이곳\n",
    "        if row_slice:  # recursive 가 아닌 indi. 의 latency 를 고려한 slicing\n",
    "            df, df_3T, df_5T, df_15T, df_30T, df_H, df_4H = [df_s.iloc[-row_list[row_idx]:].copy() for row_idx, df_s in\n",
    "                                                             enumerate(htf_df_list)]\n",
    "            rec_df, rec_df_3T, rec_df_5T, rec_df_15T, rec_df_30T, rec_df_H, rec_df_4H = [\n",
    "                df_s.iloc[-rec_row_list[row_idx]:].copy() for row_idx, df_s\n",
    "                in\n",
    "                enumerate(htf_df_list)]\n",
    "        else:\n",
    "            df, df_3T, df_5T, df_15T, df_30T, df_H, df_4H = htf_df_list\n",
    "            rec_df, rec_df_3T, rec_df_5T, rec_df_15T, rec_df_30T, rec_df_H, rec_df_4H = htf_df_list\n",
    "\n",
    "        # --------- add indi. --------- #\n",
    "\n",
    "        #        1. 필요한 indi. 는 enlist_epouttp & mr_check 보면서 삽입\n",
    "        #        2. min use_rows 계산을 위해서, tf 별로 gathering 함        #\n",
    "        # start_0 = time.time()\n",
    "\n",
    "        # ------ T ------ #\n",
    "        # df = dc_line(df, None, 'T', dc_period=20)\n",
    "        # df = bb_line(df, None, 'T')\n",
    "        #\n",
    "        # ------ 3T ------ #\n",
    "        # df = dc_line(df, df_3T, '3T')\n",
    "\n",
    "        # ------ 5T ------ #\n",
    "        # h_candle_v3(df, '5T')\n",
    "        # df = dc_line(df, df_5T, '5T')\n",
    "        # df = bb_line(df, df_5T, '5T')\n",
    "        #\n",
    "        # ------ 15T ------ #\n",
    "        # h_candle_v3(df, '15T')\n",
    "        # df = dc_line(df, df_15T, '15T')\n",
    "        # df = bb_line(df, df_15T, '15T')\n",
    "        #\n",
    "        # ------ 30T ------ #\n",
    "        # df = bb_line(df, df_30T, '30T')\n",
    "        #\n",
    "        # ------ H ------ #\n",
    "        # h_candle_v3(df, 'H')\n",
    "        # df = dc_line(df, df_H, 'H')\n",
    "\n",
    "        # ------ 4H ------ #\n",
    "        # df = bb_line(df, df_4H, '4H')\n",
    "\n",
    "        # rec_df['rsi_1m'] = rsi(rec_df, 14)  # Todo - recursive, 250 period\n",
    "        # df = df.join(to_lower_tf_v2(df, rec_df.iloc[:, [-1]], [-1], backing_i=0), how='inner')  # <-- join same_tf manual\n",
    "        #\n",
    "        # if order_side in [\"OPEN\"]:\n",
    "        #     rec_df_5T['ema_5T'] = ema(rec_df_5T['close'], 195)  # Todo - recursive, 1100 period (5T)\n",
    "        #     df = df.join(to_lower_tf_v2(df, rec_df_5T, [-1]), how='inner')\n",
    "\n",
    "    except Exception as e:\n",
    "        sys_log.error(\"error in sync_check :\", e)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "def public_indi(res_df, config, np_timeidx, mode=\"OPEN\"):\n",
    "    selection_id = config.selection_id\n",
    "\n",
    "    wave_itv1 = config.tr_set.wave_itv1\n",
    "    wave_itv2 = config.tr_set.wave_itv2\n",
    "    wave_period1 = config.tr_set.wave_period1\n",
    "    wave_period2 = config.tr_set.wave_period2\n",
    "    roll_hl_cnt = 3\n",
    "\n",
    "    # assert itv_to_number(wave_itv1) > 1  # wave_itv2 == 'T' and\n",
    "    # ====== public ====== #\n",
    "    # res_df = wave_range_dcbase_v11_3(res_df, config, over_period=2)\n",
    "\n",
    "    try:\n",
    "        # ------------ wave_period1 ------------ #\n",
    "        if itv_to_number(wave_itv1) > 1:\n",
    "            offset = '1h' if wave_itv1 != 'D' else '9h'\n",
    "            htf_df_ = to_htf(res_df, wave_itv1, offset=offset)  # to_htf 는 ohlc, 4개의 col 만 존재 (현재까지)\n",
    "            htf_df = htf_df_[~pd.isnull(htf_df_.close)]\n",
    "\n",
    "            htf_df = wave_range_cci_v4_1(htf_df, wave_period1, itv=wave_itv1)\n",
    "\n",
    "            cols = list(htf_df.columns[4:])  # 15T_ohlc 를 제외한 wave_range_cci_v4 로 추가된 cols, 다 넣어버리기 (추후 혼란 방지)\n",
    "\n",
    "            valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(htf_df,\n",
    "                                                                                                           wave_itv1,\n",
    "                                                                                                           wave_period1,\n",
    "                                                                                                           roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "            \"\"\" \n",
    "            1. wave_bb 의 경우 roll_hl 의 기준이 co <-> cu 변경됨 (cci 와 비교)\n",
    "            2. wave_bb : high_fill_ -> cu_prime_idx 사용\n",
    "            \"\"\"\n",
    "            htf_df = get_roll_wave_data_v2(htf_df, valid_co_prime_idx, roll_co_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "            cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "            htf_df = get_roll_wave_data_v2(htf_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "            cols += list(htf_df.columns[-roll_hl_cnt:])\n",
    "\n",
    "            htf_df = wave_range_ratio_v4_2(htf_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "            cols += list(htf_df.columns[-4:])\n",
    "            # print(cols)\n",
    "\n",
    "            htf_df = get_wave_length(htf_df, valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "            cols += list(htf_df.columns[-4:])\n",
    "            # print(cols)\n",
    "\n",
    "            # ------ 필요한 cols 만 join (htf's idx 정보는 ltf 와 sync. 가 맞지 않음 - join 불가함) ------ #\n",
    "            res_df.drop(cols, inplace=True, axis=1, errors='ignore')\n",
    "            res_df = res_df.join(to_lower_tf_v4(res_df, htf_df, cols, backing_i=0, ltf_itv='T').loc[res_df.index], how='inner')\n",
    "\n",
    "        else:\n",
    "            res_df = wave_range_cci_v4_1(res_df, wave_period1, itv=wave_itv1)\n",
    "\n",
    "            valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(res_df,\n",
    "                                                                                                           wave_itv1,\n",
    "                                                                                                           wave_period1,\n",
    "                                                                                                           roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "            res_df = get_roll_wave_data_v2(res_df, valid_co_prime_idx, roll_co_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "            res_df = get_roll_wave_data_v2(res_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv1, wave_period1), roll_hl_cnt)\n",
    "\n",
    "            res_df = wave_range_ratio_v4_2(res_df, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "            res_df = get_wave_length(res_df, valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr, wave_itv1, wave_period1, roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "            # res_df = cci_v2(res_df, 120, itv=wave_itv1)\n",
    "            \n",
    "            \n",
    "        # ------------ wave_period2 ------------ #\n",
    "#         if wave_itv1 != wave_itv2 or wave_period1 != wave_period2:\n",
    "#             if itv_to_number(wave_itv2) > 1:\n",
    "#                 offset = '1h' if wave_itv2 != 'D' else '9h'\n",
    "#                 htf_df = to_htf(res_df, wave_itv2, offset=offset)\n",
    "#                 htf_df = wave_range_cci_v4_1(htf_df, wave_period2, itv=wave_itv2)\n",
    "#                 # htf_df = wave_range_bb_v1(htf_df, wave_period2, itv=wave_itv2)\n",
    "\n",
    "#                 # cols = list(htf_df.columns[-15:-4])  # except idx col\n",
    "#                 cols = list(htf_df.columns[4:])  # 15T_ohlc 를 제외한 wave_range_cci_v4 로 추가된 cols, 다 넣어버리기 (추후 혼란 방지)\n",
    "\n",
    "#                 # ------ 필요한 cols 만 join (htf's idx 정보는 ltf 와 sync. 가 맞지 않음 - join 불가함) ------ #\n",
    "#                 res_df.drop(cols, inplace=True, axis=1, errors='ignore')\n",
    "#                 res_df = res_df.join(to_lower_tf_v4(res_df, htf_df, cols, backing_i=0, ltf_itv='T'), how='inner')  # tf_entry 진입이면, backing_i = 0 가 가능한 것 아닌가.\n",
    "\n",
    "#             else:\n",
    "#                 res_df = wave_range_cci_v4_1(res_df, wave_period2, itv=wave_itv2)\n",
    "#                 res_df = wave_range_bb_v1(res_df, wave_period2, itv=wave_itv2)\n",
    "\n",
    "\n",
    "        res_df = ma_v2(res_df, 50, itv='T')\n",
    "        res_df = ma_v2(res_df, 200, itv='T')\n",
    "\n",
    "    # valid_co_prime_idx, valid_cu_prime_idx, roll_co_idx_arr, roll_cu_idx_arr = roll_wave_hl_idx_v5(res_df, wave_itv2, wave_period2,\n",
    "    #                                                                                                roll_hl_cnt=roll_hl_cnt)\n",
    "    # res_df = get_roll_wave_data_v2(res_df, valid_co_prime_idx, roll_co_idx_arr, 'wave_high_fill_{}{}'.format(wave_itv2, wave_period2),\n",
    "    #                                roll_hl_cnt)\n",
    "    # res_df = get_roll_wave_data_v2(res_df, valid_cu_prime_idx, roll_cu_idx_arr, 'wave_low_fill_{}{}'.format(wave_itv2, wave_period2), roll_hl_cnt)\n",
    "    #\n",
    "    # res_df = wave_range_ratio_v4_2(res_df, wave_itv2, wave_period2, roll_hl_cnt=roll_hl_cnt)\n",
    "\n",
    "    # ------ wave_loc_pct (bb) ------ #\n",
    "    # res_df = wave_loc_pct_v2(res_df, config, 'T', 60)\n",
    "    # res_df = wave_loc_pct(res_df, config, 'T', 60)\n",
    "\n",
    "    # future_cols = ['cu_es_15T1', 'co_es_15T1', 'upper_wick_ratio_15T', 'lower_wick_ratio_15T']\n",
    "    # itv_list = ['15T', '15T', '15T', '15T']\n",
    "    # res_df = backing_future_data(res_df, future_cols, itv_list)\n",
    "\n",
    "    # ====== intervaly ====== #\n",
    "    # ------ 5T ------ #\n",
    "    # res_df = dc_level(res_df, '5T', 1)\n",
    "    # res_df = bb_level(res_df, '5T', 1)\n",
    "\n",
    "    # res_df = st_level(res_df, '5T', 1)\n",
    "\n",
    "    # ------ 15T ------ #\n",
    "    # res_df = wick_ratio(res_df, '15T')\n",
    "    # res_df = dc_level(res_df, '15T', 1)\n",
    "    # res_df = bb_level(res_df, '15T', 1)\n",
    "    # res_df = dtk_plot(res_df, dtk_itv2='15T', hhtf_entry=15, use_dtk_line=config.loc_set.zone.use_dtk_line, np_timeidx=np_timeidx)\n",
    "\n",
    "    # res_df = st_level(res_df, '15T', 1)\n",
    "\n",
    "    # ------ 30T ------ #\n",
    "    # res_df = wick_ratio(res_df, '30T')\n",
    "    # res_df = dc_level(res_df, '30T', 1)\n",
    "    # res_df = bb_level(res_df, '30T', 1)\n",
    "    # res_df = st_level(res_df, '30T', 1)\n",
    "\n",
    "    # ------ H ------ #\n",
    "    # res_df = wick_ratio(res_df, 'H')\n",
    "    # res_df = bb_level(res_df, 'H', 1)\n",
    "\n",
    "    # ------ 4H ------ #\n",
    "    # res_df = wick_ratio(res_df, '4H')\n",
    "    # res_df = bb_level(res_df, '4H', 1)\n",
    "\n",
    "    # res_df['dc_upper_v2'.format(selection_id)] = res_df['high'].rolling(config.loc_set.zone.dc_period).max()   # Todo, consider dc_period\n",
    "    # res_df['dc_lower_v2'.format(selection_id)] = res_df['low'].rolling(config.loc_set.zone.dc_period).min()\n",
    "\n",
    "    # res_df['zone_dc_upper_v2'.format(selection_id)] = res_df['high'].rolling(config.loc_set.zone.zone_dc_period).max()   # Todo, consider zone_dc_period\n",
    "    # res_df['zone_dc_lower_v2'.format(selection_id)] = res_df['low'].rolling(config.loc_set.zone.zone_dc_period).min()\n",
    "\n",
    "    # if order_side in [\"OPEN\"]:\n",
    "    # candle_score_v3(res_df, 'T', unsigned=False)\n",
    "    # candle_score_v3(res_df, config.loc_set.point1.exp_itv, unsigned=False)\n",
    "\n",
    "    #     temp indi.    #\n",
    "    # res_df[\"ma30_1m\"] = res_df['close'].rolling(30).mean()\n",
    "    # res_df[\"ma60_1m\"] = res_df['close'].rolling(60).mean()\n",
    "    # res_df = dtk_plot(res_df, dtk_itv2='15T', hhtf_entry=15, use_dtk_line=config.loc_set.zone.use_dtk_line, np_timeidx=np_timeidx)\n",
    "\n",
    "    except Exception as e:\n",
    "        sys_log.error(\"error in public : {}\".format(e))\n",
    "    else:\n",
    "        return res_df\n",
    "\n",
    "\n",
    "def expiry_v0(res_df, config, op_idx, e_j, tp_j, np_datas, open_side):\n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "\n",
    "    if config.tr_set.expire_tick != \"None\":\n",
    "        if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "            expire = 1\n",
    "\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if open_side == OrderSide.SELL:\n",
    "            short_tp_1_ = res_df['short_tp_1_{}'.format(selection_id)].to_numpy()  # id 에 따라 dynamic 변수라 이곳에서 numpy 화 진행\n",
    "            short_tp_gap_ = res_df['short_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if low[e_j] <= short_tp_1_[tp_j] - short_tp_gap_[tp_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "        else:\n",
    "            long_tp_1_ = res_df['long_tp_1_{}'.format(\n",
    "                selection_id)].to_numpy()  # iloc 이 빠를까, to_numpy() 가 빠를까  # 3.94 ms --> 5.34 ms (iloc)\n",
    "            long_tp_gap_ = res_df['long_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if high[e_j] >= long_tp_1_[tp_j] + long_tp_gap_[tp_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire\n",
    "\n",
    "\n",
    "def expiry_tp(res_df, config, op_idx, e_j, tp_j, np_datas, open_side):\n",
    "    \"\"\"\n",
    "    tp, tp_gap 기준 expiry\n",
    "    \"\"\"\n",
    "\n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "\n",
    "    if config.tr_set.expire_tick != \"None\":\n",
    "        if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "            expire = 1\n",
    "\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if open_side == OrderSide.SELL:\n",
    "            short_tp_ = res_df['short_tp_{}'.format(selection_id)].to_numpy()  # id 에 따라 dynamic 변수라 이곳에서 numpy 화 진행\n",
    "            short_tp_gap_ = res_df['short_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if low[e_j] <= short_tp_[tp_j] + short_tp_gap_[tp_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "        else:\n",
    "            long_tp_ = res_df['long_tp_{}'.format(\n",
    "                selection_id)].to_numpy()  # iloc 이 빠를까, to_numpy() 가 빠를까  # 3.94 ms --> 5.34 ms (iloc)\n",
    "            long_tp_gap_ = res_df['long_tp_gap_{}'.format(selection_id)].to_numpy()\n",
    "            if high[e_j] >= long_tp_[tp_j] - long_tp_gap_[tp_j] * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire\n",
    "\n",
    "\n",
    "def expiry_wave(res_df, config, op_idx, e_j, wave1, wave_gap, np_datas, open_side):\n",
    "    \"\"\"\n",
    "    wave_1, wave_gap 기준 expiry\n",
    "    \"\"\"\n",
    "\n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "\n",
    "    if config.tr_set.expire_tick != \"None\":\n",
    "        if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "            expire = 1\n",
    "\n",
    "    if config.tr_set.expire_k2 != \"None\":\n",
    "        if open_side == OrderSide.SELL:\n",
    "            if low[e_j] <= wave1 + wave_gap * config.tr_set.expire_k2:\n",
    "                expire = 1\n",
    "        else:\n",
    "            if high[e_j] >= wave1 - wave_gap * config.tr_set.expire_k2:\n",
    "                expire = 1\n",
    "\n",
    "    return expire\n",
    "\n",
    "\n",
    "def expiry_p1p2(res_df, config, op_idx1, op_idx2, tp1, tp0, tp_gap, np_datas, open_side):\n",
    "    \"\"\"\n",
    "    op_idx1 과 op_idx2 사이의 high / low 통해 expiration survey 라고 보면 됨\n",
    "    \"\"\"\n",
    "\n",
    "    high, low = np_datas\n",
    "    selection_id = config.selection_id\n",
    "    expire = 0\n",
    "    touch_idx = None\n",
    "\n",
    "    # if config.tr_set.expire_tick != \"None\":\n",
    "    #     if e_j - op_idx >= config.tr_set.expire_tick:\n",
    "    #         expire = 1\n",
    "\n",
    "    # Todo, p1's tp1, 0 cannot be vectorized\n",
    "    #   a. expiration 의 조건은 wave1, 0 의 broken\n",
    "    idx_range = np.arange(op_idx1, op_idx2)\n",
    "    if config.tr_set.expire_k1 != \"None\":\n",
    "        if open_side == OrderSide.SELL:\n",
    "            touch_idx = np.where((low[op_idx1:op_idx2] <= tp1 + tp_gap * config.tr_set.expire_k1) | \\\n",
    "                                 (high[op_idx1:op_idx2] >= tp0 - tp_gap * config.tr_set.expire_k1),\n",
    "                                 idx_range, np.nan)\n",
    "            # if op_idx1 >= 16353:\n",
    "            #   print(\"high[16353], tp0 :\", high[16353], tp0)\n",
    "            if np.sum(~np.isnan(touch_idx)) > 0:  # touch 가 존재하면,\n",
    "                # if low[op_idx1:op_idx2].min() <= tp1 + tp_gap * config.tr_set.expire_k1 or \\\n",
    "                # high[op_idx1:op_idx2].max() >= tp0 - tp_gap * config.tr_set.expire_k1:   # p2_box loc. 이 있어서, op_idx2 + 1 안함\n",
    "                expire = 1\n",
    "        else:\n",
    "            touch_idx = np.where((high[op_idx1:op_idx2] >= tp1 - tp_gap * config.tr_set.expire_k1) | \\\n",
    "                                 (low[op_idx1:op_idx2] <= tp0 + tp_gap * config.tr_set.expire_k1),\n",
    "                                 idx_range, np.nan)\n",
    "            if np.sum(~np.isnan(touch_idx)) > 0:\n",
    "                # if high[op_idx1:op_idx2].max() >= tp1 - tp_gap * config.tr_set.expire_k1 or \\\n",
    "                # low[op_idx1:op_idx2].min() <= tp0 + tp_gap * config.tr_set.expire_k1:\n",
    "                expire = 1\n",
    "\n",
    "    return expire, np.nanmin(touch_idx)\n",
    "\n",
    "\n",
    "def ep_loc_p1_v3(res_df, config, np_timeidx, show_detail=True, ep_loc_side=OrderSide.SELL):\n",
    "\n",
    "    \"\"\"\n",
    "    vectorized calc.\n",
    "        1. multi-stem 에 따라 dynamic vars.가 입력되기 때문에 class 내부 vars. 로 종속시키지 않음\n",
    "        2. min & max variables 사용\n",
    "    \"\"\"\n",
    "\n",
    "    # 0. param init\n",
    "    selection_id = config.selection_id\n",
    "    wave_itv1 = config.tr_set.wave_itv1\n",
    "    wave_period1 = config.tr_set.wave_period1\n",
    "    c_i = config.trader_set.complete_index\n",
    "\n",
    "    len_df = len(res_df)\n",
    "    mr_res = np.ones(len_df)\n",
    "    zone_arr = np.full(len_df, 0)\n",
    "\n",
    "    # 1. wrr\n",
    "    if config.loc_set.point1.wrr_32_min_short != \"None\":\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            mr_res *= cu_wrr_32_ >= config.loc_set.point1.wrr_32_min_short\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"cu_wrr_32_ >= config.loc_set.point1.wrr_32_min_short : {:.5f} {:.5f} ({})\".format(cu_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point1.wrr_32_min_short,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "    if config.loc_set.point1.wrr_32_max_short != \"None\":\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            mr_res *= cu_wrr_32_ <= config.loc_set.point1.wrr_32_max_short\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"cu_wrr_32_ <= config.loc_set.point1.wrr_32_max_short : {:.5f} {:.5f} ({})\".format(cu_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point1.wrr_32_max_short,\n",
    "                                                                                                 mr_res[c_i]))                \n",
    "    if config.loc_set.point1.wrr_32_min_long != \"None\":\n",
    "        if ep_loc_side == OrderSide.BUY:\n",
    "            co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            mr_res *= co_wrr_32_ >= config.loc_set.point1.wrr_32_min_long\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"co_wrr_32_ >= config.loc_set.point1.wrr_32_min_long : {:.5f} {:.5f} ({})\".format(co_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point1.wrr_32_min_long,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "    if config.loc_set.point1.wrr_32_max_long != \"None\":\n",
    "        if ep_loc_side == OrderSide.BUY:\n",
    "            co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "            mr_res *= co_wrr_32_ <= config.loc_set.point1.wrr_32_max_long\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"co_wrr_32_ <= config.loc_set.point1.wrr_32_max_long : {:.5f} {:.5f} ({})\".format(co_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point1.wrr_32_max_long,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "\n",
    "    # 2. spread\n",
    "    if config.loc_set.point1.spread_min_short != \"None\":  # and not config.tr_set.check_hlm:\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            short_spread_ = res_df['short_spread_{}'.format(selection_id)].to_numpy()\n",
    "            mr_res *= short_spread_ >= config.loc_set.point1.spread_min_short\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"short_spread_ : {:.5f} ({})\".format(short_spread_[c_i], mr_res[c_i]))\n",
    "\n",
    "    if config.loc_set.point1.spread_max_short != \"None\":  # and not config.tr_set.check_hlm:\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            short_spread_ = res_df['short_spread_{}'.format(selection_id)].to_numpy()\n",
    "            mr_res *= short_spread_ <= config.loc_set.point1.spread_max_short\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"short_spread_ : {:.5f} ({})\".format(short_spread_[c_i], mr_res[c_i]))\n",
    "    \n",
    "    if config.loc_set.point1.spread_min_long != \"None\":  # and not config.tr_set.check_hlm:\n",
    "        if ep_loc_side == OrderSide.BUY:\n",
    "            long_spread_ = res_df['long_spread_{}'.format(selection_id)].to_numpy()\n",
    "            mr_res *= long_spread_ >= config.loc_set.point1.spread_min_long\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"long_spread_ : {:.5f} ({})\".format(long_spread_[c_i], mr_res[c_i]))\n",
    "    \n",
    "    if config.loc_set.point1.spread_max_long != \"None\":  # and not config.tr_set.check_hlm\n",
    "        if ep_loc_side == OrderSide.BUY:\n",
    "            long_spread_ = res_df['long_spread_{}'.format(selection_id)].to_numpy()\n",
    "            mr_res *= long_spread_ <= config.loc_set.point1.spread_max_long\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"long_spread_ : {:.5f} ({})\".format(long_spread_[c_i], mr_res[c_i]))\n",
    "\n",
    "    # 3. zone\n",
    "    #     a. config var. 이 등록되지 않은 dur. 은 selection_id 으로 조건문을 나눔 (lvrg_set 과 동일)\n",
    "    if config.loc_set.zone1.use_zone:\n",
    "        \n",
    "        # i.  on_price\n",
    "        # wave_itv1 = config.tr_set.wave_itv1\n",
    "        # wave_period1 = config.tr_set.wave_period1\n",
    "\n",
    "        # wave_high_fill1_ = res_df['wave_high_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "        # wave_low_fill1_ = res_df['wave_low_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "        # short_tp_0_ = res_df['short_tp_0_{}'.format(selection_id)].to_numpy()\n",
    "        # long_tp_0_ = res_df['long_tp_0_{}'.format(selection_id)].to_numpy()\n",
    "        \n",
    "#         short_ep_0_ = res_df['short_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "#         long_ep_0_ = res_df['long_ep1_0_{}'.format(selection_id)].to_numpy()\n",
    "        \n",
    "        # -1. ma50 & ma200\n",
    "        lb_period = 250\n",
    "        thresh_k = 0.5\n",
    "        \n",
    "        high = res_df['high']\n",
    "        low = res_df['low']\n",
    "        ma50 = res_df['ma_T50']#.to_numpy()\n",
    "        ma200 = res_df['ma_T200']#.to_numpy()\n",
    "        ma50_b1 = res_df['ma_T50'].shift(lb_period).to_numpy()\n",
    "        ma200_b1 = res_df['ma_T200'].shift(lb_period).to_numpy()\n",
    "        \n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            # mr_res *= ma50 < ma200\n",
    "            # mr_res *= ma50_b1 < ma200_b1\n",
    "            mr_res *= (ma50 < ma200).rolling(lb_period).sum() == lb_period\n",
    "            mr_res *= (high < ma50).rolling(lb_period).sum() >= lb_period * thresh_k\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"ma50 < ma200 : {:.5f} {:.5f} ({})\".format(ma50[c_i], ma200[c_i], mr_res[c_i]))\n",
    "        else:\n",
    "            # mr_res *= ma50 > ma200\n",
    "            # mr_res *= ma50_b1 > ma200_b1\n",
    "            mr_res *= (ma50 > ma200).rolling(lb_period).sum() == lb_period\n",
    "            mr_res *= (low > ma50).rolling(lb_period).sum() >= lb_period * thresh_k\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"ma50 > ma200 : {:.5f} {:.5f} ({})\".format(ma50[c_i], ma200[c_i], mr_res[c_i]))\n",
    "        \n",
    "\n",
    "        #    1. sar\n",
    "        #         high_ = res_df['high_15T'].to_numpy()\n",
    "        #         low_ = res_df['low_15T'].to_numpy()\n",
    "        #         sar_ = res_df['sar_5T'].to_numpy()\n",
    "\n",
    "        #         if ep_loc_side == OrderSide.SELL:\n",
    "        #             mr_res *= high_ < sar_\n",
    "        #             if show_detail:\n",
    "        #                 sys_log.warning(\"high_ < sar_ : {:.5f} {:.5f} ({})\".format(high_[c_i], sar_[c_i], mr_res[c_i]))\n",
    "        #         else:\n",
    "        #             mr_res *= low_ > sar_\n",
    "        #             if show_detail:\n",
    "        #                 sys_log.warning(\"low_ > sar_ : {:.5f} {:.5f} ({})\".format(low_[c_i], sar_[c_i], mr_res[c_i]))\n",
    "\n",
    "        #    2. dc_base\n",
    "        # dc_base_ = res_df['dc_base_T30'].to_numpy()\n",
    "        # dc_base_T20 = res_df['dc_base_T20'].to_numpy()\n",
    "        # dc_base_5T20 = res_df['dc_base_5T20'].to_numpy()\n",
    "        # dc_base_15T20 = res_df['dc_base_15T20'].to_numpy()\n",
    "        # dc_base_H20 = res_df['dc_base_H20'].to_numpy()\n",
    "        # dc_base_4H20 = res_df['dc_base_4H20'].to_numpy()\n",
    "\n",
    "        # if ep_loc_side == OrderSide.SELL:\n",
    "        #     mr_res *= short_tp_0_ < dc_base_H20\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\"short_tp_0_ < dc_base_H20 : {:.5f} {:.5f} ({})\".format(short_tp_0_[c_i], dc_base_H20[c_i], mr_res[c_i]))\n",
    "        # else:\n",
    "        #     mr_res *= long_tp_0_ > dc_base_H20\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\"long_tp_0_ > dc_base_H20 : {:.5f} {:.5f} ({})\".format(long_tp_0_[c_i], dc_base_H20[c_i], mr_res[c_i]))\n",
    "\n",
    "        #    3. bb\n",
    "#         bb_base_T200 = res_df['bb_base_T200'].to_numpy()\n",
    "        \n",
    "#         if ep_loc_side == OrderSide.SELL:\n",
    "#             mr_res *= short_ep_0_ < bb_base_T200\n",
    "#             # mr_res *= short_tp_0_ < bb_base_T200\n",
    "#             if show_detail:\n",
    "#                 sys_log.warning(\"short_ep_0_ < bb_base_T200 : {:.5f} {:.5f} ({})\".format(short_ep_0_[c_i], bb_base_T200[c_i], mr_res[c_i]))\n",
    "#                 # sys_log.warning(\"short_tp_0_ < bb_base_T200 : {:.5f} {:.5f} ({})\".format(short_tp_0_[c_i], bb_base_T200[c_i], mr_res[c_i]))\n",
    "#         else:\n",
    "#             mr_res *= long_ep_0_ > bb_base_T200\n",
    "#             # mr_res *= long_tp_0_ > bb_base_T200\n",
    "#             if show_detail:\n",
    "#                 sys_log.warning(\"long_ep_0_ > bb_base_T200 : {:.5f} {:.5f} ({})\".format(long_ep_0_[c_i], bb_base_T200[c_i], mr_res[c_i]))\n",
    "#                 # sys_log.warning(\"long_tp_0_ > bb_base_T200 : {:.5f} {:.5f} ({})\".format(long_tp_0_[c_i], bb_base_T200[c_i], mr_res[c_i]))\n",
    "\n",
    "        \n",
    "        # ii. outer_price\n",
    "        #     a. cci\n",
    "#         cci_ = res_df['cci_T120'].to_numpy()\n",
    "        \n",
    "#         # cci_ = res_df['cci_30T20'].to_numpy()\n",
    "#         # b1_cci_ = res_df['cci_30T20'].shift(30).to_numpy()\n",
    "#         threshold = 100\n",
    "\n",
    "#         if ep_loc_side == OrderSide.SELL:\n",
    "#             mr_res *= cci_ < -threshold\n",
    "#             # mr_res *= cci_ < 0\n",
    "#             # mr_res *= cci_ < b1_cci_\n",
    "#             # mr_res *= (cci_ > -100) & (cci_ < -80)\n",
    "#             if show_detail:\n",
    "#                 sys_log.warning(\"cci_ < -threshold : {:.5f} {:.5f} ({})\".format(cci_[c_i], -threshold, mr_res[c_i]))\n",
    "#                 # sys_log.warning(\"cci_ < b1_cci_ : {:.5f} {:.5f} ({})\".format(cci_[c_i], b1_cci_[c_i], mr_res[c_i]))\n",
    "#         else:\n",
    "#             mr_res *= cci_ > threshold\n",
    "#             # mr_res *= cci_ < 0\n",
    "#             # mr_res *= cci_ > b1_cci_\n",
    "#             # mr_res *= (cci_ > 80) & (cci_ < 100)\n",
    "#             if show_detail:\n",
    "#                 sys_log.warning(\"cci_ > threshold : {:.5f} {:.5f} ({})\".format(cci_[c_i], threshold, mr_res[c_i]))\n",
    "#                 # sys_log.warning(\"cci_ > b1_cci_ : {:.5f} {:.5f} ({})\".format(cci_[c_i], b1_cci_[c_i], mr_res[c_i]))\n",
    "\n",
    "\n",
    "        #     b. macd\n",
    "#         # macd_ = res_df['macd_T535'].to_numpy()\n",
    "#         macd_ = res_df['macd_hist_T53515'].to_numpy()\n",
    "\n",
    "#         if ep_loc_side == OrderSide.SELL:\n",
    "#           mr_res *= macd_ < 0\n",
    "#           if show_detail:\n",
    "#             sys_log.warning(\"macd_ < 0 : {:.5f} {:.5f} ({})\".format(macd_[c_i], 0, mr_res[c_i]))\n",
    "#         else:\n",
    "#           mr_res *= macd_ > 0\n",
    "#           if show_detail:\n",
    "#             sys_log.warning(\"macd_ > 0 : {:.5f} {:.5f} ({})\".format(macd_[c_i], 0, mr_res[c_i]))\n",
    "\n",
    "    return mr_res, zone_arr  # mr_res 의 True idx 가 open signal\n",
    "\n",
    "\n",
    "def ep_loc_p2_v3(res_df, config, np_timeidx, show_detail=True, ep_loc_side=OrderSide.SELL):\n",
    "\n",
    "    # ------- param init ------- #\n",
    "    selection_id = config.selection_id\n",
    "    wave_itv2 = config.tr_set.wave_itv2\n",
    "    wave_period2 = config.tr_set.wave_period2\n",
    "    c_i = config.trader_set.complete_index\n",
    "\n",
    "    len_df = len(res_df)\n",
    "    mr_res = np.ones(len_df)\n",
    "    zone_arr = np.full(len_df, 0)\n",
    "\n",
    "    # ------------ wave_range_ratio ------------ #\n",
    "    if config.loc_set.point2.wrr_32_min != \"None\":\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "            mr_res *= cu_wrr_32_ >= config.loc_set.point2.wrr_32_min\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"cu_wrr_32_ >= config.loc_set.point2.wrr_32_min : {:.5f} {:.5f} ({})\".format(cu_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point2.wrr_32_min,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "        else:\n",
    "            co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "            mr_res *= co_wrr_32_ >= config.loc_set.point2.wrr_32_min\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"co_wrr_32_ >= config.loc_set.point2.wrr_32_min : {:.5f} {:.5f} ({})\".format(co_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point2.wrr_32_min,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "    if config.loc_set.point2.wrr_32_max != \"None\":\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            cu_wrr_32_ = res_df['cu_wrr_32_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "            mr_res *= cu_wrr_32_ <= config.loc_set.point2.wrr_32_max\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"cu_wrr_32_ <= config.loc_set.point2.wrr_32_max : {:.5f} {:.5f} ({})\".format(cu_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point2.wrr_32_max,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "        else:\n",
    "            co_wrr_32_ = res_df['co_wrr_32_{}{}'.format(wave_itv2, wave_period2)].to_numpy()\n",
    "            mr_res *= co_wrr_32_ <= config.loc_set.point2.wrr_32_max\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"co_wrr_32_ <= config.loc_set.point2.wrr_32_max : {:.5f} {:.5f} ({})\".format(co_wrr_32_[c_i],\n",
    "                                                                                                 config.loc_set.point2.wrr_32_max,\n",
    "                                                                                                 mr_res[c_i]))\n",
    "\n",
    "    if config.loc_set.zone2.use_zone:\n",
    "        # ------------ outer_price ------------ #\n",
    "        # ------ cci ------ #\n",
    "        cci_ = res_df['cci_30T20'].to_numpy()\n",
    "        b1_cci_ = res_df['cci_30T20'].shift(30).to_numpy()\n",
    "        # base_value = -100\n",
    "\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            # mr_res *= cci_ < 0\n",
    "            mr_res *= cci_ < b1_cci_\n",
    "            # mr_res *= (cci_ > -100) & (cci_ < -80)\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"cci_ < b1_cci_ : {:.5f} {:.5f} ({})\".format(cci_[c_i], b1_cci_[c_i], mr_res[c_i]))\n",
    "        else:\n",
    "            # mr_res *= cci_ < 0\n",
    "            mr_res *= cci_ > b1_cci_\n",
    "            # mr_res *= (cci_ > 80) & (cci_ < 100)\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"cci_ > b1_cci_ : {:.5f} {:.5f} ({})\".format(cci_[c_i], b1_cci_[c_i], mr_res[c_i]))\n",
    "\n",
    "    return mr_res, zone_arr  # mr_res 의 True idx 가 open signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ63Jwpvr7qA",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csZwxsP5r_Pz"
   },
   "outputs": [],
   "source": [
    "      \n",
    "    # ------------ tr_thresh ------------ #  # vectorize allow only for p1_hhm\n",
    "    # if config.loc_set.point1.short_tr_thresh != \"None\":  #  and not config.tr_set.check_hlm:\n",
    "    #     if ep_loc_side == OrderSide.SELL:\n",
    "    #         short_tr_ = res_df['short_tr_{}'.format(selection_id)].to_numpy()\n",
    "    #         mr_res *= short_tr_ >= config.loc_set.point1.short_tr_thresh\n",
    "    #         # mr_res *= short_tr_ <= config.loc_set.point1.short_tr_thresh + 0.1\n",
    "    #         if show_detail:\n",
    "    #             sys_log.warning(\n",
    "    #                 \"short_tr_ >= short_tr_thresh : {:.5f} {:.5f} ({})\".format(short_tr_[c_i], config.loc_set.point1.short_tr_thresh, mr_res[c_i]))\n",
    "    #     else:\n",
    "    #         long_tr_ = res_df['long_tr_{}'.format(selection_id)].to_numpy()\n",
    "    #         mr_res *= long_tr_ >= config.loc_set.point1.long_tr_thresh\n",
    "    #         # mr_res *= long_tr_ <= config.loc_set.point1.long_tr_thresh + 0.1\n",
    "    #         if show_detail:\n",
    "    #             sys_log.warning(\n",
    "    #                 \"long_tr_ >= long_tr_thresh : {:.5f} {:.5f} ({})\".format(long_tr_[c_i], config.loc_set.point1.long_tr_thresh, mr_res[c_i]))\n",
    "    \n",
    "        \"\"\"\n",
    "        future data phase\n",
    "        \"\"\"\n",
    "\n",
    "    #         close_ = res_df['close_30T'].to_numpy()\n",
    "    #         f1_close_ = res_df['close_30T'].shift(-30).to_numpy()\n",
    "\n",
    "    #         if ep_loc_side == OrderSide.SELL:\n",
    "    #             mr_res *= f1_close_ < close_\n",
    "    #             if show_detail:\n",
    "    #                 sys_log.warning(\"f1_close_ < close_ : {:.5f} {:.5f} ({})\".format(f1_close_[c_i], close_[c_i], mr_res[c_i]))\n",
    "    #         else:\n",
    "    #             mr_res *= f1_close_ > close_\n",
    "    #             if show_detail:\n",
    "    #                 sys_log.warning(\"f1_close_ < close_ : {:.5f} {:.5f} ({})\".format(f1_close_[c_i], close_[c_i], mr_res[c_i]))\n",
    "\n",
    "    #         cci_ = res_df['cci_30T20'].to_numpy()\n",
    "    #         f1_cci_ = res_df['cci_30T20'].shift(-30).to_numpy()\n",
    "\n",
    "    #         if ep_loc_side == OrderSide.SELL:\n",
    "    #             mr_res *= f1_cci_ < cci_\n",
    "    #             if show_detail:\n",
    "    #                 sys_log.warning(\"f1_cci_ < cci_ : {:.5f} {:.5f} ({})\".format(f1_cci_[c_i], cci_[c_i], mr_res[c_i]))\n",
    "    #         else:\n",
    "    #             mr_res *= f1_cci_ > cci_\n",
    "    #             if show_detail:\n",
    "    #                 sys_log.warning(\"f1_cci_ < cci_ : {:.5f} {:.5f} ({})\".format(f1_cci_[c_i], cci_[c_i], mr_res[c_i]))\n",
    "    \n",
    "    # ------ hl_loc_pct ------ #\n",
    "    if config.loc_set.zone.hl_loc_pct != \"None\":      \n",
    "      wave_high_loc_pct_ = res_df['wave_high_loc_pct_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "      wave_low_loc_pct_ = res_df['wave_low_loc_pct_{}{}'.format(wave_itv1, wave_period1)].to_numpy()\n",
    "\n",
    "      if ep_loc_side == OrderSide.SELL:\n",
    "        mr_res *= wave_high_loc_pct_ >= config.loc_set.zone.hl_loc_pct\n",
    "        mr_res *= wave_high_loc_pct_ <= config.loc_set.zone.hl_loc_pct + 0.5\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"wave_high_loc_pct_ >= config.loc_set.zone.hl_loc_pct : {:.5f} {:.5f} ({})\".format(wave_high_loc_pct_[c_i], config.loc_set.zone.hl_loc_pct, mr_res[c_i]))\n",
    "      else:\n",
    "        mr_res *= wave_low_loc_pct_ >= config.loc_set.zone.hl_loc_pct\n",
    "        mr_res *= wave_low_loc_pct_ <= config.loc_set.zone.hl_loc_pct + 0.5\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"wave_low_loc_pct_ >= config.loc_set.zone.hl_loc_pct : {:.5f} {:.5f} ({})\".format(wave_low_loc_pct_[c_i], config.loc_set.zone.hl_loc_pct, mr_res[c_i]))\n",
    "\n",
    "            \n",
    "        # ------------------ wave_biaser (sr_confirmer) ------------------ #\n",
    "        if selection_id in ['3_9']:     \n",
    "          itv, period1, period2 = config.tr_set.p1_itv1, config.tr_set.p1_period1, config.tr_set.p1_period2          \n",
    "\n",
    "          if ep_loc_side == OrderSide.SELL:\n",
    "            short_wave_high_ = res_df['short_wave_high_{}{}{}'.format(itv, period1, period2)]\n",
    "            bb_lower_5T_amax = get_line(res_df['short_wave_high_idx_{}{}{}'.format(itv, period1, period2)].to_numpy(), res_df['bb_lower_5T'].to_numpy())\n",
    "            mr_res *= short_wave_high_ <= bb_lower_5T_amax\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"short_wave_high_ <= bb_lower_5T_amax : {:.5f} {:.5f} ({})\".format(short_wave_high_[c_i], bb_lower_5T_amax[c_i], mr_res[c_i]))\n",
    "          else:\n",
    "            long_wave_low_ = res_df['long_wave_low_{}{}{}'.format(itv, period1, period2)]\n",
    "            bb_upper_5T_amax = get_line(res_df['long_wave_low_idx_{}{}{}'.format(itv, period1, period2)].to_numpy(), res_df['bb_upper_5T'].to_numpy())\n",
    "            mr_res *= long_wave_low_ >= bb_upper_5T_amax\n",
    "            if show_detail:\n",
    "                sys_log.warning(\"long_wave_low_ >= bb_upper_5T_amax : {:.5f} {:.5f} ({})\".format(long_wave_low_[c_i], bb_upper_5T_amax[c_i], mr_res[c_i]))\n",
    "\n",
    "\n",
    "        if selection_id in ['4_3', '3_5', '3_51']:\n",
    "            dc_base_T20 = res_df['dc_base_T20'].to_numpy()\n",
    "            dc_base_3T20 = res_df['dc_base_3T20'].to_numpy()\n",
    "            # b1_dc_base_3T20 = res_df['dc_base_3T20'].shift(3).to_numpy()\n",
    "            # dc_base_5T = res_df['dc_base_5T'].to_numpy()\n",
    "            # dc_base_15T = res_df['dc_base_15T'].to_numpy()\n",
    "            # dc_base_30T = res_df['dc_base_30T'].to_numpy()\n",
    "            dc_base_H20 = res_df['dc_base_H20'].to_numpy()\n",
    "            # dc_base_4H = res_df['dc_base_4H'].to_numpy()\n",
    "            # dc_base_D = res_df['dc_base_D'].to_numpy()\n",
    "\n",
    "            itv, period1, period2 = config.tr_set.p1_itv1, config.tr_set.p1_period1, config.tr_set.p1_period2\n",
    "            if ep_loc_side == OrderSide.SELL:\n",
    "                # ------ short_base_ <= dc_base_3T20 ------ #\n",
    "                short_base_ = res_df['short_base_{}{}{}'.format(itv, period1, period2)].to_numpy()\n",
    "                mr_res *= short_base_ <= dc_base_3T20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"short_base_ <= dc_base_3T20 : {:.5f} {:.5f} ({})\".format(short_base_[c_i], dc_base_3T20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # mr_res *= short_base_ <= dc_base_T20\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"short_base_ <= dc_base_T20 : {:.5f} {:.5f} ({})\".format(short_base_[c_i], dc_base_T20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # ------ reject csd ------ #\n",
    "                # dc_upper_ = res_df['dc_upper_{}{}'.format(itv, period1)].to_numpy()\n",
    "                # mr_res *= dc_upper_ <= dc_base_3T\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"dc_upper_ <= dc_base_3T20 : {:.5f} {:.5f} ({})\".format(dc_upper_[c_i], dc_base_3T[c_i], mr_res[c_i]))\n",
    "\n",
    "                # Todo, 부호 조심\n",
    "                # dc_upper2_ = res_df['dc_upper_{}{}'.format(itv, period2)].to_numpy()\n",
    "                # mr_res *= dc_upper2_ >= dc_base_H\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"dc_upper2_ >= dc_base_H20 : {:.5f} {:.5f} ({})\".format(dc_upper2_[c_i], dc_base_H[c_i], mr_res[c_i]))  \n",
    "\n",
    "                # long 과 동일한 dur.\n",
    "                dc_lower2_ = res_df['dc_lower_{}{}'.format(itv, period2)].to_numpy()\n",
    "                mr_res *= dc_lower2_ >= dc_base_H20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"dc_lower2_ >= dc_base_H20 : {:.5f} {:.5f} ({})\".format(dc_lower2_[c_i], dc_base_H20[c_i], mr_res[c_i]))  \n",
    "\n",
    "                # ------ consecutive base ascender ------ #\n",
    "                # ------ 1. roll_min ------ #\n",
    "                dc_base_3T20_rollmin = res_df['dc_base_3T20'].rolling(config.loc_set.zone.base_roll_period).min().to_numpy()\n",
    "                mr_res *= dc_base_3T20_rollmin == dc_base_3T20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\n",
    "                        \"dc_base_3T20_rollmin == dc_base_3T2020 : {:.5f} {:.5f} ({})\".format(dc_base_3T20_rollmin[c_i], dc_base_3T20[c_i], mr_res[c_i]))\n",
    "            else:\n",
    "                # ------ long_base >= dc_base_3T20 ------ #\n",
    "                long_base_ = res_df['long_base_{}{}{}'.format(itv, period1, period2)].to_numpy()\n",
    "                mr_res *= long_base_ >= dc_base_3T20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"long_base_ >= dc_base_3T20 : {:.5f} {:.5f} ({})\".format(long_base_[c_i], dc_base_3T20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # mr_res *= long_base_ >= dc_base_T20\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"long_base_ >= dc_base_T20 : {:.5f} {:.5f} ({})\".format(long_base_[c_i], dc_base_T20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # ------ reject csd ------ #\n",
    "                # dc_lower_ = res_df['dc_lower_{}{}'.format(itv, period1)].to_numpy()\n",
    "                # mr_res *= dc_lower_ >= dc_base_3T\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"dc_lower_ >= dc_base_3T20 : {:.5f} {:.5f} ({})\".format(dc_lower_[c_i], dc_base_3T[c_i], mr_res[c_i]))\n",
    "\n",
    "                dc_lower2_ = res_df['dc_lower_{}{}'.format(itv, period2)].to_numpy()\n",
    "                mr_res *= dc_lower2_ >= dc_base_H20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"dc_lower2_ >= dc_base_H20 : {:.5f} {:.5f} ({})\".format(dc_lower2_[c_i], dc_base_H20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # bb_lower_5T = res_df['bb_lower_5T'].to_numpy()\n",
    "                # mr_res *= dc_lower2_ >= bb_lower_5T\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"dc_lower2_ >= bb_lower_5T : {:.5f} {:.5f} ({})\".format(dc_lower2_[c_i], bb_lower_5T[c_i], mr_res[c_i]))\n",
    "\n",
    "                # ------ alignment ------ #\n",
    "                # mr_res *= (dc_base_3T20 > dc_base_5T) & (dc_base_5T > dc_base_15T) & (dc_base_15T > dc_base_30T)\n",
    "\n",
    "                # ------ consecutive base ascender ------ #\n",
    "                # ------ 1. roll_max ------ #\n",
    "                dc_base_3T20_rollmax = res_df['dc_base_3T20'].rolling(config.loc_set.zone.base_roll_period).max().to_numpy()\n",
    "                mr_res *= dc_base_3T20_rollmax == dc_base_3T20\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\n",
    "                        \"dc_base_3T20_rollmax == dc_base_3T2020 : {:.5f} {:.5f} ({})\".format(dc_base_3T20_rollmax[c_i], dc_base_3T20[c_i], mr_res[c_i]))\n",
    "\n",
    "                # ------ 2. roll_max_v2 - ascender  ------ #\n",
    "                # dc_base_3T_ascend = (res_df['dc_base_3T'] >= res_df['dc_base_3T'].shift(3)).rolling(config.loc_set.zone.base_roll_period).sum().to_numpy()\n",
    "                # # mr_res *= dc_base_3T_ascend == config.loc_set.zone.base_roll_period\n",
    "                # mr_res *= dc_base_3T_ascend != config.loc_set.zone.base_roll_period\n",
    "                # if show_detail:\n",
    "                #     sys_log.warning(\"dc_base_3T_ascend == config.loc_set.zone.base_roll_period : {:.5f} {:.5f} ({})\".format(dc_base_3T_ascend[c_i], config.loc_set.zone.base_roll_period, mr_res[c_i]))\n",
    "\n",
    "\n",
    "    if config.loc_set.point.wrr != \"None\":            \n",
    "      wave_itv = 'T'\n",
    "      wave_period = config.tr_set.wave_period\n",
    "      co_wrr_ = res_df['co_wrr_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "      cu_wrr_ = res_df['cu_wrr_{}{}'.format(wave_itv, wave_period)].to_numpy()\n",
    "      if ep_loc_side == OrderSide.SELL:\n",
    "        mr_res *= co_wrr_ <= config.loc_set.point.wrr\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"co_wrr_ <= config.loc_set.point.wrr : {:.5f} {:.5f} ({})\".format(co_wrr_[c_i], config.loc_set.point.wrr, mr_res[c_i]))\n",
    "      else:\n",
    "        mr_res *= cu_wrr_ <= config.loc_set.point.wrr\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"cu_wrr_ <= config.loc_set.point.wrr : {:.5f} {:.5f} ({})\".format(cu_wrr_[c_i], config.loc_set.point.wrr, mr_res[c_i]))\n",
    "            \n",
    "      # if ep_loc_side == OrderSide.SELL:\n",
    "      #   mr_res *= cu_es_ >= config.loc_set.point.cu_es\n",
    "      #   mr_res *= cu_es_ <= config.loc_set.point.cu_es + 2\n",
    "      #   if show_detail:\n",
    "      #       sys_log.warning(\"cu_es_ >= config.loc_set.point.cu_es : {:.5f} {:.5f} ({})\".format(cu_es_[c_i], config.loc_set.point.cu_es, mr_res[c_i]))\n",
    "      # else:\n",
    "      #   mr_res *= co_es_ >= config.loc_set.point.co_es\n",
    "      #   mr_res *= co_es_ <= config.loc_set.point.co_es + 1\n",
    "      #   if show_detail:\n",
    "      #       sys_log.warning(\"co_es_ >= config.loc_set.point.co_es : {:.5f} {:.5f} ({})\".format(co_es_[c_i], config.loc_set.point.co_es, mr_res[c_i]))\n",
    "\n",
    "\n",
    "      if ep_loc_side == OrderSide.SELL:\n",
    "          mr_res *= lower_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          # mr_res *= upper_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          if show_detail:\n",
    "              sys_log.warning(\"upper_wick_ratio_ >= config.loc_set.point.wick_ratio : {:.5f} {:.5f} ({})\".format(upper_wick_ratio_[c_i], config.loc_set.point.wick_ratio, mr_res[c_i]))\n",
    "      else:\n",
    "          mr_res *= upper_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          mr_res *= upper_wick_ratio_ <= config.loc_set.point.wick_ratio + 0.1\n",
    "          # mr_res *= lower_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          if show_detail:\n",
    "              sys_log.warning(\"lower_wick_ratio_ >= config.loc_set.point.wick_ratio : {:.5f} {:.5f} ({})\".format(lower_wick_ratio_[c_i], config.loc_set.point.wick_ratio, mr_res[c_i]))\n",
    "              \n",
    "      crr_ = res_df['crr_{}'.format(config.loc_set.point.tf_entry)].to_numpy()\n",
    "      mr_res *= crr_ >= config.loc_set.point.crr\n",
    "     \n",
    "      if show_detail:\n",
    "          sys_log.warning(\"crr_ >= config.loc_set.point.crr : {:.5f} {:.5f} ({})\".format(crr_[c_i], config.loc_set.point.crr, mr_res[c_i]))\n",
    "\n",
    "      b1_upper_wick_ratio_ = res_df['upper_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].shift(itv_num).to_numpy()\n",
    "      b1_lower_wick_ratio_ = res_df['lower_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].shift(itv_num).to_numpy()\n",
    "\n",
    "      if ep_loc_side == OrderSide.SELL:\n",
    "          upper_wick_ratio_ = res_df['upper_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].to_numpy()\n",
    "          mr_res *= upper_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          if show_detail:\n",
    "              sys_log.warning(\"upper_wick_ratio_ >= config.loc_set.point.wick_ratio : {:.5f} {:.5f} ({})\".format(upper_wick_ratio_[c_i], config.loc_set.point.wick_ratio, mr_res[c_i]))\n",
    "      else:\n",
    "          lower_wick_ratio_ = res_df['lower_wick_ratio_{}'.format(config.loc_set.point.wick_itv)].to_numpy()\n",
    "          mr_res *= lower_wick_ratio_ >= config.loc_set.point.wick_ratio\n",
    "          if show_detail:\n",
    "              sys_log.warning(\"lower_wick_ratio_ >= config.loc_set.point.wick_ratio : {:.5f} {:.5f} ({})\".format(lower_wick_ratio_[c_i], config.loc_set.point.wick_ratio, mr_res[c_i]))\n",
    "\n",
    "    if config.loc_set.point.cppr != \"None\":   \n",
    "      tf_entry = itv_to_number(config.loc_set.point.tf_entry)\n",
    "      b1_cppr_ = res_df['b1_cppr_{}'.format(config.loc_set.point.tf_entry)].to_numpy()  # check b1's cppr in ep_loc\n",
    "      if ep_loc_side == OrderSide.SELL:\n",
    "        mr_res *= b1_cppr_ >= config.loc_set.point.cppr\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"b1_cppr_ >= config.loc_set.point.cppr : {:.5f} {:.5f} ({})\".format(b1_cppr_[c_i], config.loc_set.point.cppr, mr_res[c_i]))\n",
    "      else:\n",
    "        mr_res *= b1_cppr_ <= -config.loc_set.point.cppr\n",
    "        if show_detail:\n",
    "            sys_log.warning(\"b1_cppr_ <= -config.loc_set.point.cppr : {:.5f} {:.5f} ({})\".format(b1_cppr_[c_i], config.loc_set.point.cppr, mr_res[c_i]))\n",
    "            \n",
    "    # ------------ candle_score ------------ #\n",
    "    wick_score_list = literal_eval(config.loc_set.point.wick_score_list)\n",
    "    if len(wick_score_list) != 0:\n",
    "        score_itv_list = literal_eval(config.loc_set.point.score_itv_list)\n",
    "        # ------ candle_score_v0 (1m initial tick 기준임) ------ #  Todo - higher timeframe 경우 back_data 사용해야함\n",
    "        for wick_score_, score_itv_ in zip(wick_score_list, score_itv_list):\n",
    "            wick_score = res_df['wick_score_{}'.format(score_itv_)].to_numpy()\n",
    "            if ep_loc_side == OrderSide.SELL:\n",
    "                mr_res *= wick_score <= -wick_score_\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"wick_score <= -wick_score_ : {:.5f} {:.5f} ({})\".format(wick_score[c_i], -wick_score_, mr_res[c_i]))\n",
    "            else:\n",
    "                mr_res *= wick_score >= wick_score_\n",
    "                if show_detail:\n",
    "                    sys_log.warning(\"wick_score >= wick_score_ : {:.5f} {:.5f} ({})\".format(wick_score[c_i], wick_score_, mr_res[c_i]))\n",
    "            \n",
    "\n",
    "        # ------------------ swing_middle ------------------ #\n",
    "        # ------------ 1. envelope ------------ #\n",
    "\n",
    "        # ------ a. dc ------ #\n",
    "        # ep_loc check 기준 idx 가 entry 기준이라는 걸 명심\n",
    "        if selection_id in ['v3_2']:\n",
    "            hc_itv = '15T'\n",
    "            dc_itv = '15T'\n",
    "            shift_num = [0, itv_to_number(hc_itv)]\n",
    "            div_res = [1, 0]\n",
    "            for itv_num, res in zip(shift_num, div_res):\n",
    "                close_ = res_df['close_{}'.format(hc_itv)].shift(itv_num).to_numpy()  # close_bar timein 사용하는 경우, 특수로 shift(0) 사용가능\n",
    "                if ep_loc_side == OrderSide.SELL:\n",
    "                    dc_lower_ = res_df['dc_lower_%s' % dc_itv].shift(itv_num).to_numpy()\n",
    "                    mr_res *= (close_ < dc_lower_) == res\n",
    "                else:\n",
    "                    dc_upper_ = res_df['dc_upper_%s' % dc_itv].shift(itv_num).to_numpy()\n",
    "                    mr_res *= (close_ > dc_upper_) == res\n",
    "\n",
    "        # ------------ 2. degree ------------ #\n",
    "        # ------ a. norm_body_ratio ------ #\n",
    "        if config.loc_set.zone.abs_ratio != \"None\":\n",
    "            itv = config.loc_set.point.tf_entry\n",
    "            abs_ratio_ = res_df['abs_ratio_{}'.format(itv)].to_numpy()\n",
    "            mr_res *= abs_ratio_ >= config.loc_set.zone.abs_ratio\n",
    "            # mr_res *= abs_ratio_ <= config.loc_set.zone.abs_ratio\n",
    "\n",
    "    # ------------ 2. imbalance_ratio ------------ #\n",
    "    if config.loc_set.zone.ir != \"None\":\n",
    "        itv = config.loc_set.point.tf_entry\n",
    "        itv_num = itv_to_number(itv)\n",
    "        if ep_loc_side == OrderSide.SELL:\n",
    "            short_ir_ = res_df['short_ir_{}'.format(itv)].to_numpy()\n",
    "            # short_ir_ = res_df['short_ir_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "\n",
    "            # mr_res *= short_ir_ >= config.loc_set.zone.ir     # greater\n",
    "            mr_res *= short_ir_ <= config.loc_set.zone.ir  # lesser\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"short_ir_ <= config.loc_set.zone.ir : {:.5f} {:.5f} ({})\".format(short_ir_[c_i], config.loc_set.zone.ir, mr_res[c_i]))\n",
    "        else:\n",
    "            long_ir_ = res_df['long_ir_{}'.format(itv)].to_numpy()\n",
    "            # long_ir_ = res_df['long_ir_{}'.format(itv)].shift(itv_num).to_numpy()\n",
    "\n",
    "            # mr_res *= long_ir_ >= config.loc_set.zone.ir\n",
    "            mr_res *= long_ir_ <= config.loc_set.zone.ir\n",
    "            if show_detail:\n",
    "                sys_log.warning(\n",
    "                    \"long_ir_ <= config.loc_set.zone.ir : {:.5f} {:.5f} ({})\".format(long_ir_[c_i], config.loc_set.zone.ir, mr_res[c_i]))\n",
    "                \n",
    "        # if selection_id in ['3_6']:\n",
    "        #   itv, period1, period2 = config.loc_set.point.p1_itv0, config.loc_set.point.p1_period1, config.loc_set.point.p1_period2          \n",
    "\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     high_5T = res_df['high_5T'].to_numpy()  # Todo, tf_entry - 1 open 기준이라 future_data 사용 가능\n",
    "        #     short_base_ = res_df['short_base_{}{}{}'.format(itv, period1, period2)]\n",
    "        #     mr_res *= high_5T < short_base_\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\n",
    "        #             \"high_5T < short_base_ : {:.5f} {:.5f} ({})\".format(high_5T[c_i], short_base_[c_i], mr_res[c_i]))\n",
    "        #   else:\n",
    "        #     low_5T = res_df['low_5T'].to_numpy()  # Todo, tf_entry - 1 open 기준이라 future_data 사용 가능\n",
    "        #     long_base_ = res_df['long_base_{}{}{}'.format(itv, period1, period2)]\n",
    "        #     mr_res *= low_5T > long_base_\n",
    "        #     if show_detail:\n",
    "        #         sys_log.warning(\n",
    "        #             \"low_5T > long_base_ : {:.5f} {:.5f} ({})\".format(low_5T[c_i], long_base_[c_i], mr_res[c_i]))'\n",
    "        \n",
    "        # ------ dc_base ------ #\n",
    "        # if selection_id in ['4']:  # 'v3_3', 'v3_4',\n",
    "        #   hc_itv = '5T'\n",
    "        #   dc_itv = '5T'\n",
    "        #   itv_num = itv_to_number(hc_itv)\n",
    "        #   close_ = res_df['close_{}'.format(hc_itv)].shift(itv_num).to_numpy()   # 따라서 future_data 사용시, shifting 필요함\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     dc_lower_ = res_df['dc_lower_%s' % dc_itv].shift(itv_num).to_numpy()\n",
    "        #     mr_res *= close_ < dc_lower_\n",
    "        #   else:\n",
    "        #     dc_upper_ = res_df['dc_upper_%s' % dc_itv].shift(itv_num).to_numpy()\n",
    "        #     mr_res *= close_ > dc_upper_\n",
    "\n",
    "        # ------ ema ------ #\n",
    "        # if selection_id in ['v5_2']: # 'v3'\n",
    "        #   ema_5T = res_df['ema_5T'].to_numpy()\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     mr_res *= close < ema_5T\n",
    "        #   else:\n",
    "        #     mr_res *= close > ema_5T\n",
    "        \n",
    "        # ------ b. bb ------ #\n",
    "        # close = res_df['close'].to_numpy()\n",
    "\n",
    "        # if selection_id in ['v3_3']:\n",
    "        #   open = res_df['open'].to_numpy()\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     bb_lower_1m = res_df['bb_lower_1m'].to_numpy()\n",
    "        #     # mr_res *= close <= bb_lower_1m\n",
    "        #     mr_res *= open <= bb_lower_1m\n",
    "        #   else:\n",
    "        #     bb_upper_1m = res_df['bb_upper_1m'].to_numpy()\n",
    "        #     # mr_res *= close >= bb_upper_1m\n",
    "        #     mr_res *= open >= bb_upper_1m\n",
    "\n",
    "        if selection_id in ['4_1']:\n",
    "            if ep_loc_side == OrderSide.SELL:\n",
    "                bb_lower_15T = res_df['bb_lower_15T'].to_numpy()\n",
    "                short_ep_ = res_df['short_ep_{}'.format(selection_id)].to_numpy()\n",
    "                mr_res *= bb_lower_15T >= short_ep_\n",
    "            else:\n",
    "                bb_upper_15T = res_df['bb_upper_15T'].to_numpy()\n",
    "                long_ep_ = res_df['long_ep_{}'.format(selection_id)].to_numpy()\n",
    "                mr_res *= bb_upper_15T <= long_ep_\n",
    "\n",
    "        # if selection_id in ['v5_2']:\n",
    "        #   bb_upper2_ = res_df['bb_upper2_%s' % config.loc_set.zone.bbz_itv].to_numpy()\n",
    "        #   bb_lower2_ = res_df['bb_lower2_%s' % config.loc_set.zone.bbz_itv].to_numpy()\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     mr_res *= bb_upper2_ < close\n",
    "        #   else:\n",
    "        #     mr_res *= bb_lower2_ > close\n",
    "\n",
    "        # degree_list = literal_eval(config.loc_set.zone.degree_list)\n",
    "        # if len(degree_list) != 0:\n",
    "        # # if selection_id in ['v3_3', 'v3_4']:\n",
    "        #   norm_close_15 = res_df['norm_close_15'].to_numpy()   # -> 이거 뭘로 만들었는지 불분명함,,\n",
    "        #   b1_norm_close_15 = res_df['norm_close_15'].shift(15).to_numpy()\n",
    "\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     mr_res *= norm_close_15 <= -degree_list[0]\n",
    "        #     # mr_res *= b1_norm_close_15 <= -degree_list[1]\n",
    "        #   else:\n",
    "        #     mr_res *= norm_close_15 >= degree_list[0]\n",
    "        #     # mr_res *= b1_norm_close_15 >= degree_list[1]\n",
    "\n",
    "        # ------ b. dc ------ #\n",
    "        # if selection_id in ['v3_3']:\n",
    "        #   if ep_loc_side == OrderSide.SELL:\n",
    "        #     dc_lower_ = res_df['dc_lower_1m'].to_numpy()\n",
    "        #     b1_dc_lower_ = res_df['dc_lower_1m'].shift(1).to_numpy()\n",
    "        #     mr_res *= dc_lower_ < b1_dc_lower_\n",
    "        #   else:\n",
    "        #     dc_upper_ = res_df['dc_upper_1m'].to_numpy()\n",
    "        #     b1_dc_upper_ = res_df['dc_upper_1m'].shift(1).to_numpy()\n",
    "        #     mr_res *= dc_upper_ > b1_dc_upper_\n",
    "\n",
    "        # ------ c. sar ------ #\n",
    "        # if selection_id in ['v3_3']:\n",
    "        # sar_uptrend_3T = res_df['sar_uptrend_3T'].to_numpy()\n",
    "        # if ep_loc_side == OrderSide.SELL:\n",
    "        #   mr_res *= sar_uptrend_3T == 0\n",
    "        # else:\n",
    "        #   mr_res *= sar_uptrend_3T == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjKHyqftzhD7"
   },
   "source": [
    "### config paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1489,
     "status": "ok",
     "timestamp": 1666567980466,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "q_4E-zH02WJy"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_dict = {\n",
    "  \"selection_id\": \"1\",\n",
    "  \"trader_set\": {\n",
    "    \"backtrade\": 1,\n",
    "    \"back_data_path\": \"D:\\\\Projects\\\\System_Trading\\\\JnQ\\\\database\\\\binance\\\\cum\\\\2023-01-12\\\\2023-01-12 ETHUSDT_1m.ftr\",\n",
    "    \"start_datetime\": \"2022-12-12 00:00:59.999\",\n",
    "    \"run\": 1,\n",
    "    \"df_log\": 0,\n",
    "    \"show_detail\": 0,\n",
    "    \"latest_index\": -1,\n",
    "    \"complete_index\": -2,\n",
    "    \"limit_fee\": 0.0002,\n",
    "    \"market_fee\": 0.0004,\n",
    "    \"initial_asset\": 10,\n",
    "    \"profit_mode\": \"PROD\",\n",
    "    \"asset_changed\": 0,\n",
    "    \"symbol\": \"ETHUSDT\",\n",
    "    \"symbol_changed\": 0,\n",
    "    \"token\": \"5859375131:AAHPzzz_Dv2OSxFsSOLChiXhfL0jN_6fOWU\",\n",
    "    \"messenger_on\": 0,\n",
    "    \"itv_list\": \"['T', '3T', '5T', '15T', '30T', 'H', '4H']\",\n",
    "    \"row_list\": \"[500, 1, 1, 1, 1, 1, 1]\",\n",
    "    \"rec_row_list\": \"[1, 1, 1, 1, 1, 1, 1]\",\n",
    "    \"offset_list\": \"['1h', '1h', '1h', '1h', '1h', '1h', '1h']\",\n",
    "    \"loop_duration\": 3.6,\n",
    "    \"realtime_term\": 0.2,\n",
    "    \"api_term\": 1,\n",
    "    \"order_term\": 0.5,\n",
    "    \"market_check_term\": 5,\n",
    "    \"open_exec_check_term\": 5,\n",
    "    \"open_exec_qty_ratio\": 0.97,\n",
    "    \"tp_exec_check_term\": 5\n",
    "  },\n",
    "  \"pos_set\": {\n",
    "    \"short_inversion\": 0,\n",
    "    \"long_inversion\": 0,\n",
    "    \"short_ban\": 0,\n",
    "    \"long_ban\": 0,\n",
    "    \"short_fake\": 0,\n",
    "    \"long_fake\": 0\n",
    "  },\n",
    "  \"loc_set\": {\n",
    "    \"point1\": {\n",
    "      \"exp_itv\": \"5T\",\n",
    "      \"tf_entry\": \"15T\",\n",
    "      \"candle_pattern\": \"CDLMARUBOZU\",\n",
    "      \"spread_min_short\": 1.025,\n",
    "      \"spread_max_short\": \"None\",\n",
    "      \"spread_min_long\": 1.027,\n",
    "      \"spread_max_long\": \"None\",\n",
    "      \"tr_thresh_short\": \"None\",\n",
    "      \"tr_thresh_long\": \"None\",\n",
    "      \"wick_ratio_short\": \"None\",\n",
    "      \"wick_ratio_long\": \"None\",\n",
    "      \"wick_itv\": \"5T\",\n",
    "      \"wrr_10\": \"None\",\n",
    "      \"wrr_21\": \"None\",\n",
    "      \"wrr_32_min_short\": \"None\",\n",
    "      \"wrr_32_max_short\": 0.7,\n",
    "      \"wrr_32_min_long\": \"None\",\n",
    "      \"wrr_32_max_long\": 0.7,\n",
    "      \"co_es\": \"None\",\n",
    "      \"cu_es\": \"None\",\n",
    "      \"crr\": \"None\",\n",
    "      \"cppr\": \"None\",\n",
    "      \"ppr\": \"None\",\n",
    "      \"wbr\": \"None\",\n",
    "      \"dbr\": \"None\",\n",
    "      \"dbr2\": \"None\",\n",
    "      \"brr\": \"None\",\n",
    "      \"ir\": \"None\",\n",
    "      \"abs_ratio\": \"None\"\n",
    "    },\n",
    "    \"point2\": {\n",
    "      \"wrr_32_min\": \"None\",\n",
    "      \"wrr_32_max\": \"None\",\n",
    "      \"csdbox_range\": 0.3,\n",
    "      \"tr_thresh_short\": \"None\",\n",
    "      \"tr_thresh_long\": \"None\",\n",
    "      \"csd_period\": \"None\"\n",
    "    },\n",
    "    \"zone1\": {\n",
    "      \"use_zone\": 0,\n",
    "      \"base_roll_period\": 50,\n",
    "      \"degree_list\": \"[]\",\n",
    "      \"dtk_itv\": \"5T\",\n",
    "      \"dt_k\": \"None\",\n",
    "      \"dc_period\": 135,\n",
    "      \"use_dtk_line\": 0,\n",
    "      \"zone_dt_k\": 0.4,\n",
    "      \"zone_dc_period\": 135\n",
    "    },\n",
    "    \"zone2\": {\n",
    "      \"use_zone\": 0\n",
    "    }\n",
    "  },\n",
    "  \"tr_set\": {\n",
    "    \"check_hlm\": 0,\n",
    "    \"wave_itv1\": \"T\",\n",
    "    \"wave_period1\": 20,\n",
    "    \"wave_length_min_short1\": 80,\n",
    "    \"wave_length_max_short1\": \"None\",\n",
    "    \"wave_length_min_long1\": \"None\",\n",
    "    \"wave_length_max_long1\": 85,\n",
    "    \"wave_spread1\": \"None\",\n",
    "    \"wave_time_ratio1\": \"None\",\n",
    "    \"wave_itv2\": \"T\",\n",
    "    \"wave_period2\": 20,\n",
    "    \"tc_period\": 20,\n",
    "    \"wave_greater1\": 0,\n",
    "    \"wave_greater2\": 0,\n",
    "    \"wave_lesser1\": 2,\n",
    "    \"wave_lesser2\": 2,\n",
    "    \"expire_k1\": -1.2,\n",
    "    \"expire_k2\": 0.0,\n",
    "    \"expire_tick\": \"None\",\n",
    "    \"p2_box_k1\": 0,\n",
    "    \"p2_box_k2\": 0,\n",
    "    \"p1p2_low\": 0.0,\n",
    "    \"tp_gap\": 0.0,\n",
    "    \"ep1_gap\": 0.7,\n",
    "    \"ep2_gap\": 0.3,\n",
    "    \"out_gap\": 0,\n",
    "    \"decay_gap\": \"None\",\n",
    "    \"c_ep_gap\": \"None\",\n",
    "    \"t_out_gap\": \"None\",\n",
    "    \"wb_tp_gap\": 0,\n",
    "    \"wb_out_gap\": 0,\n",
    "    \"bias_tick\": 100\n",
    "  },\n",
    "  \"ep_set\": {\n",
    "    \"entry_type\": \"LIMIT\",\n",
    "    \"static_ep\": 1,\n",
    "    \"point2\": {\n",
    "      \"entry_type\": \"LIMIT\"\n",
    "    }\n",
    "  },\n",
    "  \"tp_set\": {\n",
    "    \"non_tp\": 0,\n",
    "    \"static_tp\": 1,\n",
    "    \"tp_onexec\": 0,\n",
    "    \"decay_term\": 60,\n",
    "    \"partial_ranges\": \"[1]\",\n",
    "    \"partial_qty_ratio\": \"[1]\"\n",
    "  },\n",
    "  \"out_set\": {\n",
    "    \"non_out\": 0,\n",
    "    \"hl_out\": 1,\n",
    "    \"static_out\": 1,\n",
    "    \"out_onexec\": 0,\n",
    "    \"tf_exit\": \"None\",\n",
    "    \"fisher_exit\": \"None\",\n",
    "    \"rsi_exit\": 0,\n",
    "    \"cci_exit\": 0\n",
    "  },\n",
    "  \"lvrg_set\": {\n",
    "    \"static_lvrg_short\": 1,\n",
    "    \"static_lvrg_long\": 0,\n",
    "    \"limit_leverage\": \"None\",\n",
    "    \"leverage\": 3,\n",
    "    \"target_pct\": 0.3,\n",
    "    \"allow_float\": 0,\n",
    "    \"lvrg_rejection\": 0\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuD_2vY7TI_8",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKag94Y2TMCO"
   },
   "outputs": [],
   "source": [
    ",\n",
    "      \"hc_itv\": 60,\n",
    "      \"osc_band\": 20\n",
    "      \n",
    "      \"wick_score_list\": \"[]\",\n",
    "      \"body_score_list\": \"[]\",\n",
    "      \"score_itv_list\": \"[]\",,\n",
    "\n",
    "      \"wick_score_list\": \"[]\",\n",
    "      \"body_score_list\": \"[]\",\n",
    "      \"score_itv_list\": \"['T']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HOjnZjSgzk1"
   },
   "source": [
    "## Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = '2023-01-12 ETHUSDT'  # 2023-01-12 ETHUSDT / 2023-02-21 FTMUSDT  2023-02-21 ALICEUSDT /2022-04-27 ETH / 2023-02-20 BTC 2023-03-23 KRW-ETH_1m 2023-03-23 KRW-SSX_1m\n",
    "date, ticker = data_name.split(\" \")\n",
    "\n",
    "mode = \"CRYPTO\"\n",
    "database_type = 'database/binance/'  # 'binance/' kiwoom upbit\n",
    "file_system = \"ftr\" if mode == \"CRYPTO\" else \"pkl\"\n",
    "\n",
    "\"\"\"\n",
    "database 는 JnQ 내부로 통일할 것.\n",
    "\"\"\"\n",
    "database_dir_path = os.path.join(pkg_path, database_type, \"cum\", date).replace(\"JnQ_32bit\", \"JnQ\")  # cum non_cum -> use, non_cum data for backtrade validation\n",
    "data_list = [s for s in os.listdir(database_dir_path) if file_system in s if date in s if ticker in s]\n",
    "print(data_list)\n",
    "\n",
    "start_0 = time.time()\n",
    "key = data_list[0]  # tempoaray use single key\n",
    "data_path = os.path.join(database_dir_path, key)\n",
    "\n",
    "if mode == \"CRYPTO\":\n",
    "    res_df_ = pd.read_feather(data_path, columns=None, use_threads=True).set_index(\"index\")\n",
    "else:\n",
    "    res_df_ = pd.read_pickle(data_path)\n",
    "    \n",
    "# print(res_df_.head())\n",
    "print(data_path, \"loaded !\")\n",
    "print(\"load res_df_ elapsed time :\", time.time() - start_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQH_l4opEh_O"
   },
   "outputs": [],
   "source": [
    "print(res_df_.dtypes)\n",
    "# print(res_df_.index[[0, 1, -1]]) # '2021-12-01 09:00:00'\n",
    "# len(res_df_)\n",
    "# res_df_.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2yj2SwAXDLp",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### edit cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1657898275247,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "x9wkWw15XCAm",
    "outputId": "cf3fee46-d616-45e7-a3e2-3e0683513582"
   },
   "outputs": [],
   "source": [
    "col_list = list(res_df_.columns)\n",
    "\n",
    "# ------ check target cols ------ #\n",
    "# print([col_ for col_ in col_list if 'stoch' in col_])\n",
    "\n",
    "# ------ drop ------ #\n",
    "# res_df_.drop([col_ for col_ in col_list if 'open_15T' in col_], inplace=True, axis=1)\n",
    "res_df_.drop([col_ for col_ in col_list if 'bb' in col_], inplace=True, axis=1)\n",
    "# res_df_.drop([col_ for col_ in col_list if 'min' in col_], inplace=True, axis=1)\n",
    "# res_df_.drop([col_ for col_ in col_list if 'ma' in col_], inplace=True, axis=1)\n",
    "# res_df_.drop([col_ for col_ in col_list if 'long_base' in col_], inplace=True, axis=1)\n",
    "# res_df_.drop([col_ for col_ in col_list[5:]], inplace=True, axis=1)\n",
    "\n",
    "# ------ replace ------ #\n",
    "# for c_i, col_ in enumerate(col_list):\n",
    "#   if 'basis' in col_:\n",
    "# #   # if col_[-1] in ['m', 'h', 'd', 'H'] and '_' in col_:eTa_5T\n",
    "# #   # if col_[0] in ['h'] and '_' in col_:\n",
    "# #   if 'bir_' in col_:\n",
    "\n",
    "#     col_list[c_i] = col_.replace('basis', 'base')\n",
    "# #     # col_list[c_i] = col_.replace('m', 'T').replace('h', 'H').replace('1T', 'T')\n",
    "# #     # col_list[c_i] = col_.replace('1d', 'D')\n",
    "# #     # col_list[c_i] = col_.replace('eTa_5T', 'ema_5T')\n",
    "# #     # col_list[c_i] = col_list[c_i][1:]\n",
    "# #     # print(col_list[c_i][0])\n",
    "# res_df_.columns = col_list\n",
    "# col_list[-2:] = ['resi_T', 'sup_T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLI8unIyroiC"
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1666570076577,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "qBJfPsmJzVIr",
    "outputId": "d0fabcac-50f2-416c-ec2b-5ee2353bdb1e"
   },
   "outputs": [],
   "source": [
    "config = EasyDict(param_dict)\n",
    "\n",
    "\"\"\"\n",
    "1. get_open_info_df_v2 에서 id_list, config_list를 유지하기 위해서는, override 형식을 유지하는게 맞고, override 한 내용만을 확인하기 위해서\n",
    "특정 idx 만을 선택하는 현재의 구조를 유지하는게 옳다고 봄.\n",
    "    a. 따라서, len(config_list) == 1 로 제한을 둔 것\n",
    "\"\"\"\n",
    "\n",
    "id_idx_list = [0]  # IDEP 에서 편집할 idx 선택, 원본 파일에 영향 주지는 않음\n",
    "public_override = 1\n",
    "utils_override = 1\n",
    "config_override = 1\n",
    "\n",
    "# ------ config_list 와 같은 org_var 에 override 하는거 다시 생각하기 ------ #\n",
    "id_list = id_arr[id_idx_list]\n",
    "utils_list = utils_arr[id_idx_list]\n",
    "config_list = config_arr[id_idx_list]\n",
    "\n",
    "if config_override or utils_override:\n",
    "  assert len(config_list) == 1\n",
    "  if config_override:    \n",
    "    config_list[0] = config\n",
    "    id_list[0] = config.selection_id  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqRF1eyZ0xBL"
   },
   "source": [
    "### Edit configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1666570021879,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "afUV2b1jaggN"
   },
   "outputs": [],
   "source": [
    "config.trader_set.start_datetime = \"2020-05-05 00:00:59.999\"  # \"2020-05-05 00:00:59.999\" # \"None\" \"2022-08-05 00:00:59.999\" #  \"2020-05-05 00:00:59.999\" # 2022-02-01 16:34:59.999000 \"2022-01-14 16:34:59.999000\"  \"2020-09-05 00:00:59.999\" \"2022-01-10 00:00:59.999\" \"2021-10-04 02:39:59.999000\"\n",
    "# # 2020-05-05 00:00:59.999 <- all_in method ETH bank 의 세력 진입 분기점으로 봄, 이전 data 는 불규칙적임.\n",
    "\n",
    "\"\"\"\n",
    "p1_hhm 의 경우 out_box 를 위해 wave_itv 1 & 2 를 동일하게 설정해야함\n",
    "\"\"\"\n",
    "config_list[0].tr_set.wave_itv1 = 'T'\n",
    "# config_list[0].tr_set.wave_period1 = 20\n",
    "# config_list[0].tr_set.wave_itv2 = '30T'\n",
    "# config_list[0].tr_set.wave_period2 = 20\n",
    "# config_list[0].tr_set.tc_period = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1101,
     "status": "ok",
     "timestamp": 1666570079162,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "WstWVNihCNH8",
    "outputId": "123f8ee6-04df-4bc8-ed0d-fc86309a9f62"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "res_df slicing : ta_lib 연산을 위해서, > double 의 data type 이 요구됨\n",
    "\"\"\"\n",
    "\n",
    "if config.trader_set.start_datetime != \"None\":\n",
    "    res_df = res_df_.astype(float).loc[pd.to_datetime(config.trader_set.start_datetime):]\n",
    "else:    \n",
    "    res_df = res_df_.astype(float)\n",
    "\n",
    "np_timeidx = np.array([intmin_np(date_) for date_ in res_df.index.to_numpy()])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "public_indi : public 이니까, 첫번째 config 를 기준으로 작성해도 무방함.\n",
    "\"\"\"\n",
    "start_0 = time.time()\n",
    "if public_override:\n",
    "    res_df = public_indi(res_df, config_list[0], np_timeidx)  # 현재 대부분의 시간은 h_candle 에서 소비되고 있음\n",
    "else:\n",
    "    res_df = bank.public.public_indi(res_df, config_list[0], np_timeidx)\n",
    "print(\"public_indi elapsed time :\", time.time() - start_0)\n",
    "\n",
    "\n",
    "# ------------ make data_list ------------ # - 반복될 이유가 없는 phase - public_indo 에 종속\n",
    "start_0 = time.time()\n",
    "ohlc_cols = ['open', 'high', 'low', 'close']\n",
    "ohlc_list = [res_df[col_].to_numpy() for col_ in ohlc_cols]\n",
    "print(\"make data_list elapsed time :\", time.time() - start_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.dtypes\n",
    "# res_df.tail()\n",
    "# res_df.index[[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666570030992,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "_iYcJk8nK8Yq"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. p1's entry_type 잘살필 것\n",
    "\"\"\"\n",
    "\n",
    "# config_list[0].ep_set.entry_type = \"LIMIT\" # \"LIMIT\" # \"MARKET\"\n",
    "# config_list[0].ep_set.point2.entry_type = \"LIMIT\" # \"LIMIT\" # \"MARKET\"\n",
    "\n",
    "# config_list[0].tr_set.check_hlm = 0  # 0 : p1_hhm, 1: p1_hlm, 2 : p2_hlm  => p1_hlm 은 p1_hhm 의 p1_idx 를 유지하면서, hlm 을 확인하기 위함임.\n",
    "# if config_list[0].tr_set.check_hlm == 2:\n",
    "#     assert config_list[0].ep_set.entry_type == \"MARKET\"\n",
    "    \n",
    "# config_list[0].loc_set.point.candle_pattern = talib.get_function_groups()['Pattern Recognition'][51]   # \"None\" # 0.5 0.7\n",
    "# config_list[0].pos_set.short_ban = 0\n",
    "# config_list[0].pos_set.long_ban = 0\n",
    "\n",
    "# config_list[0].tr_set.wave_lesser = 3\n",
    "config_list[0].tr_set.wave_length_min_short1 = \"None\" # 80  # \"None\" 50 45 15 110 100 \n",
    "config_list[0].tr_set.wave_length_max_short1 = \"None\"  # \"None\" 45 15 110 100 \n",
    "config_list[0].tr_set.wave_length_min_long1 = \"None\" # \"None\" 45 15 110 100 \n",
    "config_list[0].tr_set.wave_length_max_long1 = \"None\"  # \"None\" 45 15 110 100 \n",
    "# config_list[0].tr_set.wave_spread1 = \"None\"  # \"None\" 15 110 100 \n",
    "# config_list[0].tr_set.wave_time_ratio1 = \"None\"  # \"None\" 6\n",
    "# config_list[0].tr_set.wave_greater1 = 0  # 0 50 \n",
    "# config_list[0].tr_set.wave_greater2 = 0  # 10\n",
    "# config_list[0].tr_set.p1_period1 = 5\n",
    "# config_list[0].tr_set.p1_period2 = 5\n",
    "# # config_list[0].tr_set.p2_period1 = 20\n",
    "# # config_list[0].tr_set.p2_period2 = 20\n",
    "\n",
    "# config_list[0].tr_set.tp_gap = -0.05 # 0.68\n",
    "# config_list[0].tr_set.ep1_gap = 0.3 # -0.8 -0.618 -0.23 -0.382 0.19 0.8 -0.12 -0.26\n",
    "# config_list[0].tr_set.ep2_gap = -0.5 # -0.618 -0.23 -0.382 0.19 \n",
    "# config_list[0].tr_set.out_gap = 1.4 # -0.48  # 0 -0.35 -0.6\n",
    "# config_list[0].tr_set.wb_tp_gap = 0.5\n",
    "# config_list[0].tr_set.wb_out_gap = -0.0\n",
    "\n",
    "# config_list[0].trader_set.limit_fee = 1e-10\n",
    "# config_list[0].trader_set.market_fee = 1e-10\n",
    "# config_list[0].trader_set.limit_fee = 0.0002\n",
    "# config_list[0].trader_set.market_fee = 0.0004\n",
    "# config_list[0].trader_set.limit_fee = 0.0005\n",
    "# config_list[0].trader_set.market_fee = 0.0005\n",
    "# config_list[0].trader_set.limit_fee = 0.00015\n",
    "# config_list[0].trader_set.market_fee = 0.00215\n",
    "# config_list[0].loc_set.point.short_wick_ratio = 0.2 # \"None\" # 2.5\n",
    "# config_list[0].loc_set.point.long_wick_ratio = 0.2 # \"None\" # 2.5\n",
    "# config_list[0].loc_set.point.crr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1666570079924,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "iI39YI_5GguK",
    "outputId": "56609f9d-e6f8-44c7-cf40-a3eb8c1214ce"
   },
   "outputs": [],
   "source": [
    "start_0 = time.time()\n",
    "\n",
    "if utils_override:   # 현재, utils_override 하는 경우 1개의 ID 만 허용함 \n",
    "  res_df = enlist_tr(res_df, config_list[0], np_timeidx, env='BANK')    # 36995.0 -> 152766.0 # 4044 np.sum(long_open_res == 1) : 4325\n",
    "else:\n",
    "    for utils_, config_ in zip(utils_list, config_list):\n",
    "        res_df = utils_.enlist_tr(res_df, config_, np_timeidx)\n",
    "        \n",
    "print(\"enlist_tr elapsed time :\", time.time() - start_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666569812768,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "gfDSOGMd91rE"
   },
   "outputs": [],
   "source": [
    "# ------ edit loc_set config ------ #\n",
    "# config_list[0].loc_set.point1.wrr_10 = \"None\" # \"None\" 0.3\n",
    "# config_list[0].loc_set.point1.wrr_21 = \"None\" # \"None\" \n",
    "# config_list[0].loc_set.point1.wrr_32_min_short = \"None\" # 0.7 # \"None\" 1 0.5 0.482 0.302\n",
    "config_list[0].loc_set.point1.wrr_32_max_short = 0.3 # 0.7 # \"None\" 1 0.5 0.482 0.302\n",
    "# config_list[0].loc_set.point1.wrr_32_min_long = \"None\" # 0.7 # \"None\" 1 0.5 0.482 0.302\n",
    "config_list[0].loc_set.point1.wrr_32_max_long = 0.3 # 0.7 # \"None\" 1 0.5 0.482 0.302\n",
    "# config_list[0].loc_set.point1.dsc_ratio = 0.8\n",
    "# config_list[0].loc_set.point2.wrr_32 = \"None\" # \"None\" 1 0.5 0.382 0.302 0.25\n",
    "# config_list[0].loc_set.point2.csd_period = \"None\"  # \"None\" 100\n",
    "config_list[0].loc_set.zone1.use_zone = 0\n",
    "# config_list[0].loc_set.zone1.bb_trend_period = 150\n",
    "# config_list[0].loc_set.zone1.hl_loc_pct = \"None\" # \"None\" 1 0.5\n",
    "# config_list[0].loc_set.zone2.use_zone = 0\n",
    "# config_list[0].loc_set.point1.cu_es = \"None\" # \"None\" # -2\n",
    "# config_list[0].loc_set.point1.co_es = \"None\" # \"None\" # -3\n",
    "# config_list[0].loc_set.point1.cppr = 0.5   # \"None\" # 0.5 0.7\n",
    "# config_list[0].loc_set.point1.wbr = \"None\" # 0.7\n",
    "# config_list[0].loc_set.point1.dbr = \"None\"   # 0.7\n",
    "# config_list[0].loc_set.point1.dbr2 = \"None\"  # 0.7\n",
    "# config_list[0].loc_set.point1.brr = \"None\"   # 0.8\n",
    "# config_list[0].loc_set.point1.ir = \"None\" # \"None\" 0.8\n",
    "# config_list[0].loc_set.point1.wick_score_list = \"[]\"\n",
    "# config_list[0].loc_set.point1.score_itv_list = \"['H']\"\n",
    "# config_list[0].loc_set.point1.abs_ratio = \"None\"  # 0.7\n",
    "# config_list[0].loc_set.point1.short_tr_thresh = \"None\"  #  \"None\" 0.5 2 0.8 # # 0.7  5 # tr_thresh 엄청 민감함\n",
    "# config_list[0].loc_set.point1.long_tr_thresh = 5  #  \"None\" 2 0.8 ## 0.7 5 \n",
    "config_list[0].loc_set.point1.spread_min_short = \"None\" # \"None\" # 1.02 1.05 1.0054 # 1.0054 # \"None\" # --> default 1.0054\n",
    "config_list[0].loc_set.point1.spread_max_short = \"None\"  # \"None\" # 1.0054 # 1.0054 # \"None\" # --> default 1.0054\n",
    "config_list[0].loc_set.point1.spread_min_long = \"None\" # \"None\" 1.02  1.0054\n",
    "config_list[0].loc_set.point1.spread_max_long = \"None\" # 1.0054 \"None\" 1.05\n",
    "# # # config_list[0].loc_set.zone1.base_roll_period = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1741,
     "status": "ok",
     "timestamp": 1666570082803,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "9DPgykxQ92mU",
    "outputId": "36d777e8-db04-41d9-97d5-83201d40a6f4"
   },
   "outputs": [],
   "source": [
    "open_info_df1 = get_open_info_df_v2(ep_loc_p1_v3, res_df, np_timeidx, id_list, config_list, id_idx_list, open_num=1)  # --> point * dur. 관련 (loc_set) param 에 종속 (open_info 가 변경되는게 아니라면, 재실행할 필요없음)\n",
    "open_info_df2 = get_open_info_df_v2(ep_loc_p2_v3, res_df, np_timeidx, id_list, config_list, id_idx_list, open_num=2)\n",
    "open_info_df_list = [open_info_df1, open_info_df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666568396877,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "KqVkg236t_f2"
   },
   "outputs": [],
   "source": [
    "# ------ edit entry & exit (ep, tp, out, ..) config ------ #\n",
    "config_list[0].tr_set.expire_k1 = 0.0\n",
    "# config_list[0].tr_set.expire_tick = \"None\"\n",
    "# config_list[0].tr_set.p2_box_k1 = 0.0  # 0 default --> 0 ~ 1 사이 값 사용 tp_1 로부터 떨어지는 거리\n",
    "# config_list[0].tr_set.p2_box_k2 = 0.0  # 0.5 0 default --> \"None\" 불가, 0 ~ 1 사이 값 사용 tp_0 로부터 떨어지는 거리, 본디 p2_box 는 p1_box 내부에 존재해야, 정확한 hhm 이 측정가능해짐\n",
    "# config_list[0].tr_set.p1p2_low = 0.5  # 0.5 0.7 0  0 is equal to \"None\", 마찬가지로 tp_0 로부터 떨어지는 거리\n",
    "\n",
    "# config_list[0].loc_set.point2.short_tr_thresh = \"None\" #1.5 # \"None\"  #  \"None\" 0.5 2 0.8 # # 0.7 # tr_thresh 엄청 민감함\n",
    "# config_list[0].loc_set.point2.long_tr_thresh = \"None\" #1.5 # \"None\"  #  \"None\" 2 0.8 ## 0.7\n",
    "\n",
    "# config_list[0].ep_set.point2.entry_type = \"LIMIT\"\n",
    "# config_list[0].ep_set.point2.wick_score_list = str([])\n",
    "\n",
    "# config_list[0].tp_set.static_tp = 1\n",
    "# config_list[0].tp_set.non_tp = 0 # 0 1\n",
    "# config_list[0].tp_set.partial_ranges = \"[1]\"\n",
    "# config_list[0].tp_set.partial_qty_ratio = \"[1]\"\n",
    "# config_list[0].tp_set.partial_ranges = \"[0.2, 0.66, 1]\"\n",
    "# config_list[0].tp_set.partial_qty_ratio = \"[0.25, 0.25, 0.5]\"\n",
    "# config_list[0].tp_set.partial_ranges = \"[0.5, 1]\"\n",
    "# config_list[0].tp_set.partial_qty_ratio = \"[0.25, 0.75]\"\n",
    "\n",
    "# config_list[0].out_set.non_out = 0\n",
    "# config_list[0].out_set.hl_out = 1\n",
    "# config_list[0].out_set.cci_exit = 0\n",
    "# config_list[0].out_set.tf_exit = \"None\" # 15 \"None\"\n",
    "\n",
    "config_list[0].lvrg_set.static_lvrg_short = 1\n",
    "config_list[0].lvrg_set.static_lvrg_long = 1\n",
    "config_list[0].lvrg_set.leverage = 1\n",
    "# config_list[0].lvrg_set.target_pct = 0.3 # 0.1 0.03\n",
    "# config_list[0].lvrg_set.allow_float = 1\n",
    "# config_list[0].lvrg_set.lvrg_rejection = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "executionInfo": {
     "elapsed": 2055,
     "status": "ok",
     "timestamp": 1666570084856,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "TvGs5mBxsuBK",
    "outputId": "6669fd7c-067f-4c8f-a364-d65f8e7982e9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cautions\n",
    "    1. if lvrg_rejection = 0, spread 가 큰 경우, min_lvrg 1 이기 때문에 target_pct < min_pr 가능함.\n",
    "    2. liqd = exit 까지의 min_low / high 를 의미함. (long / short 기준), 따라서 zero 일 필요가 없다는 이야기.\n",
    "    3. long & short point 의 open_side 가 일치하는 경우, p2 side_check release 해줄 것.\n",
    "    4. hlm != 1.0 인 경우는 market 으로 인해 목표가에 도달했음에도 불구하고, pr > 1 이 되지 않는 경우. hlm() function 참조.\n",
    "\"\"\"\n",
    "\n",
    "en_ex_pairing = en_ex_pairing_v9_44 # en_ex_pairing_v9_3 en_ex_pairing_v9_42 en_ex_pairing_v9_4\n",
    "# funcs1 = [expiry_p1p2, expiry_tp, lvrg_liqd_set_v2, check_entry_v6_3, check_signal_out_v4, check_hl_out_v4, check_limit_tp_exec_v3]  # 보수적 검증\n",
    "funcs1 = [expiry_p1p2, expiry_tp, lvrg_liqd_set_v2, check_entry_v6_2, check_signal_out_v4, check_hl_out_v4, check_limit_tp_exec]  # expiry_tp / expiry_wave\n",
    "\n",
    "idep_plot = idep_plot_v16_6\n",
    "funcs2 = [get_wave_bias_v6_2, get_pr_v7, get_res_info_nb_v3, plot_info_v8_2, frq_dev_plot_v5]  # get_wave_bias_v6_1 / # 여기서 입력되는 get_res_info 는 signi. mode 에 사용됨.\n",
    "\n",
    "test_ratio = 0.0\n",
    "plot_is = 1  # insample\n",
    "signi = 0\n",
    "show_detail = 0\n",
    "\n",
    "short_pr, short_obj, short_lvrg_arr, short_fee_arr, short_tpout_arr, short_tr_arr, short_bias_arr, short_net_p1_bias_tick, short_p2exec_p1_bias_tick, short_net_p1_idx_arr, short_p2_idx_arr, short_tp_1, short_tp_0, short_out_1, short_out_0, short_ep2_0, \\\n",
    "      long_pr, long_obj, long_lvrg_arr, long_fee_arr, long_tpout_arr, long_tr_arr, long_bias_arr, long_net_p1_bias_tick, long_p2exec_p1_bias_tick, long_net_p1_idx_arr, long_p2_idx_arr, long_tp_1, long_tp_0, long_out_1, long_out_0, long_ep2_0 = \\\n",
    "get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot, funcs2, test_ratio=test_ratio, plot_is=plot_is, signi=signi, show_detail=show_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lYgsqH-rfAM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------ inversion ------ #\n",
    "# _ = get_res_v5(res_df, open_info_df, ohlc_list, config_list, np_timeidx, funcs, inversion=True, test_ratio=test_ratio, plot_is=1, signi=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(long_obj[-1])\n",
    "long_obj[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_cols = ['open', 'high', 'low', 'close', 'ma_T50', 'ma_T200']\n",
    "# input_cols = ['open', 'high', 'low', 'close', 'ma_T50', 'ma_T200', 'long_open1_1']\n",
    "\n",
    "data_size = 200\n",
    "\n",
    "# min\n",
    "# (v - v.min()) / (v.max() - v.min())\n",
    "\n",
    "long_p1_idx_arr = long_obj[-1].astype(int).ravel()\n",
    "\n",
    "res_df_data = res_df[input_cols].to_numpy()\n",
    "# print(res_df_data[long_p1_idx_arr])\n",
    "# print(long_p1_idx_arr)\n",
    "# break\n",
    "\n",
    "x_data = []\n",
    "for p1 in long_p1_idx_arr:\n",
    "    \n",
    "    start_0 = time.time()\n",
    "    # data_np = res_df[input_cols].iloc[p1 + 1 - data_size:p1 + 1].to_numpy()\n",
    "    data_np = res_df_data[p1 + 1 - data_size:p1 + 1]\n",
    "    # plt.plot(data_np[:, -2:])\n",
    "    # plt.show()\n",
    "    \n",
    "    data_np_norm = min_max_scaler(data_np)\n",
    "    # plt.plot(data_np_norm[:, -2:])\n",
    "    # plt.show()\n",
    "    x_data.append(data_np_norm)\n",
    "    # print(data_np_norm.shape)\n",
    "    # break\n",
    "    # print(\"elapsed time : {}\".format(time.time() - start_0)) # 0.012034177780151367 --> 0.0009989738464355469s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_data).reshape(-1, 1200)\n",
    "# x_train = np.array(x_data).reshape(-1, 200, 6)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idep_mode = \"CRYPTO\"  # CRYPTO STOCK\n",
    "\n",
    "# data_name = '2023-02-28 208370'  # 2023-01-12 ETH / 2023-02-21 FTM /2022-04-27 ETH / 2023-02-20 BTC\n",
    "# date, ticker = data_name.split(\" \")\n",
    "date = \"2023-02-21\" # \"2023-02-21\"  \"2023-03-23\"\n",
    "save_mode = 0\n",
    "\n",
    "\"\"\"\n",
    "database 는 JnQ 내부로 통일할 것.\n",
    "\"\"\"\n",
    "database_type = 'database/binance/'  # 'binance' kiwoom upbit\n",
    "database_dir_abspath = os.path.join(pkg_path, database_type, \"cum\", date).replace(\"JnQ_32bit\", \"JnQ\")  # cum non_cum -> use, non_cum data for backtrade validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if idep_mode == \"CRYPTO\":\n",
    "    data_list = [f_name for f_name in os.listdir(database_dir_abspath) if 'ftr' in f_name if date in f_name]\n",
    "else:\n",
    "    data_list = pd.read_pickle(os.path.join(database_dir_abspath, \"rank.pkl\"))  # [:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_list_x = []\n",
    "concat_list_y = []\n",
    "\n",
    "for data_name in data_list:\n",
    "    \n",
    "    pkl_save_path_x = r\"D:\\Projects\\System_Trading\\JnQ\\database\\binance\\ML\\{}\".format(data_name.replace('.ftr', '_x.pkl'))\n",
    "    pkl_save_path_y = r\"D:\\Projects\\System_Trading\\JnQ\\database\\binance\\ML\\{}\".format(data_name.replace('.ftr', '_y.pkl'))\n",
    "\n",
    "    with open(pkl_save_path_x, 'rb') as f:\n",
    "        concat_list_x.append(pickle.load(f))\n",
    "        \n",
    "    with open(pkl_save_path_y, 'rb') as f:\n",
    "        concat_list_y.append(pickle.load(f))\n",
    "    \n",
    "    if len(concat_list_x) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1752, 1200)\n",
      "(1752, 1)\n",
      "[   0    1    2 ... 1749 1750 1751]\n"
     ]
    }
   ],
   "source": [
    "x_train_ = np.concatenate(concat_list_x)\n",
    "y_train_ = np.concatenate(concat_list_y)\n",
    "print(x_train_.shape)\n",
    "print(y_train_.shape)\n",
    "\n",
    "# len(pd.isnull(x_train).sum(axis=1))\n",
    "# len(pd.isnull(x_train).sum(axis=1) != 0)\n",
    "valid_idx = np.where(pd.isnull(x_train_).sum(axis=1) == 0)[0]\n",
    "print(valid_idx)\n",
    "x_train = x_train_[valid_idx]\n",
    "y_train = y_train_[valid_idx]\n",
    "\n",
    "input_cols = ['open', 'high', 'low', 'close', 'ma_T50', 'ma_T200']\n",
    "# input_cols = ['open', 'high', 'low', 'close', 'ma_T50', 'ma_T200', 'long_open1_1']\n",
    "data_size = 200\n",
    "\n",
    "x_data = x_train.reshape(-1, data_size, len(input_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_save_path = r\"D:\\Projects\\System_Trading\\JnQ\\database\\binance\\ML\\profitable_indexes.pkl\"\n",
    "                    \n",
    "# with open(pkl_save_path, 'wb') as f:\n",
    "#     pickle.dump(profitable_indexes, f)\n",
    "#     print(pkl_save_path, 'saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linkage_matrix = hierarchy.linkage(cos_sim, method=\"complete\")\n",
    "\n",
    "# Plot dendrogram\n",
    "dendrogram = hierarchy.dendrogram(linkage_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cut dendrogram and assign cluster labels\n",
    "num_clusters = 15\n",
    "labels = hierarchy.cut_tree(linkage_matrix, n_clusters=num_clusters).flatten()\n",
    "\n",
    "# Print cluster labels\n",
    "# for i, label in enumerate(clusters):\n",
    "#     print(f\"String: {data[i]}, Cluster: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 3, 5, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "cs = []\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(cos_sim)\n",
    "    cs.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), cs)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('CS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 1576, 0: 52, 1: 38, 2: 15, 3: 11, 4: 9, 5: 12, 6: 8, 7: 11, 8: 10, 9: 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# model_DB = DBSCAN( min_samples = 5, metric = 'cosine').fit(cos_sim)\n",
    "model_DB = DBSCAN(min_samples = 10).fit(cos_sim)\n",
    "labels = model_DB.labels_\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts = True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1,  4, -1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1752, 6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[:, :, 0].shape #\n",
    "x_data[:, 0].shape #\n",
    "# x_data.shape #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(cos_sim[:, 0], cos_sim[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, label in enumerate(labels):\n",
    "    \n",
    "    if label == 3:\n",
    "\n",
    "        plt.plot(x_train[i])\n",
    "plt.show()\n",
    "\n",
    "        # plt.plot(x_data[index_a])\n",
    "        # plt.plot(x_data[index_b])\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "profitable_indexes = {}\n",
    "usded_indexes = []\n",
    "\n",
    "for i_ in range(len(x_train)):\n",
    "    \n",
    "    if i_ in usded_indexes:\n",
    "        # print(usded_indexes)\n",
    "        continue\n",
    "    \n",
    "    start_0 = time.time()\n",
    "    similarity_ratio = cosine_similarity([x_train[i_]], x_train)\n",
    "    print(\"elapsed time (~cosine_similarity) : {}\".format(time.time() - start_0))\n",
    "    \n",
    "    # for i in range(len(similarity_ratio)):\n",
    "\n",
    "    ratio_row = similarity_ratio.ravel()\n",
    "    # print(ratio_row)\n",
    "    # closest_index = np.argsort(ratio_row)[::-1][1])\n",
    "    # print(closest_index)\n",
    "    close_indexes = np.where((ratio_row > 0.99) & (ratio_row < 0.999))[0]\n",
    "    # print(close_indexes)\n",
    "    # print(long_pr[close_indexes])\n",
    "\n",
    "    close_indexes_len = len(close_indexes)    \n",
    "    if close_indexes_len > 0:\n",
    "    # if close_indexes_len > 100:\n",
    "        \n",
    "        y_train_close = y_train[close_indexes]\n",
    "\n",
    "        pr_cumprod = np.cumprod(y_train_close)\n",
    "        acc_pr = pr_cumprod[-1]\n",
    "        \n",
    "\n",
    "        if acc_pr > 1:\n",
    "            \n",
    "#             close_indexes_list = close_indexes.tolist()\n",
    "#             # profitable_indexes.append(close_indexes_list)\n",
    "#             profitable_indexes[i_] = close_indexes.tolist()\n",
    "#             usded_indexes += [i_] + close_indexes_list\n",
    "#             # print(profitable_indexes)\n",
    "#             # print(usded_indexes)            \n",
    "\n",
    "#             print(\"profit_index : {}\".format(i_))\n",
    "#             print(\"wr :\", (y_train_close > 1).sum() / close_indexes_len)\n",
    "#             print(\"close_indexes_len : {}\".format(close_indexes_len))   \n",
    "#             print(\"acc_pr : {}\".format(acc_pr))\n",
    "\n",
    "#             plt.plot(pr_cumprod)\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.plot(x_data[i_])\n",
    "#             plt.show()\n",
    "            \n",
    "#             print(\"elapsed time (~plot) : {}\".format(time.time() - start_0))\n",
    "    \n",
    "\n",
    "            for i2 in close_indexes:\n",
    "                plt.plot(x_train[i_])\n",
    "                plt.plot(x_train[i2])\n",
    "\n",
    "                # plt.plot(x_data[i_])\n",
    "                # plt.plot(x_data[i2])\n",
    "\n",
    "                plt.title(ratio_row[i2])\n",
    "                print(y_train[i_], y_train[i2])\n",
    "                plt.show()\n",
    "                # break             \n",
    "\n",
    "        print()\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8617235539182387\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_a = 0\n",
    "index_b = 1\n",
    "\n",
    "data_a = x_train[0]\n",
    "data_b = x_train[1]\n",
    "\n",
    "similarity_ratio = cosine_similarity([x_train[index_a]], [x_train[index_b]])[0][0]\n",
    "print(similarity_ratio)\n",
    "\n",
    "plt.plot(data_a)\n",
    "plt.plot(data_b)\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(x_data[index_a])\n",
    "# plt.plot(x_data[index_b])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_img(y_pred):\n",
    "    n = 10\n",
    "    fig = plt.figure(1)\n",
    "    box_index = 1\n",
    "    for cluster in range(10):\n",
    "        result = np.where(y_pred == cluster)\n",
    "        for i in np.random.choice(result[0].tolist(), n, replace=False):\n",
    "            ax = fig.add_subplot(n, n, box_index)\n",
    "            plt.imshow(x_train[i].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            box_index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TSNE(learning_rate=300)\n",
    "transformed = model.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DBSCAN(eps=2.4, min_samples=100)\n",
    "predict = model.fit(transformed)\n",
    "y_pred = predict.labels_\n",
    "\n",
    "# Assign result to df\n",
    "dataset = pd.DataFrame({'Column1':transformed[:,0],'Column2':transformed[:,1]})\n",
    "dataset['cluster_num'] = pd.Series(predict.labels_)\n",
    "\n",
    "viz_img(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### print config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- print config ------- #\n",
    "config_sets = ['selection_id', 'trader_set', 'pos_set', 'loc_set', 'tr_set', 'ep_set', 'tp_set', 'out_set', 'lvrg_set']\n",
    "for set_i, set_ in enumerate(config_sets):\n",
    "    if set_i == len(config_sets) - 1:\n",
    "        end = '\\n'\n",
    "    else:\n",
    "        end = ', \\n'\n",
    "    print('\"{}\": {}'.format(set_, json.dumps(config_list[0][set_], indent=2)), end=end)\n",
    "# _ = [print(key_ + \":\", json.dumps(config_list[0][key_], indent=1), end=',\\n') for key_ in ['selection_id', 'trader_set', 'pos_set', 'loc_set', 'tr_set', 'ep_set', 'tp_set', 'out_set', 'lvrg_set']] #  'trader_set',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### on multiple ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idep_on_multiple_ticker(database_dir_abspath, data_list, signi=True, ml=False):\n",
    "    \n",
    "    sub_title_list = ['hhm', 'hlm', 'frq', 'dpf', 'wr', 'sr', 'acc_pr', 'sum_pr', 'min_pr', 'liqd', 'acc_mdd', 'sum_mdd_prod', 'sum_mdd_sum']\n",
    "    sub_title_list_long = [col + '_long' for col in sub_title_list]\n",
    "    sub_title_list_short = [col + '_short' for col in sub_title_list]    \n",
    "    sub_title_list_len = len(sub_title_list)    \n",
    "    res_list_long = []\n",
    "    res_list_short = []\n",
    "    for r_, ticker in enumerate(data_list):\n",
    "\n",
    "        print(\"# ------------ rank : {}, ticker : {} ------------ #\".format(r_, ticker))\n",
    "\n",
    "        # while 1:  # memory allocation 문제로 진행했으나, while 은 해결책이 아님 (eternal loop+\n",
    "        try:                \n",
    "            start_0 = time.time()\n",
    "            if idep_mode == \"CRYPTO\":\n",
    "                data_path = os.path.join(database_dir_abspath, \"{}\".format(ticker))\n",
    "                res_df_ =pd.read_feather(data_path, columns=None, use_threads=True).set_index(\"index\")\n",
    "            else:\n",
    "                data_path = os.path.join(database_dir_abspath, \"{} {}.pkl\".format(date, ticker))\n",
    "                res_df_ = pd.read_pickle(data_path)\n",
    "            print(data_path, \"loaded !\")\n",
    "            print(\"load res_df_ elapsed time :\", time.time() - start_0)\n",
    "            \n",
    "            # timeindex_str = str(res_df_.index[0])\n",
    "            # if timeindex_str != \"2021-03-05 09:01:00\":\n",
    "            #     print(\"res_df_.index[0] : {}\\n\".format(timeindex_str))\n",
    "            #     continue\n",
    "\n",
    "            if config.trader_set.start_datetime != \"None\":\n",
    "                res_df = res_df_.astype(float).loc[pd.to_datetime(config.trader_set.start_datetime):]\n",
    "            else:    \n",
    "                res_df = res_df_.astype(float)\n",
    "            np_timeidx = np.array([intmin_np(date_) for date_ in res_df.index.to_numpy()])\n",
    "\n",
    "\n",
    "            start_0 = time.time()\n",
    "            if public_override:\n",
    "                res_df = public_indi(res_df, config_list[0], np_timeidx)  # 현재 대부분의 시간은 h_candle 에서 소비되고 있음\n",
    "            else:\n",
    "                res_df = bank.public.public_indi(res_df, config_list[0], np_timeidx)\n",
    "            print(\"public_indi elapsed time :\", time.time() - start_0)\n",
    "\n",
    "\n",
    "            start_0 = time.time()\n",
    "            ohlc_cols = ['open', 'high', 'low', 'close']\n",
    "            ohlc_list = [res_df[col_].to_numpy() for col_ in ohlc_cols]\n",
    "            print(\"make data_list elapsed time :\", time.time() - start_0)\n",
    "\n",
    "\n",
    "            start_0 = time.time()\n",
    "            if utils_override:   # 현재, utils_override 하는 경우 1개의 ID 만 허용함 \n",
    "              res_df = enlist_tr(res_df, config_list[0], np_timeidx)    # 36995.0 -> 152766.0 # 4044 np.sum(long_open_res == 1) : 4325\n",
    "            else:\n",
    "                for utils_, config_ in zip(utils_list, config_list):\n",
    "                    res_df = utils_.enlist_tr(res_df, config_, np_timeidx)\n",
    "            print(\"enlist_tr elapsed time :\", time.time() - start_0)\n",
    "\n",
    "\n",
    "            open_info_df1 = get_open_info_df_v2(ep_loc_p1_v3, res_df, np_timeidx, id_list, config_list, id_idx_list, open_num=1)  # --> point * dur. 관련 (loc_set) param 에 종속 (open_info 가 변경되는게 아니라면, 재실행할 필요없음)\n",
    "            open_info_df2 = get_open_info_df_v2(ep_loc_p2_v3, res_df, np_timeidx, id_list, config_list, id_idx_list, open_num=2)\n",
    "            open_info_df_list = [open_info_df1, open_info_df2]\n",
    "            \n",
    "            \n",
    "            en_ex_pairing = en_ex_pairing_v9_44 # en_ex_pairing_v9_3 en_ex_pairing_v9_42 en_ex_pairing_v9_4\n",
    "            # funcs1 = [expiry_p1p2, expiry_tp, lvrg_liqd_set_v2, check_entry_v6_3, check_signal_out_v4, check_hl_out_v4, check_limit_tp_exec_v3]  # 보수적 검증\n",
    "            funcs1 = [expiry_p1p2, expiry_tp, lvrg_liqd_set_v2, check_entry_v6_2, check_signal_out_v4, check_hl_out_v4, check_limit_tp_exec]  # expiry_tp / expiry_wave\n",
    "\n",
    "            idep_plot = idep_plot_v16_6\n",
    "            funcs2 = [get_wave_bias_v6_2, get_pr_v7, get_res_info_nb_v3, plot_info_v8_2, frq_dev_plot_v5]  # get_wave_bias_v6_1 / # 여기서 입력되는 get_res_info 는 signi. mode 에 사용됨.\n",
    "\n",
    "            \n",
    "            test_ratio = 0.0\n",
    "            plot_is = 1  # insample\n",
    "            show_detail = 0\n",
    "\n",
    "            if signi:\n",
    "                short_res, long_res, both_res = get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot, funcs2, test_ratio=test_ratio, plot_is=plot_is, signi=signi, show_detail=show_detail)\n",
    "                \n",
    "                res_list_long.append([np.nan] * sub_title_list_len)\n",
    "                res_list_short.append([np.nan] * sub_title_list_len)\n",
    "                \n",
    "                if len(long_res) != 0 and type(long_res) != float:\n",
    "                    res_list_long.append(list(long_res))\n",
    "                else:\n",
    "                    res_list_long.append([np.nan] * sub_title_list_len)\n",
    "                \n",
    "                if len(short_res) != 0 and type(short_res) != float:\n",
    "                    res_list_short.append(list(short_res))\n",
    "                else:\n",
    "                    res_list_short.append([np.nan] * sub_title_list_len)\n",
    "                    \n",
    "            else:\n",
    "                # get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot, funcs2, test_ratio=test_ratio, plot_is=plot_is, signi=signi, show_detail=show_detail)\n",
    "                short_pr, short_obj, short_lvrg_arr, short_fee_arr, short_tpout_arr, short_tr_arr, short_bias_arr, short_net_p1_bias_tick, short_p2exec_p1_bias_tick, short_net_p1_idx_arr, short_p2_idx_arr, short_tp_1, short_tp_0, short_out_1, short_out_0, short_ep2_0, \\\n",
    "                      long_pr, long_obj, long_lvrg_arr, long_fee_arr, long_tpout_arr, long_tr_arr, long_bias_arr, long_net_p1_bias_tick, long_p2exec_p1_bias_tick, long_net_p1_idx_arr, long_p2_idx_arr, long_tp_1, long_tp_0, long_out_1, long_out_0, long_ep2_0 = \\\n",
    "                get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot, funcs2, test_ratio=test_ratio, plot_is=plot_is, signi=signi, show_detail=show_detail)\n",
    "                \n",
    "                if ml:\n",
    "                    input_cols = ['open', 'high', 'low', 'close', 'ma_T50', 'ma_T200'] #, 'long_open1_1']\n",
    "\n",
    "                    data_size = 200\n",
    "                    cols_len = len(input_cols)\n",
    "                    flatten_len = data_size * cols_len\n",
    "\n",
    "                    # min\n",
    "                    # (v - v.min()) / (v.max() - v.min())\n",
    "                    res_df_data = res_df[input_cols].to_numpy()                    \n",
    "                    long_p1_idx_arr = long_obj[-1].astype(int).ravel()\n",
    "\n",
    "                    x_data = []\n",
    "                    for p1 in long_p1_idx_arr:\n",
    "\n",
    "                        start_0 = time.time()\n",
    "                        # data_np = res_df[input_cols].iloc[p1 + 1 - data_size:p1 + 1].to_numpy()\n",
    "                        data_np = res_df_data[p1 + 1 - data_size:p1 + 1]\n",
    "                        # plt.plot(data_np[:, -2:])\n",
    "                        # plt.show()\n",
    "\n",
    "                        data_np_norm = min_max_scaler(data_np)\n",
    "                        # plt.plot(data_np_norm[:, -2:])\n",
    "                        # plt.show()\n",
    "                        x_data.append(data_np_norm)\n",
    "                        # print(data_np_norm.shape)\n",
    "                        # break\n",
    "                        # print(\"elapsed time : {}\".format(time.time() - start_0)) # 0.012034177780151367 --> 0.0009989738464355469s\n",
    "\n",
    "                    pkl_save_path_x = r\"D:\\Projects\\System_Trading\\JnQ\\database\\binance\\ML\\{}\".format(ticker.replace('.ftr', '_x.pkl'))\n",
    "                    pkl_save_path_y = r\"D:\\Projects\\System_Trading\\JnQ\\database\\binance\\ML\\{}\".format(ticker.replace('.ftr', '_y.pkl'))\n",
    "                    \n",
    "                    with open(pkl_save_path_x, 'wb') as f:\n",
    "                        x_train = np.array(x_data).reshape(-1, flatten_len)\n",
    "                        pickle.dump(x_train, f)\n",
    "                        print(pkl_save_path_x, 'saved.')\n",
    "                        \n",
    "                    with open(pkl_save_path_y, 'wb') as f:\n",
    "                        pickle.dump(long_pr, f)\n",
    "                        print(pkl_save_path_y, 'saved.')\n",
    "\n",
    "                    # with open(pkl_save_path, 'rb') as ')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"error in get_res : {}\".format(e))\n",
    "\n",
    "    \n",
    "    if signi:\n",
    "        if type(data_list) == list:\n",
    "            df_rank = pd.Series(data_list).to_frame()\n",
    "        else:        \n",
    "            df_rank = data_list.to_frame()\n",
    "        df_rank[sub_title_list_long] = np.array(res_list_long)\n",
    "        df_rank[sub_title_list_short] = np.array(res_list_short)\n",
    "\n",
    "        return df_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "idep_mode = \"CRYPTO\"  # CRYPTO STOCK\n",
    "\n",
    "# data_name = '2023-02-28 208370'  # 2023-01-12 ETH / 2023-02-21 FTM /2022-04-27 ETH / 2023-02-20 BTC\n",
    "# date, ticker = data_name.split(\" \")\n",
    "date = \"2023-02-21\" # \"2023-02-21\"  \"2023-03-23\"\n",
    "save_mode = 0\n",
    "\n",
    "\"\"\"\n",
    "database 는 JnQ 내부로 통일할 것.\n",
    "\"\"\"\n",
    "database_type = 'database/binance/'  # 'binance' kiwoom upbit\n",
    "database_dir_abspath = os.path.join(pkg_path, database_type, \"cum\", date).replace(\"JnQ_32bit\", \"JnQ\")  # cum non_cum -> use, non_cum data for backtrade validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if idep_mode == \"CRYPTO\":\n",
    "    data_list = [f_name for f_name in os.listdir(database_dir_abspath) if 'ftr' in f_name if date in f_name]\n",
    "else:\n",
    "    data_list = pd.read_pickle(os.path.join(database_dir_abspath, \"rank.pkl\"))  # [:10]\n",
    "    \n",
    "# data_list = [\"2023-02-21 ZRXUSDT_1m.ftr\"] \n",
    "    \n",
    "df_rank = idep_on_multiple_ticker(database_dir_abspath, data_list, signi=False, ml=True)\n",
    "\n",
    "if save_mode:\n",
    "    df_rank.to_pickle(os.path.join(database_dir_abspath, \"df_rank_wrr32_03.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(database_dir_abspath, \"df_rank_wrr32_03.pkl\"), 'rb') as f:\n",
    "    df_rank = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_rank\n",
    "df_rank.to_excel(r\"D:\\Projects\\E_Book\\result\\binance\\df_rank.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(np.mean(df_rank[df_rank.sr < 0.15]))\n",
    "# print(np.mean(df_rank[df_rank.sr > 0.15]))\n",
    "df_rank2 = df_rank[df_rank.hhm_long > 0.80]\n",
    "print(len(df_rank2))\n",
    "\n",
    "# valid_ticker = [\"2023-02-21 ICXUSDT_1m.ftr\", \"2023-02-21 RSRUSDT_1m.ftr\", \"2023-02-21 TRXUSDT_1m.ftr\"]\n",
    "# valid_ticker = [\"2023-02-21 ICXUSDT_1m.ftr\", \"2023-02-21 ALICEUSDT_1m.ftr\", \"2023-02-21 COMPUSDT_1m.ftr\", \"2023-02-21 DOTUSDT_1m.ftr\", \"2023-02-21 SNXUSDT_1m.ftr\", \"2023-02-21 SUSHIUSDT_1m.ftr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idep_on_multiple_ticker(database_dir_abspath, df_rank.iloc[:, 0], False)\n",
    "idep_on_multiple_ticker(database_dir_abspath, df_rank2.iloc[:, 0], False)\n",
    "# idep_on_multiple_ticker(database_dir_abspath, valid_ticker, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6gc7lERC4VE",
    "tags": []
   },
   "source": [
    "### Statistics (case by ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOFkzUX2imQu",
    "tags": []
   },
   "source": [
    "#### ep_loc value optimization based on hhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHjIdn2MC4VE"
   },
   "outputs": [],
   "source": [
    "selection_id = config.selection_id\n",
    "\n",
    "short_p1_idx = short_obj[-1].astype(int)\n",
    "long_p1_idx = long_obj[-1].astype(int)\n",
    "\n",
    "short_open_tp_1 = res_df['short_tp_1_{}'.format(selection_id)].to_numpy()[short_p1_idx]\n",
    "long_open_tp_1 = res_df['long_tp_1_{}'.format(selection_id)].to_numpy()[long_p1_idx]\n",
    "\n",
    "short_open_tp_0 = res_df['short_tp_0_{}'.format(selection_id)].to_numpy()[short_p1_idx]\n",
    "long_open_tp_0 = res_df['long_tp_0_{}'.format(selection_id)].to_numpy()[long_p1_idx]\n",
    "\n",
    "short_open_tp_gap = res_df['short_tp_gap_{}'.format(selection_id)].to_numpy()[short_p1_idx]  # use open_i\n",
    "long_open_tp_gap = res_df['long_tp_gap_{}'.format(selection_id)].to_numpy()[long_p1_idx]\n",
    "\n",
    "short_open_out_0 = res_df['short_out_0_{}'.format(selection_id)].to_numpy()[short_p1_idx]\n",
    "long_open_out_0 = res_df['long_out_0_{}'.format(selection_id)].to_numpy()[long_p1_idx]\n",
    "\n",
    "short_open_out_gap = res_df['short_out_gap_{}'.format(selection_id)].to_numpy()[short_p1_idx]  # use open_i\n",
    "long_open_out_gap = res_df['long_out_gap_{}'.format(selection_id)].to_numpy()[long_p1_idx]\n",
    "\n",
    "# ------ out case 의 max_high check (long) ------ # => tp_case 의 max_high = tp 라, 의미가 없음.\n",
    "short_max_tpg = get_max_tpg_v2(OrderSide.SELL, ohlc_list, short_pr, short_obj[:4], short_open_tp_1, short_open_tp_gap)\n",
    "long_max_tpg = get_max_tpg_v2(OrderSide.BUY, ohlc_list, long_pr, long_obj[:4], long_open_tp_1, long_open_tp_gap)\n",
    "# short_max_tpg = get_max_tpg_v2(OrderSide.SELL, ohlc_list, short_pr, short_obj[:4], short_open_tp_1, short_open_out_gap)\n",
    "# long_max_tpg = get_max_tpg_v2(OrderSide.BUY, ohlc_list, long_pr, long_obj[:4], long_open_tp_1, long_open_out_gap)\n",
    "\n",
    "# ------ true_bias 의 outg 확인 ------ # --> 추후, outg 로 tp_gap / out_gap custom 여부를 위해, 본 cell 을 지우지 않음\n",
    "short_max_outg = get_max_outg_v4(OrderSide.SELL, config, ohlc_list, short_obj, short_tpout_arr, short_open_tp_0, short_open_tp_gap)  # tp_box's mean_low 확인 위해 tp_gap 입력함\n",
    "long_max_outg = get_max_outg_v4(OrderSide.BUY, config, ohlc_list, long_obj, long_tpout_arr, long_open_tp_0, long_open_tp_gap)\n",
    "\n",
    "current_tpg = config.tr_set.tp_gap\n",
    "current_outg = config.tr_set.out_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnSvYKIzC4VF"
   },
   "outputs": [],
   "source": [
    "# ------------ dependent vars. ------------ #\n",
    "# res_df 에 존재하는 col 는 모두 사용가능함\n",
    "\n",
    "wave_itv1 = 'T'\n",
    "wave_period1 = config.tr_set.wave_period1\n",
    "\n",
    "# ------ 1. 도출한 outg 와 vars. pairing 진행 (by valid_idx) ------ #\n",
    "devided_cols, public_cols = [], []\n",
    "\n",
    "devided_cols.append('tr_{}'.format(selection_id))\n",
    "\n",
    "devided_cols.append('wave_length_fill_{}{}'.format(wave_itv1, wave_period1))\n",
    "devided_cols.append('spread_{}'.format(selection_id))\n",
    "\n",
    "\n",
    "# public_cols.append('cu_wrr_21_{}{}'.format(wave_itv1, wave_period1))\n",
    "public_cols.append('cu_wrr_32_{}{}'.format(wave_itv1, wave_period1))\n",
    "# public_cols.append('co_wrr_21_{}{}'.format(wave_itv1, wave_period1))\n",
    "public_cols.append('co_wrr_32_{}{}'.format(wave_itv1, wave_period1))\n",
    "\n",
    "# public_cols.append('wave_high_terms_cnt_fill_T5')\n",
    "# public_cols.append('wave_low_terms_cnt_fill_T5')\n",
    "# public_cols.append('wave_high_loc_pct_T5')\n",
    "# public_cols.append('wave_low_loc_pct_T5')\n",
    "\n",
    "# public_cols.append('b1_co_es_15T1')\n",
    "# public_cols.append('b1_cu_es_15T1')\n",
    "# public_cols.append('b1_upper_wick_ratio_15T')\n",
    "# public_cols.append('b1_lower_wick_ratio_15T')\n",
    "\n",
    "#  'co_wrr_T5', 'cu_wrr_T5', 'b1_cppr_15T', 'b1_updbr', 'b1_lwdbr', 'b1_updbr_cppr', 'b1_lwdbr_cppr' 'abs_ratio_5T', 'rel_ratio_5T', 'body_rel_ratio_5T'\n",
    "\n",
    "# devided_cols = ['tr_{}'.format(selection_id)]  # , 'ir_5T'\n",
    "# public_cols = ['wave_high_terms_cnt_fill_T5', 'wave_low_terms_cnt_fill_T5', 'wave_high_loc_pct_T5', 'wave_low_loc_pct_T5', \n",
    "#                'b1_co_es_15T1', 'b1_cu_es_15T1', 'b1_upper_wick_ratio_15T', 'b1_lower_wick_ratio_15T']\n",
    "\n",
    "short_datas = [res_df['short_' + col].to_numpy() for col in devided_cols] + [res_df[col].to_numpy() for col in public_cols]\n",
    "long_datas = [res_df['long_' + col].to_numpy() for col in devided_cols] + [res_df[col].to_numpy() for col in public_cols]\n",
    "\n",
    "titles = devided_cols + public_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4479,
     "status": "ok",
     "timestamp": 1658034578976,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "Sahvc-R0jD1A",
    "outputId": "d8b458c5-24c9-40d3-cc1d-5672d1432ae9"
   },
   "outputs": [],
   "source": [
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(14, len(titles) * 5), dpi=60)\n",
    "nrows, ncols = len(short_datas), 1\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                        ncols=ncols\n",
    "                        )\n",
    "\n",
    "num_samples = 30\n",
    "alpha = 0.8\n",
    "\n",
    "\"\"\"\n",
    "xmin / xmax 이용해서 closeup 가능함\n",
    "\"\"\"\n",
    "\n",
    "xmin = 0\n",
    "xmax = 1.1\n",
    "\n",
    "for ings_idx, (title, short_data, long_data) in enumerate(zip(titles, short_datas, long_datas)):\n",
    "  inner_gs = gs[ings_idx].subgridspec(nrows=2, ncols=2)\n",
    "\n",
    "  short_open_data = short_data[short_p1_idx]\n",
    "  long_open_data = long_data[long_p1_idx]\n",
    "\n",
    "  short_bias_ravel = short_bias_arr.ravel()\n",
    "  long_bias_ravel = long_bias_arr.ravel()\n",
    "\n",
    "  short_open_data_y = np.zeros_like(short_open_data)\n",
    "  short_open_data_y[short_bias_ravel] = 1\n",
    "\n",
    "  long_open_data_y = np.zeros_like(long_open_data)\n",
    "  long_open_data_y[long_bias_ravel] = 1\n",
    "\n",
    "  print(\"short {} corr : {}\".format(title, stats.pearsonr(short_open_data.ravel(), short_open_data_y.ravel())))\n",
    "  print(\"long {} corr : {}\".format(title, stats.pearsonr(long_open_data.ravel(), long_open_data_y.ravel())))\n",
    "\n",
    "  short_true_data = short_open_data[short_bias_ravel]    \n",
    "  # print(short_open_data)\n",
    "  # print(short_bias_arr)\n",
    "  # short_false_data = short_open_data[short_false_bias_arr.ravel()]\n",
    "  short_false_data = short_open_data[~short_bias_ravel]\n",
    "  long_true_data = long_open_data[long_bias_ravel]\n",
    "  # long_false_data = long_open_data[long_false_bias_arr.ravel()]\n",
    "  long_false_data = long_open_data[~long_bias_ravel]\n",
    "  \n",
    "  short_true_valid_idx = np.ones_like(short_true_data).astype(bool)\n",
    "  short_false_valid_idx = np.ones_like(short_false_data).astype(bool)\n",
    "  long_true_valid_idx = np.ones_like(long_true_data).astype(bool)\n",
    "  long_false_valid_idx = np.ones_like(long_false_data).astype(bool)\n",
    "\n",
    "  short_true_valid_idx *= ~np.isinf(short_true_data)\n",
    "  short_false_valid_idx *= ~np.isinf(short_false_data)\n",
    "  long_true_valid_idx *= ~np.isinf(long_true_data)\n",
    "  long_false_valid_idx *= ~np.isinf(long_false_data)\n",
    "\n",
    "  try:\n",
    "    short_true_valid_idx *= short_true_data > xmin\n",
    "    short_false_valid_idx *= short_false_data > xmin\n",
    "    long_true_valid_idx *= long_true_data > xmin\n",
    "    long_false_valid_idx *= long_false_data > xmin\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  try:\n",
    "    short_true_valid_idx *= short_true_data < xmax\n",
    "    short_false_valid_idx *= short_false_data < xmax\n",
    "    long_true_valid_idx *= long_true_data < xmax\n",
    "    long_false_valid_idx *= long_false_data < xmax\n",
    "    \n",
    "  except:\n",
    "    pass\n",
    "    \n",
    "  plt.subplot(inner_gs[0])\n",
    "  ns, bins, patches = plt.hist([short_true_data[short_true_valid_idx], short_false_data[short_false_valid_idx]], \n",
    "           bins=num_samples, alpha=alpha, color=['#00ff00', '#ff0000'], edgecolor='black')  \n",
    "  plt.title('short_' + title)  \n",
    "\n",
    "  plt.subplot(inner_gs[2])\n",
    "  total_ns = np.sum(ns, axis=0)\n",
    "  hist_ratio = ns[0] / total_ns\n",
    "  # valid_idx = total_ns > 1\n",
    "  valid_idx = np.full(len(hist_ratio), True)\n",
    "  valid_hist_ratio = hist_ratio[valid_idx]\n",
    "  plt.hist(bins[:-1][valid_idx], weights=valid_hist_ratio, bins=num_samples, color='#00ff00', edgecolor='black')\n",
    "  plt.ylim(0, 1)\n",
    "  \n",
    "\n",
    "  plt.subplot(inner_gs[1])\n",
    "  ns, bins, patches = plt.hist([long_true_data[long_true_valid_idx], long_false_data[long_false_valid_idx]], \n",
    "           bins=num_samples, alpha=alpha, color=['#00ff00', '#ff0000'], edgecolor='black')\n",
    "  plt.title('long_' + title)\n",
    "  \n",
    "  plt.subplot(inner_gs[3])\n",
    "  total_ns = np.sum(ns, axis=0)\n",
    "  hist_ratio = ns[0] / total_ns\n",
    "  # valid_idx = total_ns > 1\n",
    "  valid_idx = np.full(len(hist_ratio), True)\n",
    "  valid_hist_ratio = hist_ratio[valid_idx]\n",
    "  plt.hist(bins[:-1][valid_idx], weights=valid_hist_ratio, bins=num_samples, color='#00ff00', edgecolor='black')\n",
    "  plt.ylim(0, 1)\n",
    "\n",
    "  \n",
    "# plt.suptitle(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtjwB7Qk-Grj",
    "tags": []
   },
   "source": [
    "#### get significance (v4 -> v5 : split short / long / both res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 54864,
     "status": "ok",
     "timestamp": 1660577567405,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "oVifICO4-Grk",
    "outputId": "c82b56a6-e10b-4f3a-9364-41cbdffdb937",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 일단은 현재까지의 logic 은 short & long result 가 온전한 경우에 대해 정상적으로 돌아가도록 구성함.\n",
    "\"\"\"\n",
    "\n",
    "# ------------ survey param ------------ #\n",
    "# itv_num_list = [1, 3, 5, 15]\n",
    "# itv_list = ['15m', '30m', '1h', '4h']\n",
    "# itv_list = ['3m', '5m', '15m', '30m', '1h', '4h']\n",
    "\n",
    "# val_list = np.arange(0, 10, 0.5)     # prcn 1\n",
    "val_list = np.arange(-0.0, 0.5, 0.02)  # prcn 2\n",
    "# val_list = np.arange(-0.5, 0., 0.03)  # prcn 2\n",
    "# val_list = np.arange(-0.5, -0.6, -0.005)    # prcn 3\n",
    "# val_list = np.arange(0.944, 0.945, 0.0001)    # prcn 4\n",
    "# val_list = np.arange(1, 10, 1)   # prcn -1\n",
    "# val_list = np.arange(100, 120, 1)   # prcn -2\n",
    "# val_list = talib.get_function_groups()['Pattern Recognition']\n",
    "\n",
    "# ------------ get survey_res ------------ #\n",
    "short_res_list, long_res_list, both_res_list = [], [], []\n",
    "result = []\n",
    "res_shape = (3, 12)  # short, long, both x data\n",
    "config_list_copy = copy.deepcopy(config_list)\n",
    "for set_val in val_list:\n",
    "    # ------------ open 결정 이전의 인자값 ------------ #\n",
    "    # ------ point * dur. ------ #\n",
    "    # config_list_copy[0].loc_set.point1.wrr_32 = set_val\n",
    "    # config_list_copy[0].loc_set.point1.candle_pattern = set_val\n",
    "    # config_list_copy[0].loc_set.zone.degree_list = set_val\n",
    "    # config_list_copy[0].loc_set.point2.wick_score_list = str([set_val])\n",
    "    # config_list_copy[0].loc_set.zone.ir = set_val  \n",
    "    # config_list_copy[0].loc_set.zone.abs_ratio = set_val\n",
    "\n",
    "    # ------------ open 결정 이후의 인자값 ------------ #\n",
    "    # ------ utils ------ #\n",
    "    # config_list_copy[0].tr_set.tp_gap = set_val  \n",
    "    # config_list_copy[0].tr_set.ep1_gap = set_val \n",
    "    # config_list_copy[0].tr_set.ep2_gap = set_val \n",
    "    config_list_copy[0].tr_set.out_gap = set_val  \n",
    "    # config_list_copy[0].tr_set.wave_length1 = set_val  \n",
    "    # config_list_copy[0].tr_set.wave_time_ratio1 = set_val\n",
    "\n",
    "    # config_list_copy[0].tr_set.tp_gap = abs(set_val) - 0.5\n",
    "    # config_list_copy[0].tr_set.out_gap = set_val + 0.5\n",
    "    # config_list_copy[0].tr_set.wb_tp_gap = config_list_copy[0].tr_set.tp_gap\n",
    "    # config_list_copy[0].tr_set.wb_out_gap = config_list_copy[0].tr_set.out_gap\n",
    "\n",
    "    # ------ entry, exit (ep, tp, out vars.) ------ #\n",
    "    # config_list_copy[0].tr_set.expire_k = set_val\n",
    "    # config_list_copy[0].ep_set.expire_tick = set_val  \n",
    "\n",
    "    for utils_, config_ in zip(utils_list, config_list_copy):\n",
    "        enlist_tr(res_df, config_, np_timeidx)\n",
    "        \n",
    "    # open_info_df = get_open_info_df(ep_loc_v3, res_df, np_timeidx, id_list, config_list_copy, id_idx_list)   # point * mr_res 이기 때문에 utils_tr & rtc 의 영향을 충분히 받음\n",
    "    open_info_df1 = get_open_info_df_v2(ep_loc_p1_v3, res_df, np_timeidx, id_list, config_list_copy, id_idx_list, open_num=1)  # --> point * dur. 관련 (loc_set) param 에 종속 (open_info 가 변경되는게 아니라면, 재실행할 필요없음)\n",
    "    open_info_df2 = get_open_info_df_v2(ep_loc_p2_v3, res_df, np_timeidx, id_list, config_list_copy, id_idx_list, open_num=2)\n",
    "    open_info_df_list = [open_info_df1, open_info_df2]\n",
    "\n",
    "    # try:    \n",
    "    short_res, long_res, both_res = get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot_v16_5, funcs2, test_ratio=test_ratio, plot_is=plot_is, signi=True, show_detail=show_detail)\n",
    "    short_res_list.append(short_res)\n",
    "    long_res_list.append(long_res)\n",
    "    both_res_list.append(both_res)\n",
    "    # except Exception as e\n",
    "    #   result.append(np.full(res_shape, np.nan))\n",
    "    #   print(\"error in get_res() phase : {}\".format(e))\n",
    "    # pass\n",
    "    \n",
    "# survey_res_list = [np.array(result)[:, s_i::3] for s_i in range(3)]   # 3 for s, l, b\n",
    "survey_res_list = [short_res_list, long_res_list, both_res_list]   # 3 for s, l, b\n",
    "# short_res, long_res, both_res = survey_res_list\n",
    "\n",
    "# ------------ plot survey_res ------------ #\n",
    "title_list = [\"short\", \"long\", \"both\"]\n",
    "sub_title_list = ['hhm', 'hlm', 'frq', 'dpf', 'wr', 'sr', 'acc_pr', 'sum_pr', 'min_pr', 'liqd', 'acc_mdd', 'sum_mdd_prod', 'sum_mdd_sum']\n",
    "space_ = \" \" * 120\n",
    "\n",
    "fig = plt.figure(figsize=(24, 8), dpi=70)\n",
    "plt.style.use('dark_background')\n",
    "gs = gridspec.GridSpec(nrows=1,\n",
    "                        ncols=3,\n",
    "                        # height_ratios=[1, 1, 1]\n",
    "                      )\n",
    "\n",
    "sub_rows, sub_cols, sub_height_ratio = 4, 4, [1, 1, 1, 1]\n",
    "\n",
    "for d_idx, (title_name, survey_res) in enumerate(zip(title_list, survey_res_list)):  \n",
    "    inner_gs = gs[d_idx].subgridspec(nrows=sub_rows,\n",
    "                        ncols=sub_cols,\n",
    "                        height_ratios=sub_height_ratio\n",
    "                      )\n",
    "            \n",
    "    for in_idx, (data_, sub_title) in enumerate(zip(np.array(survey_res).T, sub_title_list)):\n",
    "        plt.subplot(inner_gs[in_idx])\n",
    "        data = data_.ravel()                \n",
    "        valid_idx = ~pd.isnull(data)\n",
    "        if np.sum(valid_idx) > 0:\n",
    "            if type(val_list[0]) == str:\n",
    "                x, y = np.arange(len(val_list))[valid_idx], data[valid_idx]\n",
    "            else:\n",
    "                x, y = val_list[valid_idx], data[valid_idx]\n",
    "            plt.plot(x, y)  # 앞에서부터 len(result) 만큼만    \n",
    "            plt.title(sub_title + '_{:.2f}'.format(x[np.argmax(y)]))\n",
    "        else:\n",
    "            plt.title(sub_title)\n",
    "\n",
    "plt.suptitle(space_.join(title_list))\n",
    "plt.show()\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arnb-kXlC4VF",
    "tags": []
   },
   "source": [
    "#### tpg & outg survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 2820,
     "status": "ok",
     "timestamp": 1659074362424,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "jHh0uFkXC4VF",
    "outputId": "cf21f56c-faf2-471d-b7e0-5c16e0ff2bdd"
   },
   "outputs": [],
   "source": [
    "# 1. outg 는 partial 을 위한 histogram 작성 진행\n",
    "# 현재, outg 내부에는 tp 한것과 out 한것이 공존하는 상태\n",
    "titles = ['outg', 'tpg']\n",
    "short_max_datas = [short_max_outg[short_bias_arr], short_max_tpg]\n",
    "long_max_datas = [long_max_outg[long_bias_arr], long_max_tpg]\n",
    "\n",
    "# titles = ['tpg']\n",
    "# short_max_datas = [short_max_tpg]\n",
    "# long_max_datas = [long_max_tpg]\n",
    "\n",
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "nrows, ncols = 2, 1\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                        ncols=ncols\n",
    "                        )\n",
    "  \n",
    "for ings_idx, (title, short_max_data, long_max_data) in enumerate(zip(titles, short_max_datas, long_max_datas)):\n",
    "\n",
    "  inner_gs = gs[ings_idx].subgridspec(nrows=1, ncols=2)\n",
    "  if ings_idx == 0:\n",
    "    axvline = current_outg\n",
    "    title_add = 'true_' + title\n",
    "  else:\n",
    "    axvline = current_tpg\n",
    "    title_add = 'false_' + title\n",
    "\n",
    "  print(len(short_max_data))\n",
    "  print(len(long_max_data))\n",
    "\n",
    "  short_plot_idx = np.ones_like(short_max_data).astype(bool)\n",
    "  long_plot_idx = np.ones_like(long_max_data).astype(bool)\n",
    "  # short_plot_idx = short_max_data <= axvline\n",
    "  # long_plot_idx = long_max_data <= axvline\n",
    "\n",
    "  print(np.sum(short_plot_idx))\n",
    "  print(np.sum(long_plot_idx))    \n",
    "\n",
    "  short_plot_idx *= ~np.isnan(short_max_data)\n",
    "  long_plot_idx *= ~np.isnan(long_max_data)  # nan 과 inf 때문에 이 방식 채택\n",
    "\n",
    "  print(np.sum(short_plot_idx))\n",
    "  print(np.sum(long_plot_idx))\n",
    "\n",
    "  short_plot_idx *= ~np.isinf(short_max_data)\n",
    "  long_plot_idx *= ~np.isinf(long_max_data)  # nan 과 inf 때문에 이 방식 채택\n",
    "  \n",
    "  print(np.sum(short_plot_idx))\n",
    "  print(np.sum(long_plot_idx))\n",
    "    \n",
    "  plt.subplot(inner_gs[0])\n",
    "  kde_plot_v2(*np.unique(short_max_data[short_plot_idx], return_counts=True))\n",
    "  plt.title('short_' + title_add)  \n",
    "  plt.axvline(axvline, color='red', linewidth=3)\n",
    "\n",
    "  plt.subplot(inner_gs[1])\n",
    "  kde_plot_v2(*np.unique(long_max_data[long_plot_idx], return_counts=True))\n",
    "  plt.title('long_' + title_add)\n",
    "  plt.axvline(axvline, color='red', linewidth=3)\n",
    "\n",
    "  print()\n",
    "\n",
    "# plt.suptitle(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mScdfR9hmjVu",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### cci updown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htf_df = to_htf(res_df, '30T', offset='9h')\n",
    "htf_df = cci_v2(htf_df, period=20, smooth=None, itv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci_updown = htf_df.cci_30T20 < htf_df.cci_30T20.shift(-1)\n",
    "\n",
    "# 1. 특정 조건에 대한 updown 확률을 구해라.\n",
    "# 2. valid_idx & incondition_idx's \"true / len(idx)\" = precision\n",
    "incondition_idx = htf_df.cci_30T20 > htf_df.cci_30T20.shift(1)\n",
    "\n",
    "valid_idx = ~(pd.isnull(htf_df.cci_30T20.shift(-1)) | pd.isnull(htf_df.cci_30T20) | pd.isnull(htf_df.cci_30T20.shift(1)))\n",
    "\n",
    "def get_odds(gt_series):\n",
    "    return np.sum(gt_series) / len(gt_series)\n",
    "\n",
    "# cci_updown[valid_idx & incondition_idx]\n",
    "print(\"original odds : {}\".format(get_odds(cci_updown[valid_idx])))\n",
    "print(\"incondition odds : {}\".format(get_odds(cci_updown[valid_idx & incondition_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xivLUsSGC4VF",
    "tags": []
   },
   "source": [
    "##### outg survey for precision (eploc vars. dependency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LB28R3QIjCDc"
   },
   "outputs": [],
   "source": [
    "# ------------ dependent vars. ------------ #\n",
    "# res_df 에 존재하는 col 는 모두 사용가능함\n",
    "# ------ 1. 도출한 outg 와 vars. pairing 진행 (by valid_idx) ------ #\n",
    "devided_cols = ['tr_{}'.format(strat_version)]  # , 'ir_5T'\n",
    "public_cols = ['wave_body_ratio']  # 'abs_ratio_5T', 'rel_ratio_5T', 'body_rel_ratio_5T'\n",
    "\n",
    "short_datas = [res_df['short_' + col].to_numpy() for col in devided_cols] + [res_df[col].to_numpy() for col in public_cols]\n",
    "long_datas = [res_df['long_' + col].to_numpy() for col in devided_cols] + [res_df[col].to_numpy() for col in public_cols]\n",
    "\n",
    "titles = devided_cols + public_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX9TpLcvFu7T"
   },
   "outputs": [],
   "source": [
    "plot_outg_range = (-1, 10)\n",
    "plot_data_range = (-10, 100)\n",
    "\n",
    "plt.style.use(['dark_background', 'fast'])\n",
    "fig = plt.figure(figsize=(12, 18))\n",
    "nrows, ncols = len(short_datas), 1\n",
    "gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                        ncols=ncols\n",
    "                        )\n",
    "\n",
    "for ings_idx, (title, short_data, long_data) in enumerate(zip(titles, short_datas, long_datas)):\n",
    "  inner_gs = gs[ings_idx].subgridspec(nrows=1, ncols=2)\n",
    "\n",
    "  print(len(long_max_outg))\n",
    "\n",
    "  short_plot_idx = (plot_outg_range[0] <= short_max_outg) & (short_max_outg <= plot_outg_range[1])\n",
    "  long_plot_idx = (plot_outg_range[0] <= long_max_outg) & (long_max_outg <= plot_outg_range[1])  # nan 과 inf 때문에 이 방식 채택\n",
    "\n",
    "  print(np.sum(long_plot_idx))\n",
    "\n",
    "  short_open_data = short_data[short_open_idx]\n",
    "  long_open_data = long_data[long_open_idx]\n",
    "  \n",
    "  short_plot_idx *= (plot_data_range[0] <= short_open_data) * (short_open_data <= plot_data_range[1])\n",
    "  long_plot_idx *= (plot_data_range[0] <= long_open_data) * (long_open_data <= plot_data_range[1]) # nan 과 inf 때문에 이 방식 채택\n",
    "\n",
    "  short_plot_idx *= ~np.isnan(short_open_data)\n",
    "  long_plot_idx *= ~np.isnan(long_open_data)  # nan 과 inf 때문에 이 방식 채택\n",
    "\n",
    "  print(np.sum(long_plot_idx))\n",
    "\n",
    "  short_plot_idx *= ~np.isinf(short_open_data)\n",
    "  long_plot_idx *= ~np.isinf(long_open_data)  # nan 과 inf 때문에 이 방식 채택\n",
    "\n",
    "  print(np.sum(long_plot_idx))\n",
    "\n",
    "  short_true_idx = short_plot_idx * short_true_open_idxth\n",
    "  long_true_idx = long_plot_idx * long_true_open_idxth\n",
    "  \n",
    "  short_false_idx = short_plot_idx * ~short_true_open_idxth\n",
    "  long_false_idx = long_plot_idx * ~long_true_open_idxth\n",
    "\n",
    "  plt.subplot(inner_gs[0])\n",
    "  # ------ true_bias ------ #\n",
    "  x, y = short_max_outg[short_true_idx].ravel(), short_open_data[short_true_idx].ravel()  \n",
    "  plt.scatter(x, y, color='white', alpha=0.5)\n",
    "  # ------ false_bias ------ #\n",
    "  x, y = short_max_outg[short_false_idx].ravel(), short_open_data[short_false_idx].ravel()\n",
    "  plt.scatter(x, y, color='fuchsia', alpha=0.3)\n",
    "  plt.axvline(current_outg, color='red', linewidth=3)\n",
    "  plt.title(\"{} coef : {:0.3f}\".format(title, np.corrcoef(-x, y)[0, 1]))\n",
    "\n",
    "  plt.subplot(inner_gs[1])    \n",
    "  # ------ true_bias ------ #\n",
    "  x, y = long_max_outg[long_true_idx].ravel(), long_open_data[long_true_idx].ravel()  \n",
    "  plt.scatter(x, y, color='white', alpha=0.5)\n",
    "  # ------ false_bias ------ #\n",
    "  x, y = long_max_outg[long_false_idx].ravel(), long_open_data[long_false_idx].ravel()\n",
    "  plt.scatter(x, y, color='fuchsia', alpha=0.3)\n",
    "  plt.axvline(current_outg, color='red', linewidth=3)\n",
    "  plt.title(\"{} coef : {:0.3f}\".format(title, np.corrcoef(-x, y)[0, 1]))\n",
    "\n",
    "  print()  \n",
    "\n",
    "# plt.suptitle(title)\n",
    "plt.show()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "983aUwM76s6X",
    "tags": []
   },
   "source": [
    "#### olds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ4f-3Zf4ImT",
    "tags": []
   },
   "source": [
    "### Backtrader validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPI-9QX74ImW"
   },
   "outputs": [],
   "source": [
    "trade_log_dir_path = \"wave_cci_wrr32_spread_wave_length\"\n",
    "trade_log_name = \"1682307814.pkl\"\n",
    "\n",
    "with open(os.path.join(\"Bank/logs/trade_log\", trade_log_dir_path, trade_log_name), 'rb') as f:\n",
    "  trade_log = pickle.load(f)\n",
    "\n",
    "trade_log  # both pos_side's log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1658222594162,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "DiTKuq9T4ImY",
    "outputId": "a06c3f6a-311d-4a7d-c425-00563fd8980f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "missed_data : Bank 에 missed 된 data.\n",
    "\"\"\"\n",
    "\n",
    "pos_side = \"BUY\" # BUY SELL\n",
    "val_obj = short_obj if pos_side == \"SELL\" else long_obj\n",
    "\n",
    "idep_log = []\n",
    "bank_log = []\n",
    "\n",
    "data_name = [\"open\", \"entry\", \"exit\", \"entry\", \"exit\"]\n",
    "\n",
    "# 1. idep log\n",
    "idep_log.append(list(map(lambda x : str(x), res_df.index[val_obj[4].astype(int).ravel()])))\n",
    "idep_log.append(list(map(lambda x : str(x), res_df.index[val_obj[2].astype(int).ravel()])))\n",
    "idep_log.append(list(map(lambda x : str(x), res_df.index[val_obj[3].astype(int).ravel()])))\n",
    "idep_log.append(val_obj[0].ravel())\n",
    "idep_log.append(val_obj[1].ravel())\n",
    "\n",
    "# 2. bank log\n",
    "bank_log.append([log[\"open\"][0] for log in trade_log if log[\"open\"][1] == pos_side])\n",
    "bank_log.append([log[\"entry\"][0] for log in trade_log if log[\"entry\"][1] == pos_side])\n",
    "bank_log.append([log[\"exit\"][0] for log in trade_log if log[\"exit\"][1] == pos_side])\n",
    "bank_log.append([log[\"entry\"][2] for log in trade_log if log[\"entry\"][1] == pos_side])\n",
    "bank_log.append([log[\"exit\"][2] for log in trade_log if log[\"exit\"][1] == pos_side])\n",
    "\n",
    "for name, idep_res, bank_res in zip(data_name, idep_log, bank_log):\n",
    "    \n",
    "    missed_data = [data for data in idep_res if not data in bank_res]\n",
    "    over_data = [data for data in bank_res if not data in idep_res]\n",
    "\n",
    "    print(\"{}_missed_data :\".format(name), missed_data)\n",
    "    print(\"{}_over_data :\".format(name), over_data)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GVZ03zDyU2N",
    "tags": []
   },
   "source": [
    "### method override"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiQ36_SLLE3w"
   },
   "outputs": [],
   "source": [
    "def get_res_v2(res_df, open_info_df_list, ohlc_list, config_list, np_timeidx, en_ex_pairing, funcs1, idep_plot, funcs2, inversion=False, test_ratio=0.3, plot_is=True, signi=False, show_detail=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1 -> v2\n",
    "    1. en_ex_pairing, idep_plot 에 필요한 funcs 를 분리함, funcs1, funcs2\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------ make open_info_list ------------ #\n",
    "    open_idx1, open_idx2 = [open_info_df.index.to_numpy() for open_info_df in open_info_df_list]\n",
    "    len_df = len(res_df)\n",
    "\n",
    "    sample_len = int(len_df * (1 - test_ratio))\n",
    "    sample_idx1 = (open_idx1 < sample_len) == plot_is  # in / out sample plot 여부\n",
    "    sample_open_idx1 = open_idx1[sample_idx1]\n",
    "    \n",
    "    sample_idx2 = (open_idx2 < sample_len) == plot_is  # in / out sample plot 여부\n",
    "\n",
    "    # ------------ open_info_list 기준 = p1 ------------ #\n",
    "    sample_open_info_df1, sample_open_info_df2 = [df_[idx_] for df_, idx_ in zip(open_info_df_list, [sample_idx1, sample_idx2])]\n",
    "    open_info1 = [sample_open_info_df1[col_].to_numpy() for col_ in sample_open_info_df1.columns]\n",
    "\n",
    "    if config_list[0].tr_set.check_hlm in [0, 1]:  # 여기서 open_info 자동화하더라도, utils info 는 직접 실행해주어야함\n",
    "        sample_open_idx2 = sample_open_idx1\n",
    "        open_info2 = open_info1\n",
    "    else:\n",
    "        sample_open_idx2 = open_idx2[sample_idx2]\n",
    "        open_info2 = [sample_open_info_df2[col_].to_numpy() for col_ in sample_open_info_df2.columns]\n",
    "\n",
    "    # ------------ get paired_res ------------ #\n",
    "    start_0 = time.time()\n",
    "    paired_res = en_ex_pairing(res_df, [sample_open_idx1, sample_open_idx2], [open_info1, open_info2], ohlc_list, config_list, np_timeidx, funcs1, show_detail)\n",
    "    # net_p1_idx_arr, p1_idx_arr, p2_idx_arr, pair_idx_arr, pair_price_arr, lvrg_arr, fee_arr, tpout_arr, tr_arr = paired_res    \n",
    "    # print(pair_price_arr)\n",
    "    print(\"en_ex_pairing elapsed time :\", time.time() - start_0)  # 0.37 --> 0.3660471439361572 --> 0.21(lesser if)\n",
    "\n",
    "    # ------------ idep_plot ------------ #\n",
    "    start_0 = time.time()\n",
    "    high, low = ohlc_list[1:3]\n",
    "    res = idep_plot(res_df, len_df, config_list[0], high, low, sample_open_info_df1, paired_res, funcs2, inversion=inversion, sample_ratio=1 - test_ratio, signi=signi)\n",
    "    print(\"idep_plot elapsed time :\", time.time() - start_0)  # 1.40452 (v6) 1.4311 (v5)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWO7KkqltMFt",
    "tags": []
   },
   "source": [
    "#### get_open_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MY1csdNRLGsk"
   },
   "outputs": [],
   "source": [
    "def get_open_info_df_v2(ep_loc_v2, res_df, np_timeidx, id_list, config_list, id_idx_list, open_num=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    v1 -> v2\n",
    "        1. <U32 dtype 으로 인한 memory allocate error 에 대응하기 위해 zone, side value 를 integer 기준으로 수정함.\n",
    "    \"\"\"\n",
    "    start_0 = time.time()\n",
    "    # ------ get mr_res, zone_arr ------ #\n",
    "    short_mr_res_obj = np.array([ep_loc_v2(res_df, config_, np_timeidx, show_detail=True, ep_loc_side=OrderSide.SELL) for config_ in config_list])\n",
    "    long_mr_res_obj = np.array([ep_loc_v2(res_df, config_, np_timeidx, show_detail=True, ep_loc_side=OrderSide.BUY) for config_ in config_list])\n",
    "    short_open_idx_list = [np.where(res_df['short_open{}_{}'.format(open_num, id)].to_numpy() * mr_res)[0] for id, mr_res in zip(id_list, short_mr_res_obj[:, 0])]   # \"point * mr_Res\"\n",
    "    long_open_idx_list = [np.where(res_df['long_open{}_{}'.format(open_num, id)].to_numpy() * mr_res)[0] for id, mr_res in zip(id_list, long_mr_res_obj[:, 0])]  # zip 으로 zone (str) 과 묶어서 dtype 변경됨\n",
    "    print(\"~ ep_loc_v2 elapsed time :\", time.time() - start_0)\n",
    "\n",
    "    # ------ open_info_arr ------ #\n",
    "    short_side_list = [np.full(len(list_), -1) for list_ in short_open_idx_list]\n",
    "    long_side_list = [np.full(len(list_), 1) for list_ in long_open_idx_list]\n",
    "\n",
    "    short_zone_list = [zone_res[short_open_idx] for zone_res, short_open_idx in zip(short_mr_res_obj[:, 1], short_open_idx_list)]\n",
    "    long_zone_list = [zone_res[long_open_idx] for zone_res, long_open_idx in zip(long_mr_res_obj[:, 1], long_open_idx_list)]\n",
    "\n",
    "    short_id_list = [np.full(len(list_), id) for id, list_ in zip(id_list, short_open_idx_list)]\n",
    "    long_id_list = [np.full(len(list_), id) for id, list_ in zip(id_list, long_open_idx_list)]\n",
    "\n",
    "    selected_id_idx = np.arange(len(id_idx_list))\n",
    "    short_id_idx_list = [np.full(len(list_), id) for id, list_ in zip(selected_id_idx, short_open_idx_list)]\n",
    "    long_id_idx_list = [np.full(len(list_), id) for id, list_ in zip(selected_id_idx, long_open_idx_list)]\n",
    "\n",
    "    # ------ get open_info_df ------ #\n",
    "    #   series 만들어서 short / long 끼리 합치고 둘이 합치고, 중복은 우선 순위 정해서 제거\n",
    "    short_open_df_list = [pd.DataFrame(index=index_, data=np.vstack((data_)).T, columns=['side', 'zone', 'id', 'id_idx']) for index_, data_ in zip(short_open_idx_list, zip(short_side_list, short_zone_list, short_id_list, short_id_idx_list))]\n",
    "    long_open_df_list = [pd.DataFrame(index=index_, data=np.vstack((data_)).T, columns=['side', 'zone', 'id', 'id_idx']) for index_, data_ in zip(long_open_idx_list, zip(long_side_list, long_zone_list, long_id_list, long_id_idx_list))]\n",
    "\n",
    "    open_info_df = pd.concat(short_open_df_list + long_open_df_list)\n",
    "    # ------ sorting + unique ------ #\n",
    "    open_info_df.sort_index(inplace=True)\n",
    "    # print(len(open_info_df))\n",
    "    # print(len(open_info_df))\n",
    "    # open_info_df.head()\n",
    "    print(\"~ get_open_info_df elapsed time :\", time.time() - start_0)\n",
    "    return open_info_df[~open_info_df.index.duplicated(keep='first')]  # 먼저 순서를 우선으로 지정  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFyWTuscH8VH",
    "tags": []
   },
   "source": [
    "#### en_ex_pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfbtFVMR01UJ"
   },
   "outputs": [],
   "source": [
    "def en_ex_pairing_v9_44(res_df, open_idx_list, open_info_list, ohlc_list, config_list, np_timeidx, funcs, show_detail=False):  # 이미 충분히 줄여놓은 idx 임\n",
    "\n",
    "    \"\"\"\n",
    "    v9_43 -> v9_44\n",
    "        1. 내부 version 관리 함수들을 모두 외부 참조로 구성함\n",
    "            a. version 에 가변적으로 대응하기 위함임.\n",
    "        2. liqd_p 기능 도입함.        \n",
    "        3. p2_tr_set_idx 직접 지정하도록 구성함.\n",
    "        4. integer type 으로 수정된 side_arr 를 수용하기 위해 코드 변경 진행함.\n",
    "    \"\"\"\n",
    "\n",
    "    open_info1, open_info2 = open_info_list\n",
    "    side_arr1, _, _, id_idx_arr1 = open_info1\n",
    "    side_arr2, _, _, _ = open_info2\n",
    "\n",
    "    expiry_p1p2, expiry, lvrg_set, check_entry, check_signal_out, check_hl_out, check_limit_tp_exec = funcs\n",
    "\n",
    "    net_p1_idx_list, p1_idx_list, p2_idx_list, pair_idx_list, pair_price_list, lvrg_list, fee_list, tpout_list, tr_list = [[] for li in range(9)]\n",
    "    len_df = len(res_df)\n",
    "\n",
    "    open, high, low, close = ohlc_list\n",
    "\n",
    "    open_idx1, open_idx2 = open_idx_list\n",
    "    len_open_idx1 = len(open_idx1)\n",
    "    len_open_idx2 = len(open_idx2)\n",
    "    i, open_i1, open_i2 = 0, -1, -1  # i for total_res_df indexing\n",
    "\n",
    "    while 1:\n",
    "        \n",
    "        # ------------ p1 phase ------------ #\n",
    "\n",
    "        # Todo,\n",
    "        #   1. (갱신) p1's open_i + 1 과 op_idx 를 꺼내오는 건, eik1 또는 tp 체결의 경우만 해당됨,\n",
    "        #   2. out 의 경우 p2's op_idx 기준으로 retry 필요\n",
    "        #     a. 또한, p2's op_idx > p1's op_idx\n",
    "\n",
    "        # ------ 1. get p1_info ------ #\n",
    "        # if eik1 or tp_done or first loop:\n",
    "        open_i1 += 1  # 확인 끝났으면 조기 이탈(+1), 다음 open_idx 조사 진행\n",
    "        if open_i1 >= len_open_idx1:\n",
    "            break\n",
    "\n",
    "        if show_detail:\n",
    "            print(\"open_i1 : {}, side_arr1 : {}\".format(open_i1, side_arr1[open_i1]))\n",
    "\n",
    "        op_idx1 = open_idx1[open_i1]  # open_i1 는 i 와 별개로 운영\n",
    "        if op_idx1 < i:  # i = 이전 거래 끝난후의 res_df index - \"거래 종료후 거래 시작\", '<' : 거래 종료시점 진입 가능하다는 의미\n",
    "            continue\n",
    "\n",
    "        # ------ 2. set loop index i ------ #\n",
    "        i = op_idx1  # + 1 --> op_idx1 = op_idx2 가능함 # open_signal 이 close_bar.shift(1) 이라고 가정하고 다음 bar 부터 체결확인한다는 의미\n",
    "        if i >= len_df:  # res_df 의 last_index 까지 돌아야함\n",
    "            break\n",
    "\n",
    "        # ------ 3. get open info ------ #\n",
    "        #            a. ID 별로 수행하기 위해 selection_id, config 호출함.\n",
    "        open_side_num = side_arr1[open_i1]\n",
    "        id_idx = id_idx_arr1.astype(int)[open_i1]  # indexing 을 위해 integer 로 변환.\n",
    "        config = config_list[id_idx]\n",
    "        selection_id = config.selection_id\n",
    "        check_hlm = config.tr_set.check_hlm\n",
    "\n",
    "        open_side = OrderSide.SELL if open_side_num == -1 else OrderSide.BUY\n",
    "        side_pos = 'short' if open_side == OrderSide.SELL else 'long'  # utils paper 접근을 위한 long / short string.\n",
    "        if show_detail:\n",
    "            print(\"------------ op_idx1 : {} {} ------------\".format(op_idx1, open_side))\n",
    "\n",
    "        # if show_detail:\n",
    "        #   print(\"check_hlm :\", check_hlm)\n",
    "\n",
    "        \n",
    "        # ------ 4. load util paper data ------ #        \n",
    "        \"\"\" \n",
    "        tr_set_idx initialize.\n",
    "            1. j 를 둔 이유는 본래 dynamic_tp / out 을 가능케 하기 위함이였음.\n",
    "                a. exec_j : open 체결 index\n",
    "                b. ep_j : entry_price 기준 index\n",
    "                c. tp_j : tp_price 기준 index\n",
    "                d. out_j : out_price 기준 index\n",
    "        \"\"\"\n",
    "        ep_j, tp_j, out_j = op_idx1, op_idx1, op_idx1  # tr_set p1, p2 에 가변적으로 기준할 수 있도록 구성함.        \n",
    "        p1_tr_set_idx = (ep_j, tp_j, out_j)\n",
    "        \n",
    "        tp_arr = res_df['{}_tp_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "        ep1_arr = res_df['{}_ep1_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "        ep2_arr = res_df['{}_ep2_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "        out_arr = res_df['{}_out_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "\n",
    "        tr_arr = res_df['{}_tr_{}'.format(side_pos, selection_id)].to_numpy()  # just for p1_hhm\n",
    "\n",
    "        tp_1_ = res_df['{}_tp_1_{}'.format(side_pos, selection_id)].to_numpy()[tp_j]  # for p2_box location & p1's exipiry\n",
    "        tp_0_ = res_df['{}_tp_0_{}'.format(side_pos, selection_id)].to_numpy()[tp_j]\n",
    "        tp_gap_ = res_df['{}_tp_gap_{}'.format(side_pos, selection_id)].to_numpy()[tp_j]        \n",
    "        \n",
    "        # if not check_net_hhm:  # this phase exist for p1 entry (net hhm sync.) in p2_platform\n",
    "        exec_j, entry_done, en_p, fee = check_entry(res_df, config, config.ep_set.entry_type, op_idx1, p1_tr_set_idx, len_df, open_side, [*ohlc_list, ep1_arr], expiry)\n",
    "        \n",
    "        i = exec_j  # = entry_loop 를 돌고 나온 e_j\n",
    "        if not entry_done:\n",
    "            if show_detail:\n",
    "                print(\"p1's expiry : continue\")\n",
    "            continue\n",
    "            # else:\n",
    "        #   tp_j = op_idx1\n",
    "\n",
    "        \n",
    "        prev_open_i2 = open_i2\n",
    "        net_p1_idx_list.append(op_idx1)\n",
    "        # if check_hlm in [0, 1]:\n",
    "        #   i = op_idx1  # allow op_idx2 = op_idx1\n",
    "        allow_exit = 1\n",
    "        \n",
    "        while 1:\n",
    "            # ------------ p2 phase ------------ #\n",
    "\n",
    "            # ------ 1. get p2_info ------ #\n",
    "            if check_hlm in [1, 2]:\n",
    "                open_i2 += 1  # 확인 끝났으면 조기 이탈(+1), 다음 open_idx 조사 진행\n",
    "                if open_i2 >= len_open_idx2:  # open_i2 소진\n",
    "                    if show_detail:\n",
    "                        print(\"open_i2 >= len_open_idx2, open_i2 소진 : break\")\n",
    "                    break\n",
    "\n",
    "                # ------ check side sync. ------ #\n",
    "                if side_arr1[open_i1] != side_arr2[open_i2]:                \n",
    "                    if show_detail:\n",
    "                        print(\"side check rejection, open_i2 {}, side_arr2 {}\".format(open_i2, side_arr2[open_i2]))\n",
    "                    continue\n",
    "\n",
    "                # ------ assert, op_idx2 >= exec_j ------ #\n",
    "                op_idx2 = open_idx2[open_i2]  # open_i2 는 i 와 별개로 운영\n",
    "                if check_hlm == 1 and allow_exit:\n",
    "                    if op_idx2 < op_idx1:                        \n",
    "                        if show_detail:\n",
    "                            print(\"check_hlm 1's allow_exit rejection, op_idx2 {} < op_idx1 {}\".format(op_idx2, op_idx1))\n",
    "                        continue\n",
    "                else:\n",
    "                    if op_idx2 < i:  # p1 execution 이후의 i 를 허용 (old, 이곳 i = op_idx1 + 1 or p2's exec_j or exit_loop's i + 1)\n",
    "                        if show_detail:\n",
    "                            print(\"op_idx2 {} < i {} : continue\".format(op_idx2, i))\n",
    "                        continue\n",
    "\n",
    "                if check_hlm == 2:\n",
    "                    i = op_idx2 + 1  # open_signal 이 close_bar.shift(1) 이라고 가정하고 다음 bar 부터 체결확인한다는 의미\n",
    "                    if i >= len_df:  # res_df 의 last_index 까지 돌아야함\n",
    "                        break\n",
    "\n",
    "                if show_detail:\n",
    "                    print(\"op_idx1 : {} op_idx2 : {}\".format(op_idx1, op_idx2))\n",
    "\n",
    "            else:\n",
    "                op_idx2 = op_idx1\n",
    "                \n",
    "            # ------ 2. load util paper data for p2  ------ #   \n",
    "            ep_j, tp_j, out_j = op_idx1, op_idx1, op_idx1\n",
    "            p2_tr_set_idx = (ep_j, tp_j, out_j)\n",
    "            \n",
    "            ep2_ = ep2_arr[ep_j]\n",
    "            tp_ = tp_arr[tp_j]\n",
    "            out_ = out_arr[out_j]      \n",
    "        \n",
    "            out_1_ = res_df['{}_out_1_{}'.format(side_pos, selection_id)].to_numpy()[out_j]\n",
    "            out_0_ = res_df['{}_out_0_{}'.format(side_pos, selection_id)].to_numpy()[out_j]\n",
    "            out_gap_ = res_df['{}_out_gap_{}'.format(side_pos, selection_id)].to_numpy()[out_j]\n",
    "\n",
    "            # ------ const. for p2_wave ------ #\n",
    "            wave_itv1 = config.tr_set.wave_itv1\n",
    "            wave_period1 = config.tr_set.wave_period1\n",
    "            wave_itv2 = config.tr_set.wave_itv2\n",
    "            wave_period2 = config.tr_set.wave_period2\n",
    "\n",
    "            \n",
    "            if check_hlm in [1, 2]:\n",
    "                \n",
    "                # ------ check p1's expiry ------ # - p2_box 생성 이전의 hl_survey\n",
    "                # 1. op_idx1 ~ op_idx2 까지의 expiry check (high & low 둘다)\n",
    "                #     a. if check_hlm:  # p1_hlm, p2_hlm --> Todo, 이거를 왜 p1_hlm 에도 적용했는지 잘 모르겠음\n",
    "                if op_idx1 < op_idx2:\n",
    "                    expire, touch_idx = expiry_p1p2(res_df, config, op_idx1, op_idx2, tp_1_, tp_0_, tp_gap_, ohlc_list[1:3], open_side)\n",
    "                    if expire:  # p1's expiry\n",
    "                        if show_detail:\n",
    "                            print(\"expiry_p1p2, touch_idx = {} : break\".format(touch_idx))\n",
    "                        i = touch_idx  # + 1  --> 이거 아닌것 같음 # op_idx1 과 op_idx2 사이의 op_idx1' 을 살리기 위함, 즉 바로 다음 op_idx1 로 회귀 (건너뛰지 않고)\n",
    "                        open_i2 = prev_open_i2\n",
    "                        break  # change op_idx1\n",
    "\n",
    "                if check_hlm == 2:\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    p2 point_validation - vectorization unavailable\n",
    "                        1. p2 로 wave_unit 을 사용할 경우만, p2 wave_validation & wave_box location 사용할 것.\n",
    "                        2. p1_loop 로 return 되는 정확한 i 를 반환하기 위해서 expiry_p1p2 뒤에 배치함\n",
    "                        3. Todo - 새로운 tp, ep, out 에 대한 처리 필요 (p1_hlm 사용시)                        \n",
    "                    \"\"\"                    \n",
    "                    \n",
    "                    # ------ p2_wave validation : 정확한 뜻을 아직 잘 모르겠음. ------ #\n",
    "#                     if open_side == OrderSide.SELL:                        \n",
    "#                         wave_co_post_idx = res_df['wave_co_post_idx_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()[op_idx2]\n",
    "#                         if not (op_idx1 < wave_co_post_idx):\n",
    "#                             if show_detail:\n",
    "#                                 print(\"p2_wave validation : continue\")\n",
    "#                             continue  # change op_idx2\n",
    "                        \n",
    "#                         # --- p2_wave high validation --- #\n",
    "#                         # wave_high_fill1_ = res_df['wave_high_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()[op_idx1]\n",
    "#                         # wave_high_fill2_ = res_df['wave_high_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()[op_idx2]\n",
    "#                         # if not (wave_high_fill1_ >= wave_high_fill2_):\n",
    "#                         #   if show_detail:\n",
    "#                         #     print(\"p2_wave high validation : continue\")\n",
    "#                         #   continue  # change op_idx2\n",
    "                        \n",
    "#                     else:\n",
    "#                         wave_cu_post_idx = res_df['wave_cu_post_idx_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()[op_idx2]\n",
    "#                         if not (op_idx1 < wave_cu_post_idx):\n",
    "#                             if show_detail:\n",
    "#                                 print(\"p2_wave validation : continue\")\n",
    "#                             continue  # change op_idx2\n",
    "                            \n",
    "#                         # --- p2_wave low validation --- #\n",
    "#                         # wave_low_fill1_ = res_df['wave_low_fill_{}{}'.format(wave_itv1, wave_period1)].to_numpy()[op_idx1]\n",
    "#                         # wave_low_fill2_ = res_df['wave_low_fill_{}{}'.format(wave_itv2, wave_period2)].to_numpy()[op_idx2]\n",
    "#                         # if not (wave_low_fill1_ <= wave_low_fill2_):\n",
    "#                         #   if show_detail:\n",
    "#                         #     print(\"p2_wave low validation : continue\")\n",
    "#                         #   continue  # change op_idx2\n",
    "                        \n",
    "#                     # ------ p2 wave_box location ------ #\n",
    "#                     if open_side == OrderSide.SELL:\n",
    "#                         if not ((tp_1_ + tp_gap_ * config.tr_set.p2_box_k1 <= out_1_) and (\n",
    "#                                 out_0_ <= tp_0_ - tp_gap_ * config.tr_set.p2_box_k2)):  # tp1, tp0 에 닿으면 expiry\n",
    "#                             # if not ((tp_1_ + tp_gap_ * config.tr_set.p2_box_k1 >= out_1_) and (out_0_ <= tp_0_ - tp_gap_ * config.tr_set.p2_box_k2)):  # tp1, tp0 에 닿으면 expiry\n",
    "#                             if show_detail:\n",
    "#                                 print(\"p2_box rejection : continue\")\n",
    "#                             continue\n",
    "#                     else:\n",
    "#                         if not ((tp_1_ - tp_gap_ * config.tr_set.p2_box_k1 >= out_1_) and (out_0_ >= tp_0_ + tp_gap_ * config.tr_set.p2_box_k2)):\n",
    "#                             # if not ((tp_1_ - tp_gap_ * config.tr_set.p2_box_k1 <= out_1_) and (out_0_ >= tp_0_ + tp_gap_ * config.tr_set.p2_box_k2)):\n",
    "#                             if show_detail:\n",
    "#                                 print(\"p2_box rejection : continue\")\n",
    "#                             continue\n",
    "                    \n",
    "                    # ------ tr_set validation & reject hl_out open_exec. ------ #\n",
    "                    if open_side == OrderSide.SELL:\n",
    "                        if not (tp_ < ep2_):\n",
    "                            break  # change op_idx1\n",
    "                        elif not (ep2_ < out_ and close[op_idx2] < out_):\n",
    "                            if show_detail:\n",
    "                                print(\"p2 tr_set validation : continue\")\n",
    "                            continue  # change op_idx2     \n",
    "                    else:\n",
    "                        if not (tp_ > ep2_):\n",
    "                            break\n",
    "                        elif not (ep2_ > out_ and close[op_idx2] > out_):\n",
    "                            if show_detail:\n",
    "                                print(\"p2 tr_set validation : continue\")\n",
    "                            continue\n",
    "                            \n",
    "                    # ------ p1p2_low ------ #\n",
    "                    if open_side == OrderSide.SELL:\n",
    "                        if not high[op_idx1:op_idx2 + 1].max() < tp_0_ - tp_gap_ * config.tr_set.p1p2_low:\n",
    "                            if show_detail:\n",
    "                                print(\"p1p2_low rejection : continue\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        if not low[op_idx1:op_idx2 + 1].min() > tp_0_ + tp_gap_ * config.tr_set.p1p2_low:\n",
    "                            if show_detail:\n",
    "                                print(\"p1p2_low rejection : continue\")\n",
    "                            continue\n",
    "\n",
    "                    # ------ check p2's expiry ------ # - 현재, op_idx2 기준의 ep2_arr 을 사용 중임.\n",
    "                    \"\"\"\n",
    "                    Caution : tr_set_idx 상황에 따라 잘 확인할 것\n",
    "                    \"\"\"\n",
    "                    exec_j, entry_done, en_p, fee = check_entry(res_df, config, config.ep_set.point2.entry_type,\n",
    "                                                                                     op_idx2, p2_tr_set_idx, len_df, open_side,\n",
    "                                                                                     [*ohlc_list, ep2_arr], expiry)\n",
    "                    i = exec_j  # = entry_loop 를 돌고 나온 e_j\n",
    "                    if not entry_done:  # p2's expiry\n",
    "                        if show_detail:\n",
    "                            print(\"expiry, i = {} at p2's : continue\".format(i))\n",
    "                        continue  # change op_idx2\n",
    "\n",
    "                        \n",
    "                    # ------ devectorized tr_calc ------ #\n",
    "                    #    1. en_p 에 대해 하는게 맞을 것으로봄\n",
    "                    #    2. tr_thresh 와 무관하게 있어야할 phase.\n",
    "                    #    Todo, fee 계산에 오류가 있는 걸로 보임 => limit_fee 를 앞에 더해주어야할 것.\n",
    "                    if open_side == OrderSide.SELL:\n",
    "                        tr_ = abs((en_p / tp_ - config.trader_set.limit_fee - 1) / (en_p / out_ - config.trader_set.market_fee - 1))\n",
    "                    else:\n",
    "                        tr_ = abs((tp_ / en_p - config.trader_set.limit_fee - 1) / (out_ / en_p - config.trader_set.market_fee - 1))\n",
    "\n",
    "                        \n",
    "                    # ------ tr_threshold ------ #\n",
    "                    if config.loc_set.point2.short_tr_thresh != \"None\":\n",
    "                        if open_side == OrderSide.SELL:\n",
    "                            if tr_ < config.loc_set.point2.short_tr_thresh:\n",
    "                                if show_detail:\n",
    "                                    print(\"tr_threshold : continue\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            if tr_ < config.loc_set.point2.long_tr_thresh:\n",
    "                                if show_detail:\n",
    "                                    print(\"tr_threshold : continue\")\n",
    "                                continue\n",
    "\n",
    "            # 1. allow_exit = \"p1_hlm 의 경우, 한번 out 되면 price 가 \"wave_range 에 닿기전까지\" retrade 를 허용하지 않음\" (expiry_p1p2 을 이용해 op_idx1 을 변경할 것)\n",
    "            #     a. while phase 내부에 if not allow_exit 을 위치한 이유 : \"wave_range 에 닿기전까지\" 를 구현하기 위해서.\n",
    "            if not allow_exit:\n",
    "                if show_detail:\n",
    "                    print(\"allow_exit = {} : continue\".format(allow_exit))\n",
    "                continue\n",
    "\n",
    "            if check_hlm in [0, 1]:\n",
    "                tr_ = tr_arr[op_idx1]\n",
    "\n",
    "            # ------ leverage ------ #\n",
    "            # out = out_arr[out_j]  # lvrg_set use out on out_j (out_j shoud be based on p2)\n",
    "            leverage, liqd_p = lvrg_set(res_df, config, open_side, en_p, out_, fee)  # res_df 변수 사용됨 - 주석 처리 된 상태일뿐\n",
    "            \n",
    "            if leverage is None:\n",
    "                if show_detail:\n",
    "                    print(\"leverage is None : continue\")\n",
    "                if check_hlm:\n",
    "                    continue  # change op_idx2\n",
    "                else:\n",
    "                    break  # change op_idx1                \n",
    "\n",
    "            # ------------ exit phase ------------ #\n",
    "            exit_done, cross_on = 0, 0\n",
    "            \n",
    "            # ------ check tpout_onexec ------ #\n",
    "            if config.ep_set.entry_type == \"LIMIT\":\n",
    "                if config.tp_set.tp_onexec:\n",
    "                    tp_j = exec_j\n",
    "                if config.out_set.out_onexec:\n",
    "                    out_j = exec_j\n",
    "\n",
    "            while 1:                \n",
    "                # dynamic tp / out 을 사용하고 싶은 경우\n",
    "                if not config.tp_set.static_tp:\n",
    "                    tp_j = i\n",
    "                if not config.out_set.static_out:\n",
    "                    out_j = i\n",
    "\n",
    "                # ------------ 1. out ------------ #  # out 우선 (보수적 검증)\n",
    "                    # ------ a. signal_out ------ #\n",
    "                if not exit_done:\n",
    "                    exit_done, cross_on, ex_p, fee = check_signal_out(res_df, config, open_i2, i, len_df, fee, open_side, cross_on, exit_done, [*ohlc_list, np_timeidx])\n",
    "                    # ------ b. hl_out ------ #\n",
    "                if config.out_set.hl_out:\n",
    "                    if not exit_done:  # and i != len_df - 1:\n",
    "                        exit_done, ex_p, fee = check_hl_out(config, i, out_j, len_df, fee, open_side, exit_done, [*ohlc_list, out_arr, liqd_p])\n",
    "\n",
    "                # ------------ 2. tp ------------ #\n",
    "                if not config.tp_set.non_tp and i != exec_j:\n",
    "                    if not exit_done:                        \n",
    "                        # 1. partial_tps 를 고려해 [tp_arr, ...] 형태 사용함.\n",
    "                        # 2. if config.tp_set.tp_type in ['LIMIT']:  # 'BOTH' -> 앞으로는, LIMIT 밖에 없을거라 주석처리함\n",
    "                        # 3. Todo, open_i2 는 deacy 기능을 위해 도입한 것 (추후 사용시 재확인)\n",
    "                        exit_done, ex_p, fee = check_limit_tp_exec(res_df, config, open_i2, i, tp_j, len_df, fee, open_side, exit_done, [*ohlc_list, [tp_arr]])\n",
    "\n",
    "                if exit_done:  # 이 phase 는 exit_phase 뒤에도 있어야할 것 - entry_done var. 사용은 안하겠지만\n",
    "                    # ------ 3. append dynamic result vars. ------ #\n",
    "                    p1_idx_list.append(op_idx1)  # side, zone, start_ver arr 모두 openi_list 로 접근하기 위해 open_i 를 담음\n",
    "                    p2_idx_list.append(op_idx2)\n",
    "                    pair_idx_list.append([exec_j, i])  # entry & exit (체결 기준임)\n",
    "                    pair_price_list.append([en_p, ex_p])\n",
    "                    lvrg_list.append(leverage)\n",
    "                    fee_list.append(fee)\n",
    "                    tr_list.append(tr_)  # Todo, tr vectorize 불가함, 직접 구해주어야할 건데.. (오래걸리지 않을까 --> tr_set 데이터만 모아서 vecto 계산이 나을 것)\n",
    "                    \n",
    "                    # for tpout_line plot_check & get_pr calc.\n",
    "                    if exit_done == 2:\n",
    "                        tpout_list.append([tp_arr[tp_j], liqd_p])\n",
    "                    else:\n",
    "                        tpout_list.append([tp_arr[tp_j], out_arr[out_j]])\n",
    "\n",
    "                    # open_i += 1  # 다음 open_idx 조사 진행\n",
    "                    break\n",
    "\n",
    "                # 1. 아래있으면, 체결 기준부터 tp, out 허용 -> tp 가 entry_idx 에 체결되는게 다소 염려되기는 함, 일단 진행 (그런 case 가 많지 않았으므로)\n",
    "                # 2. 위에있으면, entry 다음 tick 부터 exit 허용\n",
    "                i += 1\n",
    "                if i >= len_df:  # res_df 의 last_index 까지 돌아야함\n",
    "                    break\n",
    "\n",
    "            if i >= len_df:  # res_df 의 last_index 까지 돌아야함\n",
    "                break\n",
    "                \n",
    "                \n",
    "            \"\"\"\n",
    "            exit_done description            \n",
    "                1. 1 : tp_done\n",
    "                    a. check_hlm 여부와 무관하게 outer loop 의 op_idx1 을 변경 가능하도록함.\n",
    "                2. -1 : out done\n",
    "                2. 2 : liquidation done\n",
    "                3. 0 : database done                \n",
    "            \"\"\"\n",
    "            \n",
    "            if exit_done == 1: \n",
    "                if show_detail:\n",
    "                    print(\"exit_done = {}, i = {} : break\".format(exit_done, i))\n",
    "                break  # change op_idx1\n",
    "            else:\n",
    "                if check_hlm in [1, 2]:\n",
    "                    if check_hlm == 1:  # exit only once in p1_hlm mode\n",
    "                        allow_exit = 0\n",
    "                    if show_detail:\n",
    "                        print(\"exit_done = {}, i = {} : continue\".format(exit_done, i))\n",
    "                    continue  # change op_idx2\n",
    "                else:\n",
    "                    if show_detail:\n",
    "                        print(\"exit_done = {}, i = {} : break\".format(exit_done, i))\n",
    "                    break  # change op_idx1\n",
    "\n",
    "        if i >= len_df:  # or open_i >= len_open_idx:  # res_df 의 last_index 까지 돌아야함\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return np.array(net_p1_idx_list), np.array(p1_idx_list), np.array(p2_idx_list), np.array(pair_idx_list), np.array(pair_price_list), np.array(lvrg_list), np.array(fee_list), np.array(tpout_list), np.array(tr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### check_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_entry_v6_2(res_df, config, entry_type, op_idx, tr_set_idx, len_df, open_side, np_datas, expiry):\n",
    "\n",
    "    \"\"\"\n",
    "    v6_1 -> v6_2\n",
    "        1. tr_set 을 p1, p2 에 가변적으로 기준하기 위해 ep_base_idx, tp_base_idx, out_base_idx 를 외부 참조하도록 함.\n",
    "    \"\"\"\n",
    "\n",
    "    open, high, low, close, ep_arr = np_datas\n",
    "    ep_base_idx, tp_base_idx, out_base_idx = tr_set_idx\n",
    "\n",
    "    # selection_id = config.selection_id\n",
    "    # allow_ep_in = 0 if config.ep_set.point2.use_point2 else 1\n",
    "    entry_done = 0\n",
    "    ep = None\n",
    "\n",
    "    if entry_type == \"LIMIT\":\n",
    "        fee = config.trader_set.limit_fee\n",
    "        \n",
    "        for e_j in range(op_idx + 1, len_df):\n",
    "            # ------ index setting for dynamic options ------ #\n",
    "            if not config.ep_set.static_ep:\n",
    "                ep_base_idx = e_j  # dynamic_ep 를 위한 ep_index var.\n",
    "                out_base_idx = e_j  # dynamic_out 를 위한 out_index var. - 조건식이 static_ep 와 같이 있는 이유 모름 => dynamic_lvrg 로 사료됨\n",
    "\n",
    "            if not config.tp_set.static_tp:\n",
    "                tp_base_idx = e_j\n",
    "\n",
    "            # ------ expire_k & expire_tick ------ # - limit 사용하면 default 로 expire_k 가 존재해야함\n",
    "            if expiry(res_df, config, op_idx, e_j, tp_base_idx, [high, low], open_side):\n",
    "                break\n",
    "\n",
    "            # ------ point2 ------ #\n",
    "            # if not allow_ep_in:\n",
    "            #     allow_ep_in, out_base_idx = ep_loc_point2(res_df, config, e_j, out_base_idx, side=OrderSide.SELL)\n",
    "            #     if allow_ep_in:\n",
    "            #       if config.ep_set.point2.entry_type == \"LIMIT\":\n",
    "            #         ep_base_idx = e_j\n",
    "            #         # print(\"e_j in point2 :\", e_j)\n",
    "            #         continue\n",
    "\n",
    "            # ------ check ep_exec ------ #\n",
    "            # if allow_ep_in:\n",
    "            # if config.ep_set.point2.use_point2 and config.ep_set.point2.entry_type == 'MARKET':\n",
    "            #   entry_done = 1\n",
    "            #   ep = c[e_j]\n",
    "            #   break\n",
    "            # else:\n",
    "\n",
    "            if open_side == OrderSide.SELL:\n",
    "                if high[e_j] >= ep_arr[ep_base_idx]:\n",
    "                    entry_done = 1\n",
    "                    ep = ep_arr[ep_base_idx]\n",
    "                    if open[e_j] >= ep_arr[ep_base_idx]:  # open comp 는 결국, 수익률에 얹어주는 logic (반보수) -> 사용 보류\n",
    "                        ep = open[e_j]\n",
    "                    break\n",
    "            else:\n",
    "                if low[e_j] <= ep_arr[ep_base_idx]:\n",
    "                    entry_done = 1\n",
    "                    ep = ep_arr[ep_base_idx]\n",
    "                    if open[e_j] <= ep_arr[ep_base_idx]:\n",
    "                        ep = open[e_j]\n",
    "                    break\n",
    "\n",
    "        try:\n",
    "            exec_idx = e_j\n",
    "            \n",
    "        except Exception as e:\n",
    "            exec_idx = None  # 어차피, 외부에서 entry_done = 0 로 빠지면 continue 되기 때문에 의미 없음.\n",
    "            print(\"error in check_entry e_j loop : {}\".format(e))\n",
    "\n",
    "    else:  # market entry\n",
    "        exec_idx = op_idx + 1\n",
    "        entry_done = 1\n",
    "        ep = close[op_idx]\n",
    "        fee = config.trader_set.market_fee\n",
    "\n",
    "    return exec_idx, entry_done, ep, fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### check_limit_tp_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_limit_tp_exec(res_df, config, open_i, i, tp_j, len_df, fee, open_side, exit_done, np_datas):\n",
    "\n",
    "    open, high, low, close, tps = np_datas\n",
    "    tp = None\n",
    "    selection_id = config.selection_id\n",
    "    len_tps = len(tps)\n",
    "\n",
    "    for tp_i, tp_arr in enumerate(tps):\n",
    "\n",
    "        #     decay adjustment    #\n",
    "        #     tp_j includes dynamic_j - functionalize  #\n",
    "        # try:\n",
    "        #     if config.tr_set.decay_gap != \"None\":\n",
    "        #         decay_share = (j - open_i) // config.tp_set.decay_term\n",
    "        #         decay_remain = (j - open_i) % config.tp_set.decay_term\n",
    "        #         if j != open_i and decay_remain == 0:\n",
    "        #             if open_side == OrderSide.SELL:\n",
    "        #                 tp_arr[tp_j] += res_df['short_tp_gap_{}'.format(selection_id)].iloc[open_i] * config.tr_set.decay_gap * decay_share\n",
    "        #             else:\n",
    "        #                 tp_arr[tp_j] -= res_df['long_tp_gap_{}'.format(selection_id)].iloc[open_i] * config.tr_set.decay_gap * decay_share\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "        if open_side == OrderSide.SELL:\n",
    "            \n",
    "            # if low[i] < tp_arr[tp_j]:  # and partial_tp_cnt == tp_i:  # we use static tp now\n",
    "            if low[i] <= tp_arr[tp_j]:  # and partial_tp_cnt == tp_i:  # we use static tp now\n",
    "                # if low[i] <= tp_arr[i] <= h[i]: --> 이건 잘못되었음\n",
    "                # partial_tp_cnt += 1 --> partial_tp 보류\n",
    "\n",
    "                # 1. dynamic tp\n",
    "                if tp_arr[i] != tp_arr[i - 1] and not config.tp_set.static_tp:\n",
    "                    # tp limit 이 불가한 경우 - open 이 이미, tp 를 넘은 경우\n",
    "                    if open[i] < tp_arr[i]:\n",
    "                        tp = open[i]\n",
    "                    # tp limit 이 가능한 경우 - open 이 아직, tp 를 넘지 않은 경우\n",
    "                    else:\n",
    "                        tp = tp_arr[i]\n",
    "\n",
    "                # 2. static tp\n",
    "                else:\n",
    "                    #   tp limit 이 불가한 경우 - open 이 이미, tp 를 넘은 경우\n",
    "                    if open[i] < tp_arr[tp_j]:  # static 해놓고 decay 사용하면 dynamic 이니까\n",
    "                        if config.tr_set.decay_gap != \"None\" and decay_remain == 0:\n",
    "                            tp = open[i]  # tp_j -> open_i 를 가리키기 때문에 decay 는 한번만 진행되는게 맞음\n",
    "                        else:\n",
    "                            tp = tp_arr[tp_j]\n",
    "                    else:\n",
    "                        tp = tp_arr[tp_j]\n",
    "\n",
    "                if tp_i == len_tps - 1:\n",
    "                    exit_done = 1  # partial 을 고려해 exit_done = 1 상태는 tp_i 가 last_index 로 체결된 경우만 해당\n",
    "\n",
    "        else:\n",
    "            # if high[i] > tp_arr[tp_j]:\n",
    "            if high[i] >= tp_arr[tp_j]:\n",
    "            \n",
    "                # 1. dynamic tp\n",
    "                if tp_arr[i] != tp_arr[i - 1] and not config.tp_set.static_tp:\n",
    "                    if open[i] > tp_arr[i]:\n",
    "                        tp = open[i]\n",
    "                    else:\n",
    "                        tp = tp_arr[i]\n",
    "\n",
    "                # 2. static tp\n",
    "                else:\n",
    "                    if open[i] > tp_arr[tp_j]:\n",
    "                        if config.tr_set.decay_gap != \"None\" and decay_remain == 0:\n",
    "                            tp = open[i]\n",
    "                        else:\n",
    "                            tp = tp_arr[tp_j]\n",
    "                    else:\n",
    "                        tp = tp_arr[tp_j]\n",
    "\n",
    "                if tp_i == len_tps - 1:\n",
    "                    exit_done = 1  # partial 을 고려해 exit_done = 1 상태는 tp_i 가 last_index 로 체결된 경우만 해당\n",
    "\n",
    "    if exit_done:\n",
    "        fee += config.trader_set.limit_fee\n",
    "\n",
    "    return exit_done, tp, fee\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### check_signal_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_signal_out_v4(res_df, config, open_i, i, len_df, fee, open_side, cross_on, exit_done, np_datas):\n",
    "\n",
    "    \"\"\"\n",
    "    v3 -> v4\n",
    "        1. remove unnecessary conditions.\n",
    "    \"\"\"\n",
    "    _, _, _, close, np_timeidx = np_datas\n",
    "    ex_p = None\n",
    "    selection_id = config.selection_id\n",
    "\n",
    "    # 1. timestamp\n",
    "    if config.out_set.tf_exit != \"None\":\n",
    "        if np_timeidx[i] % config.out_set.tf_exit == config.out_set.tf_exit - 1 and i != open_i:\n",
    "            exit_done = -1\n",
    "\n",
    "    # 2. cci\n",
    "    if config.out_set.cci_exit:\n",
    "        cci_ = res_df['cci_T20'].to_numpy()\n",
    "\n",
    "        if open_side == OrderSide.SELL:\n",
    "            if (cci_[i - 1] >= -100) & (cci_[i] < -100):\n",
    "            # if (cci_[i - 1] <= -100) & (cci_[i] > -100):\n",
    "                exit_done = -1\n",
    "        else:\n",
    "            if (cci_[i - 1] <= 100) & (cci_[i] > 100):\n",
    "            # if (cci_[i - 1] >= 100) & (cci_[i] < 100):\n",
    "                exit_done = -1\n",
    "\n",
    "    if exit_done:\n",
    "        ex_p = close[i]\n",
    "        fee += config.trader_set.market_fee\n",
    "\n",
    "    return exit_done, cross_on, ex_p, fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### check_hl_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hl_out_v4(config, i, out_j, len_df, fee, open_side, exit_done, np_datas):\n",
    "    \n",
    "    \"\"\"\n",
    "    v3 -> v4\n",
    "        1. Add non_out function.\n",
    "    \"\"\"\n",
    "\n",
    "    open, high, low, close, out_arr, liqd_p = np_datas\n",
    "    ex_p = None\n",
    "\n",
    "    # 1. liquidation default check\n",
    "    if open_side == OrderSide.SELL:\n",
    "        if high[i] >= liqd_p:\n",
    "            exit_done = 2\n",
    "    else:\n",
    "        if low[i] <= liqd_p:\n",
    "            exit_done = 2\n",
    "    \n",
    "    if not config.out_set.non_out:\n",
    "        # 2. hl_out\n",
    "        if config.out_set.hl_out:\n",
    "            if open_side == OrderSide.SELL:\n",
    "                if high[i] >= out_arr[out_j]:\n",
    "                    exit_done = -1\n",
    "            else:\n",
    "                if low[i] <= out_arr[out_j]:\n",
    "                    exit_done = -1\n",
    "        # 3. close_out\n",
    "        else:\n",
    "            if open_side == OrderSide.SELL:\n",
    "                if close[i] >= out_arr[out_j]:\n",
    "                    exit_done = -1\n",
    "            else:\n",
    "                if close[i] <= out_arr[out_j]:\n",
    "                    exit_done = -1            \n",
    "\n",
    "    if exit_done:  # exit_done should not be zero in this phase      \n",
    "        if exit_done == 2:\n",
    "            ex_p = liqd_p\n",
    "        else:\n",
    "            if config.out_set.hl_out:\n",
    "                ex_p = out_arr[out_j]\n",
    "            else:\n",
    "                ex_p = close[i]\n",
    "\n",
    "            # check open out execution\n",
    "            if open_side == OrderSide.SELL:\n",
    "                if open[i] >= out_arr[out_j]:\n",
    "                    ex_p = open[i]\n",
    "            else:\n",
    "                if open[i] <= out_arr[out_j]:\n",
    "                    ex_p = open[i]\n",
    "\n",
    "        fee += config.trader_set.market_fee\n",
    "\n",
    "    return exit_done, ex_p, fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### idep_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xafHpMLwESKf"
   },
   "outputs": [],
   "source": [
    "def idep_plot_v16_5(res_df, len_df, config, high, low, open_info_df1, paired_res, funcs, inversion=False, sample_ratio=0.7,\n",
    "                    title_position=(0.5, 0.5), fontsize=15, signi=False):  # open_idx, side_arr\n",
    "\n",
    "    \"\"\"\n",
    "    v16_4 -> v16_5\n",
    "        1. sum_pr 을 periodic_pr plot 을 위해 plot_info 외부에 위치시킴.\n",
    "        2. frq_dev_plot 을 plot_info 와 같은 phase 에 위치함 (long / short_ban 에 영향받지 않고 plot 하기 위함임.)\n",
    "        3. integer type side_arr 를 수용하기 위해 코드 변경 진행함.\n",
    "    \"\"\"\n",
    "\n",
    "    get_wave_bias, get_pr, get_res_info, plot_info, frq_dev_plot = funcs\n",
    "\n",
    "    if not signi:\n",
    "        plt.style.use(['dark_background', 'fast'])\n",
    "        plt.figure(figsize=(24, 8), dpi=60)\n",
    "        gs = gridspec.GridSpec(nrows=2,  # row 몇 개\n",
    "                               ncols=3,  # col 몇 개\n",
    "                               height_ratios=[10, 1]\n",
    "                               # height_ratios=[10, 10, 1]\n",
    "                               )\n",
    "    gs_idx = 0\n",
    "    gs_idx_below = 3\n",
    "    # plt.suptitle(key)\n",
    "\n",
    "    partial_ranges, partial_qty_ratio = literal_eval(config.tp_set.partial_ranges), literal_eval(config.tp_set.partial_qty_ratio)\n",
    "    assert np.sum(partial_qty_ratio) == 1.0\n",
    "    assert len(partial_ranges) == len(partial_qty_ratio)\n",
    "\n",
    "    if sample_ratio is not None:\n",
    "        sample_len = int(len_df * sample_ratio)\n",
    "    else:\n",
    "        sample_len = len_df\n",
    "\n",
    "    # ------ short & long data preparation ------ #\n",
    "    # start_0 = time.time()\n",
    "\n",
    "    net_p1_idx_arr, p1_idx_arr, p2_idx_arr, pair_idx_arr, pair_price_arr, lvrg_arr, fee_arr, tpout_arr, tr_arr = paired_res\n",
    "    assert len(p1_idx_arr) != 0, \"assert len(p1_idx_arr) != 0\"\n",
    "\n",
    "    # short_net_p1_idx_arr = net_p1_idx_arr[np.where(open_info_df1.side.loc[net_p1_idx_arr] == OrderSide.SELL)[0]]\n",
    "    # long_net_p1_idx_arr = net_p1_idx_arr[np.where(open_info_df1.side.loc[net_p1_idx_arr] == OrderSide.BUY)[0]]\n",
    "    short_net_p1_idx_arr = net_p1_idx_arr[np.where(open_info_df1.side.loc[net_p1_idx_arr] == -1)[0]]\n",
    "    long_net_p1_idx_arr = net_p1_idx_arr[np.where(open_info_df1.side.loc[net_p1_idx_arr] == 1)[0]]\n",
    "\n",
    "    short_net_p1_frq = len(short_net_p1_idx_arr)\n",
    "    long_net_p1_frq = len(long_net_p1_idx_arr)\n",
    "    # print(\"len(short_net_p1_true_bias_bool) :\", len(short_net_p1_idx_arr))\n",
    "    # print(\"len(long_net_p1_true_bias_bool) :\", len(long_net_p1_idx_arr))\n",
    "\n",
    "    # short_p1_openi_idx = np.where(open_info_df1.side.loc[p1_idx_arr] == OrderSide.SELL)[0]  # p1_idx_arr 에 대한 idx, # side_arr,\n",
    "    # long_p1_openi_idx = np.where(open_info_df1.side.loc[p1_idx_arr] == OrderSide.BUY)[0]\n",
    "    short_p1_openi_idx = np.where(open_info_df1.side.loc[p1_idx_arr] == -1)[0]  # p1_idx_arr 에 대한 idx, # side_arr,\n",
    "    long_p1_openi_idx = np.where(open_info_df1.side.loc[p1_idx_arr] == 1)[0]\n",
    "\n",
    "    # p1_idx = open_idx[p1_openi_arr].reshape(-1, 1)   # != p1_idx_arr, p1_openi_arr 은 exit_done 기준임\n",
    "\n",
    "    np_obj = np.hstack((pair_price_arr, pair_idx_arr,\n",
    "                        p1_idx_arr.reshape(-1, 1)))  # p1_idx_arr is 1d, need to be changed to 2d (for stacking)\n",
    "    short_obj = np_obj[short_p1_openi_idx]\n",
    "    long_obj = np_obj[long_p1_openi_idx]\n",
    "    both_obj = np.vstack((short_obj, long_obj))\n",
    "    # print(\"short_obj.shape :\", short_obj.shape)\n",
    "    # print(\"long_obj.shape :\", long_obj.shape)\n",
    "\n",
    "    short_obj, long_obj, both_obj = [np.split(obj_, 5, axis=1) for obj_ in [short_obj, long_obj, both_obj]]\n",
    "\n",
    "    short_p2_idx_arr, long_p2_idx_arr = [p2_idx_arr[openi_idx_].reshape(-1, 1) for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    short_lvrg_arr, long_lvrg_arr = [lvrg_arr[openi_idx_].reshape(-1, 1) for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    short_fee_arr, long_fee_arr = [fee_arr[openi_idx_].reshape(-1, 1) for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    short_tpout_arr, long_tpout_arr = [tpout_arr[openi_idx_] for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    short_tr_arr, long_tr_arr = [tr_arr[openi_idx_] for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    # short_bias_arr, long_bias_arr = [bias_arr[openi_idx_] for openi_idx_ in [short_p1_openi_idx, long_p1_openi_idx]]\n",
    "    # print(\"long_bias_arr.shape :\", long_bias_arr.shape)\n",
    "    # print(\"short / long arr setting elapsed time :\", time.time() - start_0)\n",
    "\n",
    "    # start_0 = time.time()\n",
    "\n",
    "    short_tpbox_hhm, long_tpbox_hhm, short_tpbox_p2exec_hhm, long_tpbox_p2exec_hhm, short_outbox_hhm, long_outbox_hhm, \\\n",
    "    short_net_p1_bias_tick, long_net_p1_bias_tick, short_p2exec_p1_bias_tick, long_p2exec_p1_bias_tick, short_p2_true_bias_bool, long_p2_true_bias_bool, \\\n",
    "    short_tp_1, short_tp_0, long_tp_1, long_tp_0, short_out_1, short_out_0, long_out_1, long_out_0, short_ep2_0, long_ep2_0 = \\\n",
    "        get_wave_bias(res_df, config, high, low, len_df, short_net_p1_idx_arr, long_net_p1_idx_arr, short_p2_idx_arr,\n",
    "                      long_p2_idx_arr, short_obj, long_obj)\n",
    "\n",
    "    # print(\"get_wave_bias elapsed time :\", time.time() - start_0)\n",
    "    # print(\"short_net_p1_bias_tick, long_net_p1_bias_tick, short_p2exec_p1_bias_tick, long_p2exec_p1_bias_tick :\", short_net_p1_bias_tick, long_net_p1_bias_tick, short_p2exec_p1_bias_tick, long_p2exec_p1_bias_tick)\n",
    "\n",
    "    len_short, len_long = len(short_p1_openi_idx), len(long_p1_openi_idx)\n",
    "\n",
    "    # ------ plot_data ------ #\n",
    "    try:\n",
    "        # start_0 = time.time()\n",
    "        if len_short == 0:  # 0 이 아닌 경우에만 계산이 가능함\n",
    "            short_pr = []\n",
    "            short_idep_res_obj = np.nan\n",
    "        else:\n",
    "            short_tr = short_tr_arr.mean()\n",
    "            short_pr, short_liqd = get_pr(OrderSide.SELL, high, low, short_obj, short_tpout_arr, short_lvrg_arr,\n",
    "                                          short_fee_arr, partial_ranges,\n",
    "                                          partial_qty_ratio, inversion)\n",
    "            short_total_pr = to_total_pr(len_df, short_pr, short_obj[-2])\n",
    "            short_acc_pr = np.cumprod(short_total_pr)\n",
    "            short_sum_pr = get_sum_pr_nb(short_total_pr)\n",
    "            short_hlm = hlm(short_pr, short_p2_true_bias_bool)\n",
    "            short_trade_ticks = np.mean(short_obj[-2] - short_obj[-1])\n",
    "            if signi:\n",
    "                short_idep_res_obj = short_tpbox_p2exec_hhm, short_hlm, *get_res_info(sample_len, short_pr,\n",
    "                                                                                        short_total_pr,\n",
    "                                                                                        short_acc_pr, short_liqd)\n",
    "            else:\n",
    "                plot_info(gs, gs_idx, len_df, sample_len, short_tr, short_tpbox_hhm, short_tpbox_p2exec_hhm,\n",
    "                          short_outbox_hhm, short_hlm, short_trade_ticks, short_net_p1_frq, short_pr, short_total_pr,\n",
    "                          short_acc_pr, short_sum_pr, short_liqd, short_lvrg_arr.mean(), title_position, fontsize)\n",
    "\n",
    "                frq_dev_plot(gs, gs_idx_below, len_df, sample_len, short_obj[-2], short_p2_true_bias_bool, short_acc_pr[-1], short_sum_pr[-1], fontsize)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error in short plot_data :\", e)\n",
    "\n",
    "    gs_idx += 1\n",
    "    gs_idx_below += 1\n",
    "\n",
    "    try:\n",
    "        # start_0 = time.time()\n",
    "        if len_long == 0:\n",
    "            long_pr = []\n",
    "            long_idep_res_obj = np.nan\n",
    "        else:\n",
    "            long_tr = long_tr_arr.mean()\n",
    "            long_pr, long_liqd = get_pr(OrderSide.BUY, high, low, long_obj, long_tpout_arr, long_lvrg_arr,\n",
    "                                        long_fee_arr, partial_ranges, partial_qty_ratio,\n",
    "                                        inversion)\n",
    "            long_total_pr = to_total_pr(len_df, long_pr, long_obj[-2])\n",
    "            long_acc_pr = np.cumprod(long_total_pr)\n",
    "            long_sum_pr = get_sum_pr_nb(long_total_pr)\n",
    "            long_hlm = hlm(long_pr, long_p2_true_bias_bool)\n",
    "            long_trade_ticks = np.mean(long_obj[-2] - long_obj[-1])\n",
    "            if signi:\n",
    "                long_idep_res_obj = long_tpbox_p2exec_hhm, long_hlm, *get_res_info(sample_len, long_pr,\n",
    "                                                                                     long_total_pr, long_acc_pr,\n",
    "                                                                                     long_liqd)\n",
    "            else:\n",
    "                plot_info(gs, gs_idx, len_df, sample_len, long_tr, long_tpbox_hhm, long_tpbox_p2exec_hhm,\n",
    "                          long_outbox_hhm, long_hlm, long_trade_ticks, long_net_p1_frq, long_pr, long_total_pr,\n",
    "                          long_acc_pr, long_sum_pr, long_liqd, long_lvrg_arr.mean(), title_position, fontsize)\n",
    "\n",
    "                frq_dev_plot(gs, gs_idx_below, len_df, sample_len, long_obj[-2], long_p2_true_bias_bool, long_acc_pr[-1], long_sum_pr[-1], fontsize)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error in long plot_data :\", e)\n",
    "\n",
    "    gs_idx += 1\n",
    "    gs_idx_below += 1\n",
    "\n",
    "    try:\n",
    "        # start_0 = time.time()\n",
    "        if len_short * len_long == 0:\n",
    "            both_pr = []\n",
    "            both_idep_res_obj = np.nan\n",
    "        else:\n",
    "            both_tr = (short_tr + long_tr) / 2\n",
    "            both_pr = np.vstack((short_pr, long_pr))  # for 2d arr, obj 를 1d 로 만들지 않는 이상, pr 은 2d 유지될 것\n",
    "            both_total_pr = to_total_pr(len_df, both_pr, both_obj[-2])\n",
    "            both_acc_pr = np.cumprod(both_total_pr)\n",
    "            both_sum_pr = get_sum_pr_nb(both_total_pr)\n",
    "            both_liqd = min(short_liqd, long_liqd)\n",
    "\n",
    "            both_p2_true_bias_bool = np.hstack((short_p2_true_bias_bool, long_p2_true_bias_bool))  # hstack for 1d arr, vstack for 2d arr\n",
    "            both_tpbox_hhm = (short_tpbox_hhm + long_tpbox_hhm) / 2\n",
    "            both_tpbox_p2exec_hhm, both_hlm = (short_tpbox_p2exec_hhm + long_tpbox_p2exec_hhm) / 2, (short_hlm + long_hlm) / 2\n",
    "            both_outbox_hhm = (short_outbox_hhm + long_outbox_hhm) / 2\n",
    "            both_trade_ticks = np.mean(both_obj[-2] - both_obj[-1])\n",
    "            both_net_p1_frq = short_net_p1_frq + long_net_p1_frq\n",
    "            if signi:\n",
    "                both_idep_res_obj = both_tpbox_p2exec_hhm, both_hlm, *get_res_info(sample_len, both_pr,\n",
    "                                                                                     both_total_pr, both_acc_pr,\n",
    "                                                                                     both_liqd)\n",
    "            else:\n",
    "                plot_info(gs, gs_idx, len_df, sample_len, both_tr, both_tpbox_hhm, both_tpbox_p2exec_hhm,\n",
    "                          both_outbox_hhm, both_hlm, both_trade_ticks, both_net_p1_frq, both_pr, both_total_pr,\n",
    "                          both_acc_pr, both_sum_pr, both_liqd, lvrg_arr.mean(), title_position, fontsize)\n",
    "\n",
    "                frq_dev_plot(gs, gs_idx_below, len_df, sample_len, both_obj[-2], both_p2_true_bias_bool, both_acc_pr[-1], both_sum_pr[-1], fontsize)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error in both plot_data :\", e)\n",
    "\n",
    "    gs_idx += 1\n",
    "    gs_idx_below += 1\n",
    "\n",
    "    if not signi:\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        return short_pr, short_obj, short_lvrg_arr, short_fee_arr, short_tpout_arr, short_tr_arr, short_p2_true_bias_bool, short_net_p1_bias_tick, short_p2exec_p1_bias_tick, short_net_p1_idx_arr, short_p2_idx_arr, short_tp_1, short_tp_0, short_out_1, short_out_0, short_ep2_0, \\\n",
    "               long_pr, long_obj, long_lvrg_arr, long_fee_arr, long_tpout_arr, long_tr_arr, long_p2_true_bias_bool, long_net_p1_bias_tick, long_p2exec_p1_bias_tick, long_net_p1_idx_arr, long_p2_idx_arr, long_tp_1, long_tp_0, long_out_1, long_out_0, long_ep2_0  # long_net_p1_idx_arr long_p2_idx_arr\n",
    "    else:\n",
    "        return short_idep_res_obj, long_idep_res_obj, both_idep_res_obj    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get_wave_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wave_bias_v6_2(res_df, config, high, low, len_df, short_net_p1_idx_arr, long_net_p1_idx_arr, short_p2_idx_arr, long_p2_idx_arr, short_obj, long_obj):\n",
    "\n",
    "    \"\"\"\n",
    "    v6_1 -> v6_2\n",
    "    1. p1's tr_set 을 사용하는 p2 (en_ex_pairing_v9_43) 의 올바른 out_box plotting 을 위해 ffill_line 에 p2_idx -> net_p1_idx 사용함.\n",
    "    2. hlm = 1.0 으로 오차없이 나오는 version.\n",
    "\n",
    "    Todo : p2_idx -> en2_idx 도 필요함 (outbox 를 위한 hhm)\n",
    "    \"\"\"\n",
    "\n",
    "    short_net_p1_idx = short_net_p1_idx_arr.astype(int)  # .reshape(-1, 1)\n",
    "    short_p1_idx = short_obj[-1].astype(int).ravel()\n",
    "    short_p2_idx = short_p2_idx_arr.astype(int).ravel()  # .reshape(-1, 1)\n",
    "    short_en_idx = short_obj[2].astype(int).ravel()\n",
    "\n",
    "    # tr_set 은 p1 기준이 맞음.\n",
    "    short_tp_1 = ffill_line(res_df['short_tp_1_{}'.format(config.selection_id)].to_numpy(), short_net_p1_idx)  # net_p1_idx ~ net_p1_idx' 사이에 대한 momentum 조사 (net 이유는 logic's validation)\n",
    "    short_tp_0 = ffill_line(res_df['short_tp_0_{}'.format(config.selection_id)].to_numpy(), short_net_p1_idx)\n",
    "    short_out_1 = ffill_line(res_df['short_out_1_{}'.format(config.selection_id)].to_numpy(), short_net_p1_idx)  # 체결된, p2_idx ~ p2_idx' 사이에 대한 momentum 조사\n",
    "    short_out_0 = ffill_line(res_df['short_out_0_{}'.format(config.selection_id)].to_numpy(), short_net_p1_idx)\n",
    "    short_ep2_0 = ffill_line(res_df['short_ep2_0_{}'.format(config.selection_id)].to_numpy(), short_p2_idx)\n",
    "    # short_net_wave_1 = ffill_line(res_df['short_wave_1_{}'.format(config.selection_id)].to_numpy(), short_op_idx)  # en_idx 에 sync 된 open_idx 를 사용해야함\n",
    "    # short_net_wave_0 = ffill_line(res_df['short_wave_0_{}'.format(config.selection_id)].to_numpy(), short_op_idx)\n",
    "\n",
    "    long_net_p1_idx = long_net_p1_idx_arr.astype(int)  # .reshape(-1, 1)\n",
    "    long_p1_idx = long_obj[-1].astype(int).ravel()\n",
    "    long_p2_idx = long_p2_idx_arr.astype(int).ravel()  # .reshape(-1, 1)\n",
    "    long_en_idx = long_obj[2].astype(int).ravel()\n",
    "\n",
    "    long_tp_1 = ffill_line(res_df['long_tp_1_{}'.format(config.selection_id)].to_numpy(), long_net_p1_idx)\n",
    "    long_tp_0 = ffill_line(res_df['long_tp_0_{}'.format(config.selection_id)].to_numpy(), long_net_p1_idx)\n",
    "    long_out_1 = ffill_line(res_df['long_out_1_{}'.format(config.selection_id)].to_numpy(), long_net_p1_idx)  # 체결된, p2_idx ~ p2_idx' 사이에 대한 momentum 조사\n",
    "    long_out_0 = ffill_line(res_df['long_out_0_{}'.format(config.selection_id)].to_numpy(), long_net_p1_idx)\n",
    "    long_ep2_0 = ffill_line(res_df['long_ep2_0_{}'.format(config.selection_id)].to_numpy(), long_p2_idx)\n",
    "\n",
    "    short_p2exec_p1_idx = np.unique(short_p1_idx)  # .reshape(-1, 1)   # 통일성을 위해 2d 로 설정\n",
    "    long_p2exec_p1_idx = np.unique(long_p1_idx)  # .reshape(-1, 1)\n",
    "\n",
    "    # print(\"long_net_p1_idx.shape :\", long_net_p1_idx.shape)\n",
    "    # print(\"long_en_idx.shape :\", long_en_idx.shape)\n",
    "\n",
    "    # ================== touch idx ================== #\n",
    "    # 1. min 에 초점을 맞추는 거니까, touch 없을시 len_df 로 설정\n",
    "    # 2. future_data 사용이니까, shift(-bias_info_tick) 설정 --> olds\n",
    "    # 3. entry 다음 idx 부터 -> tp & out 체결 logic 이 현재 entry_idx 부터 되어있어서 취소\n",
    "    # Todo, high 와 low 중 어디에 먼저닿느냐가 중요함을 key 로 잡고만든 logic 임\n",
    "    len_df_range = np.arange(len_df)\n",
    "    last_idx = len_df - 1  # nan 발생하면 대소 비교로 hhm 확인이 불가능해짐, np.nan <= np.nan --> false\n",
    "\n",
    "    # ------------ pair & idxs ------------ #\n",
    "    short_en_pair = list(zip(short_en_idx, np.append(short_en_idx[1:], last_idx)))  # p1's 1st & 2nd pair 위해서 last_idx 마지막에 붙여준 것\n",
    "    long_en_pair = list(zip(long_en_idx, np.append(long_en_idx[1:], last_idx)))\n",
    "\n",
    "    short_p2_pair = list(zip(short_p2_idx, np.append(short_p2_idx[1:], last_idx)))\n",
    "    long_p2_pair = list(zip(long_p2_idx, np.append(long_p2_idx[1:], last_idx)))\n",
    "\n",
    "    short_tp_1_touch_idxs = np.where(low <= short_tp_1, len_df_range, last_idx)\n",
    "    short_tp_0_touch_idxs = np.where(high >= short_tp_0, len_df_range, last_idx)\n",
    "    long_tp_1_touch_idxs = np.where(high >= long_tp_1, len_df_range, last_idx)\n",
    "    long_tp_0_touch_idxs = np.where(low <= long_tp_0, len_df_range, last_idx)\n",
    "\n",
    "    short_out_1_touch_idxs = np.where(low <= short_out_1, len_df_range, last_idx)\n",
    "    short_out_0_touch_idxs = np.where(high >= short_out_0, len_df_range, last_idx)\n",
    "    long_out_1_touch_idxs = np.where(high >= long_out_1, len_df_range, last_idx)\n",
    "    long_out_0_touch_idxs = np.where(low <= long_out_0, len_df_range, last_idx)\n",
    "\n",
    "    # ------------ min touch_idx ------------ #\n",
    "    # print(short_en_pair)\n",
    "    short_tp_1_touch_idx = get_touch_idx_fill_v2(short_tp_1_touch_idxs, short_en_pair, short_en_idx, len_df)  # pair means 구간\n",
    "    short_tp_0_touch_idx = get_touch_idx_fill_v2(short_tp_0_touch_idxs, short_en_pair, short_en_idx, len_df)\n",
    "    long_tp_1_touch_idx = get_touch_idx_fill_v2(long_tp_1_touch_idxs, long_en_pair, long_en_idx, len_df)\n",
    "    long_tp_0_touch_idx = get_touch_idx_fill_v2(long_tp_0_touch_idxs, long_en_pair, long_en_idx, len_df)\n",
    "\n",
    "    short_out_1_touch_idx = get_touch_idx_fill_v2(short_out_1_touch_idxs, short_en_pair, short_en_idx, len_df)  # pair means 구간\n",
    "    short_out_0_touch_idx = get_touch_idx_fill_v2(short_out_0_touch_idxs, short_en_pair, short_en_idx, len_df)\n",
    "    long_out_1_touch_idx = get_touch_idx_fill_v2(long_out_1_touch_idxs, long_en_pair, long_en_idx, len_df)\n",
    "    long_out_0_touch_idx = get_touch_idx_fill_v2(long_out_0_touch_idxs, long_en_pair, long_en_idx, len_df)\n",
    "\n",
    "    # ------------ point's touch_idx ------------ #\n",
    "    short_tp_1_en_touch_idx = short_tp_1_touch_idx[short_en_idx]  # for tp_box's net_hhm\n",
    "    short_tp_0_en_touch_idx = short_tp_0_touch_idx[short_en_idx]\n",
    "    long_tp_1_en_touch_idx = long_tp_1_touch_idx[long_en_idx]\n",
    "    long_tp_0_en_touch_idx = long_tp_0_touch_idx[long_en_idx]\n",
    "    # print(\"long_tp_1_en_touch_idx :\", long_tp_1_en_touch_idx)\n",
    "\n",
    "    short_tp_1_p2exec_p1_touch_idx = short_tp_1_touch_idx[short_p2exec_p1_idx]  # p2 까지 체결된 p1's hhm (p2 executed p1_hhm)\n",
    "    short_tp_0_p2exec_p1_touch_idx = short_tp_0_touch_idx[short_p2exec_p1_idx]\n",
    "    long_tp_1_p2exec_p1_touch_idx = long_tp_1_touch_idx[long_p2exec_p1_idx]\n",
    "    long_tp_0_p2exec_p1_touch_idx = long_tp_0_touch_idx[long_p2exec_p1_idx]\n",
    "\n",
    "    short_tp_1_p2_touch_idx = short_tp_1_touch_idx[short_en_idx]  # hlm 을 위한 hhm (on p2)\n",
    "    short_tp_0_p2_touch_idx = short_tp_0_touch_idx[short_en_idx]\n",
    "    long_tp_1_p2_touch_idx = long_tp_1_touch_idx[long_en_idx]\n",
    "    long_tp_0_p2_touch_idx = long_tp_0_touch_idx[long_en_idx]\n",
    "\n",
    "    short_out_1_p2_touch_idx = short_out_1_touch_idx[short_en_idx]  # for out_box's executed_hhm\n",
    "    short_out_0_p2_touch_idx = short_out_0_touch_idx[short_en_idx]\n",
    "    long_out_1_p2_touch_idx = long_out_1_touch_idx[long_en_idx]\n",
    "    long_out_0_p2_touch_idx = long_out_0_touch_idx[long_en_idx]\n",
    "\n",
    "    # ------------ get wave's bias_tick ------------ #\n",
    "    short_tp_1_en_touch_idx2 = np.where(short_tp_1_en_touch_idx == last_idx, np.nan, short_tp_1_en_touch_idx)\n",
    "    long_tp_1_en_touch_idx2 = np.where(long_tp_1_en_touch_idx == last_idx, np.nan, long_tp_1_en_touch_idx)\n",
    "\n",
    "    short_tp_1_p2exec_p1_touch_idx2 = np.where(short_tp_1_p2exec_p1_touch_idx == last_idx, np.nan, short_tp_1_p2exec_p1_touch_idx)\n",
    "    long_tp_1_p2exec_p1_touch_idx2 = np.where(long_tp_1_p2exec_p1_touch_idx == last_idx, np.nan, long_tp_1_p2exec_p1_touch_idx)\n",
    "\n",
    "    # short_net_p1_bias_tick = short_tp_1_en_touch_idx2 - short_net_p1_idx\n",
    "    # long_net_p1_bias_tick = long_tp_1_en_touch_idx2 - long_net_p1_idx\n",
    "    short_en_bias_tick = short_tp_1_en_touch_idx2 - short_en_idx\n",
    "    long_en_bias_tick = long_tp_1_en_touch_idx2 - long_en_idx\n",
    "\n",
    "    short_p2exec_p1_bias_tick = short_tp_1_p2exec_p1_touch_idx2 - short_p2exec_p1_idx\n",
    "    long_p2exec_p1_bias_tick = long_tp_1_p2exec_p1_touch_idx2 - long_p2exec_p1_idx\n",
    "\n",
    "    # ------------------ bias_bool & hhm ------------------ #\n",
    "    short_en_true_bias_bool = short_tp_1_en_touch_idx < short_tp_0_en_touch_idx  # true_bias 의 조건\n",
    "    short_en_false_bias_bool = short_tp_1_en_touch_idx >= short_tp_0_en_touch_idx  # false_bias 의 조건, ~true_bias_bool 와 같지 않음, why ..? = en_idx\n",
    "    long_en_true_bias_bool = long_tp_1_en_touch_idx < long_tp_0_en_touch_idx\n",
    "    long_en_false_bias_bool = long_tp_1_en_touch_idx >= long_tp_0_en_touch_idx\n",
    "\n",
    "    short_p2exec_p1_true_bias_bool = short_tp_1_p2exec_p1_touch_idx < short_tp_0_p2exec_p1_touch_idx  # true_bias 의 조건\n",
    "    short_p2exec_p1_false_bias_bool = short_tp_1_p2exec_p1_touch_idx >= short_tp_0_p2exec_p1_touch_idx  # false_bias 의 조건, ~true_bias_bool 와 같지 않음, why ..? = en_idx\n",
    "    long_p2exec_p1_true_bias_bool = long_tp_1_p2exec_p1_touch_idx < long_tp_0_p2exec_p1_touch_idx\n",
    "    long_p2exec_p1_false_bias_bool = long_tp_1_p2exec_p1_touch_idx >= long_tp_0_p2exec_p1_touch_idx\n",
    "\n",
    "    short_p2_true_bias_bool = short_tp_1_p2_touch_idx < short_tp_0_p2_touch_idx\n",
    "    # short_p2_false_bias_bool = short_tp_1_p2_touch_idx >= short_tp_0_p2_touch_idx\n",
    "    long_p2_true_bias_bool = long_tp_1_p2_touch_idx < long_tp_0_p2_touch_idx\n",
    "    # long_p2_false_bias_bool = long_tp_1_p2_touch_idx >= long_tp_0_p2_touch_idx\n",
    "\n",
    "    short_p2_out_true_bias_bool = short_out_1_p2_touch_idx < short_out_0_p2_touch_idx\n",
    "    short_p2_out_false_bias_bool = short_out_1_p2_touch_idx >= short_out_0_p2_touch_idx\n",
    "    long_p2_out_true_bias_bool = long_out_1_p2_touch_idx < long_out_0_p2_touch_idx\n",
    "    long_p2_out_false_bias_bool = long_out_1_p2_touch_idx >= long_out_0_p2_touch_idx\n",
    "\n",
    "    short_tpbox_hhm = hhm(short_en_true_bias_bool, short_en_false_bias_bool)\n",
    "    long_tpbox_hhm = hhm(long_en_true_bias_bool, long_en_false_bias_bool)\n",
    "\n",
    "    short_p2exec_tpbox_hhm = hhm(short_p2exec_p1_true_bias_bool, short_p2exec_p1_false_bias_bool)\n",
    "    long_p2exec_tpbox_hhm = hhm(long_p2exec_p1_true_bias_bool, long_p2exec_p1_false_bias_bool)\n",
    "\n",
    "    # short_p2_hhm = hhm(short_p2_true_bias_bool, short_p2_false_bias_bool)\n",
    "    # long_p2_hhm = hhm(long_p2_true_bias_bool, long_p2_false_bias_bool)\n",
    "\n",
    "    short_outbox_hhm = hhm(short_p2_out_true_bias_bool, short_p2_out_false_bias_bool)\n",
    "    long_outbox_hhm = hhm(long_p2_out_true_bias_bool, long_p2_out_false_bias_bool)\n",
    "\n",
    "    # print(\"short_tpbox_hhm, short_p2_hhm, short_outbox_hhm :\", short_tpbox_hhm, short_p2_hhm, short_outbox_hhm)\n",
    "    short_en_idx_2d = short_en_idx.reshape(-1, 1)\n",
    "    long_en_idx_2d = long_en_idx.reshape(-1, 1)\n",
    "\n",
    "    return short_tpbox_hhm, long_tpbox_hhm, short_p2exec_tpbox_hhm, long_p2exec_tpbox_hhm, short_outbox_hhm, long_outbox_hhm, \\\n",
    "           short_en_bias_tick, long_en_bias_tick, short_p2exec_p1_bias_tick, long_p2exec_p1_bias_tick, short_p2_true_bias_bool, long_p2_true_bias_bool, \\\n",
    "           short_tp_1[short_en_idx_2d], short_tp_0[short_en_idx_2d], long_tp_1[long_en_idx_2d], long_tp_0[long_en_idx_2d], \\\n",
    "           short_out_1[short_en_idx_2d], short_out_0[short_en_idx_2d], long_out_1[long_en_idx_2d], long_out_0[long_en_idx_2d], \\\n",
    "           short_ep2_0[short_en_idx_2d], long_ep2_0[long_en_idx_2d]  # plot_check 을 위해 en_idx 넣음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pr_v7(open_side, h, l, obj, tpout, lvrg, fee, partial_ranges, partial_qty_ratio, non_tp=False, inversion=False):  # --> 여기서 사용하는 ex_p = ex_p\n",
    "\n",
    "    \"\"\"\n",
    "    v6 -> v7\n",
    "        1. partial 을 위한 수정. (np.tile(min_low, (1, len_p)) <= p_tps) # * (np.tile(max_high, (1, len_p)) <= outs)\n",
    "        2. liqd 구하는 방식도 * (1 - fee) 계산 방식 도입.\n",
    "    \"\"\"\n",
    "\n",
    "    en_p = obj[0]\n",
    "    ex_p = obj[1]\n",
    "\n",
    "    tp, out = np.split(tpout, 2, axis=1)\n",
    "    len_p = len(partial_ranges)\n",
    "    en_ps, ex_ps, tps, outs, lvrgs, fees = [np.tile(arr_, (1, len_p)) for arr_ in [en_p, ex_p, tp, out, lvrg, fee]]\n",
    "    \n",
    "    # print(partial_ranges)\n",
    "    # print(\"ex_ps (up): \", ex_ps)\n",
    "\n",
    "    np_obj = np.array(obj).T[0]\n",
    "    assert len(np_obj.shape) == 2\n",
    "\n",
    "    # iin == iout 인 경우 분리\n",
    "    en_idx = np_obj[:, 2]\n",
    "    ex_idx = np_obj[:, 3]\n",
    "    equal_idx = en_idx == ex_idx  # equal_idx 는 어차피 out 임\n",
    "\n",
    "    # 0. tp part 에 대해서는 ex_ps 를 다르게 특정한다.\n",
    "    if not non_tp:\n",
    "        min_low = np.full_like(en_p, np.nan)\n",
    "        min_low[~equal_idx] = np.array(\n",
    "            [np.min(l[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)  # start from iin + 1 (tp 체결을 entry_idx 부터 보지 않음)\n",
    "        max_high = np.full_like(en_p, np.nan)\n",
    "        max_high[~equal_idx] = np.array(\n",
    "            [np.max(h[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "\n",
    "        if open_side == \"SELL\":\n",
    "            p_tps = en_ps - (en_ps - tps) * partial_ranges\n",
    "            # min_low = np.full_like(en_p, np.nan)\n",
    "            # min_low[~equal_idx] = np.array([np.min(l[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)  # start from iin + 1 (tp 체결을 entry_idx 부터 보지 않음)\n",
    "\n",
    "            # 보수적 검증은 이곳에서 하는 것이 아니다.\n",
    "            tp_idx = (np.tile(min_low, (1, len_p)) <= p_tps) # * (np.tile(max_high, (1, len_p)) <= outs)\n",
    "        else:\n",
    "            p_tps = en_ps + (tps - en_ps) * partial_ranges\n",
    "            # max_high = np.full_like(en_p, np.nan)\n",
    "            # max_high[~equal_idx] = np.array([np.max(h[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "\n",
    "            # out_line touch 이력이 없고 partial_tp_line touch 이력이 있는 경우 => tp 체결 완료.\n",
    "            tp_idx = (np.tile(max_high, (1, len_p)) >= p_tps) # * (np.tile(min_low, (1, len_p)) >= outs)\n",
    "\n",
    "        # 1. 위 구간에서 tps 설정으로 인해, signal_out 에 대한 고려가 진행되지 않고 있음.\n",
    "        ex_ps = outs.copy()\n",
    "        ex_ps[tp_idx] = p_tps[tp_idx]\n",
    "        \n",
    "        \n",
    "        # print(\"ex_ps (2): \", ex_ps)\n",
    "        # return\n",
    "\n",
    "    # 2. get pr, liquidation\n",
    "    if open_side == \"SELL\":\n",
    "        if not inversion:\n",
    "            pr = ((en_ps / ex_ps * (1 - fees) - 1) * lvrgs * partial_qty_ratio).sum(axis=1) + 1\n",
    "\n",
    "            max_high = np.full_like(en_p, np.nan)\n",
    "            max_high[~equal_idx] = np.array([np.max(h[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)  # start from iin (liquidation 을 entry_idx 봄)\n",
    "            liqd = (en_p / max_high * (1 - fees) - 1) * lvrg + 1\n",
    "        else:\n",
    "            pr = ((ex_ps / en_ps * (1 - fees) - 1) * lvrgs * partial_qty_ratio).sum(axis=1) + 1\n",
    "\n",
    "            min_low = np.full_like(en_p, np.nan)\n",
    "            min_low[~equal_idx] = np.array([np.min(l[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = (min_low / en_p * (1 - fees) - 1) * lvrg + 1\n",
    "    else:\n",
    "        if not inversion:\n",
    "            pr = ((ex_ps / en_ps * (1 - fees) - 1) * lvrgs * partial_qty_ratio).sum(axis=1) + 1\n",
    "\n",
    "            min_low = np.full_like(en_p, np.nan)\n",
    "            min_low[~equal_idx] = np.array([np.min(l[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = (min_low / en_p * (1 - fees) - 1) * lvrg + 1\n",
    "        else:\n",
    "            pr = ((en_ps / ex_ps * (1 - fees) - 1) * lvrgs * partial_qty_ratio).sum(axis=1) + 1\n",
    "\n",
    "            max_high = np.full_like(en_p, np.nan)\n",
    "            max_high[~equal_idx] = np.array([np.max(h[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = (en_p / max_high * (1 - fees) - 1) * lvrg + 1\n",
    "\n",
    "    pr_2d = pr.reshape(-1, 1)\n",
    "    # pr_2d[liqd <= 0] = 0  # liquidation platform 에서는 억지로 0 을 대입시킬 필요가 없어짐.\n",
    "    pr_2d[pr_2d < 0] = 0  # pr 음수 오차 수정.\n",
    "\n",
    "    return pr_2d, np.nanmin(liqd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### plot_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hdpN7S8JJF-"
   },
   "outputs": [],
   "source": [
    "def plot_info_v8_2(gs, gs_idx, len_df, sample_len, tr, hhm, p2_hhm, out_hhm, hlm, bars_in, net_p1_frq, pr, total_pr,\n",
    "                 acc_pr, sum_pr, liqd, leverage, title_position, fontsize):\n",
    "    \n",
    "    \"\"\"\n",
    "    v8 -> v8_2\n",
    "        1. peridic sum_pr plot 을 위해 get_res_info_nb_v3, title_msg 수정함.\n",
    "        2. sum_mdd -> prod & sum mdd 둘다 plot 함.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        plt.subplot(gs[gs_idx])\n",
    "        idep_res_obj = get_res_info_nb_v3(sample_len, pr, acc_pr, sum_pr, liqd)\n",
    "        plt.plot(acc_pr)\n",
    "        plt.plot(sum_pr, color='gold')\n",
    "        if sample_len is not None:\n",
    "            plt.axvline(sample_len, alpha=1., linestyle='--', color='#ffeb3b')\n",
    "        plt.xlim(0, len_df)\n",
    "\n",
    "        title_str = \"tr : {:.3f}\\n tpbox_hhm : {:.3f}\\n tpbox_p2exec_hhm : {:.3f}\\n outbox_hhm : {:.3f}\\n hlm : {:.3f}\\n bars_in : {:.3f}\\n net_p1_frq : {}\\n frq : {}\\n dpf : {:.3f}\\n wr : {:.3f}\\n sr : {:.3f}\\n acc_pr : {:.3f}\\n sum_pr : {:.3f}\\n\" + \\\n",
    "                    \"min_pr : {:.3f}\\n liqd : {:.3f}\\n acc_mdd : -{:.3f}\\n sum_mdd : -{:.3f} ({:.3f})\\n leverage {:.3f}\"\n",
    "        plt.title(title_str.format(tr, hhm, p2_hhm, out_hhm, hlm, bars_in, net_p1_frq, *idep_res_obj, leverage), position=title_position, fontsize=fontsize)\n",
    "    except Exception as e:\n",
    "        print(\"error in plot_info :\", e)\n",
    "\n",
    "    return gs_idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### sum_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdd_v2(pr, mode=\"PROD\"):\n",
    "    \n",
    "    rollmax_pr = np.maximum.accumulate(pr)\n",
    "    \n",
    "    if mode == \"PROD\":\n",
    "        return np.max((rollmax_pr - pr) / rollmax_pr)\n",
    "    else:\n",
    "        return np.max(rollmax_pr - pr)\n",
    "\n",
    "\n",
    "# @jit  # almost equal\n",
    "def get_res_info_nb_v3(len_df, np_pr, acc_pr, sum_pr, liqd):\n",
    "\n",
    "    \"\"\"\n",
    "    v2 -> v3\n",
    "        1. get_sum_pr_nb 에 total_pr 을 사용함\n",
    "            a. total_pr 은 np_pr 의 거래 체결과 체결 사이에 non_trade_pr (= 1) 을 추가한 것\n",
    "    \"\"\"\n",
    "    wr = len(np_pr[np_pr > 1]) / len(np_pr[np_pr != 1])\n",
    "    sr = sharpe_ratio(np_pr)\n",
    "    min_pr = np.min(np_pr)\n",
    "\n",
    "    len_pr = len(np_pr)\n",
    "    assert len_pr != 0\n",
    "    dpf = (len_df / 1440) / len_pr  # devision zero warning\n",
    "\n",
    "    acc_mdd = mdd_v2(acc_pr)\n",
    "    sum_mdd_prod = mdd_v2(sum_pr)\n",
    "    sum_mdd_sum = mdd_v2(sum_pr, mode=\"SUM\")\n",
    "\n",
    "    return len_pr, dpf, wr, sr, acc_pr[-1], sum_pr[-1] - 1, min_pr, liqd, acc_mdd, sum_mdd_prod, sum_mdd_sum\n",
    "\n",
    "# @jit\n",
    "def get_sum_pr_nb(np_pr):\n",
    "    \n",
    "    for_sum_pr = np_pr - 1\n",
    "    for_sum_pr[0] = 1  # 1 로 시작하지 않을 경우, sum_mdd = nan 출력됨.\n",
    "    \n",
    "    # print(\"np_pr :\", np_pr[np_pr != 1])\n",
    "    # print(\"for_sum_pr :\", for_sum_pr[np_pr != 1])\n",
    "    \n",
    "    sum_pr = np.cumsum(for_sum_pr)\n",
    "    # sum_pr = np.where(sum_pr < 0, 0, sum_pr)  # sum_mdd 의 정확한 측정을 위해 주석처리함.\n",
    "\n",
    "    return sum_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frq_dev_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frq_dev_plot_v5(gs, gs_idx, len_df, sample_len, exit_idx, bias_arr, acc_pr, sum_pr, fontsize, mode='CRYPTO'):\n",
    "    \n",
    "    \"\"\"\n",
    "    v4 -> v5\n",
    "        1. add periodic sum_pr\n",
    "        2. remove return value\n",
    "        3. use get_period_pr_v3 for Stock.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.subplot(gs[gs_idx])\n",
    "\n",
    "    plt.vlines(exit_idx[bias_arr], ymin=0, ymax=1, color='#00ff00')\n",
    "    # plt.vlines(exit_idx[~bias_arr], ymin=0, ymax=1, color='#ff00ff')\n",
    "    plt.xlim(0, len_df)\n",
    "\n",
    "    title_msg = \"periodic_pr (acc | sum)\\n day : {:.2f} | {:.2f}\\n month : {:.2f} | {:.2f}\\n year : {:.2f} | {:.2f}\"  # \\n rev_acc_day : {:.4f}\\n month : {:.4f}\\n year : {:.4f}\"\n",
    "    array_zip = np.array(list(zip(get_period_pr_v3(sample_len, acc_pr, mode=mode), get_period_pr_v3(sample_len, sum_pr, pr_type=\"SUM\", mode=mode)))).ravel()\n",
    "\n",
    "    plt.title(title_msg.format(*array_zip, fontsize=fontsize))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_pr_v2(len_df, pr_, pr_type=\"PROD\"):\n",
    "    \n",
    "    days = len_df / 1440\n",
    "    months = days / 30\n",
    "    years = days / 365\n",
    "    \n",
    "    if pr_type == \"PROD\":\n",
    "        return [pr_ ** (1 / period) for period in [days, months, years]]\n",
    "    else:\n",
    "        return [(pr_ - 1) / period for period in [days, months, years]]  # sum_pr 은 초기 자산을 제외한 증분에 대해서만 진행함 (sum 특성상.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ-roiifspcX",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Archive : ep_loc.point & zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Js5eL87VspcX"
   },
   "outputs": [],
   "source": [
    "\n",
    "    # res_df['entry_{}'.format(selection_id)] = np.where((res_df['open'] >= res_df['cloud_bline_%s' % cb_itv]) &\n",
    "    #                 # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['cloud_bline_%s' % cb_itv]) &\n",
    "    #                 (res_df['close'] < res_df['cloud_bline_%s' % cb_itv])\n",
    "    #                 , res_df['entry_{}'.format(selection_id)] - 1, res_df['entry_{}'.format(selection_id)])\n",
    "\n",
    "    # res_df['entry_{}'.format(selection_id)] = np.where((res_df['open'] >= res_df['bb_lower_1m']) &\n",
    "    #                 # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['bb_lower_1m']) &\n",
    "    #                 (res_df['close'] < res_df['bb_lower_1m'])\n",
    "    #                 , res_df['entry_{}'.format(selection_id)] - 1, res_df['entry_{}'.format(selection_id)])\n",
    "\n",
    "    # res_df['entry_{}'.format(selection_id)] = np.where((res_df['open'] <= res_df['cloud_bline_%s' % cb_itv]) &\n",
    "    #                   # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['cloud_bline_%s' % cb_itv]) &\n",
    "    #                   (res_df['close'] > res_df['cloud_bline_%s' % cb_itv])\n",
    "    #                 , res_df['entry_{}'.format(selection_id)] + 1, res_df['entry_{}'.format(selection_id)])\n",
    "\n",
    "    # res_df['entry_{}'.format(selection_id)] = np.where((res_df['open'] <= res_df['bb_upper_1m']) &\n",
    "    #                   # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['bb_upper_1m']) &\n",
    "    #                   (res_df['close'] > res_df['bb_upper_1m'])\n",
    "    #                 , res_df['entry_{}'.format(selection_id)] + 1, res_df['entry_{}'.format(selection_id)])\n",
    "\n",
    "\n",
    "    \n",
    "   # --------------- ema --------------- #   \n",
    "  # res_df['ema5_1m'] = ema(res_df['close'], 5).shift(1)\n",
    "\n",
    "  #   # --------------- cloud bline --------------- #   \n",
    "  # res_df['cloud_bline_1m'] = cloud_bline(res_df, 26).shift(1)\n",
    "  \n",
    "    #       stochastic      #\n",
    "  # res_df['stoch'] = stoch(res_df, 5, 3, 3)\n",
    "\n",
    "    #       fisher      #\n",
    "  # res_df['fisher30'] = fisher(res_df, 30)\n",
    "  # res_df['fisher60'] = fisher(res_df, 60)\n",
    "  # res_df['fisher120'] = fisher(res_df, 120)\n",
    "\n",
    "    #       cctbbo      #\n",
    "  # res_df['cctbbo'], _ = cct_bbo(res_df, 21, 13)\n",
    "\n",
    "    #       ema_roc      #\n",
    "  # res_df['ema_roc'] = ema_roc(res_df['close'], 13, 9)\n",
    "\n",
    "\n",
    "   # ------------------------------ htf data ------------------------------ #    \n",
    "\n",
    "  #             Todo              #\n",
    "  # htf_df = pd.read_excel(date_path2 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n",
    "  # htf_df = pd.read_excel(date_path3 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n",
    "  # # htf_df = pd.read_excel(date_path4 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n",
    "  # # # htf_df = pd.read_excel(date_path5 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n",
    "  # # # # # # htf_df = pd.read_excel(date_path6 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n",
    "\n",
    "  # # ---- htf index slicing ---- #\n",
    "  # htf_df = htf_df.loc[:res_df.index[-1]]\n",
    "  \n",
    "  # print(\"res_df.index[-1] :\", res_df.index[-1])\n",
    "  # print(\"htf_df.index[-1] :\", htf_df.index[-1])\n",
    "\n",
    "  # res_df = dc_line(res_df, htf_df, '5m')\n",
    "  # res_df = dc_level(res_df, '5m', 1)\n",
    "\n",
    "\n",
    "  # # # if \"sma4\" in res_df.columns:\n",
    "  # # #   res_df.drop(\"sma4\", axis=1, inplace=1)\n",
    "\n",
    "  # # htf_df['sma'] = htf_df['close'].rolling(60).mean()\n",
    "  # # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf_v2(res_df, htf_df, [-1]), columns=['sma_30m']))\n",
    "  \n",
    "  # htf_df['stoch'] = stoch(htf_df, 13, 3, 3)\n",
    "  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf_v2(res_df, htf_df, [-1], backing_i=-1), columns=['stoch_5m']))\n",
    "\n",
    "   \n",
    "  # fifth_df['ema'] = ema(fifth_df['close'], 5)\n",
    "  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf_v2(res_df, fifth_df, [-1]), columns=['ema5']))\n",
    "\n",
    "        # ------------------------------------ short ------------------------------------ # \n",
    "\n",
    "        # --------- by sar --------- # \n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_3m'].iloc[i] == 0:\n",
    "        #   mr_score += 1\n",
    "\n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_5m'].iloc[i] == 0:\n",
    "        #   mr_score += 1          \n",
    "\n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_15m'].iloc[i] == 0:\n",
    "        #   mr_score += 1\n",
    "\n",
    "          #      dc & sar      # \n",
    "        # mr_const_cnt += 1\n",
    "        # # if res_df['dc_upper_1m'].iloc[i] <= res_df['sar_15m'].iloc[i]:\n",
    "        # if res_df['dc_upper_3m'].iloc[i] <= res_df['sar_5m'].iloc[i]:\n",
    "        # # if res_df['dc_upper_5m'].iloc[i] <= res_df['sar_15m'].iloc[i]:\n",
    "        #   mr_score += 1\n",
    "\n",
    "        # -------------- dr scheduling -------------- #\n",
    "        # if config.ep_set.entry_type == 'MARKET':\n",
    "        #   mr_const_cnt += 1\n",
    "        #   if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error):  \n",
    "        #     mr_score += 1\n",
    "\n",
    "           \n",
    "        # ------- entry once ------- #   \n",
    "        # prev_entry_cnt = 0\n",
    "        # for back_i in range(i - 1, 0, -1):\n",
    "        #   if res_df['entry'][back_i] == 1:\n",
    "        #     break\n",
    "\n",
    "        #   elif res_df['entry'][back_i] == -1:\n",
    "        #     prev_entry_cnt += 1          \n",
    "        # # # print(\"prev_entry_cnt :\", prev_entry_cnt)\n",
    "\n",
    "        # mr_const_cnt += 1\n",
    "        # # if prev_entry_cnt <= config.ep_set.entry_incycle:\n",
    "        # # if prev_entry_cnt == config.ep_set.entry_incycle:\n",
    "        # if prev_entry_cnt >= config.ep_set.entry_incycle:\n",
    "        #   mr_score += 1\n",
    "\n",
    "        # ------- htf zoning ------- #   \n",
    "        # mr_const_cnt += 1\n",
    "        #   #       bb zone     #\n",
    "        # if res_df['close'].iloc[i] < res_df['bb_lower_%s' % bbz_interval].iloc[i]:\n",
    "        # # if res_df['close'].iloc[i] < res_df['bb_lower2_1h'].iloc[i]:\n",
    "        # # if res_df['close'].iloc[i] < res_df['bb_base_1h'].iloc[i]:\n",
    "\n",
    "        #   #       cbline zone     #\n",
    "        # # if res_df['close'].iloc[i] < res_df['cloud_bline_%s' % cb_interval].iloc[i]:\n",
    "\n",
    "        #   mr_score += 1\n",
    "\n",
    "  \n",
    "        # ------- ben ep_in's tp done ------- #   \n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['low'].iloc[i] > res_df['short_tp'].iloc[i]:\n",
    "        #   mr_score += 1\n",
    "\n",
    "\n",
    "        # -------------- feature dist const. -------------- #\n",
    "        # if initial_i < input_size:\n",
    "        #   i += 1\n",
    "        #   if i >= len(res_df):\n",
    "        #     break\n",
    "        #   continue\n",
    "\n",
    "        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n",
    "       \n",
    "        # re_entry_input_x = expand_dims(entry_input_x)\n",
    "\n",
    "        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n",
    "        # # print(test_result.shape)\n",
    "\n",
    "        # f_dist = vector_dist(entry_vector, selected_vector)\n",
    "        # print(\"f_dist :\", f_dist)\n",
    "\n",
    "        # if f_dist < fdist_thresh:\n",
    "          # mr_score += 1\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------------------ long ------------------------------------ # \n",
    "          \n",
    "\n",
    "        # --------- by sar --------- # \n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_3m'].iloc[i] == 1:\n",
    "        #   mr_score += 1   \n",
    "\n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_5m'].iloc[i] == 1:\n",
    "        #   mr_score += 1     \n",
    "\n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['sar_uptrend_15m'].iloc[i] == 1:\n",
    "          # mr_score += 1\n",
    "\n",
    "          #      dc & sar      # \n",
    "        # mr_const_cnt += 1\n",
    "        # # if res_df['dc_lower_1m'].iloc[i] >= res_df['sar_15m'].iloc[i]:\n",
    "        # if res_df['dc_lower_3m'].iloc[i] >= res_df['sar_5m'].iloc[i]:\n",
    "        # # if res_df['dc_lower_5m'].iloc[i] >= res_df['sar_15m'].iloc[i]:\n",
    "        #   mr_score += 1\n",
    "\n",
    "        # -------------- dr scheduling -------------- #\n",
    "        # if config.ep_set.entry_type == \"MARKET\":\n",
    "          # mr_const_cnt += 1        \n",
    "          # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error): # 일반적으로 dr 상에서 tp 비율이 더 커짐 (tr 보다)\n",
    "          #   mr_score += 1\n",
    "\n",
    "        # -------------- ep limit -------------- #    \n",
    "        # mr_const_cnt += 1\n",
    "        # # if (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n",
    "        # if config.ep_set.min_eplim_pct < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n",
    "        # # if 0 < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n",
    "        #   # if res_df['st_gap_15m'].iloc[i] / res_df['open'].iloc[i] < 0:\n",
    "        #   #   print(\"i, res_df['st_gap_15m'].iloc[i] :\", i, res_df['st_gap_15m'].iloc[i])\n",
    "        #   mr_score += 1\n",
    "\n",
    "\n",
    "        # -------------- entry once -------------- #    \n",
    "        # prev_entry_cnt = 0\n",
    "        # for back_i in range(i - 1, 0, -1):\n",
    "        #   if res_df['entry'][back_i] == -1:\n",
    "        #     break\n",
    "\n",
    "        #   elif res_df['entry'][back_i] == 1:\n",
    "        #     prev_entry_cnt += 1\n",
    "          \n",
    "        # mr_const_cnt += 1\n",
    "        # # if prev_entry_cnt <= config.ep_set.entry_incycle:\n",
    "        # # if prev_entry_cnt == config.ep_set.entry_incycle:\n",
    "        # if prev_entry_cnt >= config.ep_set.entry_incycle:\n",
    "        #   mr_score += 1\n",
    "\n",
    "\n",
    "        # ------- htf zoning ------- #   \n",
    "        # mr_const_cnt += 1\n",
    "          \n",
    "        #   #       bb zone     #\n",
    "        # if res_df['close'].iloc[i] > res_df['bb_upper_%s' % bbz_interval].iloc[i]:\n",
    "        # # if res_df['close'].iloc[i] > res_df['bb_upper2_1h'].iloc[i]:\n",
    "        # # if res_df['close'].iloc[i] > res_df['bb_base_1h'].iloc[i]:\n",
    "        \n",
    "        #   #       cbline zone     #\n",
    "        # # if res_df['close'].iloc[i] > res_df['cloud_bline_%s' % cb_interval].iloc[i]:\n",
    "\n",
    "        #   mr_score += 1\n",
    "\n",
    "\n",
    "        # ------- ben ep_in's tp done ------- #   \n",
    "        # mr_const_cnt += 1\n",
    "        # if res_df['high'].iloc[i] < res_df['long_tp'].iloc[i]:\n",
    "        #   mr_score += 1\n",
    "\n",
    "\n",
    "        # -------------- feature dist const. -------------- #\n",
    "        # if initial_i < input_size:\n",
    "        #   i += 1\n",
    "        #   if i >= len(res_df):\n",
    "        #     break\n",
    "        #   continue\n",
    "          \n",
    "        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n",
    "       \n",
    "        # re_entry_input_x = expand_dims(entry_input_x)\n",
    "\n",
    "        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n",
    "        # # print(test_result.shape)\n",
    "\n",
    "        # f_dist = vector_dist(entry_vector, selected_vector)\n",
    "        # print(\"f_dist :\", f_dist)\n",
    "\n",
    "        # if f_dist < fdist_thresh:\n",
    "          # mr_score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDQWK3v5xOFa"
   },
   "outputs": [],
   "source": [
    "def get_pr_v4(open_side, h, l, obj, tpout, lvrg, fee, p_ranges, p_qty_ratio, inversion=False):  # --> 여기서 사용하는 ex_p = ex_p\n",
    "\n",
    "    en_p = obj[0]\n",
    "    # ex_p = obj[1]\n",
    "    tp, out = np.split(tpout, 2, axis=1)\n",
    "    len_p = len(p_ranges)\n",
    "    en_ps, tps, outs, lvrgs, fees = [np.tile(arr_, (1, len_p)) for arr_ in [en_p, tp, out, lvrg, fee]]\n",
    "\n",
    "    np_obj = np.array(obj).T[0]\n",
    "    assert len(np_obj.shape) == 2\n",
    "\n",
    "    # iin == iout 인 경우 분리\n",
    "    en_idx = np_obj[:, 2]\n",
    "    ex_idx = np_obj[:, 3]\n",
    "    equal_idx = en_idx == ex_idx    # equal_idx 는 어차피 out 임\n",
    "    issue_idx = en_idx > ex_idx    # equal_idx 는 어차피 out 임\n",
    "\n",
    "    print('pass')\n",
    "    idx_gap_ = (ex_idx - en_idx)[~equal_idx]\n",
    "    print(\"en_idx[issue_idx] :\", en_idx[issue_idx])\n",
    "    print(\"ex_idx[issue_idx] :\", ex_idx[issue_idx])\n",
    "    print(\"idx_gap_[idx_gap_ <= 0] :\", idx_gap_[idx_gap_ <= 0])\n",
    "\n",
    "    min_low = np.full_like(en_p, np.nan)\n",
    "    min_low[~equal_idx] = np.array([np.min(l[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)  # start from iin + 1 (tp 체결을 entry_idx 부터 보지 않음)\n",
    "    max_high = np.full_like(en_p, np.nan)\n",
    "    max_high[~equal_idx] = np.array([np.max(h[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "\n",
    "    if open_side == \"SELL\":\n",
    "        p_tps = en_ps - (en_ps - tps) * p_ranges\n",
    "        # min_low = np.full_like(en_p, np.nan)\n",
    "        # min_low[~equal_idx] = np.array([np.min(l[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)  # start from iin + 1 (tp 체결을 entry_idx 부터 보지 않음)\n",
    "        tp_idx = (np.tile(min_low, (1, len_p)) <= p_tps) * (np.tile(max_high, (1, len_p)) <= outs)  # entry_idx 포함해서 out touch 금지 (보수적 검증)\n",
    "    else:\n",
    "        p_tps = en_ps + (tps - en_ps) * p_ranges\n",
    "        # max_high = np.full_like(en_p, np.nan)\n",
    "        # max_high[~equal_idx] = np.array([np.max(h[int(iin + 1):int(iout + 1)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "        tp_idx = (np.tile(max_high, (1, len_p)) >= p_tps) * (np.tile(min_low, (1, len_p)) >= outs)\n",
    "\n",
    "    ex_ps = outs.copy()\n",
    "    ex_ps[tp_idx] = p_tps[tp_idx]\n",
    "\n",
    "    if open_side == \"SELL\":\n",
    "        if not inversion:\n",
    "            pr = ((en_ps / ex_ps - fees - 1) * lvrgs * p_qty_ratio).sum(axis=1) + 1\n",
    "            # ------ liquidation ------ #\n",
    "            max_high = np.full_like(en_p, np.nan)\n",
    "            max_high[~equal_idx] = np.array([np.max(h[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = np.nanmin((en_p / max_high - fee - 1) * lvrg + 1)\n",
    "        else:\n",
    "            pr = ((ex_ps / en_ps - fees - 1) * lvrgs * p_qty_ratio).sum(axis=1) + 1\n",
    "            # ------ liquidation ------ #\n",
    "            min_low = np.full_like(en_p, np.nan)\n",
    "            min_low[~equal_idx] = np.array([np.min(l[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = np.nanmin((min_low / en_p - fee - 1) * lvrg + 1)\n",
    "    else:\n",
    "        if not inversion:\n",
    "            pr = ((ex_ps / en_ps - fees - 1) * lvrgs * p_qty_ratio).sum(axis=1) + 1\n",
    "            # ------ liquidation ------ #\n",
    "            min_low = np.full_like(en_p, np.nan)\n",
    "            min_low[~equal_idx] = np.array([np.min(l[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = np.nanmin((min_low / en_p - fee - 1) * lvrg + 1)\n",
    "        else:\n",
    "            pr = ((en_ps / ex_ps - fees - 1) * lvrgs * p_qty_ratio).sum(axis=1) + 1\n",
    "            # ------ liquidation ------ #\n",
    "            max_high = np.full_like(en_p, np.nan)\n",
    "            max_high[~equal_idx] = np.array([np.max(h[int(iin):int(iout)]) for _, _, iin, iout in np_obj[~equal_idx, :4]]).reshape(-1, 1)\n",
    "            liqd = np.nanmin((en_p / max_high - fee - 1) * lvrg + 1)\n",
    "\n",
    "    return pr.reshape(-1, 1), liqd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE5zkT75Beiy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------ plot survey_res ------------ #\n",
    "title_list = [\"short\", \"long\", \"both\"]\n",
    "sub_title_list = ['prcn', 'wb', 'len_pr', 'dpf', 'wr', 'sr', 'acc_pr', 'sum_pr', 'min_pr', 'liqd', 'acc_mdd', 'sum_mdd']\n",
    "space_ = \" \" * 120\n",
    "\n",
    "fig = plt.figure(figsize=(24, 8))\n",
    "plt.style.use('dark_background')\n",
    "gs = gridspec.GridSpec(nrows=1,\n",
    "                        ncols=3,\n",
    "                        # height_ratios=[1, 1, 1]\n",
    "                      )\n",
    "# nrows, ncols, h_r = 3, 3, [1, 1, 1]\n",
    "nrows, ncols, h_r = 3, 4, [1, 1, 1]\n",
    "# nrows, ncols, h_r = 4, 3, [1, 1, 1, 1]\n",
    "# if d_idx == 0:\n",
    "# else:\n",
    "  # nrows, ncols, h_r = 2, 2, [1, 1]\n",
    "\n",
    "for d_idx, (title_name, survey_res) in enumerate(zip(title_list, survey_res_list)):  \n",
    "  inner_gs = gs[d_idx].subgridspec(nrows=nrows,\n",
    "                        ncols=ncols,\n",
    "                        height_ratios=h_r\n",
    "                      )\n",
    "  for in_idx, (data_, sub_title) in enumerate(zip(survey_res.T, sub_title_list)):\n",
    "    plt.subplot(inner_gs[in_idx])\n",
    "    data = data_.ravel()\n",
    "    valid_idx = ~np.isnan(data)\n",
    "    if np.sum(valid_idx) > 0:\n",
    "      if type(val_list[0]) == str:\n",
    "        x, y = np.arange(len(val_list))[valid_idx], data[valid_idx]\n",
    "      else:\n",
    "        x, y = val_list[valid_idx], data[valid_idx]\n",
    "      plt.plot(x, y)  # 앞에서부터 len(result) 만큼만    \n",
    "      plt.title(sub_title + '_{:.2f}'.format(x[np.argmax(y)]))\n",
    "    else:\n",
    "      plt.title(sub_title)\n",
    "\n",
    "plt.suptitle(space_.join(title_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbYUlJl34ImU"
   },
   "outputs": [],
   "source": [
    "# ------ open validation ------ #\n",
    "pos_side = \"SELL\" # SELL BUY\n",
    "\n",
    "if pos_side == \"SELL\":\n",
    "  open_ = res_df['short_open1_{}'.format(config.selection_id)].to_numpy()\n",
    "  open_ts = list(map(lambda x : str(x), res_df.index[open_ == 1]))  \n",
    "else:\n",
    "  open_ = res_df['long_open1_{}'.format(config.selection_id)].to_numpy()\n",
    "  open_ts = list(map(lambda x : str(x), res_df.index[open_ == 1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyYMYcxx4ImV"
   },
   "outputs": [],
   "source": [
    "pos_index = open_info_df1.side == pos_side\n",
    "for ts in res_df.index[open_info_df1.index[pos_index]]:\n",
    "  print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YcqQQzsl6Ys"
   },
   "outputs": [],
   "source": [
    "\n",
    "def hlm(pr_list, true_bool):   # true_pr in true_bias / true_bias\n",
    "  true_bias_pr = pr_list[true_bool].ravel()\n",
    "  print(\"len(pr_list) :\", len(pr_list))\n",
    "  print(\"len(true_bias_pr) :\", len(true_bias_pr))\n",
    "  print(\"np.sum(pr_list > 1) :\", np.sum(pr_list > 1))\n",
    "  print(\"np.sum(true_bias_pr > 1) :\", np.sum(true_bias_pr > 1))\n",
    "  return np.sum(true_bias_pr > 1) / len(true_bias_pr)  # 차원을 고려한 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsI-R8Zz7ls1"
   },
   "outputs": [],
   "source": [
    "\n",
    "        # tr_arr = res_df['{}_tr_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "\n",
    "        # ------ point1 & 2's tp_j ------ #\n",
    "        # point_idxgap = point_idxgap_arr[op_idx]\n",
    "        # if np.isnan(point_idxgap):\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     # ------ allow point2 only next to point1 ------ #\n",
    "        #     open_arr = res_df['{}_open_{}'.format(side_pos, selection_id)].to_numpy()\n",
    "        #     tp_j = int(op_idx - point_idxgap)\n",
    "        #     if np.sum(open_arr[tp_j:op_idx]) != 0:\n",
    "        #         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1652751452213,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "gMur2u8WeQ2K",
    "outputId": "7b506c38-7a8f-4bd1-a021-8a065d009882"
   },
   "outputs": [],
   "source": [
    "# ------ bias frquency ------ #\n",
    "len_df = len(res_df)\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "plt.fill_between(short_obj[-2].ravel(), 0, 1, where=short_bias_arr.ravel() > 0,\n",
    "                facecolor='#00ff00', alpha=1, transform=ax1.get_xaxis_transform())   # 00ff00\n",
    "# plt.fill_between(short_obj[-2].ravel(), 0, 1, where=short_bias_arr.ravel() < 1,\n",
    "#                 facecolor='#ff00ff', alpha=1, transform=ax1.get_xaxis_transform())\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.fill_between(long_obj[-2].ravel(), 0, 1, where=long_bias_arr.ravel() > 0,\n",
    "                facecolor='#00ff00', alpha=1, transform=ax2.get_xaxis_transform())\n",
    "plt.fill_between(long_obj[-2].ravel(), 0, 1, where=long_bias_arr.ravel() < 1,\n",
    "                facecolor='#ff00ff', alpha=1, transform=ax2.get_xaxis_transform())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1652756329304,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "eoXMxRm3qdz2",
    "outputId": "98c90b55-4c14-402c-e2d4-d7b88f9e2e62"
   },
   "outputs": [],
   "source": [
    "# ------ bias frquency ------ #\n",
    "len_df = len(res_df)\n",
    "\n",
    "plt.figure(figsize=(16, 2))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "plt.fill_between(short_obj[-2].ravel(), 0, 1, where=short_bias_arr.ravel() > 0,\n",
    "                facecolor='#00ff00', alpha=1, transform=ax1.get_xaxis_transform())   # 00ff00\n",
    "# plt.fill_between(short_obj[-2].ravel(), 0, 1, where=short_bias_arr.ravel() < 1,\n",
    "#                 facecolor='#ff00ff', alpha=1, transform=ax1.get_xaxis_transform())\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.vlines(long_obj[-2][long_bias_arr], ymin=0, ymax=1, color='#00ff00')\n",
    "plt.vlines(long_obj[-2][~long_bias_arr], ymin=0, ymax=1, color='#ff00ff')\n",
    "# [plt.axvline(x_, color='#ff00ff') for x_, bias_ in zip(long_obj[-2], long_bias_arr) if not bias_]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dm7ZqzS9vqhm"
   },
   "outputs": [],
   "source": [
    "%timeit -n1 -r10 plt.vlines(long_obj[-2][long_bias_arr], ymin=0, ymax=1, color='#00ff00')  # 528 ms per loop --> 8.71 ms per loop\n",
    "%timeit -n1 -r10 [plt.axvline(x_, color='#00ff00') for x_, bias_ in zip(long_obj[-2], long_bias_arr) if bias_]\n",
    "\n",
    "# np.sum(long_bias_arr == ~long_bias_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOE2YSzntx8v"
   },
   "outputs": [],
   "source": [
    "# %timeit -n1 -r10 [plt.axvline(x_) for x_, bias_ in zip(long_obj[-2].ravel(), long_bias_arr.ravel()) if bias_]\n",
    "%timeit -n1 -r10 plt.fill_between(long_obj[-2].ravel(), 0, 1, where=long_bias_arr.ravel() > 0, facecolor='#00ff00', alpha=1, transform=ax2.get_xaxis_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHFkv6Ar1ojU"
   },
   "source": [
    "## Plot_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1666568170706,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "rMIwv1Nr1ojX"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "해당 order_side data 가 없을시, pr.ravel() 불가해짐\n",
    "\"\"\"\n",
    "\n",
    "# ------------------ plot_config ------------------ #\n",
    "save_mode = 0\n",
    "\n",
    "front_plot = 0    # 0 : p1_tick, 1 : p2_tick\n",
    "back_plot = 4     # 0 : post_plot_size, 1 : open, 2 : p2_tick, 3 : ep_tick, 4 : tp_tick\n",
    "x_max = 300       # back_plot : 0 사용시, custom x_max 반영됨\n",
    "\n",
    "bias_plot = 0     # 1 : true_bias only, -1 : false_bias only, 0 : both\n",
    "\n",
    "pr_descend = -1   # 1 : 큰 pr 부터, -1 : 작은 pr 부터, 0 : 순서대로\n",
    "\n",
    "position = 1      # -1 : short, 0 & 1 : long\n",
    "\n",
    "x_margin_mult = 1/30\n",
    "y_margin_mult = 1/30  # 0 \n",
    "\n",
    "prev_plotsize = 200 #  150 100 20 500 1000\n",
    "post_plotsize = 200 #\n",
    "\n",
    "inversion = 0\n",
    "hedge = 0\n",
    "\n",
    "# ------ show or save ------ #\n",
    "if save_mode:\n",
    "  plot_check_dir = pkg_path + \"plot_check/\" +  key.replace(\".ftr\", \"\")\n",
    "  shutil.rmtree(plot_check_dir, ignore_errors=True)  # remove existing dir\n",
    "  os.makedirs(plot_check_dir)\n",
    "  print(plot_check_dir)\n",
    "else:\n",
    "  plot_check_dir = None\n",
    "\n",
    "# ------------ 한 방향에 대해 plot_check 함 (by position var.) ------------ #\n",
    "#   obj by position  \n",
    "if position == -1:\n",
    "  pos_str = \"SELL\"\n",
    "  pr_, obj_ = short_pr, short_obj\n",
    "  arr_list = [short_p2_idx_arr, short_lvrg_arr, short_fee_arr, short_tpout_arr, short_bias_arr, short_net_p1_bias_tick, short_tp_1, short_tp_0, short_out_1, short_out_0, short_ep2_0]\n",
    "else:   # both option currently not supported\n",
    "  pos_str = \"BUY\"\n",
    "  pr_, obj_ = long_pr, long_obj\n",
    "  arr_list = [long_p2_idx_arr, long_lvrg_arr, long_fee_arr, long_tpout_arr, long_bias_arr, long_net_p1_bias_tick, long_tp_1, long_tp_0, long_out_1, long_out_0, long_ep2_0]\n",
    "\n",
    "if pr_descend:\n",
    "  if pr_descend == -1:\n",
    "    pr_descend = 0\n",
    "  pr, obj, [p2_idx_arr, lvrg_arr, fee_arr, tpout_arr, bias_arr, bias_tick, tp_1, tp_0, out_1, out_0, ep2_0] = sort_bypr_v4(pr_, obj_, arr_list, descending=pr_descend)  # --> pr_descend 의 의미가 사라짐.. (false -> true plot 으로 이동한 것뿐)\n",
    "else:\n",
    "  pr, obj, [p2_idx_arr, lvrg_arr, fee_arr, tpout_arr, bias_arr, bias_tick, tp_1, tp_0, out_1, out_0, ep2_0] = pr_, obj_, arr_list\n",
    "\n",
    "pr_msg = \"%s\\n {} ~ {} -> {:.5f}\\n lvrg : {}\\n fee : {:.4f}\" % (pos_str)  # = data_window, pos_str 으로 이곳에서 정의함\n",
    "\n",
    "try:   # wave_range 단독 실행의 경우 tr_arr 이 존재하지 않기 때문에 try 처리함\n",
    "  res_df['short_tr_{}'.format(selection_id)].iloc[short_obj[-1].astype(int).ravel()] = short_tr_arr\n",
    "  res_df['long_tr_{}'.format(selection_id)].iloc[long_obj[-1].astype(int).ravel()] = long_tr_arr\n",
    "except:\n",
    "  pass\n",
    "\n",
    "if front_plot == 0:\n",
    "  front_idx = obj[4]      # left_margin 기준 - open_idx\n",
    "else:\n",
    "  front_idx = p2_idx_arr  # left_margin 기준 - p2_idx\n",
    "\n",
    "left_end_idx = front_idx - prev_plotsize  \n",
    "right_end_idx = obj[3] + post_plotsize\n",
    "invalid_left_end = np.sum(left_end_idx < 0)\n",
    "\n",
    "np_plot_params = np.hstack((left_end_idx, right_end_idx, pr, *obj, p2_idx_arr, lvrg_arr, fee_arr, tpout_arr, tp_1, tp_0, out_1, out_0, ep2_0))[invalid_left_end:]  # all arr should have same dimension\n",
    "# plot_idx = np.full(len(np_plot_params), True)\n",
    "\n",
    "if bias_plot:\n",
    "  if bias_plot == 1:\n",
    "    bias_idx = bias_arr[invalid_left_end:].ravel()  # true_bias 만 plot\n",
    "  else:\n",
    "    bias_idx = ~bias_arr[invalid_left_end:].ravel()  # false_bias 만 plot\n",
    "  \n",
    "  # trendy_idx = bias_tick[invalid_left_end:] < config.tr_set.bias_tick  # temp location\n",
    "\n",
    "  np_plot_params = np_plot_params[bias_idx] #  * trendy_idx]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4CXGqEN1ojY"
   },
   "source": [
    "### Plot indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1666568173244,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "2bjxKCIh1ojZ",
    "outputId": "ee095203-adee-4f09-decc-f7447de637a2"
   },
   "outputs": [],
   "source": [
    "selection_id = config.selection_id\n",
    "\n",
    "# ============ make col_idx_dict config ============ #\n",
    "nonstep_col_list = []\n",
    "step_col_list = []\n",
    "step_col_list2 = []\n",
    "stepmark_col_list = []\n",
    "data_window_p1_col_list = []\n",
    "data_window_p2_col_list = []\n",
    "\n",
    "# ============ nonstep_col_list - add info(col, alpha, color, linewidth) ============ #\n",
    "# nonstep_col_list.append([['close'], 1, '#ffffff', 2])\n",
    "\n",
    "# ============ step_col_list - add info(col, alpha, color, linewidth) ============ #\n",
    "# ------ htf_candle ------ #\n",
    "# hc_tf1 = '5T'\n",
    "hc_tf2 = '30T'\n",
    "hc_tf3 = '4H'\n",
    "\n",
    "# step_col_list.append([['open_{}'.format(hc_tf1), 'close_{}'.format(hc_tf1)], 1, '#ffffff', 1])\n",
    "# step_col_list.append([['open_{}'.format(hc_tf2), 'close_{}'.format(hc_tf2)], 1, '#ffffff', 2])\n",
    "# step_col_list.append([['open_{}'.format(hc_tf3), 'close_{}'.format(hc_tf3)], 1, '#ffffff', 3])\n",
    "\n",
    "# ------ resi_sup ------ #\n",
    "# rs_tf = 'T'\n",
    "# step_col_list.append([['resi_{}'.format(rs_tf), 'sup_{}'.format(rs_tf)], 1, '#ffeb3b', 1])\n",
    "# step_col_list.append([['resi_out_{}'.format(rs_tf), 'sup_out_{}'.format(rs_tf)], 1, 'dodgerblue', 2])\n",
    "\n",
    "# ------ wave_base ------ #\n",
    "wave_itv1 = config.tr_set.wave_itv1\n",
    "wave_itv2 = config.tr_set.wave_itv2\n",
    "wave_period1 = config.tr_set.wave_period1\n",
    "wave_period2 = config.tr_set.wave_period2\n",
    "\n",
    "# step_col_list.append([['dc_base_{}{}'.format(wave_itv1, wave_period1)], 1, '#5b9cf6', 1])\n",
    "# step_col_list.append([['dc_base_{}{}'.format(wave_itv2, wave_period2)], 1, '#5b9cf6', 5])\n",
    "\n",
    "# step_col_list.append([['wave_low_fill_{}{}'.format(wave_tf, wave_period)], 1, '#ffeb3b', 1])\n",
    "# step_col_list.append([['wave_high_fill_{}{}'.format(wave_tf, wave_period)], 1, '#ffeb3b', 1])\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(wave_tf, wave_period), 'dc_lower_{}{}'.format(wave_tf, wave_period)], 1, '#ffeb3b', 1])\n",
    "\n",
    "# ------ dc ------ #\n",
    "dc_tf1 = 'T'\n",
    "dc_period1 = 20 # wave_period2  # 20\n",
    "dc_tf2 = '5T'\n",
    "dc_period2 = 20 # config.loc_set.point2.csd_period if config.loc_set.point2.csd_period != \"None\" else wave_period2 \n",
    "dc_tf3 = '15T'\n",
    "dc_period3 = 20\n",
    "dc_tf3 = 'H'\n",
    "dc_period3 = 20\n",
    "\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(dc_tf1, dc_period1), 'dc_lower_{}{}'.format(dc_tf1, dc_period1)], 1, '#ff00ff', 1]),  # inner #ffeb3b\n",
    "# step_col_list.append([['dc_base_{}{}'.format(dc_tf1, dc_period1)], 1, '#5b9cf6', 1]) # ffee58 5b9cf6 \n",
    "# step_col_list.append([['dc_upper_{}{}'.format(dc_tf2, dc_period2), 'dc_lower_{}{}'.format(dc_tf2, dc_period2)], 1, '#ffee58', 2]),  # inner #ffeb3b\n",
    "# step_col_list.append([['dc_base_{}{}'.format(dc_tf2, dc_period2)], 1, '#5b9cf6', 3]) # ffee58 5b9cf6\n",
    "# step_col_list.append([['dc_base_{}{}'.format(dc_tf3, dc_period3)], 1, '#5b9cf6', 5]) # ffee58 5b9cf6\n",
    "# step_col_list.append([['dc_base_{}{}'.format(dc_tf3, dc_period3)], 1, '#5b9cf6', 7]) # ffee58 5b9cf6\n",
    "\n",
    "# ------ bb ------ #\n",
    "bb_tf1 = 'T'\n",
    "bb_period1 = 200\n",
    "\n",
    "# step_col_list.append([['bb_upper_{}{}'.format(bb_tf1, bb_period1), 'bb_lower_{}{}'.format(bb_tf1, bb_period1)], 1, '#ffffff', 1])\n",
    "# step_col_list.append([['bb_upper2_{}{}'.format(bb_tf1, bb_period1), 'bb_lower2_{}{}'.format(bb_tf1, bb_period1)], 1, '#ffffff', 1])\n",
    "# step_col_list.append([['bb_upper3_{}{}'.format(bb_tf1, bb_period1), 'bb_lower3_{}{}'.format(bb_tf1, bb_period1)], 1, '#ffffff', 1])\n",
    "# step_col_list.append([['bb_base_{}{}'.format(bb_tf1, bb_period1)], 1, '#00ff00', 1])\n",
    "\n",
    "\n",
    "# ------ ma / ema ------ #\n",
    "# step_col_list.append([['ema_5T'], 1, '#03ed30', 2])\n",
    "\n",
    "ma_period1 = 50\n",
    "ma_period2 = 200\n",
    "step_col_list.append([['ma_T{}'.format(ma_period1)], 1, '#ffffff', 1])\n",
    "step_col_list.append([['ma_T{}'.format(ma_period2)], 1, '#ffffff', 2])\n",
    "# step_col_list.append([['long_ma_T{}_-1'.format(ma_period)], 1, '#03ed30', 2])\n",
    "\n",
    "# ============ step_col_list2 - add info(col, alpha, color, linewidth) ============ #\n",
    "# ------ cci ------ #\n",
    "# cci_itv1 = 'T'\n",
    "cci_itv1 = wave_itv1\n",
    "cci_period1 = 20\n",
    "# cci_itv2 = 'T'  # 30T 15T\n",
    "# cci_period2 = 120\n",
    "\n",
    "step_col_list2.append([['cci_{}{}'.format(cci_itv1, cci_period1)], 1, '#00ff00', 1])\n",
    "# step_col_list2.append([['cci_{}{}'.format(cci_itv2, cci_period2)], 1, '#ff0000', 3])\n",
    "\n",
    "# ------ stoch ------ #\n",
    "# step_col_list2.append([['stoch_{}{}33'.format(wave_itv1, wave_period1)], 1, '#00ff00', 3])\n",
    "\n",
    "# ------ macd ------ #\n",
    "# step_col_list2.append([['macd_T535'], 1, '#00ff00', 1])\n",
    "\n",
    "\n",
    "# ============ stepmark_col_list - add info(col, alpha, color, linewidth, marker_style) ============ #\n",
    "# stepmark_col_list.append([['sar_T'], 1, 'dodgerblue', 7])\n",
    "\n",
    "# ------ st_level ------ #\n",
    "st_period1 = '15T'\n",
    "st_period2 = '4H'\n",
    "\n",
    "# stepmark_col_list.append([['st_base_{}'.format(st_period1)], 1, '#ffffff', 2, '*'])\n",
    "# stepmark_col_list.append([['st_upper_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "# stepmark_col_list.append([['st_upper2_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "# stepmark_col_list.append([['st_upper3_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "# stepmark_col_list.append([['st_lower_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "# stepmark_col_list.append([['st_lower2_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "# stepmark_col_list.append([['st_lower3_{}'.format(st_period1)], 1, '#ffffff', 1, '*'])\n",
    "\n",
    "# stepmark_col_list.append([['st_base_{}'.format(st_period2)], 1, '#ffeb3b', 4, '*'])\n",
    "# stepmark_col_list.append([['st_upper_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "# stepmark_col_list.append([['st_upper2_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "# stepmark_col_list.append([['st_upper3_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "# stepmark_col_list.append([['st_lower_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "# stepmark_col_list.append([['st_lower2_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "# stepmark_col_list.append([['st_lower3_{}'.format(st_period2)], 1, '#ffeb3b', 3, '*'])\n",
    "\n",
    "# ------ wave_range ------ #\n",
    "stepmark_col_list.append([['wave_low_fill_{}{}'.format(wave_itv1, wave_period1)], 1, '#e91e63', 10, '*'])\n",
    "stepmark_col_list.append([['wave_high_fill_{}{}'.format(wave_itv1, wave_period1)], 1, '#2962ff', 10, '*'])\n",
    "\n",
    "# stepmark_col_list.append([['wave_low_fill_{}{}'.format(wave_itv2, wave_period2)], 1, '#ff00ff', 7, '*'])\n",
    "# stepmark_col_list.append([['wave_high_fill_{}{}'.format(wave_itv2, wave_period2)], 1, '#00ff00', 7, '*'])\n",
    "  \n",
    "# stepmark_col_list.append([['wave_co_marker_{}{}'.format(wave_itv1, wave_period1)], 1, '#00ff00', 3, 'o'])\n",
    "# stepmark_col_list.append([['wave_cu_marker_{}{}'.format(wave_itv1, wave_period1)], 1, '#ff00ff', 3, 'o'])\n",
    "\n",
    "# ============ data_window_col_list ============ #\n",
    "# ------ wrr ------ #\n",
    "# data_window_col_list.append([['cu_wrr_21_{}{}'.format(wave_itv1, wave_period1)], 'cu_wrr_21_{}{}'.format(wave_itv1, wave_period1)])\n",
    "# data_window_col_list.append([['co_wrr_21_{}{}'.format(wave_itv1, wave_period1)], 'co_wrr_21_{}{}'.format(wave_itv1, wave_period1)])\n",
    "# data_window_p1_col_list.append([['cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)], 'cu_wrr_32_{}{}'.format(wave_itv1, wave_period1)])\n",
    "# data_window_p1_col_list.append([['co_wrr_32_{}{}'.format(wave_itv1, wave_period1)], 'co_wrr_32_{}{}'.format(wave_itv1, wave_period1)])\n",
    "# data_window_p2_col_list.append([['cu_wrr_32_{}{}'.format(wave_itv2, wave_period2)], 'cu_wrr_32_{}{}'.format(wave_itv2, wave_period2)])\n",
    "# data_window_p2_col_list.append([['co_wrr_32_{}{}'.format(wave_itv2, wave_period2)], 'co_wrr_32_{}{}'.format(wave_itv2, wave_period2)])\n",
    "\n",
    "data_window_p1_col_list.append([['short_tr_{}'.format(selection_id)], 'short_tr_{}'.format(selection_id)])\n",
    "data_window_p1_col_list.append([['long_tr_{}'.format(selection_id)], 'long_tr_{}'.format(selection_id)])\n",
    "\n",
    "\n",
    "data_window_p1_col_list.append([['short_spread_{}'.format(selection_id)], 'short_spread_{}'.format(selection_id)])\n",
    "data_window_p1_col_list.append([['long_spread_{}'.format(selection_id)], 'long_spread_{}'.format(selection_id)])\n",
    "\n",
    "\n",
    "# ====== str to numbcol ====== #\n",
    "nonstep_col_arr = strcol_tonumb(res_df, nonstep_col_list)\n",
    "step_col_arr = strcol_tonumb(res_df, step_col_list)\n",
    "step_col_arr2 = strcol_tonumb(res_df, step_col_list2)\n",
    "stepmark_col_arr = strcol_tonumb(res_df, stepmark_col_list)\n",
    "data_window_p1_col_arr = strcol_tonumb(res_df, data_window_p1_col_list)\n",
    "data_window_p2_col_arr = strcol_tonumb(res_df, data_window_p2_col_list)\n",
    "\n",
    "col_idx_dict = \\\n",
    "{\n",
    "  \"ohlc_col_idxs\": get_col_idxs(res_df, ['open', 'high', 'low', 'close']),\n",
    "  \"vp_col_idxs\": get_col_idxs(res_df, ['close', 'volume']),\n",
    "  # \"post_cu_idx\": get_col_idxs(res_df, ['wave_cu_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)]),\n",
    "  # \"post_co_idx\": get_col_idxs(res_df, ['wave_co_post_idx_fill_{}{}'.format(wave_itv1, wave_period1)]),\n",
    "  \"post_cu_idx\": get_col_idxs(res_df, ['wave_cu_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)]), # 위에 거랑 차이를 설명하긴 어려운데, 일단은 prime_idx 사용이 wave_range 내의 volume 을 모두 설명함\n",
    "  \"post_co_idx\": get_col_idxs(res_df, ['wave_co_prime_idx_fill_{}{}'.format(wave_itv1, wave_period1)]),\n",
    "  # \"ohlc_col_idxs\": get_col_idxs(res_df, ['haopen', 'hahigh', 'halow', 'haclose']),  # heikin-ashi ver.\n",
    "  \"nonstep_col_info\": nonstep_col_arr,\n",
    "  \"step_col_info\": step_col_arr,\n",
    "  \"step_col_info2\": step_col_arr2,\n",
    "  \"stepmark_col_info\": stepmark_col_arr,\n",
    "  \"data_window_p1_col_info\": data_window_p1_col_arr,\n",
    "  \"data_window_p2_col_info\": data_window_p2_col_arr,\n",
    "  \"ylim_col_idxs\": get_col_idxs(res_df, ['short_tp_1_{}'.format(selection_id), 'long_tp_1_{}'.format(selection_id), 'short_tp_0_{}'.format(selection_id), 'long_tp_0_{}'.format(selection_id)])  \n",
    "  # \"ylim_col_idxs\": get_col_idxs(res_df, ['high', 'low'])  \n",
    "}   \n",
    "# 'short_tp_1_{}'.format(selection_id), 'long_tp_1_{}'.format(selection_id), 'short_tp_0_{}'.format(selection_id), 'long_tp_0_{}'.format(selection_id)\n",
    "#   'wave_low_fill_{}{}'.format(wave_itv2, wave_period2), 'wave_high_fill_{}{}'.format(wave_itv2, wave_period2)\n",
    "#   'dc_lower_H', 'dc_lower_H', 'dc_upper_15T', 'dc_lower_15T', 'short_out_{}'.format(selection_id), 'long_out_{}'.format(selection_id)\n",
    "#   'wave_1_{}'.format(wave_itv2), 'wave_0_{}'.format(wave_itv2), 'dc_upper_15T', 'dc_lower_15T'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfvH5ngyieS9",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17981,
     "status": "error",
     "timestamp": 1666568193368,
     "user": {
      "displayName": "7th June",
      "userId": "08178289703395036410"
     },
     "user_tz": -540
    },
    "id": "OCLMABZT1ojb",
    "outputId": "494558ba-b164-4030-fc54-eef7c34fd810",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p2_hlm 의 경우, tr 확인을 우해 session_plot 우선 실행 필요함\n",
    "_ = [plot_check_v9(res_df, config, param_zip, pr_msg, x_max, x_margin_mult, y_margin_mult, back_plot, plot_check_dir, **col_idx_dict) for param_zip in zip(np_plot_params, np_plot_params[::-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTW2ZuX61ojg",
    "tags": []
   },
   "source": [
    "### plot method override"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_check_v9(res_df, config, param_zip, pr_msg, x_max, x_margin_mult, y_margin_mult, back_plot, plot_check_dir=None, **col_idx_dict):\n",
    "    # start_0 = time.time()\n",
    "    plt.style.use(['dark_background', 'fast'])\n",
    "    fig = plt.figure(figsize=(30, 18), dpi=60)\n",
    "    nrows, ncols = 2, 2\n",
    "    gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                           ncols=ncols,\n",
    "                           height_ratios=[3, 1]\n",
    "                           )\n",
    "    for gs_idx, params in enumerate(param_zip):\n",
    "\n",
    "        iin, iout, pr, en_p, ex_p, entry_idx, exit_idx, p1_idx, p2_idx, lvrg, fee, tp_line, out_line, tp_1, tp_0, out_1, out_0, ep2_0 = params\n",
    "\n",
    "        # print(\"en_p, ex_p :\", en_p, ex_p)\n",
    "        # print(\"tp_line, out_line, ep2_0 :\", tp_line, out_line, ep2_0)\n",
    "        # print(\"tp_1 :\", tp_1)\n",
    "\n",
    "        # temporary\n",
    "        # if exit_idx - p1_idx < 50:\n",
    "        # if exit_idx != entry_idx:\n",
    "        # print(\"p1_idx :\", p1_idx)\n",
    "        # if p1_idx != 370259:\n",
    "        #   break\n",
    "\n",
    "        # 1. define ax1 & ax2\n",
    "        ax1 = fig.add_subplot(gs[gs_idx])\n",
    "        ax2 = fig.add_subplot(gs[gs_idx + 2])\n",
    "\n",
    "        # 2. data range\n",
    "        #    a. hvline phase 에서 ylime 을 data[:x_max 로 정하기 때문에 iin + x_max 사용한다.\n",
    "        # if back_plot == 0:\n",
    "        #     iout = iin + x_max\n",
    "            # iout = iout + x_max\n",
    "            # print(\"iin, iout :\", iin, iout)\n",
    "\n",
    "        a_data = res_df.iloc[int(iin):int(iout + 1)].to_numpy()\n",
    "        # a_data = data[iin:iout]\n",
    "\n",
    "        # 3. add_col section\n",
    "        #     a. candles\n",
    "        candle_plot_v2(ax1, a_data[:, col_idx_dict['ohlc_col_idxs']], alpha=1.0, wickwidth=1.0)\n",
    "\n",
    "        #     b. add cols\n",
    "        [nonstep_col_plot_v2(ax1, a_data[:, params_[0]], *params_[1:]) for params_ in col_idx_dict['nonstep_col_info']]\n",
    "        [step_col_plot_v2(ax1, a_data[:, params_[0]], *params_[1:]) for params_ in col_idx_dict['step_col_info']]\n",
    "        [stepmark_col_plot_v2(ax1, a_data[:, params_[0]], *params_[1:]) for params_ in col_idx_dict['stepmark_col_info']]\n",
    "\n",
    "        [step_col_plot_v2(ax2, a_data[:, params_[0]], *params_[1:]) for params_ in col_idx_dict['step_col_info2']]\n",
    "\n",
    "        #     c. get vp_info\n",
    "        kde_factor = 0.1  # 커질 수록 전체적인 bars_shape 이 곡선이됨, 커질수록 latency 좋아짐 (0.00003s 정도)\n",
    "        num_samples = 100  # plot 되는 volume bars (y_axis) 와 비례관계\n",
    "\n",
    "        #         i. get vp_infovp by lookback\n",
    "        # vp_lookback = 500\n",
    "        # vp_data = res_df.iloc[int(p1_idx - 500):int(p1_idx), col_idx_dict['vp_col_idxs']].to_numpy().T\n",
    "\n",
    "        #         ii. vp by wave_point\n",
    "        #     if tp_1 < out_0:  # SELL order\n",
    "        #       post_co_idx = res_df.iloc[int(p1_idx), col_idx_dict['post_co_idx']]\n",
    "        #       # vp_iin = res_df.iloc[int(p1_idx) - 1, col_idx_dict['post_cu_idx']].to_numpy()  # Todo, co_idx 와 co_post_idx 의 차별을 위해서 -1 해줌 <-- 중요 point\n",
    "        #       vp_iin = res_df.iloc[post_co_idx, col_idx_dict['post_cu_idx']].to_numpy() # post_co_idx 에 있는 post_cu_idx ?\n",
    "        #     else:\n",
    "        #       post_cu_idx = res_df.iloc[int(p1_idx), col_idx_dict['post_cu_idx']]\n",
    "        #       # vp_iin = res_df.iloc[int(p1_idx) - 1, col_idx_dict['post_co_idx']].to_numpy()\n",
    "        #       vp_iin = res_df.iloc[int(post_cu_idx), col_idx_dict['post_co_idx']].to_numpy()\n",
    "        #       # print(\"post_cu_idx, vp_iin :\", post_cu_idx, vp_iin)\n",
    "\n",
    "        #     vp_data = res_df.iloc[int(vp_iin):int(p1_idx), col_idx_dict['vp_col_idxs']].to_numpy().T   # vp : ~ post_cu / co_idx 까지\n",
    "\n",
    "        #     vp_info = [*vp_data, kde_factor, num_samples]\n",
    "        vp_info = []\n",
    "\n",
    "        #     d. ep, tp + xlim\n",
    "        try:\n",
    "            eptp_hvline_v10(ax1, ax2, config, *params, back_plot, x_max, x_margin_mult, y_margin_mult, a_data, vp_info, **col_idx_dict)\n",
    "        except Exception as e:\n",
    "            print(\"error in eptp_hvline :\", e)\n",
    "\n",
    "        \"\"\" Todo \"\"\"\n",
    "        #     e. outer_price plot 일 경우, gs_idx + nrows 하면 됨\n",
    "\n",
    "        # 4. trade_info\n",
    "        data_msg_list = [\"\\n {} : {:.3f}\".format(*params_[1:], *res_df.iloc[int(p1_idx), params_[0]]) for params_ in\n",
    "                         col_idx_dict['data_window_p1_col_info']]  # * for unsupported format for arr\n",
    "        data_msg_list += [\"\\n {} : {:.3f}\".format(*params_[1:], *res_df.iloc[int(p2_idx), params_[0]]) for params_ in\n",
    "                          col_idx_dict['data_window_p2_col_info']]\n",
    "        ps_msg_expand = pr_msg.format(p1_idx, exit_idx, pr, lvrg, fee) + ''.join(data_msg_list)\n",
    "\n",
    "        ax1.set_title(ps_msg_expand)  # set_title on ax1\n",
    "\n",
    "    if plot_check_dir is None:\n",
    "        plt.show()\n",
    "        print()\n",
    "    else:\n",
    "        fig_name = plot_check_dir + \"/{}.png\".format(int(entry_idx))\n",
    "        plt.savefig(fig_name)\n",
    "        print(fig_name, \"saved !\")\n",
    "    plt.close()\n",
    "    # print(\"elapsed time :\", time.time() - start_0)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eptp_hvline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0l6joTK_1ojh"
   },
   "outputs": [],
   "source": [
    "def eptp_hvline_v10(ax1, ax2, config, iin, iout, pr, en_p, ex_p, entry_idx, exit_idx, p1_idx, p2_idx, lvrg, fee, tp_level, out_level, tp_1, tp_0,\n",
    "                    out_1, out_0, ep2_0, back_plot, x_max, x_margin_mult, y_margin_mult, a_data, vp_info, **col_idx_dict):\n",
    "    \"\"\"\n",
    "    v9_1 -> v10\n",
    "        1. back_plot = 0's x_max 개념 지움. (불필요하다고 봄), post_data_size 로 치환.\n",
    "            a. back_plot 으로 back_plot_data 의 시작점이 정해진다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. get vertical ticks\n",
    "    entry_tick = int(entry_idx - iin)\n",
    "    exit_tick = entry_tick + int(exit_idx - entry_idx)\n",
    "    p1_tick = entry_tick - int(entry_idx - p1_idx)\n",
    "    p2_tick = p1_tick + int(p2_idx - p1_idx)\n",
    "\n",
    "    if back_plot == 1:\n",
    "        x_max = p1_tick + x_max\n",
    "    elif back_plot == 2:\n",
    "        x_max = p2_tick + x_max\n",
    "    elif back_plot == 3:\n",
    "        x_max = entry_tick + x_max\n",
    "    elif back_plot == 4:\n",
    "        x_max = exit_tick + x_max\n",
    "\n",
    "    # 2. get_xlim\n",
    "    #    a. iout - iin : 보여지는 data_size, 즉 plot_size 가 data_size 보다 작아지면 (짤리면).\n",
    "    if (iout - iin) > x_max:\n",
    "        x_margin = x_max * x_margin_mult\n",
    "        ax1.set_xlim(0 - x_margin, x_max + x_margin)\n",
    "        ax2.set_xlim(0 - x_margin, x_max + x_margin)\n",
    "    x0, x1 = ax1.get_xlim()\n",
    "\n",
    "    \"\"\" 1. Axis_1 \"\"\"\n",
    "    #     a. entry & exit\n",
    "    en_xmin = entry_tick / x1\n",
    "    ex_xmin = exit_tick / x1\n",
    "    ax1.text(x0, en_p, 'en_p :\\n {:.3f}'.format(en_p), ha='right', va='center', fontweight='bold', fontsize=15)  # en_p line label\n",
    "\n",
    "    ax1.axhline(ex_p, ex_xmin, 1, linewidth=2, linestyle='--', alpha=1, color='lime')  # ex_p line axhline (signal 도 포괄함, 존재 의미)\n",
    "    ax1.text(x1, ex_p, 'ex_p :\\n {}'.format(ex_p), ha='left', va='center', fontweight='bold', fontsize=15)  # ex_p line label\n",
    "\n",
    "    #     b. tr_set line\n",
    "    left_point = 0.1\n",
    "    right_point = 1\n",
    "    text_x_pos_left = (x0 + x1) * (left_point + 0.05)\n",
    "\n",
    "    ax1.axhline(en_p, left_point, right_point, linewidth=2, linestyle='-', alpha=1, color='#005eff')  # en_p line axhline\n",
    "\n",
    "    if config.tr_set.check_hlm in [0, 1]:\n",
    "        plot_epg_tuple = (\"epg1\", config.tr_set.ep1_gap)\n",
    "    else:\n",
    "        plot_epg_tuple = (\"epg2\", config.tr_set.ep2_gap)\n",
    "    ax1.text(text_x_pos_left, en_p, '{} {}'.format(*plot_epg_tuple), ha='right', va='bottom', fontweight='bold', fontsize=15, color='#005eff')\n",
    "\n",
    "    ax1.axhline(tp_level, left_point, right_point, linewidth=2, linestyle='-', alpha=1, color='#00ff00')  # ep 와 gap 비교 용이하기 위해 ex_xmin -> 0.1 사용\n",
    "    ax1.text(text_x_pos_left, tp_level, 'tpg {}'.format(config.tr_set.tp_gap), ha='right', va='bottom', fontweight='bold', fontsize=15, color='#00ff00')\n",
    "\n",
    "    ax1.axhline(out_level, left_point, right_point, linewidth=2, linestyle='-', alpha=1, color='#ff0000')\n",
    "    ax1.text(text_x_pos_left, out_level, 'outg {}'.format(config.tr_set.out_gap), ha='right', va='bottom', fontweight='bold', fontsize=15, color='#ff0000')\n",
    "\n",
    "    #     c. tp_box\n",
    "    left_point = 0.3\n",
    "    right_point = 1\n",
    "    text_x_pos_left = (x0 + x1) * (left_point + 0.05)\n",
    "    text_x_pos_right = (x0 + x1) * right_point\n",
    "\n",
    "    ax1.axhline(tp_1, left_point, right_point, linewidth=1, linestyle='-', alpha=1, color='#ffffff')\n",
    "    ax1.text(text_x_pos_left, tp_1, ' tp_1', ha='right', va='bottom', fontweight='bold', fontsize=15)\n",
    "    ax1.axhline(tp_0, left_point, right_point, linewidth=1, linestyle='-', alpha=1, color='#ffffff')\n",
    "    ax1.text(text_x_pos_left, tp_0, ' tp_0', ha='right', va='bottom', fontweight='bold', fontsize=15)\n",
    "\n",
    "    #     d. octa_wave_box\n",
    "    wave_gap = (tp_1 - tp_0) / 8\n",
    "    [ax1.axhline(tp_0 + wave_gap * gap_i, left_point, right_point, linewidth=1, linestyle='--', alpha=1, color='#ffffff') for gap_i in range(1, 8)]\n",
    "\n",
    "    #     e. ep_box\n",
    "    ax1.axhline(ep2_0, left_point, right_point, linewidth=1, linestyle='-', alpha=1, color='#ffffff')\n",
    "    ax1.text(text_x_pos_left, ep2_0, ' ep2_0', ha='right', va='bottom', fontweight='bold', fontsize=15)\n",
    "\n",
    "    #     f. out_box\n",
    "    ax1.axhline(out_1, left_point, right_point, linewidth=1, linestyle='-', alpha=1, color='#ffffff')\n",
    "    ax1.text(text_x_pos_right, out_1, ' out_1', ha='right', va='bottom', fontweight='bold', fontsize=15)\n",
    "    ax1.axhline(out_0, left_point, right_point, linewidth=1, linestyle='-', alpha=1, color='#ffffff')\n",
    "    ax1.text(text_x_pos_right, out_0, ' out_0', ha='right', va='bottom', fontweight='bold', fontsize=15)\n",
    "\n",
    "    #     g. volume profile\n",
    "    if len(vp_info) > 0:\n",
    "        close, volume, kde_factor, num_samples = vp_info\n",
    "        # if iin >= vp_range:\n",
    "        # start_0 = time.time()\n",
    "        kde = stats.gaussian_kde(close, weights=volume, bw_method=kde_factor)\n",
    "        kdx = np.linspace(close.min(), close.max(), num_samples)\n",
    "        kdy = kde(kdx)\n",
    "        kdy_max = kdy.max()\n",
    "        # print(\"kde elapsed_time :\", time.time() - start_0)\n",
    "\n",
    "        # peaks,_ = signal.find_peaks(kdy, prominence=kdy_max * 0.3)   # get peak_entries\n",
    "        # peak_list = kdx[peaks]   # peak_list\n",
    "        # [ax1.axhline(peak, linewidth=1, linestyle='-', alpha=1, color='orange') for peak in peak_list]\n",
    "\n",
    "        kdy_ratio = p1_tick / kdy_max  # 30 / 0.0001   # max_value 가 p1_tick 까지 닿을 수 있게.\n",
    "        # print(\"kdx :\", kdx)\n",
    "        # ax1.plot(kdy * kdy_ratio, kdx, color='white')  # Todo, bars 가능 ?\n",
    "        # ax1.barh(kdy * kdy_ratio, kdx, color='white')  # Todo, bars 가능 ?\n",
    "        ax1.barh(kdx, kdy * kdy_ratio, color='#00ff00', alpha=0.5)  # Todo, bars 가능 ?\n",
    "\n",
    "    #     c. ylim - ax1 only\n",
    "    #         i. ylim by tr_set\n",
    "    y_min = min(tp_level, out_level, tp_1, tp_0, out_1, out_1)\n",
    "    y_max = max(tp_level, out_level, tp_1, tp_0, out_1, out_1)\n",
    "\n",
    "    #         ii. ylim by indicator\n",
    "    if len(col_idx_dict['ylim_col_idxs']) != 0:\n",
    "        y_lim_data = a_data[:x_max + 1, col_idx_dict['ylim_col_idxs']]  # +1 for including p1_tick\n",
    "        # if back_plot:\n",
    "        #     y_lim_data = a_data[:x_max + 1, col_idx_dict['ylim_col_idxs']]  # +1 for including p1_tick\n",
    "        # else:\n",
    "        #     y_lim_data = a_data[:, col_idx_dict['ylim_col_idxs']]\n",
    "\n",
    "        y_min = min(y_lim_data.min(), y_min)\n",
    "        y_max = max(y_lim_data.max(), y_max)\n",
    "\n",
    "    y_margin = (y_max - y_min) * y_margin_mult\n",
    "    ax1.set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "    \"\"\" 2. Axis_2 \"\"\"\n",
    "    #     y. fisher_band\n",
    "    # fisher_band = config.out_set.fisher_band\n",
    "    # ax2.axhline(fisher_band, color=\"#ffffff\")\n",
    "    # ax2.axhline(0, color=\"#ffffff\")\n",
    "    # ax2.axhline(-fisher_band, color=\"#ffffff\")\n",
    "    \n",
    "    #     x. realtime_ud\n",
    "    # ax2.axhline(0, color=\"#ffffff\")\n",
    "\n",
    "    #     a. cci_band\n",
    "    ax2.axhline(100, color=\"#ffffff\")\n",
    "    ax2.axhline(0, color=\"#ffffff\")\n",
    "    ax2.axhline(-100, color=\"#ffffff\")\n",
    "\n",
    "    #     b. stoch_band\n",
    "    # ax2.axhline(67, color=\"#ffffff\")\n",
    "    # ax2.axhline(33, color=\"#ffffff\")\n",
    "    # ax2.axhline(0, color=\"#ffffff\")\n",
    "\n",
    "    # 3. public vline (p1_tick, entry_tick, exit_tick - add p1_tick on ax2\n",
    "    y0, y1 = ax1.get_ylim()\n",
    "    low_data = a_data[:exit_tick + 1, col_idx_dict['ohlc_col_idxs'][2]]  # +1 for including exit_tick\n",
    "    p2_ymax, en_ymax, ex_ymax = [(low_data[tick_] - y0) / (y1 - y0) - .01 for tick_ in [p2_tick, entry_tick, exit_tick]]  # -.05 for margin\n",
    "    if p1_tick > 0:\n",
    "        p1_ymax = (low_data[p1_tick] - y0) / (y1 - y0) - .01\n",
    "        ax1.axvline(p1_tick, 0, p1_ymax, alpha=1, linewidth=2, linestyle='--', color='#ff0000')  # 추후, tick 별 세부 정의가 달라질 수 있음을 고려해 multi_line 작성 유지\n",
    "        ax2.axvline(p1_tick, 0, 1, alpha=1, linewidth=2, linestyle='--', color='#ff0000')\n",
    "    ax1.axvline(p2_tick, 0, p2_ymax, alpha=1, linewidth=2, linestyle='--', color='#2196f3')\n",
    "    ax1.axvline(entry_tick, 0, en_ymax, alpha=1, linewidth=2, linestyle='--', color='#ffeb3b')\n",
    "    ax1.axvline(exit_tick, 0, ex_ymax, alpha=1, linewidth=2, linestyle='--', color='#ffeb3b')\n",
    "    ax2.axvline(p2_tick, 0, 1, alpha=1, linewidth=2, linestyle='--', color='#2196f3')\n",
    "    ax2.axvline(entry_tick, 0, 1, alpha=1, linewidth=2, linestyle='--', color='#ffeb3b')\n",
    "    ax2.axvline(exit_tick, 0, 1, alpha=1, linewidth=2, linestyle='--', color='#ffeb3b')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole plot indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjFziVVIhgSr"
   },
   "outputs": [],
   "source": [
    "s_id = config.selection_id\n",
    "\n",
    "# ------------ make col_idx_dict config ------------ #\n",
    "nonstep_col_list = []\n",
    "step_col_list = []\n",
    "stepmark_col_list = []\n",
    "\n",
    "# ============ nonstep_col_list - add info(col, alpha, color, linewidth) ============ #\n",
    "# nonstep_col_list.append([['close'], 1, '#ffffff', 2])\n",
    "\n",
    "# ============ step_col_list - add info(col, alpha, color, linewidth) ============ #\n",
    "# ------ htf_candle ------ #\n",
    "hc_tf1 = '15T'\n",
    "hc_tf2 = 'H'\n",
    "hc_tf3 = '4H'\n",
    "\n",
    "step_col_list.append([['open_{}'.format(hc_tf1), 'close_{}'.format(hc_tf1)], 1, '#ffffff', 1])\n",
    "step_col_list.append([['open_{}'.format(hc_tf2), 'close_{}'.format(hc_tf2)], 1, '#ffffff', 2])\n",
    "# step_col_list.append([['open_{}'.format(hc_tf3), 'close_{}'.format(hc_tf3)], 1, '#ffffff', 4])\n",
    "\n",
    "# ------ resi_sup ------ #\n",
    "# rs_tf = 'T'\n",
    "# step_col_list.append([['resi_{}'.format(rs_tf), 'sup_{}'.format(rs_tf)], 1, '#ffeb3b', 1])\n",
    "# step_col_list.append([['resi_out_{}'.format(rs_tf), 'sup_out_{}'.format(rs_tf)], 1, 'dodgerblue', 2])\n",
    "\n",
    "# ------ wave_range ------ #\n",
    "wave_tf1 = config_list[0].tr_set.p1_itv1\n",
    "wave_period1, wave_period2 = config_list[0].tr_set.p1_period1, config_list[0].tr_set.p1_period2\n",
    "\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(wave_tf1, wave_period1), 'dc_lower_{}{}'.format(wave_tf1, wave_period1)], 1, '#ffeb3b', 1])\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(wave_tf1, wave_period2), 'dc_lower_{}{}'.format(wave_tf1, wave_period2)], 1, '#ffeb3b', 1])\n",
    "\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(wave_tf2, wave_period2), 'dc_lower_{}{}'.format(wave_tf2, wave_period2)], 1, '#e65100', 2])\n",
    "\n",
    "# ------ dc ------ #\n",
    "dc_tf1 = '5T'\n",
    "dc_period1 = 20\n",
    "dc_tf2 = 'H'\n",
    "dc_period2 = 20\n",
    "# step_col_list.append([['dc_upper_{}{}'.format(dc_tf1, dc_period1), 'dc_lower_{}{}'.format(dc_tf1, dc_period1)], 1, '#ffeb3b', 1]),  # inner\n",
    "# step_col_list.append([['dc_base_{}{}'.format(dc_tf1, dc_period1)], 1, '#5b9cf6', 1])\n",
    "step_col_list.append([['dc_upper_{}{}'.format(dc_tf2, dc_period2), 'dc_lower_{}{}'.format(dc_tf2, dc_period2)], 1, '#ff00ff', 4]),  # inner\n",
    "step_col_list.append([['dc_base_{}{}'.format(dc_tf2, dc_period2)], 1, '#5b9cf6', 4])\n",
    "\n",
    "# ------ bb ------ #\n",
    "bb_tf1 = 'T'\n",
    "bb_period1 = 20\n",
    "\n",
    "# step_col_list.append([['bb_upper_{}{}'.format(bb_tf1, bb_period1), 'bb_lower_{}{}'.format(bb_tf1, bb_period1)], 1, '#ffffff', 1])\n",
    "# step_col_list.append([['bb_base_{}{}'.format(bb_tf1, bb_period1)], 1, '#00ff00', 1])\n",
    "\n",
    "# step_col_list.append([['bb_upper_{}'.format(tf2), 'bb_lower_{}'.format(tf2)], 1, '#e91e63', 4])\n",
    "\n",
    "# ------ ema ------ #\n",
    "# step_col_list.append([['ema_5T'], 1, '#03ed30', 2])\n",
    "\n",
    "# ============ stepmark_col_list - add info(col, alpha, color, linewidth) ============ #\n",
    "# stepmark_col_list.append([['sar_T'], 1, 'dodgerblue', 7])\n",
    "\n",
    "\n",
    "# ============ str to numbcol ============ #\n",
    "nonstep_col_arr = strcol_tonumb(res_df, nonstep_col_list)\n",
    "step_col_arr = strcol_tonumb(res_df, step_col_list)\n",
    "stepmark_col_arr = strcol_tonumb(res_df, stepmark_col_list)\n",
    "\n",
    "col_idx_dict = \\\n",
    "{\n",
    "  \"ohlc_col_idxs\": get_col_idxs(res_df, ['open', 'high', 'low', 'close']),\n",
    "  \"vp_col_idxs\": get_col_idxs(res_df, ['close', 'volume']),\n",
    "  # \"ohlc_col_idxs\": get_col_idxs(res_df, ['haopen', 'hahigh', 'halow', 'haclose']),  # heikin-ashi ver.\n",
    "  \"nonstep_col_info\": nonstep_col_arr,\n",
    "  \"step_col_info\": step_col_arr,\n",
    "  \"stepmark_col_info\": stepmark_col_arr,\n",
    "  \"ylim_col_idxs\": get_col_idxs(res_df, ['open', 'high', 'low', 'close', 'dc_upper_15T4', 'dc_lower_15T4'])  # , 'dc_upper_H', 'dc_lower_H', 'dc_upper_15T', 'dc_lower_15T', 'short_out_{}'.format(selection_id), 'long_out_{}'.format(selection_id)\n",
    "}   # , 'wave_1_{}'.format(wave_tf2), 'wave_0_{}'.format(wave_tf2), 'dc_upper_15T', 'dc_lower_15T'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50HXDIdJij28",
    "tags": []
   },
   "source": [
    "#### whole_plot main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tbLsXN9eN2p"
   },
   "outputs": [],
   "source": [
    "plot_op_idx_nums = 10\n",
    "\n",
    "win_idxs = (pr_ > 1).ravel()  # [-plot_op_idx_nums:]\n",
    "selected_op_idxs = obj_[4].ravel().astype(int)  # [-plot_op_idx_nums:]\n",
    "selected_ex_idxs = obj_[3].ravel().astype(int)  # [-plot_op_idx_nums:]\n",
    "\n",
    "len_idxs = len(win_idxs)\n",
    "print(\"len_idxs :\", len_idxs)\n",
    "\n",
    "split_range = np.arange(plot_op_idx_nums, len_idxs, plot_op_idx_nums)\n",
    "win_idxs_list = np.split(win_idxs, split_range, axis=0)\n",
    "selected_op_idxs_list = np.split(selected_op_idxs, split_range, axis=0)\n",
    "selected_ex_idxs_list = np.split(selected_ex_idxs, split_range, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtILHO-4kVlO"
   },
   "outputs": [],
   "source": [
    "_ = [whole_plot_check(np_df, a, b, c, plot_check_dir=None, **col_idx_dict) for a, b, c in zip(win_idxs_list, selected_op_idxs_list, selected_ex_idxs_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZAYhcdoXnm4",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole_plot_check override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_plot_check(data, win_idxs, selected_op_idxs, selected_ex_idxs, plot_check_dir=None, **col_idx_dict):\n",
    "  # start_0 = time.time()\n",
    "  plt.style.use(['dark_background', 'fast'])\n",
    "  fig = plt.figure(figsize=(30, 12), dpi=60)\n",
    "  nrows, ncols = 1, 1\n",
    "  gs = gridspec.GridSpec(nrows=nrows,  # row 부터 index 채우고 col 채우는 순서임 (gs_idx)\n",
    "                          ncols=ncols,\n",
    "                          #height_ratios=[31, 1]\n",
    "                          )\n",
    "\n",
    "  ax = fig.add_subplot(gs[0])\n",
    "\n",
    "  # ------------ add_col section ------------ #\n",
    "  a_data = data[selected_op_idxs[0]:selected_op_idxs[-1] + 1]\n",
    "\n",
    "  plot_op_idxs = selected_op_idxs - selected_op_idxs[0]  \n",
    "  plot_win_op_idxs = plot_op_idxs[win_idxs]\n",
    "  plot_loss_op_idxs = plot_op_idxs[~win_idxs]\n",
    "\n",
    "  plot_ex_idxs = selected_ex_idxs - selected_op_idxs[0]\n",
    "  plot_win_ex_idxs = plot_ex_idxs[win_idxs]\n",
    "  plot_loss_ex_idxs = plot_ex_idxs[~win_idxs]\n",
    "\n",
    "\n",
    "  # ------ add cols ------ #\n",
    "  [nonstep_col_plot(a_data[:, params[0]], *params[1:]) for params in col_idx_dict['nonstep_col_info']]\n",
    "  [step_col_plot(a_data[:, params[0]], *params[1:]) for params in col_idx_dict['step_col_info']]\n",
    "  [stepmark_col_plot(a_data[:, params[0]], *params[1:]) for params in col_idx_dict['stepmark_col_info']]\n",
    "\n",
    "  # [plt.axvline(op_idx, color='#00ff00') for op_idx in plot_win_op_idxs]\n",
    "  # [plt.axvline(op_idx, color='#ff0000') for op_idx in plot_loss_op_idxs]\n",
    "  [plt.axvspan(op_idx, ex_idx, alpha=0.5, color='#00ff00') for op_idx, ex_idx in zip(plot_win_op_idxs, plot_win_ex_idxs)]\n",
    "  [plt.axvspan(op_idx, ex_idx, alpha=0.5, color='#ff0000') for op_idx, ex_idx in zip(plot_loss_op_idxs, plot_loss_ex_idxs)]\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "  if plot_check_dir is None:\n",
    "    plt.show()\n",
    "    print()\n",
    "  else:\n",
    "    fig_name = plot_check_dir + \"/whole_plot_{}.png\".format(selected_op_idxs[0])\n",
    "    plt.savefig(fig_name)\n",
    "    print(fig_name, \"saved !\")\n",
    "  plt.close()\n",
    "  # print(\"elapsed time :\", time.time() - start_0)\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8soVNGFt1ojj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddL_BC24buq0",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### olds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgTrEWWqbwsT",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole_plot thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4zn8wxibzAR"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Candlestick(x=t_df.index,\n",
    "                open=t_df.open,\n",
    "                high=t_df.high,\n",
    "                low=t_df.low,\n",
    "                close=t_df.close)])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IhBjPMobzAS"
   },
   "outputs": [],
   "source": [
    "cf.go_offline()\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9WZkE9wbzAS"
   },
   "outputs": [],
   "source": [
    "qf = cf.QuantFig(t_df, title=\"Apple's stock price in 2021\", name='AAPL')\n",
    "qf.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmYbP-Gc1ojs",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### brief np_pr survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82a8Km8z1ojs"
   },
   "outputs": [],
   "source": [
    "# plot_pr_list[:100]\n",
    "plt.plot(np_pr)\n",
    "plt.axhline(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rdQZm_71ojv",
    "tags": []
   },
   "source": [
    "#### plot indi. legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJqkmkpsLCYC",
    "tags": []
   },
   "source": [
    "#### tr_tresh calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u11r-dU91ojw"
   },
   "outputs": [],
   "source": [
    "\n",
    "  # ---------------------- ma ---------------------- #\n",
    "   # --------- ema --------- #\n",
    "  # alpha = 1\n",
    "  # for sm_i, item in enumerate(ema_list):\n",
    "  #   if sm_i > 0:\n",
    "  #     lw = 5\n",
    "  #   else:\n",
    "  #     lw = 2\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#03ed30', linewidth=lw)\n",
    "  #   alpha -= 0.2\n",
    "\n",
    "  #   # --------- sma --------- #\n",
    "  # alpha = 1\n",
    "  # for sm_i, sma in enumerate(sma_list):\n",
    "  #   if sm_i > 0:\n",
    "  #     lw = 5\n",
    "  #   else:\n",
    "  #     lw = 4\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='#e91e63', linewidth=lw)\n",
    "  #   alpha -= 0.2\n",
    "\n",
    "  \n",
    "  # ---------------------- cb ---------------------- #\n",
    "  # alpha = 1\n",
    "  # for sm_i, item in enumerate(cb_list):\n",
    "  #   if sm_i > 0:\n",
    "  #     lw = 5\n",
    "  #   else:\n",
    "  #     lw = 2\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#5b9cf6', linewidth=lw)\n",
    "  #   alpha -= 0.2\n",
    "\n",
    "\n",
    "  \n",
    "  # ---------------------- sar ---------------------- #\n",
    "  # alpha = 1\n",
    "  # markersize = 5\n",
    "  # for sar in sar_list:\n",
    "  #   plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n",
    "  #   markersize += 1\n",
    "  #   alpha -= 0.1\n",
    "\n",
    "  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n",
    "\n",
    "  #               cloud               #\n",
    "  # alpha = 0.7\n",
    "  # for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n",
    "  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n",
    "  #                     where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n",
    "  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n",
    "  #                     where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n",
    "  #   alpha -= 0.05\n",
    "  \n",
    "\n",
    "\n",
    "  # ---------------------- outer price indi. ---------------------- #\n",
    "  #           macd          #\n",
    "  # plt.subplot(312)\n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for macd in macd_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "\n",
    "  # plt.axhline(0, linestyle='--')\n",
    "\n",
    "  \n",
    "  # #           trix          #  \n",
    "  # # plt.subplot(313)\n",
    "  # plt.subplot(gs[2])\n",
    "  # alpha = 1\n",
    "  # for trix in trix_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "  # plt.axhline(0, linestyle='--')\n",
    "\n",
    "  \n",
    "  #           fisher          #  \n",
    "  # plt.subplot(313)\n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for fisher in fisher_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "    \n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "\n",
    "  # plt.axhline(0, linestyle='--')\n",
    "  # plt.axhline(fisher_upper, linestyle='--')\n",
    "  # plt.axhline(fisher_lower, linestyle='--')\n",
    "\n",
    "  #           stoch          #  \n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for stoch_ in stoch_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[stoch_].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axhline(50, linestyle='--')\n",
    "  # plt.axhline(stoch_upper, linestyle='--')\n",
    "  # plt.axhline(stoch_lower, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "\n",
    "  # ---------- cctbbo ---------- #  \n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for cctbbo in cctbbo_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axhline(50, linestyle='--')\n",
    "  # plt.axhline(cctbbo_upper, linestyle='--')\n",
    "  # plt.axhline(cctbbo_lower, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "\n",
    "  # ---------- ema_roc ---------- #  \n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for emaroc in emaroc_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "  # plt.axhline(0, linestyle='--')\n",
    "  \n",
    "  # ---------- bbw ---------- #  \n",
    "  # plt.subplot(gs[1])\n",
    "  # alpha = 1\n",
    "  # for bbwp_ in bbwp_list:\n",
    "  #   plt.step(np.arange(len(plot_df)), plot_df[bbwp_].values, 'g', alpha=alpha)\n",
    "  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n",
    "  #   alpha -= 0.2\n",
    "  # plt.axvline(prev_plotsize, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "  # plt.axhline(bbwp_thresh, linestyle='--')\n",
    "\n",
    "  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcpo4MGd9Wm4"
   },
   "outputs": [],
   "source": [
    "res_wr = 0.6\n",
    "# tr_thresh = 1\n",
    "# tr_thresh = ((1 - res_wr) / res_wr) ** 0.5\n",
    "tr_thresh = ((1 - res_wr) / res_wr) + 0.01\n",
    "# tr_thresh = 2.6\n",
    "print(\"res_wr :\", res_wr)\n",
    "print(\"tr_thresh :\", tr_thresh)\n",
    "\n",
    "\n",
    "#   단리    #\n",
    "trade_num = 1000\n",
    "asset = 1 # thousand USDT\n",
    "test_loss_gap = 0.95  # fee adjusted\n",
    "test_pr_gap = 1 + (1 - test_loss_gap) * tr_thresh\n",
    "\n",
    "test_loss_cnt = trade_num * (1 - res_wr)\n",
    "test_pr_cnt = trade_num * res_wr\n",
    "\n",
    "test_trade_list = [test_pr_gap] * int(test_pr_cnt) + [test_loss_gap] * int(test_loss_cnt)\n",
    "random.shuffle(test_trade_list)\n",
    "# print(\"len(test_trade_list) :\", len(test_trade_list))\n",
    "print(test_trade_list[:10])\n",
    "print()\n",
    "\n",
    "# print(\"%.5f\" % np.cumprod(test_trade_list)[-1])\n",
    "for tr_thresh_ in np.arange(1, 3, 0.2):\n",
    "  if (1 + (1 - test_loss_gap) * tr_thresh_) ** test_pr_cnt * test_loss_gap ** test_loss_cnt > 1:\n",
    "    break\n",
    "print(\"복리를 위한 tr_thresh_ :\", tr_thresh_)\n",
    "# print(\"tr_thresh :\", tr_thresh)\n",
    "print(\"np.cumprod(test_trade_list)[-1] :\", np.cumprod(test_trade_list)[-1])\n",
    "print(\"total_pr : \", np.cumprod(test_trade_list)[-1])\n",
    "print()\n",
    "#   복리 tr_thresh  #\n",
    "#   1. trade_num 에 영향 받지 않음\n",
    "#   2. loss_gap 에 비례함\n",
    "\n",
    "for tr_thresh_ in np.arange(1, 3, 0.01):\n",
    "  if ((1 - test_loss_gap) * tr_thresh_) * test_pr_cnt + (test_loss_gap - 1) * test_loss_cnt > 0:\n",
    "    break\n",
    "np_test_trade = np.array(test_trade_list) - 1\n",
    "print(np_test_trade[:10])\n",
    "# print(\"%.3f\" % )\n",
    "print(\"단리를 위한 tr_thresh_ :\", tr_thresh_)\n",
    "# print(\"tr_thresh :\", tr_thresh)\n",
    "print(\"np.cumsum(np_test_trade)[-1] :\", np.cumsum(np_test_trade)[-1])\n",
    "print(\"total_pr : \", 1 + np.cumsum(np_test_trade)[-1])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNNrEbb2LToSahBuESvKral",
   "collapsed_sections": [
    "Ic1mfmwWCIBu",
    "E0n53hflJbnp",
    "MlFkpO1MSuzl",
    "x2yj2SwAXDLp",
    "14chOHeXh6JD",
    "Q_1wJTcRYpm8",
    "EOXQbXixiQcK",
    "RZJ6uIA_VcJs",
    "xpyP5t8Ht_pE",
    "MuD_2vY7TI_8",
    "tOFkzUX2imQu",
    "983aUwM76s6X",
    "_blyFhQJUd5X",
    "50HXDIdJij28"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
