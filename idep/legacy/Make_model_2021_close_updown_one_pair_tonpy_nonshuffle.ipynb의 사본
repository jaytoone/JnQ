{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tensorflow2_p36]","language":"python","name":"conda-env-tensorflow2_p36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Make_model_2021_close_updown_one_pair_tonpy_nonshuffle.ipynb의 사본","provenance":[{"file_id":"1z4z_KLPzc6RWsxo3X_dHbpByxUAgjoMJ","timestamp":1583754134002}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AK9FjWwLOyay","executionInfo":{"status":"ok","timestamp":1619098267408,"user_tz":-540,"elapsed":18836,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"352c9f75-22d2-4918-d165-93dbf81b20b6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, sys\n","\n","current_path = '/content/drive/My Drive/Colab Notebooks/Project_Stock/'\n","\n","os.chdir(current_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8uqYv5StTazo"},"source":["### **Requirements**"]},{"cell_type":"code","metadata":{"id":"9qGt60DKTZmf"},"source":["# !pip install statsmodels==0.12.2\n","\n","# import statsmodels\n","# statsmodels.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7bVjhlwPI_-"},"source":["### **ARIMA**"]},{"cell_type":"code","metadata":{"id":"NvdpArctN_6l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619098271558,"user_tz":-540,"elapsed":4300,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"1d9433c9-a2b1-4f3e-9108-f89a02dbada7"},"source":["from statsmodels.tsa.arima_model import ARIMA\n","# from statsmodels.tsa.arima.model import ARIMA\n","\n","from datetime import datetime\n","\n","\n","def arima_test(target, use_rows=None):\n","\n","  size = int(len(target) * 0.66)\n","  train, test = target[:size].values, target[size:]\n","  test_shift = test.shift(1).values\n","  test = test.values\n","  # break\n","\n","  history = list(train)\n","  predictions = list()\n","  err_ranges = list()\n","  for t in range(len(test)):\n","    \n","      if use_rows is not None:\n","        history = history[-use_rows:]\n","        \n","      model = ARIMA(history, order=(0, 2, 4))\n","      model_fit = model.fit()\n","      output = model_fit.forecast()\n","      # print(output)\n","      # break\n","\n","      predictions.append(output[0])\n","      err_ranges.append(output[1])\n","      obs = test[t]\n","      # print('obs :', obs)\n","      history.append(obs)\n","      # break\n","      print('\\r %.2f%%' % (t / len(test) * 100), end='')\n","\n","  print(len(test), len(predictions))\n","\n","  return predictions, err_ranges\n","\n","\n","# print(high)\n","\n","\n","def get_back_result(ohlcv, predictions, err_ranges, tp=0.04, sl=None, leverage=1, show_detail=False, show_plot=False, return_pr=False, cumsum=False, \n","                    close_ver=False, reverse_short=False):\n","\n","  \n","  high, low, test = np.split(ohlcv.values[-len(predictions):, [1, 2, 3]], 3, axis=1)\n","\n","  if close_ver:\n","    predictions = ohlcv['close'].shift(1).values[-len(test):]\n","\n","  fee = 0.0006\n","  long_profits = []\n","  short_profits = []\n","  liquidations = []\n","  win_cnt = 0\n","  for i in range(len(test)):\n","\n","    long_ep = predictions[i]\n","    if sl is not None:\n","      long_sl = long_ep * (1 / (sl + 1))\n","\n","    # assert long_ep < long_exit, 'long_exit < long_ep !, %s, %s' % (long_exit, long_ep)\n","    \n","    short_ep = (predictions[i] + err_ranges[i]) * (1 + tp)\n","    # short_ep = (predictions[i] + err_ranges[i]) * (1 / (1 - tp))\n","    if sl is not None:\n","      short_sl = short_ep * (1 / (1 - sl))\n","\n","    # print((low[i]))\n","\n","    #    long 우선   # <-- long & short 둘다 체결된 상황에서는 long 체결을 우선으로 한다.\n","    if low[i] < long_ep:\n","      \n","      liquidation = low[i] / long_ep - fee\n","      l_liquidation = 1 + (liquidation - 1) * leverage\n","      liquidations.append(l_liquidation)\n","\n","      if max(l_liquidation, 0) == 0:\n","        l_profit = 0\n","        # print('low[i], long_ep, l_liquidation :', low[i], long_ep, l_liquidation)\n","      else:\n","\n","        if sl is not None:\n","          if low[i] < long_sl:\n","            profit = long_sl / long_ep - fee\n","          else:\n","            profit = test[i] / long_ep - fee\n","\n","        else:\n","          profit = test[i] / long_ep - fee\n","\n","        l_profit = 1 + (profit - 1) * leverage\n","        l_profit = max(l_profit, 0)\n","        \n","        if profit >= 1:\n","          win_cnt += 1\n","\n","      long_profits.append(l_profit)\n","      short_profits.append(1.0)\n","\n","      if show_detail:\n","        print(test[i], predictions[i], long_ep)\n","\n","    # if high[i] > short_ep > low[i]: # 지정 대기가 아니라, 해당 price 가 지나면, long 한다.\n","\n","    #   if not reverse_short:\n","    #     liquidation = short_ep / high[i]  - fee\n","    #   else:\n","    #     liquidation = low[i] / short_ep  - fee\n","    #   l_liquidation = 1 + (liquidation - 1) * leverage\n","\n","    #   if max(l_liquidation, 0) == 0:\n","    #     l_profit = 0\n","    #   else:\n","\n","    #     if sl is not None:\n","    #       if high[i] > short_sl:\n","\n","    #         if not reverse_short:\n","    #           profit = short_ep / short_sl - fee\n","    #         else:\n","    #           profit = short_sl / short_ep - fee\n","\n","    #       else:\n","    #         if not reverse_short:\n","    #           profit = short_ep / test[i] - fee\n","    #         else:\n","    #           profit = test[i] / short_ep - fee\n","\n","    #     else:\n","\n","    #       if not reverse_short:\n","    #         profit = short_ep / test[i] - fee\n","    #       else:\n","    #         profit = test[i] / short_ep - fee\n","\n","    #     l_profit = 1 + (profit - 1) * leverage\n","    #     l_profit = max(l_profit, 0)\n","\n","    #     if profit >= 1:\n","    #       win_cnt += 1\n","\n","    #   short_profits.append(l_profit)\n","    #   long_profits.append(1.0)\n","\n","    #   if show_detail:\n","    #     print(test[i], predictions[i], short_ep)\n","    \n","    else:\n","      long_profits.append(1.0)\n","      short_profits.append(1.0)\n","      liquidations.append(1.0)\n","\n","\n","  long_win_ratio = sum(np.array(long_profits) > 1.0) / sum(np.array(long_profits) != 1.0)\n","  short_win_ratio = sum(np.array(short_profits) > 1.0) / sum(np.array(short_profits) != 1.0)\n","  long_frequency = sum(np.array(long_profits) != 1.0) / len(test)\n","  short_frequency = sum(np.array(short_profits) != 1.0) / len(test)\n","  if not cumsum:\n","    long_accum_profit = np.array(long_profits).cumprod()\n","    short_accum_profit = np.array(short_profits).cumprod()\n","  else:\n","    long_accum_profit = (np.array(long_profits) - 1.0).cumsum()\n","    short_accum_profit = (np.array(short_profits) - 1.0).cumsum()\n","\n","  # print(win_ratio)\n","\n","  if show_plot:\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.suptitle('tp=%.4f, lvrg=%d' % (tp, leverage))\n","\n","    plt.subplot(151)\n","    plt.plot(liquidations)\n","    plt.title('liquidations')\n","\n","    plt.subplot(152)\n","    plt.plot(long_profits)\n","    plt.title('Win Ratio : %.2f %%\\nrequency : %.2f %%' % (long_win_ratio * 100, long_frequency * 100), color='black')\n","    # plt.show()\n","\n","    # print()\n","    plt.subplot(153)\n","    plt.plot(long_accum_profit)\n","    plt.title('Accum_profit : %.2f' % long_accum_profit[-1], color='black')\n","\n","    plt.subplot(154)\n","    plt.plot(short_profits)\n","    plt.title('Win Ratio : %.2f %%\\nrequency : %.2f %%' % (short_win_ratio * 100, short_frequency * 100), color='black')\n","    # plt.show()\n","\n","    # print()\n","    plt.subplot(155)\n","    plt.plot(short_accum_profit)\n","    plt.title('Accum_profit : %.2f' % short_accum_profit[-1], color='black')\n","    plt.show()\n","\n","  return [long_win_ratio, short_win_ratio], [long_frequency, short_frequency], [long_accum_profit[-1], short_accum_profit[-1]], [long_profits, short_profits]\n","\n","\n","# get_back_result(tp=0.04, leverage=1, show_plot=True)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aDkU3tMiM2lO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619098273169,"user_tz":-540,"elapsed":4898,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"cf1852d6-f734-45f6-8883-f52a00fa958f"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","interval = '30m'\n","date_path = './candlestick_concated/%s/2021-02-11/' % interval\n","file_list = os.listdir(date_path)\n","\n","print((file_list))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['2021-02-11 BTCUSDT.xlsx', '2021-02-11 ETHUSDT.xlsx', '2021-02-11 BCHUSDT.xlsx', '2021-02-11 XRPUSDT.xlsx', '2021-02-11 EOSUSDT.xlsx', '2021-02-11 LTCUSDT.xlsx', '2021-02-11 ETCUSDT.xlsx', '2021-02-11 LINKUSDT.xlsx', '2021-02-11 XLMUSDT.xlsx', '2021-02-11 ADAUSDT.xlsx', '2021-02-11 XMRUSDT.xlsx', '2021-02-11 SXPUSDT.xlsx', '2021-02-11 KAVAUSDT.xlsx', '2021-02-11 BANDUSDT.xlsx', '2021-02-11 DASHUSDT.xlsx', '2021-02-11 ZECUSDT.xlsx', '2021-02-11 XTZUSDT.xlsx', '2021-02-11 BNBUSDT.xlsx', '2021-02-11 ATOMUSDT.xlsx', '2021-02-11 ONTUSDT.xlsx', '2021-02-11 IOTAUSDT.xlsx', '2021-02-11 BATUSDT.xlsx', '2021-02-11 NEOUSDT.xlsx', '2021-02-11 QTUMUSDT.xlsx', '2021-02-11 WAVESUSDT.xlsx', '2021-02-11 MKRUSDT.xlsx', '2021-02-11 SNXUSDT.xlsx', '2021-02-11 DOTUSDT.xlsx', '2021-02-11 THETAUSDT.xlsx', '2021-02-11 ALGOUSDT.xlsx', '2021-02-11 KNCUSDT.xlsx', '2021-02-11 ZRXUSDT.xlsx', '2021-02-11 COMPUSDT.xlsx', '2021-02-11 OMGUSDT.xlsx']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0en4ihETQ32K"},"source":["### **Data Stacking**"]},{"cell_type":"code","metadata":{"id":"OgZyYJPg3RJa","executionInfo":{"status":"ok","timestamp":1619098273170,"user_tz":-540,"elapsed":3466,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}}},"source":["def resize_npy(x):\n","\n","  temp_x = []\n","\n","  for d_i, data in enumerate(x):\n","    # resized_data = cv2.resize(data, (row * 2, col * 2)) --> input image 홰손된다\n","    # resized_data = data.repeat(2, axis=0).repeat(2, axis=1)\n","    data = data.repeat(2, axis=0).repeat(2, axis=1)\n","    # resized_data = data.repeat(1, axis=0).repeat(1, axis=1)\n","    # cmapped = plt.cm.Set1(resized_data)[:, :, :3]  # Drop Alpha Channel\n","    \n","    if d_i == 0:\n","      plt.imshow(data)\n","      plt.show()\n","      # plt.imshow(resized_data)\n","      # plt.show()\n","    # print('resized_data.shape :', resized_data.shape)\n","    # break\n","    temp_x.append(data)\n","\n","  return temp_x"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvZuk1rPrUMe","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1619098356864,"user_tz":-540,"elapsed":12739,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"dbfd20d2-f8d7-4692-d593-654cf6bdcfea"},"source":["from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n","import pickle\n","from sklearn.model_selection import train_test_split\n","\n","with open('./arima_result/arima_opt_profit_ls_only_long_result_%s.pickle' % interval, 'rb') as f:\n","  load_dict = pickle.load(f)\n","\n","candis = list(load_dict.keys())\n","long_index = 0\n","leverage = 5\n","prev_x = None\n","\n","seed = 1\n","random_state = 20\n","np.random.seed(seed)\n","\n","for i in range(len(candis)):\n","\n","  keys = [candis[i]]\n","  \n","  # if 'algo'.upper() not in candis[i]:\n","  #   continue\n","  if '2021-03-02 DOTUSDT.xlsx' in candis[i]:\n","    # print('')\n","    continue\n","\n","  if '04-08' not in candis[i]:  # <-- 04-08 includes all timestamp range\n","    continue\n","\n","  if 'theta'.upper() not in candis[i]:\n","    continue\n","\n","  # plt.figure(figsize=(35, 10))\n","  # plt.suptitle('%s %s' % (interval, keys))\n","\n","\n","  #         get tp parameter        #\n","\n","  # plt.subplot(1,10,3)\n","  # for key in keys:  \n","  #   # plt.plot(profit_result_dict[key]['tp_list'], profit_result_dict[key]['ap_list'])\n","  #   argmax = np.argmax(profit_result_dict[key]['ap_list'][:, [long_index]])\n","  #   peak_tp = profit_result_dict[key]['tp_list'][argmax]\n","  #   # plt.axvline(peak_tp, linestyle='--')\n","  #   # plt.title('acc profit, max at %.4f' % (peak_tp))  \n","\n","  # plt.subplot(1,10,4)\n","  # plt.title('max acc profit by leverage')  \n","  # for key in keys:  \n","  #   # plt.plot(profit_result_dict[key]['tp_list'], profit_result_dict[key]['max_ap_list'], label=key)\n","  #   argmax = np.argmax(profit_result_dict[key]['max_ap_list'][:, [long_index]])\n","  #   max_peak_tp = profit_result_dict[key]['tp_list'][argmax]\n","  #   # plt.axvline(max_peak_tp, linestyle='--')\n","  #   # plt.title('max acc profit, max at %.4f' % (max_peak_tp))  \n","\n","\n","  for key in keys:  \n","    # print(profit_result_dict[key]['leverage_ap_list'])\n","\n","    # for tp in [max_peak_tp]:\n","\n","      # if tp == peak_tp:\n","      #   plt.subplot(1,10,5)\n","      # else:\n","      #   plt.subplot(1,10,6)\n","\n","      #     leverage analysis     #\n","      ohlcv = load_dict[key]['ohlcv']\n","      ohlcv = ohlcv.iloc[:-int(len(ohlcv) * 0.3)]  # exclude back_range\n","      # predictions = load_dict[key]['predictions']\n","      # err_ranges = load_dict[key]['err_ranges']\n","      print(\"ohlcv.index[0] :\", ohlcv.index[0])\n","      print(\"ohlcv.index[-1] :\", ohlcv.index[-1])\n","\n","      predictions = ohlcv['close'].shift(1).values\n","      err_ranges = np.zeros_like(predictions)\n","\n","      # leverage_list = profit_result_dict[key]['leverage_list']\n","      # temp_ap_list = list()\n","      # temp_pr_list = list()\n","\n","      try:\n","        print('-------------- %s --------------' % key)\n","        result = get_back_result(ohlcv, predictions, err_ranges, tp=0, leverage=leverage, show_plot=True, reverse_short=False, show_detail=False)\n","        # temp_ap_list.append(result[2])\n","        # temp_pr_list.append(result[3])\n","\n","        # if round(leverage) == 1:\n","        #   temp_pr_list = result[3]\n","        pr_list = result[3][long_index]\n","\n","      except Exception as e:\n","        print(e)\n","        break    \n","  # break\n","\n","\n","      pd.set_option('display.max_rows', 500)\n","      pd.set_option('display.max_columns', 500)\n","      pd.set_option('display.width', 1000)\n","\n","      #         clustering zone           #\n","\n","      #       set data features : ohlc, v, ep\n","      ohlc = ohlcv.iloc[-len(predictions):, :4]\n","      vol = ohlcv.iloc[-len(predictions):, [4]]\n","      long_ep = np.array(predictions)\n","      long_ep = long_ep.reshape(-1, 1)\n","\n","      ohlcv['u_wick'] = ohlcv['high'] / np.maximum(ohlcv['close'] , ohlcv['open'])\n","      ohlcv['d_wick'] = np.minimum(ohlcv['close'] , ohlcv['open']) / ohlcv['low']\n","      ohlcv['body'] = ohlcv['close'] / ohlcv['open']\n","\n","      candle = ohlcv.iloc[-len(predictions):, -3:]\n","\n","\n","      print('len(ohlc) :', len(ohlc))\n","      print('long_ep.shape :', long_ep.shape)\n","      print('len(pr_list) :', len(pr_list))\n","\n","\n","      #       set params    #\n","      period = 45\n","      data_x, data_pr, data_updown = [], [], []\n","      key_i = i\n","\n","      for i in range(period, len(predictions)):\n","\n","        #   pr_list != 1 인 데이터만 사용한다\n","        # if 1:\n","        if pr_list[i] != 1:\n","          \n","          #   prediction 을 제외한 이전 데이터를 사용해야한다\n","          temp_ohlc = ohlc.iloc[i - period : i].values\n","          temp_long_ep = long_ep[i - period : i]\n","          temp_vol = vol.iloc[i - period : i].values\n","          temp_candle = candle.iloc[i - period : i].values\n","\n","          # print(temp_ohlc.shape)\n","          # print(temp_long_ep.shape)\n","          # print(temp_vol.shape)\n","          # print(temp_candle.shape)\n","          # break\n","\n","          #   stacking  \n","          # temp_data = np.hstack((temp_ohlc, temp_long_ep, temp_vol, temp_candle))\n","          temp_data = np.hstack((temp_ohlc, temp_long_ep, temp_vol))\n","          # temp_data = np.hstack((temp_ohlc, temp_vol))\n","\n","          # temp_data = np.hstack((temp_ohlc, temp_long_ep))\n","          # temp_data = temp_vol\n","\n","          #   scaler 설정\n","\n","          #   ohlc & ep -> max_abs\n","          # max_abs = MaxAbsScaler()\n","          # temp_data[:, :5] = max_abs.fit_transform(temp_data[:, :5])\n","\n","\n","          min_max = MinMaxScaler()\n","          temp_data[:, :5] = min_max.fit_transform(temp_data[:, :5])\n","\n","\n","          #   vol -> min_max\n","          min_max = MinMaxScaler()\n","          temp_data[:, [5]] = min_max.fit_transform(temp_data[:, [5]])\n","\n","\n","          #   candle -> max_abs    \n","          # max_abs = MaxAbsScaler()\n","          # temp_data[:, -3:] = max_abs.fit_transform(temp_data[:, -3:])\n","\n","          # min_max = MinMaxScaler()\n","          # temp_data[:, -3:] = min_max.fit_transform(temp_data[:, -3:])\n","\n","          if np.isnan(np.sum(temp_data)):\n","            continue\n","\n","          data_x.append(temp_data)\n","          data_pr.append(pr_list[i])\n","          data_updown.append(ohlc['close'].iloc[i] / ohlc['open'].iloc[i])\n","\n","\n","      print('np.array(data_x).shape :', np.array(data_x).shape)\n","      # print(data_x[0])\n","\n","\n","      #       Reshape data for image deep - learning     #\n","      _, row, col = np.array(data_x).shape\n","\n","      input_x = np.array(data_x).reshape(-1, row, col, 1).astype(np.float32)\n","\n","      #     1c to 3c    #\n","      input_x = input_x * np.ones(3, dtype=np.float32)[None, None, None, :]\n","      input_x = np.array(resize_npy(input_x))\n","\n","\n","      input_pr = np.array(data_pr).reshape(-1, 1).astype(np.float32)\n","      input_ud = np.array(data_updown).reshape(-1, 1).astype(np.float32)\n","      print('input_x.shape :', input_x.shape)\n","      print('input_x.dtype :', input_x.dtype)\n","      print('input_pr.shape :', input_pr.shape)\n","      print('input_ud.shape :', input_ud.shape)\n","\n","      \n","      # x_train_, x_test, pr_train_, pr_test, ud_train_, ud_test = train_test_split(input_x, input_pr, input_ud, test_size=0.4, shuffle=False, random_state=random_state)\n","      # x_train, x_val, pr_train, pr_val, ud_train, ud_val = train_test_split(x_train_, pr_train_, ud_train_, test_size=0.25, shuffle=False, random_state=random_state)\n","\n","      #     do stacking   #\n","      #     do stacking   #\n","      if prev_x is None:\n","        prev_x = input_x\n","        prev_pr = input_pr\n","        prev_ud = input_ud\n","      else:\n","        total_x = np.vstack((prev_x, input_x))\n","        total_pr = np.vstack((prev_pr, input_pr))\n","        total_ud = np.vstack((prev_ud, input_ud))\n","\n","        prev_x = total_x\n","        prev_pr = total_pr\n","        prev_ud = total_ud\n","\n","        print('total_x.shape :', total_x.shape)\n","        print('total_pr.shape :', total_pr.shape)\n","        print('total_ud.shape :', total_ud.shape)\n","      # if prev_train_x is None:\n","      #   prev_train_x = x_train\n","      #   prev_val_x = x_val\n","      #   prev_test_x = x_test\n","        \n","      #   prev_train_pr = pr_train\n","      #   prev_val_pr = pr_val\n","      #   prev_test_pr = pr_test\n","\n","      #   prev_train_ud = ud_train\n","      #   prev_val_ud = ud_val\n","      #   prev_test_ud = ud_test\n","\n","      # else:\n","\n","      #   total_train_x = np.vstack((prev_train_x, x_train))\n","      #   total_val_x = np.vstack((prev_val_x, x_val))\n","      #   total_test_x = np.vstack((prev_test_x, x_test))\n","      #   total_train_pr = np.vstack((prev_train_pr, pr_train))\n","      #   total_val_pr = np.vstack((prev_val_pr, pr_val))\n","      #   total_test_pr = np.vstack((prev_test_pr, pr_test))\n","      #   total_train_ud = np.vstack((prev_train_ud, ud_train))\n","      #   total_val_ud = np.vstack((prev_val_ud, ud_val))\n","      #   total_test_ud = np.vstack((prev_test_ud, ud_test))\n","        \n","      #   prev_train_x = total_train_x\n","      #   prev_val_x = total_val_x\n","      #   prev_test_x = total_test_x\n","        \n","      #   prev_train_pr = total_train_pr\n","      #   prev_val_pr = total_val_pr\n","      #   prev_test_pr = total_test_pr\n","\n","      #   prev_train_ud = total_train_ud\n","      #   prev_val_ud = total_val_ud\n","      #   prev_test_ud = total_test_ud\n","        \n","      #   print(\"total_train_x.shape :\", total_train_x.shape)\n","      #   print(\"total_val_x.shape :\", total_val_x.shape)\n","      #   print(\"total_test_x.shape :\", total_test_x.shape)\n","      #   print(\"total_train_pr.shape :\", total_train_pr.shape)\n","      #   print(\"total_val_pr.shape :\", total_val_pr.shape)\n","      #   print(\"total_test_pr.shape :\", total_test_pr.shape)\n","      #   print(\"total_train_ud.shape :\", total_train_ud.shape)\n","      #   print(\"total_val_ud.shape :\", total_val_ud.shape)\n","      #   print(\"total_test_ud.shape :\", total_test_ud.shape)\n","\n","  break # --> use only one pair dataset\n","\n","  #         chunks 로 나누지 않아도, generator 에서 batch_size 만큼만 load 할 것   #\n","  # try:\n","  #   if len(total_x) > 300000:\n","  #     break\n","  # except:\n","  #   pass\n","\n","  \n","        "],"execution_count":6,"outputs":[{"output_type":"stream","text":["ohlcv.index[0] : 2020-05-27 17:29:59.999000\n","ohlcv.index[-1] : 2021-01-04 00:29:59.999000\n","-------------- 2021-04-08 THETAUSDT.xlsx --------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:158: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:159: RuntimeWarning: invalid value encountered in long_scalars\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:163: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order, subok=True)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 5 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["len(ohlc) : 10623\n","long_ep.shape : (10623, 1)\n","len(pr_list) : 10623\n","np.array(data_x).shape : (10048, 45, 6)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["input_x.shape : (10048, 90, 12, 3)\n","input_x.dtype : float32\n","input_pr.shape : (10048, 1)\n","input_ud.shape : (10048, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:198: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"thMdK22LQdKv","executionInfo":{"status":"ok","timestamp":1619098358093,"user_tz":-540,"elapsed":1210,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}}},"source":["period = 45\n","# x_save_path = current_path + 'npy/' + '%s_close_updown_x.npy' % period\n","# y_save_path = current_path + 'npy/' + '%s_close_updown_y.npy' % period\n","#         save to npy     #\n","# x_save_path = current_path + 'npy/' + '%s_close_updown_theta_x_ex.npy' % period\n","# y_save_path = current_path + 'npy/' + '%s_close_updown_theta_y_ex.npy' % period\n","\n","# total_x = np.load(x_save_path)\n","# total_pr = np.load(y_save_path)\n","\n","# _, row, col, _ = total_x.shape\n","\n","_, row, col, _ = input_x.shape\n","\n","\n","\n","seed = 1\n","random_state = 20\n","np.random.seed(seed)\n","from sklearn.model_selection import train_test_split\n","#         train / test split      #\n","# x_train, x_test_, pr_train, pr_test_, ud_train, ud_test_ = train_test_split(re_input_x, input_pr, input_ud, test_size=0.4, shuffle=True, random_state=random_state)\n","# x_train_, x_test, pr_train_, pr_test = train_test_split(total_x, total_pr, test_size=0.2, shuffle=False, random_state=random_state)\n","# x_train, x_val, pr_train, pr_val = train_test_split(x_train_, pr_train_, test_size=0.25, shuffle=True, random_state=random_state)\n","# break\n","x_train_, x_test, pr_train_, pr_test = train_test_split(input_x, input_pr, test_size=0.2, shuffle=True, random_state=random_state)\n","x_train, x_val, pr_train, pr_val = train_test_split(x_train_, pr_train_, test_size=0.25, shuffle=True, random_state=random_state)\n","#         pr label   #\n","y_train = np.where(pr_train > 1, 1, 0)\n","y_test = np.where(pr_test > 1, 1, 0)\n","y_val = np.where(pr_val > 1, 1, 0)\n","\n","# del total_x"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1UEFg1GVSLS"},"source":["### Load Data"]},{"cell_type":"code","metadata":{"id":"76BQc5XlUSS6"},"source":["# period = 45\n","# # x_save_path = current_path + 'npy/' + '%s_close_updown_x.npy' % period\n","# # y_save_path = current_path + 'npy/' + '%s_close_updown_y.npy' % period\n","# #         save to npy     #\n","# x_save_path = current_path + 'npy/' + '%s_close_updown_theta_x_ex.npy' % period\n","# y_save_path = current_path + 'npy/' + '%s_close_updown_theta_y_ex.npy' % period\n","\n","# total_x = np.load(x_save_path)\n","# total_pr = np.load(y_save_path)\n","\n","# _, row, col, _ = total_x.shape\n","\n","\n","\n","# seed = 1\n","# random_state = 20\n","# np.random.seed(seed)\n","# from sklearn.model_selection import train_test_split\n","# #         train / test split      #\n","# # x_train, x_test_, pr_train, pr_test_, ud_train, ud_test_ = train_test_split(re_total_x, total_pr, total_ud, test_size=0.4, shuffle=True, random_state=random_state)\n","# x_train_, x_test, pr_train_, pr_test = train_test_split(total_x, total_pr, test_size=0.2, shuffle=False, random_state=random_state)\n","# x_train, x_val, pr_train, pr_val = train_test_split(x_train_, pr_train_, test_size=0.25, shuffle=False, random_state=random_state)\n","# # break\n","# #         pr label   #\n","# y_train = np.where(pr_train > 1, 1, 0)\n","# y_test = np.where(pr_test > 1, 1, 0)\n","# y_val = np.where(pr_val > 1, 1, 0)\n","\n","# del total_x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmmgsEUMqUjN"},"source":["### **Model**"]},{"cell_type":"code","metadata":{"id":"mcDUjgQzqUSr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619098376937,"user_tz":-540,"elapsed":4839,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"4a6108e6-9abf-4dea-fe9e-412a137ee7e7"},"source":["import os\n","# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","%tensorflow_version 1.x\n","\n","import keras\n","import tensorflow as tf\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.misc \n","from math import sqrt \n","import itertools\n","from IPython.display import display\n","\n","%matplotlib inline\n","\n","from keras.utils import plot_model\n","import keras.backend as K\n","from keras.models import Model, Sequential\n","import keras.layers as layers\n","from keras.optimizers import Adam, SGD\n","from keras.regularizers import l1, l2\n","\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import plot_confusion_matrix\n","\n","\n","gdrive_path = current_path\n","\n","num_classes = 2\n","\n","def FER_Model(input_shape=(row, col, 3)):\n","    # first input model\n","    visible = layers.Input(shape=input_shape, name='input')\n","    \n","    net = layers.Conv2D(32, kernel_size=3, padding='same', kernel_initializer='he_normal')(visible)\n","    # net = layers.Conv2D(256, kernel_size=3, padding='same', kernel_initializer='he_normal')(visible)\n","    # net = layers.BatchNormalization()(net)\n","    net = layers.LeakyReLU()(net)\n","\n","    net = layers.Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal')(net)\n","    # net = layers.Conv2D(128, kernel_size=3, padding='same', kernel_initializer='he_normal')(net)\n","    # net = layers.BatchNormalization()(net)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","    # net = layers.AveragePooling2D(padding='same')(net)\n","\n","    shortcut_1 = net\n","\n","    # net = layers.Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal')(net)\n","    net = layers.Conv2D(128, kernel_size=3, padding='same', kernel_initializer='he_normal')(net)\n","    net = layers.LeakyReLU()(net)\n","\n","    net = layers.Conv2D(256, kernel_size=3, padding='same', kernel_initializer='he_normal')(net)\n","    # net = layers.BatchNormalization()(net)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    shortcut_2 = net\n","\n","#     net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","#     shortcut_3 = net\n","\n","#     net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    net = layers.Flatten()(net)\n","    net = layers.Dense(128)(net)\n","    net = layers.LeakyReLU()(net)\n","\n","    net = layers.Dense(64)(net)\n","    net = layers.LeakyReLU()(net)\n","\n","    net = layers.Dense(num_classes, activation='softmax')(net)\n","\n","    # create model \n","    model = Model(inputs=visible, outputs=net)\n","    # summary layers\n","    # print(model.summary())\n","    \n","    return model"],"execution_count":8,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zscZynIgMbAq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619098376938,"user_tz":-540,"elapsed":3605,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"2f079abb-52c6-400b-9bb0-dce1d0d0b146"},"source":["print(keras.__version__)\n","print(tf.__version__)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2.3.1\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fWUEyjzF21cJ"},"source":["### **Data Split**"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2iYLNSeSEp7p","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1619098377822,"user_tz":-540,"elapsed":3294,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"caa0e197-f4cc-46b3-ff7d-5d029b05da1b"},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator \n","from sklearn.utils import class_weight\n","# import cv2\n","\n","\n","_, row, col, _ = x_train.shape\n","\n","#         pr label   #\n","# y_train = np.where(pr_train > 1, 1, 0)\n","# y_test = np.where(pr_test > 1, 1, 0)\n","# y_val = np.where(pr_val > 1, 1, 0)\n","\n","\n","seed = 1\n","random_state = 20\n","np.random.seed(seed)\n","# tf.random.set_seed(seed)\n","\n","#         up label      #\n","# y_train = np.where(ud_train > 1, 1, 0)\n","# y_test = np.where(ud_test > 1, 1, 0)\n","# y_val = np.where(ud_val > 1, 1, 0)\n","\n","print('pr_train[:5] :', pr_train[:5])\n","# print('ud_train[:5] :', ud_train[:5])\n","print('y_train[:5] :', y_train[:5])\n","print('y_train.dtype :', y_train.dtype)\n","\n","print('x_train.shape :', x_train.shape)\n","print('x_test.shape :', x_test.shape)\n","print('x_val.shape :', x_val.shape)\n","print('y_train.shape :', y_train.shape)\n","print('y_test.shape :', y_test.shape)\n","print('y_val.shape :', y_val.shape)\n","\n","def class_ratio(in_list):\n","\n","  return in_list / in_list[1]\n","\n","print('np.unique(y_train, return_counts=True :', np.unique(y_train, return_counts=True), class_ratio(np.unique(y_train, return_counts=True)[1]))\n","print('np.unique(y_val, return_counts=True :', np.unique(y_val, return_counts=True), class_ratio(np.unique(y_val, return_counts=True)[1]))\n","print('np.unique(y_test, return_counts=True :', np.unique(y_test, return_counts=True), class_ratio(np.unique(y_test, return_counts=True)[1]))\n","\n","label = y_train.reshape(-1, )\n","class_weights = class_weight.compute_class_weight('balanced', \n","                                                    classes=np.unique(label),\n","                                                    y=label)\n","class_weights = dict(enumerate(class_weights))\n","print('class_weights :', class_weights)\n","\n","# sample_weight = np.ones(shape=(len(y_train),))\n","# sample_weight[(y_train == 1).reshape(-1,)] = 1.5\n","# print('sample_weight[:20] :', sample_weight[:20])\n","\n","\n","print('np.isnan(np.sum(x_train)) :', np.isnan(np.sum(x_train)))\n","print('np.isnan(np.sum(x_val)) :', np.isnan(np.sum(x_val)))\n","print('np.isnan(np.sum(x_test)) :', np.isnan(np.sum(x_test)))\n","\n","print('np.isnan(np.sum(y_train)) :', np.isnan(np.sum(y_train)))\n","print('np.isnan(np.sum(y_val)) :', np.isnan(np.sum(y_val)))\n","print('np.isnan(np.sum(y_test)) :', np.isnan(np.sum(y_test)))\n","\n","y_train_ohe = np_utils.to_categorical(y_train, num_classes)\n","y_val_ohe = np_utils.to_categorical(y_val, num_classes)\n","y_test_ohe = np_utils.to_categorical(y_test, num_classes)\n","print('y_train_ohe.shape :', y_train_ohe.shape)\n","print('y_val_ohe.shape :', y_val_ohe.shape)\n","print('y_test_ohe.shape :', y_test_ohe.shape)\n","\n","datagen = ImageDataGenerator( \n","    rotation_range = 45,\n","    # zoom_range = 0.5,\n","    # shear_range = 0.5,\n","    # horizontal_flip = True,\n","    # vertical_flip = True,\n","    # width_shift_range=0.5,\n","    # height_shift_range=0.5,\n","    # fill_mode = 'nearest'\n","    )\n","\n","valgen = ImageDataGenerator( \n","    )\n","\n","datagen.fit(x_train)\n","valgen.fit(x_val)\n","\n","batch_size = 16\n","\n","for x_batch, _ in datagen.flow(x_train, y_train_ohe, batch_size=9):\n","\n","    plt.suptitle(\"train x_batch\")\n","\n","    for i in range(0, 9): \n","        plt.subplot(330 + 1 + i) \n","        # resized = cv2.resize(x_batch[i].reshape(row, col), (row * 2, col * 10))\n","        # cmapped = plt.cm.Set1(resized)\n","        # plt.imshow(cmapped)\n","        # plt.imshow(x_batch[i].reshape(row, col))\n","        plt.imshow(x_batch[i])\n","        plt.axis('off') \n","    plt.show() \n","    break\n","\n","for x_batch, _ in valgen.flow(x_val, y_val_ohe, batch_size=9):\n","\n","    plt.suptitle(\"val x_batch\")\n","\n","    for i in range(0, 9): \n","        plt.subplot(330 + 1 + i) \n","        # resized = cv2.resize(x_batch[i].reshape(row, col), (row * 2, col * 10))\n","        # cmapped = plt.cm.Set1(resized)\n","        # plt.imshow(cmapped)\n","        # plt.imshow(x_batch[i].reshape(row, col))\n","        plt.imshow(x_batch[i])\n","        plt.axis('off') \n","    plt.show() \n","    break\n","    \n","train_flow = datagen.flow(x_train, y_train_ohe, batch_size=batch_size) \n","val_flow = valgen.flow(x_val, y_val_ohe, batch_size=batch_size) \n","# break\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["pr_train[:5] : [[0.9983978 ]\n"," [0.98882204]\n"," [1.0303016 ]\n"," [0.9747307 ]\n"," [1.0147763 ]]\n","y_train[:5] : [[0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]]\n","y_train.dtype : int64\n","x_train.shape : (6028, 90, 12, 3)\n","x_test.shape : (2010, 90, 12, 3)\n","x_val.shape : (2010, 90, 12, 3)\n","y_train.shape : (6028, 1)\n","y_test.shape : (2010, 1)\n","y_val.shape : (2010, 1)\n","np.unique(y_train, return_counts=True : (array([0, 1]), array([3383, 2645])) [1.27901701 1.        ]\n","np.unique(y_val, return_counts=True : (array([0, 1]), array([1103,  907])) [1.21609702 1.        ]\n","np.unique(y_test, return_counts=True : (array([0, 1]), array([1108,  902])) [1.22838137 1.        ]\n","class_weights : {0: 0.8909252143068283, 1: 1.1395085066162571}\n","np.isnan(np.sum(x_train)) : False\n","np.isnan(np.sum(x_val)) : False\n","np.isnan(np.sum(x_test)) : False\n","np.isnan(np.sum(y_train)) : False\n","np.isnan(np.sum(y_val)) : False\n","np.isnan(np.sum(y_test)) : False\n","y_train_ohe.shape : (6028, 2)\n","y_val_ohe.shape : (2010, 2)\n","y_test_ohe.shape : (2010, 2)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"s-W6LL5c2VN2"},"source":["### **Training**"]},{"cell_type":"code","metadata":{"id":"EkVg1hVI2TNP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619109710684,"user_tz":-540,"elapsed":7932629,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"5a943612-6a3a-421d-d820-9b4a36d7f91d"},"source":["(_, row, col, _) = x_train.shape\n","  \n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","\n","ckpt_path = current_path + 'ckpt/'\n","board_path = current_path + 'graph/'\n","# model_name = 'classifier_%s_close_updown_pr_theta_shuffle_without_back_03.h5' % period\n","\n","# model = keras.models.load_model(ckpt_path + model_name)\n","\n","model_name = 'classifier_%s_close_updown_pr_theta_shuffle_without_back.h5' % period\n","\n","model = FER_Model(input_shape=(row, col, 3))\n","opt = Adam(lr=0.00001, decay=0.000005)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","checkpoint = ModelCheckpoint(ckpt_path + model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","checkpoint2 = TensorBoard(log_dir=board_path,\n","                          histogram_freq=0,\n","                          write_graph=True,\n","                          write_images=True)\n","checkpoint3 = EarlyStopping(monitor='val_loss', patience=40)\n","# callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n","callbacks_list = [checkpoint, checkpoint2]\n","\n","# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n","\n","# we iterate 200 times over the entire training set\n","num_epochs = 1000\n","history = model.fit_generator(train_flow, \n","                    steps_per_epoch=len(x_train) / batch_size, \n","                    epochs=num_epochs,  \n","                    verbose=2,  \n","                    callbacks=callbacks_list,\n","                    class_weight=class_weights,\n","                    validation_data=val_flow,  \n","                    validation_steps=len(x_val) / batch_size,\n","                    shuffle=False)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n"," - 8s - loss: 0.7707 - accuracy: 0.4998 - val_loss: 0.7928 - val_accuracy: 0.4677\n","\n","Epoch 00001: val_loss improved from inf to 0.79282, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 2/1000\n"," - 8s - loss: 0.7248 - accuracy: 0.4959 - val_loss: 0.8105 - val_accuracy: 0.4468\n","\n","Epoch 00002: val_loss did not improve from 0.79282\n","Epoch 3/1000\n"," - 8s - loss: 0.7062 - accuracy: 0.5025 - val_loss: 0.6638 - val_accuracy: 0.5438\n","\n","Epoch 00003: val_loss improved from 0.79282 to 0.66383, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 4/1000\n"," - 8s - loss: 0.7009 - accuracy: 0.5028 - val_loss: 0.6173 - val_accuracy: 0.5279\n","\n","Epoch 00004: val_loss improved from 0.66383 to 0.61728, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 5/1000\n"," - 8s - loss: 0.7002 - accuracy: 0.5075 - val_loss: 0.6302 - val_accuracy: 0.5453\n","\n","Epoch 00005: val_loss did not improve from 0.61728\n","Epoch 6/1000\n"," - 8s - loss: 0.6971 - accuracy: 0.5045 - val_loss: 0.7035 - val_accuracy: 0.5473\n","\n","Epoch 00006: val_loss did not improve from 0.61728\n","Epoch 7/1000\n"," - 8s - loss: 0.6989 - accuracy: 0.5095 - val_loss: 0.6393 - val_accuracy: 0.4925\n","\n","Epoch 00007: val_loss did not improve from 0.61728\n","Epoch 8/1000\n"," - 8s - loss: 0.6934 - accuracy: 0.5269 - val_loss: 0.7271 - val_accuracy: 0.5065\n","\n","Epoch 00008: val_loss did not improve from 0.61728\n","Epoch 9/1000\n"," - 8s - loss: 0.6963 - accuracy: 0.5033 - val_loss: 0.7093 - val_accuracy: 0.5363\n","\n","Epoch 00009: val_loss did not improve from 0.61728\n","Epoch 10/1000\n"," - 8s - loss: 0.6965 - accuracy: 0.5114 - val_loss: 0.7504 - val_accuracy: 0.4647\n","\n","Epoch 00010: val_loss did not improve from 0.61728\n","Epoch 11/1000\n"," - 8s - loss: 0.6953 - accuracy: 0.5143 - val_loss: 0.7584 - val_accuracy: 0.4736\n","\n","Epoch 00011: val_loss did not improve from 0.61728\n","Epoch 12/1000\n"," - 8s - loss: 0.6939 - accuracy: 0.5246 - val_loss: 0.6953 - val_accuracy: 0.4836\n","\n","Epoch 00012: val_loss did not improve from 0.61728\n","Epoch 13/1000\n"," - 8s - loss: 0.6925 - accuracy: 0.5216 - val_loss: 0.6747 - val_accuracy: 0.4647\n","\n","Epoch 00013: val_loss did not improve from 0.61728\n","Epoch 14/1000\n"," - 8s - loss: 0.6934 - accuracy: 0.5249 - val_loss: 0.6787 - val_accuracy: 0.5085\n","\n","Epoch 00014: val_loss did not improve from 0.61728\n","Epoch 15/1000\n"," - 8s - loss: 0.6932 - accuracy: 0.5146 - val_loss: 0.6946 - val_accuracy: 0.4796\n","\n","Epoch 00015: val_loss did not improve from 0.61728\n","Epoch 16/1000\n"," - 8s - loss: 0.6929 - accuracy: 0.5279 - val_loss: 0.6338 - val_accuracy: 0.5015\n","\n","Epoch 00016: val_loss did not improve from 0.61728\n","Epoch 17/1000\n"," - 8s - loss: 0.6913 - accuracy: 0.5307 - val_loss: 0.8102 - val_accuracy: 0.4706\n","\n","Epoch 00017: val_loss did not improve from 0.61728\n","Epoch 18/1000\n"," - 8s - loss: 0.6931 - accuracy: 0.5224 - val_loss: 0.7742 - val_accuracy: 0.4796\n","\n","Epoch 00018: val_loss did not improve from 0.61728\n","Epoch 19/1000\n"," - 8s - loss: 0.6919 - accuracy: 0.5216 - val_loss: 0.7272 - val_accuracy: 0.4856\n","\n","Epoch 00019: val_loss did not improve from 0.61728\n","Epoch 20/1000\n"," - 8s - loss: 0.6916 - accuracy: 0.5260 - val_loss: 0.6541 - val_accuracy: 0.5378\n","\n","Epoch 00020: val_loss did not improve from 0.61728\n","Epoch 21/1000\n"," - 8s - loss: 0.6918 - accuracy: 0.5275 - val_loss: 0.7282 - val_accuracy: 0.5149\n","\n","Epoch 00021: val_loss did not improve from 0.61728\n","Epoch 22/1000\n"," - 8s - loss: 0.6893 - accuracy: 0.5317 - val_loss: 0.7434 - val_accuracy: 0.5483\n","\n","Epoch 00022: val_loss did not improve from 0.61728\n","Epoch 23/1000\n"," - 8s - loss: 0.6904 - accuracy: 0.5392 - val_loss: 0.6643 - val_accuracy: 0.5114\n","\n","Epoch 00023: val_loss did not improve from 0.61728\n","Epoch 24/1000\n"," - 8s - loss: 0.6896 - accuracy: 0.5260 - val_loss: 0.6896 - val_accuracy: 0.4990\n","\n","Epoch 00024: val_loss did not improve from 0.61728\n","Epoch 25/1000\n"," - 8s - loss: 0.6866 - accuracy: 0.5433 - val_loss: 0.6290 - val_accuracy: 0.5035\n","\n","Epoch 00025: val_loss did not improve from 0.61728\n","Epoch 26/1000\n"," - 8s - loss: 0.6862 - accuracy: 0.5523 - val_loss: 0.7232 - val_accuracy: 0.5164\n","\n","Epoch 00026: val_loss did not improve from 0.61728\n","Epoch 27/1000\n"," - 8s - loss: 0.6851 - accuracy: 0.5425 - val_loss: 0.7204 - val_accuracy: 0.5095\n","\n","Epoch 00027: val_loss did not improve from 0.61728\n","Epoch 28/1000\n"," - 8s - loss: 0.6882 - accuracy: 0.5362 - val_loss: 0.7426 - val_accuracy: 0.5264\n","\n","Epoch 00028: val_loss did not improve from 0.61728\n","Epoch 29/1000\n"," - 8s - loss: 0.6871 - accuracy: 0.5461 - val_loss: 0.7426 - val_accuracy: 0.5154\n","\n","Epoch 00029: val_loss did not improve from 0.61728\n","Epoch 30/1000\n"," - 8s - loss: 0.6848 - accuracy: 0.5451 - val_loss: 0.7273 - val_accuracy: 0.5303\n","\n","Epoch 00030: val_loss did not improve from 0.61728\n","Epoch 31/1000\n"," - 8s - loss: 0.6848 - accuracy: 0.5483 - val_loss: 0.7002 - val_accuracy: 0.5159\n","\n","Epoch 00031: val_loss did not improve from 0.61728\n","Epoch 32/1000\n"," - 8s - loss: 0.6797 - accuracy: 0.5584 - val_loss: 0.6912 - val_accuracy: 0.4975\n","\n","Epoch 00032: val_loss did not improve from 0.61728\n","Epoch 33/1000\n"," - 8s - loss: 0.6813 - accuracy: 0.5655 - val_loss: 0.7048 - val_accuracy: 0.4821\n","\n","Epoch 00033: val_loss did not improve from 0.61728\n","Epoch 34/1000\n"," - 8s - loss: 0.6812 - accuracy: 0.5649 - val_loss: 0.9169 - val_accuracy: 0.4866\n","\n","Epoch 00034: val_loss did not improve from 0.61728\n","Epoch 35/1000\n"," - 8s - loss: 0.6801 - accuracy: 0.5557 - val_loss: 0.7358 - val_accuracy: 0.4776\n","\n","Epoch 00035: val_loss did not improve from 0.61728\n","Epoch 36/1000\n"," - 8s - loss: 0.6790 - accuracy: 0.5625 - val_loss: 0.7445 - val_accuracy: 0.5109\n","\n","Epoch 00036: val_loss did not improve from 0.61728\n","Epoch 37/1000\n"," - 8s - loss: 0.6767 - accuracy: 0.5717 - val_loss: 0.8056 - val_accuracy: 0.5144\n","\n","Epoch 00037: val_loss did not improve from 0.61728\n","Epoch 38/1000\n"," - 8s - loss: 0.6783 - accuracy: 0.5610 - val_loss: 0.5903 - val_accuracy: 0.4905\n","\n","Epoch 00038: val_loss improved from 0.61728 to 0.59025, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 39/1000\n"," - 8s - loss: 0.6714 - accuracy: 0.5826 - val_loss: 0.7740 - val_accuracy: 0.5328\n","\n","Epoch 00039: val_loss did not improve from 0.59025\n","Epoch 40/1000\n"," - 8s - loss: 0.6710 - accuracy: 0.5810 - val_loss: 0.7701 - val_accuracy: 0.5313\n","\n","Epoch 00040: val_loss did not improve from 0.59025\n","Epoch 41/1000\n"," - 8s - loss: 0.6725 - accuracy: 0.5808 - val_loss: 0.7429 - val_accuracy: 0.4816\n","\n","Epoch 00041: val_loss did not improve from 0.59025\n","Epoch 42/1000\n"," - 8s - loss: 0.6744 - accuracy: 0.5773 - val_loss: 0.7770 - val_accuracy: 0.4980\n","\n","Epoch 00042: val_loss did not improve from 0.59025\n","Epoch 43/1000\n"," - 8s - loss: 0.6707 - accuracy: 0.5768 - val_loss: 0.7560 - val_accuracy: 0.4930\n","\n","Epoch 00043: val_loss did not improve from 0.59025\n","Epoch 44/1000\n"," - 8s - loss: 0.6679 - accuracy: 0.5781 - val_loss: 0.5772 - val_accuracy: 0.5204\n","\n","Epoch 00044: val_loss improved from 0.59025 to 0.57724, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 45/1000\n"," - 8s - loss: 0.6649 - accuracy: 0.5957 - val_loss: 0.6383 - val_accuracy: 0.5050\n","\n","Epoch 00045: val_loss did not improve from 0.57724\n","Epoch 46/1000\n"," - 8s - loss: 0.6651 - accuracy: 0.5914 - val_loss: 0.7461 - val_accuracy: 0.5035\n","\n","Epoch 00046: val_loss did not improve from 0.57724\n","Epoch 47/1000\n"," - 8s - loss: 0.6603 - accuracy: 0.5989 - val_loss: 0.6691 - val_accuracy: 0.5169\n","\n","Epoch 00047: val_loss did not improve from 0.57724\n","Epoch 48/1000\n"," - 8s - loss: 0.6622 - accuracy: 0.5936 - val_loss: 0.6763 - val_accuracy: 0.4995\n","\n","Epoch 00048: val_loss did not improve from 0.57724\n","Epoch 49/1000\n"," - 8s - loss: 0.6624 - accuracy: 0.5894 - val_loss: 0.6781 - val_accuracy: 0.5134\n","\n","Epoch 00049: val_loss did not improve from 0.57724\n","Epoch 50/1000\n"," - 8s - loss: 0.6589 - accuracy: 0.5989 - val_loss: 0.8069 - val_accuracy: 0.5328\n","\n","Epoch 00050: val_loss did not improve from 0.57724\n","Epoch 51/1000\n"," - 8s - loss: 0.6580 - accuracy: 0.5995 - val_loss: 1.0855 - val_accuracy: 0.5169\n","\n","Epoch 00051: val_loss did not improve from 0.57724\n","Epoch 52/1000\n"," - 8s - loss: 0.6533 - accuracy: 0.6072 - val_loss: 0.6891 - val_accuracy: 0.5085\n","\n","Epoch 00052: val_loss did not improve from 0.57724\n","Epoch 53/1000\n"," - 8s - loss: 0.6556 - accuracy: 0.6068 - val_loss: 0.8255 - val_accuracy: 0.4980\n","\n","Epoch 00053: val_loss did not improve from 0.57724\n","Epoch 54/1000\n"," - 8s - loss: 0.6556 - accuracy: 0.6032 - val_loss: 0.7741 - val_accuracy: 0.5035\n","\n","Epoch 00054: val_loss did not improve from 0.57724\n","Epoch 55/1000\n"," - 8s - loss: 0.6491 - accuracy: 0.6088 - val_loss: 0.6401 - val_accuracy: 0.5234\n","\n","Epoch 00055: val_loss did not improve from 0.57724\n","Epoch 56/1000\n"," - 8s - loss: 0.6458 - accuracy: 0.6196 - val_loss: 0.9274 - val_accuracy: 0.5114\n","\n","Epoch 00056: val_loss did not improve from 0.57724\n","Epoch 57/1000\n"," - 8s - loss: 0.6387 - accuracy: 0.6267 - val_loss: 0.7375 - val_accuracy: 0.4851\n","\n","Epoch 00057: val_loss did not improve from 0.57724\n","Epoch 58/1000\n"," - 8s - loss: 0.6420 - accuracy: 0.6236 - val_loss: 0.6276 - val_accuracy: 0.4915\n","\n","Epoch 00058: val_loss did not improve from 0.57724\n","Epoch 59/1000\n"," - 8s - loss: 0.6405 - accuracy: 0.6228 - val_loss: 0.7346 - val_accuracy: 0.4861\n","\n","Epoch 00059: val_loss did not improve from 0.57724\n","Epoch 60/1000\n"," - 8s - loss: 0.6408 - accuracy: 0.6194 - val_loss: 0.8710 - val_accuracy: 0.5035\n","\n","Epoch 00060: val_loss did not improve from 0.57724\n","Epoch 61/1000\n"," - 8s - loss: 0.6338 - accuracy: 0.6385 - val_loss: 0.8993 - val_accuracy: 0.5065\n","\n","Epoch 00061: val_loss did not improve from 0.57724\n","Epoch 62/1000\n"," - 8s - loss: 0.6342 - accuracy: 0.6357 - val_loss: 0.7694 - val_accuracy: 0.5075\n","\n","Epoch 00062: val_loss did not improve from 0.57724\n","Epoch 63/1000\n"," - 8s - loss: 0.6316 - accuracy: 0.6403 - val_loss: 0.6761 - val_accuracy: 0.5184\n","\n","Epoch 00063: val_loss did not improve from 0.57724\n","Epoch 64/1000\n"," - 8s - loss: 0.6306 - accuracy: 0.6412 - val_loss: 0.9254 - val_accuracy: 0.5100\n","\n","Epoch 00064: val_loss did not improve from 0.57724\n","Epoch 65/1000\n"," - 8s - loss: 0.6325 - accuracy: 0.6292 - val_loss: 0.7542 - val_accuracy: 0.4940\n","\n","Epoch 00065: val_loss did not improve from 0.57724\n","Epoch 66/1000\n"," - 8s - loss: 0.6303 - accuracy: 0.6299 - val_loss: 0.9414 - val_accuracy: 0.4900\n","\n","Epoch 00066: val_loss did not improve from 0.57724\n","Epoch 67/1000\n"," - 8s - loss: 0.6247 - accuracy: 0.6445 - val_loss: 0.7967 - val_accuracy: 0.4871\n","\n","Epoch 00067: val_loss did not improve from 0.57724\n","Epoch 68/1000\n"," - 8s - loss: 0.6214 - accuracy: 0.6496 - val_loss: 0.5921 - val_accuracy: 0.4980\n","\n","Epoch 00068: val_loss did not improve from 0.57724\n","Epoch 69/1000\n"," - 8s - loss: 0.6213 - accuracy: 0.6510 - val_loss: 0.6853 - val_accuracy: 0.4856\n","\n","Epoch 00069: val_loss did not improve from 0.57724\n","Epoch 70/1000\n"," - 8s - loss: 0.6205 - accuracy: 0.6460 - val_loss: 0.6795 - val_accuracy: 0.5144\n","\n","Epoch 00070: val_loss did not improve from 0.57724\n","Epoch 71/1000\n"," - 8s - loss: 0.6192 - accuracy: 0.6422 - val_loss: 0.5649 - val_accuracy: 0.4960\n","\n","Epoch 00071: val_loss improved from 0.57724 to 0.56491, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 72/1000\n"," - 8s - loss: 0.6154 - accuracy: 0.6566 - val_loss: 0.7951 - val_accuracy: 0.4836\n","\n","Epoch 00072: val_loss did not improve from 0.56491\n","Epoch 73/1000\n"," - 8s - loss: 0.6156 - accuracy: 0.6554 - val_loss: 0.9381 - val_accuracy: 0.5100\n","\n","Epoch 00073: val_loss did not improve from 0.56491\n","Epoch 74/1000\n"," - 8s - loss: 0.6110 - accuracy: 0.6551 - val_loss: 0.9215 - val_accuracy: 0.4930\n","\n","Epoch 00074: val_loss did not improve from 0.56491\n","Epoch 75/1000\n"," - 8s - loss: 0.6052 - accuracy: 0.6676 - val_loss: 0.6624 - val_accuracy: 0.4851\n","\n","Epoch 00075: val_loss did not improve from 0.56491\n","Epoch 76/1000\n"," - 8s - loss: 0.6087 - accuracy: 0.6612 - val_loss: 0.6107 - val_accuracy: 0.5000\n","\n","Epoch 00076: val_loss did not improve from 0.56491\n","Epoch 77/1000\n"," - 8s - loss: 0.6118 - accuracy: 0.6538 - val_loss: 0.6750 - val_accuracy: 0.5129\n","\n","Epoch 00077: val_loss did not improve from 0.56491\n","Epoch 78/1000\n"," - 8s - loss: 0.6063 - accuracy: 0.6662 - val_loss: 0.4799 - val_accuracy: 0.4950\n","\n","Epoch 00078: val_loss improved from 0.56491 to 0.47992, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 79/1000\n"," - 8s - loss: 0.5976 - accuracy: 0.6725 - val_loss: 0.6596 - val_accuracy: 0.5070\n","\n","Epoch 00079: val_loss did not improve from 0.47992\n","Epoch 80/1000\n"," - 8s - loss: 0.5993 - accuracy: 0.6712 - val_loss: 1.1618 - val_accuracy: 0.5095\n","\n","Epoch 00080: val_loss did not improve from 0.47992\n","Epoch 81/1000\n"," - 8s - loss: 0.5955 - accuracy: 0.6705 - val_loss: 1.0474 - val_accuracy: 0.5025\n","\n","Epoch 00081: val_loss did not improve from 0.47992\n","Epoch 82/1000\n"," - 8s - loss: 0.5932 - accuracy: 0.6730 - val_loss: 0.8007 - val_accuracy: 0.5025\n","\n","Epoch 00082: val_loss did not improve from 0.47992\n","Epoch 83/1000\n"," - 8s - loss: 0.6011 - accuracy: 0.6679 - val_loss: 0.6797 - val_accuracy: 0.4975\n","\n","Epoch 00083: val_loss did not improve from 0.47992\n","Epoch 84/1000\n"," - 8s - loss: 0.5929 - accuracy: 0.6744 - val_loss: 1.2278 - val_accuracy: 0.5154\n","\n","Epoch 00084: val_loss did not improve from 0.47992\n","Epoch 85/1000\n"," - 8s - loss: 0.5851 - accuracy: 0.6745 - val_loss: 0.7723 - val_accuracy: 0.5179\n","\n","Epoch 00085: val_loss did not improve from 0.47992\n","Epoch 86/1000\n"," - 8s - loss: 0.5871 - accuracy: 0.6815 - val_loss: 0.7968 - val_accuracy: 0.5204\n","\n","Epoch 00086: val_loss did not improve from 0.47992\n","Epoch 87/1000\n"," - 8s - loss: 0.5883 - accuracy: 0.6841 - val_loss: 0.6211 - val_accuracy: 0.5229\n","\n","Epoch 00087: val_loss did not improve from 0.47992\n","Epoch 88/1000\n"," - 8s - loss: 0.5747 - accuracy: 0.6946 - val_loss: 0.6412 - val_accuracy: 0.5144\n","\n","Epoch 00088: val_loss did not improve from 0.47992\n","Epoch 89/1000\n"," - 8s - loss: 0.5842 - accuracy: 0.6850 - val_loss: 1.2039 - val_accuracy: 0.5109\n","\n","Epoch 00089: val_loss did not improve from 0.47992\n","Epoch 90/1000\n"," - 8s - loss: 0.5799 - accuracy: 0.6853 - val_loss: 0.9576 - val_accuracy: 0.5139\n","\n","Epoch 00090: val_loss did not improve from 0.47992\n","Epoch 91/1000\n"," - 8s - loss: 0.5743 - accuracy: 0.7001 - val_loss: 0.5541 - val_accuracy: 0.5010\n","\n","Epoch 00091: val_loss did not improve from 0.47992\n","Epoch 92/1000\n"," - 8s - loss: 0.5716 - accuracy: 0.6914 - val_loss: 1.0457 - val_accuracy: 0.5090\n","\n","Epoch 00092: val_loss did not improve from 0.47992\n","Epoch 93/1000\n"," - 8s - loss: 0.5808 - accuracy: 0.6903 - val_loss: 1.1398 - val_accuracy: 0.5040\n","\n","Epoch 00093: val_loss did not improve from 0.47992\n","Epoch 94/1000\n"," - 8s - loss: 0.5736 - accuracy: 0.6904 - val_loss: 0.8379 - val_accuracy: 0.5114\n","\n","Epoch 00094: val_loss did not improve from 0.47992\n","Epoch 95/1000\n"," - 8s - loss: 0.5609 - accuracy: 0.7049 - val_loss: 0.7212 - val_accuracy: 0.5139\n","\n","Epoch 00095: val_loss did not improve from 0.47992\n","Epoch 96/1000\n"," - 8s - loss: 0.5628 - accuracy: 0.7040 - val_loss: 0.7393 - val_accuracy: 0.5109\n","\n","Epoch 00096: val_loss did not improve from 0.47992\n","Epoch 97/1000\n"," - 8s - loss: 0.5617 - accuracy: 0.7037 - val_loss: 0.7766 - val_accuracy: 0.5100\n","\n","Epoch 00097: val_loss did not improve from 0.47992\n","Epoch 98/1000\n"," - 8s - loss: 0.5528 - accuracy: 0.7089 - val_loss: 1.0119 - val_accuracy: 0.5124\n","\n","Epoch 00098: val_loss did not improve from 0.47992\n","Epoch 99/1000\n"," - 8s - loss: 0.5534 - accuracy: 0.7082 - val_loss: 0.6406 - val_accuracy: 0.5080\n","\n","Epoch 00099: val_loss did not improve from 0.47992\n","Epoch 100/1000\n"," - 8s - loss: 0.5546 - accuracy: 0.7031 - val_loss: 0.9229 - val_accuracy: 0.5060\n","\n","Epoch 00100: val_loss did not improve from 0.47992\n","Epoch 101/1000\n"," - 8s - loss: 0.5589 - accuracy: 0.7067 - val_loss: 0.6705 - val_accuracy: 0.5040\n","\n","Epoch 00101: val_loss did not improve from 0.47992\n","Epoch 102/1000\n"," - 8s - loss: 0.5588 - accuracy: 0.7039 - val_loss: 0.8919 - val_accuracy: 0.5025\n","\n","Epoch 00102: val_loss did not improve from 0.47992\n","Epoch 103/1000\n"," - 8s - loss: 0.5425 - accuracy: 0.7181 - val_loss: 0.8108 - val_accuracy: 0.4965\n","\n","Epoch 00103: val_loss did not improve from 0.47992\n","Epoch 104/1000\n"," - 8s - loss: 0.5404 - accuracy: 0.7238 - val_loss: 0.5838 - val_accuracy: 0.5045\n","\n","Epoch 00104: val_loss did not improve from 0.47992\n","Epoch 105/1000\n"," - 8s - loss: 0.5468 - accuracy: 0.7191 - val_loss: 0.8428 - val_accuracy: 0.5075\n","\n","Epoch 00105: val_loss did not improve from 0.47992\n","Epoch 106/1000\n"," - 8s - loss: 0.5369 - accuracy: 0.7268 - val_loss: 0.7221 - val_accuracy: 0.4985\n","\n","Epoch 00106: val_loss did not improve from 0.47992\n","Epoch 107/1000\n"," - 8s - loss: 0.5378 - accuracy: 0.7211 - val_loss: 1.1848 - val_accuracy: 0.5249\n","\n","Epoch 00107: val_loss did not improve from 0.47992\n","Epoch 108/1000\n"," - 8s - loss: 0.5374 - accuracy: 0.7208 - val_loss: 0.6829 - val_accuracy: 0.5100\n","\n","Epoch 00108: val_loss did not improve from 0.47992\n","Epoch 109/1000\n"," - 8s - loss: 0.5286 - accuracy: 0.7236 - val_loss: 0.8235 - val_accuracy: 0.5124\n","\n","Epoch 00109: val_loss did not improve from 0.47992\n","Epoch 110/1000\n"," - 8s - loss: 0.5258 - accuracy: 0.7301 - val_loss: 1.0768 - val_accuracy: 0.5060\n","\n","Epoch 00110: val_loss did not improve from 0.47992\n","Epoch 111/1000\n"," - 8s - loss: 0.5243 - accuracy: 0.7382 - val_loss: 0.6576 - val_accuracy: 0.5109\n","\n","Epoch 00111: val_loss did not improve from 0.47992\n","Epoch 112/1000\n"," - 8s - loss: 0.5217 - accuracy: 0.7334 - val_loss: 0.7976 - val_accuracy: 0.4995\n","\n","Epoch 00112: val_loss did not improve from 0.47992\n","Epoch 113/1000\n"," - 8s - loss: 0.5294 - accuracy: 0.7294 - val_loss: 0.7709 - val_accuracy: 0.4950\n","\n","Epoch 00113: val_loss did not improve from 0.47992\n","Epoch 114/1000\n"," - 8s - loss: 0.5309 - accuracy: 0.7284 - val_loss: 1.0500 - val_accuracy: 0.5070\n","\n","Epoch 00114: val_loss did not improve from 0.47992\n","Epoch 115/1000\n"," - 8s - loss: 0.5219 - accuracy: 0.7356 - val_loss: 1.0485 - val_accuracy: 0.5005\n","\n","Epoch 00115: val_loss did not improve from 0.47992\n","Epoch 116/1000\n"," - 8s - loss: 0.5160 - accuracy: 0.7362 - val_loss: 0.7317 - val_accuracy: 0.5070\n","\n","Epoch 00116: val_loss did not improve from 0.47992\n","Epoch 117/1000\n"," - 8s - loss: 0.5096 - accuracy: 0.7422 - val_loss: 0.7630 - val_accuracy: 0.4990\n","\n","Epoch 00117: val_loss did not improve from 0.47992\n","Epoch 118/1000\n"," - 8s - loss: 0.5133 - accuracy: 0.7367 - val_loss: 1.1528 - val_accuracy: 0.5124\n","\n","Epoch 00118: val_loss did not improve from 0.47992\n","Epoch 119/1000\n"," - 8s - loss: 0.5109 - accuracy: 0.7454 - val_loss: 1.4829 - val_accuracy: 0.4945\n","\n","Epoch 00119: val_loss did not improve from 0.47992\n","Epoch 120/1000\n"," - 8s - loss: 0.5041 - accuracy: 0.7477 - val_loss: 0.6121 - val_accuracy: 0.5010\n","\n","Epoch 00120: val_loss did not improve from 0.47992\n","Epoch 121/1000\n"," - 8s - loss: 0.5060 - accuracy: 0.7410 - val_loss: 1.1047 - val_accuracy: 0.5159\n","\n","Epoch 00121: val_loss did not improve from 0.47992\n","Epoch 122/1000\n"," - 8s - loss: 0.5075 - accuracy: 0.7490 - val_loss: 1.1015 - val_accuracy: 0.4955\n","\n","Epoch 00122: val_loss did not improve from 0.47992\n","Epoch 123/1000\n"," - 8s - loss: 0.4989 - accuracy: 0.7454 - val_loss: 1.0097 - val_accuracy: 0.5025\n","\n","Epoch 00123: val_loss did not improve from 0.47992\n","Epoch 124/1000\n"," - 8s - loss: 0.5013 - accuracy: 0.7500 - val_loss: 1.4331 - val_accuracy: 0.5045\n","\n","Epoch 00124: val_loss did not improve from 0.47992\n","Epoch 125/1000\n"," - 8s - loss: 0.4999 - accuracy: 0.7495 - val_loss: 0.9736 - val_accuracy: 0.4965\n","\n","Epoch 00125: val_loss did not improve from 0.47992\n","Epoch 126/1000\n"," - 8s - loss: 0.4850 - accuracy: 0.7631 - val_loss: 1.4989 - val_accuracy: 0.4945\n","\n","Epoch 00126: val_loss did not improve from 0.47992\n","Epoch 127/1000\n"," - 8s - loss: 0.4914 - accuracy: 0.7533 - val_loss: 0.8621 - val_accuracy: 0.5129\n","\n","Epoch 00127: val_loss did not improve from 0.47992\n","Epoch 128/1000\n"," - 8s - loss: 0.4885 - accuracy: 0.7623 - val_loss: 1.0513 - val_accuracy: 0.5104\n","\n","Epoch 00128: val_loss did not improve from 0.47992\n","Epoch 129/1000\n"," - 8s - loss: 0.4739 - accuracy: 0.7692 - val_loss: 1.1323 - val_accuracy: 0.4905\n","\n","Epoch 00129: val_loss did not improve from 0.47992\n","Epoch 130/1000\n"," - 8s - loss: 0.4891 - accuracy: 0.7522 - val_loss: 0.9318 - val_accuracy: 0.5114\n","\n","Epoch 00130: val_loss did not improve from 0.47992\n","Epoch 131/1000\n"," - 8s - loss: 0.4785 - accuracy: 0.7736 - val_loss: 0.8621 - val_accuracy: 0.4990\n","\n","Epoch 00131: val_loss did not improve from 0.47992\n","Epoch 132/1000\n"," - 8s - loss: 0.4773 - accuracy: 0.7644 - val_loss: 0.7533 - val_accuracy: 0.5045\n","\n","Epoch 00132: val_loss did not improve from 0.47992\n","Epoch 133/1000\n"," - 8s - loss: 0.4806 - accuracy: 0.7714 - val_loss: 1.0961 - val_accuracy: 0.5269\n","\n","Epoch 00133: val_loss did not improve from 0.47992\n","Epoch 134/1000\n"," - 8s - loss: 0.4710 - accuracy: 0.7706 - val_loss: 0.6481 - val_accuracy: 0.5060\n","\n","Epoch 00134: val_loss did not improve from 0.47992\n","Epoch 135/1000\n"," - 8s - loss: 0.4751 - accuracy: 0.7664 - val_loss: 1.0835 - val_accuracy: 0.5060\n","\n","Epoch 00135: val_loss did not improve from 0.47992\n","Epoch 136/1000\n"," - 8s - loss: 0.4687 - accuracy: 0.7732 - val_loss: 0.4733 - val_accuracy: 0.4945\n","\n","Epoch 00136: val_loss improved from 0.47992 to 0.47328, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 137/1000\n"," - 8s - loss: 0.4640 - accuracy: 0.7754 - val_loss: 1.6097 - val_accuracy: 0.5045\n","\n","Epoch 00137: val_loss did not improve from 0.47328\n","Epoch 138/1000\n"," - 8s - loss: 0.4672 - accuracy: 0.7777 - val_loss: 1.2077 - val_accuracy: 0.5100\n","\n","Epoch 00138: val_loss did not improve from 0.47328\n","Epoch 139/1000\n"," - 8s - loss: 0.4619 - accuracy: 0.7779 - val_loss: 1.1532 - val_accuracy: 0.5035\n","\n","Epoch 00139: val_loss did not improve from 0.47328\n","Epoch 140/1000\n"," - 8s - loss: 0.4581 - accuracy: 0.7742 - val_loss: 1.0547 - val_accuracy: 0.5040\n","\n","Epoch 00140: val_loss did not improve from 0.47328\n","Epoch 141/1000\n"," - 8s - loss: 0.4569 - accuracy: 0.7750 - val_loss: 0.9635 - val_accuracy: 0.5020\n","\n","Epoch 00141: val_loss did not improve from 0.47328\n","Epoch 142/1000\n"," - 8s - loss: 0.4510 - accuracy: 0.7838 - val_loss: 0.8255 - val_accuracy: 0.5005\n","\n","Epoch 00142: val_loss did not improve from 0.47328\n","Epoch 143/1000\n"," - 8s - loss: 0.4525 - accuracy: 0.7820 - val_loss: 1.1351 - val_accuracy: 0.5055\n","\n","Epoch 00143: val_loss did not improve from 0.47328\n","Epoch 144/1000\n"," - 8s - loss: 0.4585 - accuracy: 0.7799 - val_loss: 0.9764 - val_accuracy: 0.5015\n","\n","Epoch 00144: val_loss did not improve from 0.47328\n","Epoch 145/1000\n"," - 8s - loss: 0.4533 - accuracy: 0.7827 - val_loss: 0.6964 - val_accuracy: 0.5030\n","\n","Epoch 00145: val_loss did not improve from 0.47328\n","Epoch 146/1000\n"," - 8s - loss: 0.4434 - accuracy: 0.7888 - val_loss: 0.8206 - val_accuracy: 0.4910\n","\n","Epoch 00146: val_loss did not improve from 0.47328\n","Epoch 147/1000\n"," - 8s - loss: 0.4429 - accuracy: 0.7900 - val_loss: 1.4692 - val_accuracy: 0.5030\n","\n","Epoch 00147: val_loss did not improve from 0.47328\n","Epoch 148/1000\n"," - 8s - loss: 0.4357 - accuracy: 0.8023 - val_loss: 0.8413 - val_accuracy: 0.4836\n","\n","Epoch 00148: val_loss did not improve from 0.47328\n","Epoch 149/1000\n"," - 8s - loss: 0.4464 - accuracy: 0.7878 - val_loss: 0.4618 - val_accuracy: 0.4915\n","\n","Epoch 00149: val_loss improved from 0.47328 to 0.46185, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 150/1000\n"," - 8s - loss: 0.4348 - accuracy: 0.8006 - val_loss: 0.8010 - val_accuracy: 0.4990\n","\n","Epoch 00150: val_loss did not improve from 0.46185\n","Epoch 151/1000\n"," - 8s - loss: 0.4344 - accuracy: 0.7926 - val_loss: 0.8507 - val_accuracy: 0.5030\n","\n","Epoch 00151: val_loss did not improve from 0.46185\n","Epoch 152/1000\n"," - 8s - loss: 0.4416 - accuracy: 0.7883 - val_loss: 1.0091 - val_accuracy: 0.4900\n","\n","Epoch 00152: val_loss did not improve from 0.46185\n","Epoch 153/1000\n"," - 8s - loss: 0.4282 - accuracy: 0.7984 - val_loss: 0.8170 - val_accuracy: 0.4945\n","\n","Epoch 00153: val_loss did not improve from 0.46185\n","Epoch 154/1000\n"," - 8s - loss: 0.4199 - accuracy: 0.8071 - val_loss: 0.8586 - val_accuracy: 0.5035\n","\n","Epoch 00154: val_loss did not improve from 0.46185\n","Epoch 155/1000\n"," - 8s - loss: 0.4214 - accuracy: 0.8076 - val_loss: 1.3167 - val_accuracy: 0.4915\n","\n","Epoch 00155: val_loss did not improve from 0.46185\n","Epoch 156/1000\n"," - 8s - loss: 0.4244 - accuracy: 0.8036 - val_loss: 2.0943 - val_accuracy: 0.4960\n","\n","Epoch 00156: val_loss did not improve from 0.46185\n","Epoch 157/1000\n"," - 8s - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.8944 - val_accuracy: 0.4975\n","\n","Epoch 00157: val_loss did not improve from 0.46185\n","Epoch 158/1000\n"," - 8s - loss: 0.4291 - accuracy: 0.7979 - val_loss: 1.0434 - val_accuracy: 0.5030\n","\n","Epoch 00158: val_loss did not improve from 0.46185\n","Epoch 159/1000\n"," - 8s - loss: 0.4169 - accuracy: 0.8089 - val_loss: 1.2394 - val_accuracy: 0.4965\n","\n","Epoch 00159: val_loss did not improve from 0.46185\n","Epoch 160/1000\n"," - 8s - loss: 0.4106 - accuracy: 0.8127 - val_loss: 1.5674 - val_accuracy: 0.5085\n","\n","Epoch 00160: val_loss did not improve from 0.46185\n","Epoch 161/1000\n"," - 8s - loss: 0.4178 - accuracy: 0.8059 - val_loss: 0.9343 - val_accuracy: 0.4950\n","\n","Epoch 00161: val_loss did not improve from 0.46185\n","Epoch 162/1000\n"," - 8s - loss: 0.4123 - accuracy: 0.8107 - val_loss: 1.3709 - val_accuracy: 0.5109\n","\n","Epoch 00162: val_loss did not improve from 0.46185\n","Epoch 163/1000\n"," - 8s - loss: 0.4119 - accuracy: 0.8107 - val_loss: 1.0789 - val_accuracy: 0.4995\n","\n","Epoch 00163: val_loss did not improve from 0.46185\n","Epoch 164/1000\n"," - 8s - loss: 0.4102 - accuracy: 0.8152 - val_loss: 1.2043 - val_accuracy: 0.5050\n","\n","Epoch 00164: val_loss did not improve from 0.46185\n","Epoch 165/1000\n"," - 8s - loss: 0.4088 - accuracy: 0.8102 - val_loss: 1.5656 - val_accuracy: 0.5055\n","\n","Epoch 00165: val_loss did not improve from 0.46185\n","Epoch 166/1000\n"," - 8s - loss: 0.4030 - accuracy: 0.8180 - val_loss: 1.4149 - val_accuracy: 0.4975\n","\n","Epoch 00166: val_loss did not improve from 0.46185\n","Epoch 167/1000\n"," - 8s - loss: 0.4078 - accuracy: 0.8097 - val_loss: 0.9222 - val_accuracy: 0.5030\n","\n","Epoch 00167: val_loss did not improve from 0.46185\n","Epoch 168/1000\n"," - 8s - loss: 0.3953 - accuracy: 0.8203 - val_loss: 1.6039 - val_accuracy: 0.5015\n","\n","Epoch 00168: val_loss did not improve from 0.46185\n","Epoch 169/1000\n"," - 8s - loss: 0.4000 - accuracy: 0.8091 - val_loss: 0.9687 - val_accuracy: 0.5020\n","\n","Epoch 00169: val_loss did not improve from 0.46185\n","Epoch 170/1000\n"," - 8s - loss: 0.3968 - accuracy: 0.8192 - val_loss: 1.4731 - val_accuracy: 0.4975\n","\n","Epoch 00170: val_loss did not improve from 0.46185\n","Epoch 171/1000\n"," - 8s - loss: 0.3950 - accuracy: 0.8225 - val_loss: 1.1643 - val_accuracy: 0.4970\n","\n","Epoch 00171: val_loss did not improve from 0.46185\n","Epoch 172/1000\n"," - 8s - loss: 0.3859 - accuracy: 0.8296 - val_loss: 0.5225 - val_accuracy: 0.4995\n","\n","Epoch 00172: val_loss did not improve from 0.46185\n","Epoch 173/1000\n"," - 8s - loss: 0.3877 - accuracy: 0.8281 - val_loss: 0.5115 - val_accuracy: 0.5030\n","\n","Epoch 00173: val_loss did not improve from 0.46185\n","Epoch 174/1000\n"," - 8s - loss: 0.3850 - accuracy: 0.8308 - val_loss: 1.2654 - val_accuracy: 0.5005\n","\n","Epoch 00174: val_loss did not improve from 0.46185\n","Epoch 175/1000\n"," - 8s - loss: 0.3791 - accuracy: 0.8315 - val_loss: 1.2504 - val_accuracy: 0.5085\n","\n","Epoch 00175: val_loss did not improve from 0.46185\n","Epoch 176/1000\n"," - 8s - loss: 0.3749 - accuracy: 0.8305 - val_loss: 1.4830 - val_accuracy: 0.5144\n","\n","Epoch 00176: val_loss did not improve from 0.46185\n","Epoch 177/1000\n"," - 8s - loss: 0.3836 - accuracy: 0.8255 - val_loss: 1.1012 - val_accuracy: 0.5065\n","\n","Epoch 00177: val_loss did not improve from 0.46185\n","Epoch 178/1000\n"," - 8s - loss: 0.3859 - accuracy: 0.8217 - val_loss: 1.6716 - val_accuracy: 0.5055\n","\n","Epoch 00178: val_loss did not improve from 0.46185\n","Epoch 179/1000\n"," - 8s - loss: 0.3727 - accuracy: 0.8346 - val_loss: 1.3279 - val_accuracy: 0.4955\n","\n","Epoch 00179: val_loss did not improve from 0.46185\n","Epoch 180/1000\n"," - 8s - loss: 0.3773 - accuracy: 0.8266 - val_loss: 1.6456 - val_accuracy: 0.5000\n","\n","Epoch 00180: val_loss did not improve from 0.46185\n","Epoch 181/1000\n"," - 8s - loss: 0.3819 - accuracy: 0.8228 - val_loss: 1.0236 - val_accuracy: 0.5020\n","\n","Epoch 00181: val_loss did not improve from 0.46185\n","Epoch 182/1000\n"," - 8s - loss: 0.3736 - accuracy: 0.8379 - val_loss: 1.8669 - val_accuracy: 0.5000\n","\n","Epoch 00182: val_loss did not improve from 0.46185\n","Epoch 183/1000\n"," - 8s - loss: 0.3640 - accuracy: 0.8411 - val_loss: 1.0946 - val_accuracy: 0.4990\n","\n","Epoch 00183: val_loss did not improve from 0.46185\n","Epoch 184/1000\n"," - 8s - loss: 0.3644 - accuracy: 0.8409 - val_loss: 2.0480 - val_accuracy: 0.5070\n","\n","Epoch 00184: val_loss did not improve from 0.46185\n","Epoch 185/1000\n"," - 8s - loss: 0.3694 - accuracy: 0.8351 - val_loss: 0.7378 - val_accuracy: 0.4861\n","\n","Epoch 00185: val_loss did not improve from 0.46185\n","Epoch 186/1000\n"," - 8s - loss: 0.3592 - accuracy: 0.8393 - val_loss: 0.6737 - val_accuracy: 0.4960\n","\n","Epoch 00186: val_loss did not improve from 0.46185\n","Epoch 187/1000\n"," - 8s - loss: 0.3601 - accuracy: 0.8480 - val_loss: 1.4417 - val_accuracy: 0.4925\n","\n","Epoch 00187: val_loss did not improve from 0.46185\n","Epoch 188/1000\n"," - 8s - loss: 0.3523 - accuracy: 0.8494 - val_loss: 1.0572 - val_accuracy: 0.5000\n","\n","Epoch 00188: val_loss did not improve from 0.46185\n","Epoch 189/1000\n"," - 8s - loss: 0.3556 - accuracy: 0.8406 - val_loss: 1.2045 - val_accuracy: 0.5060\n","\n","Epoch 00189: val_loss did not improve from 0.46185\n","Epoch 190/1000\n"," - 8s - loss: 0.3493 - accuracy: 0.8469 - val_loss: 1.3643 - val_accuracy: 0.4985\n","\n","Epoch 00190: val_loss did not improve from 0.46185\n","Epoch 191/1000\n"," - 8s - loss: 0.3498 - accuracy: 0.8467 - val_loss: 0.8957 - val_accuracy: 0.4960\n","\n","Epoch 00191: val_loss did not improve from 0.46185\n","Epoch 192/1000\n"," - 8s - loss: 0.3595 - accuracy: 0.8389 - val_loss: 1.6559 - val_accuracy: 0.4965\n","\n","Epoch 00192: val_loss did not improve from 0.46185\n","Epoch 193/1000\n"," - 8s - loss: 0.3489 - accuracy: 0.8494 - val_loss: 0.7010 - val_accuracy: 0.4861\n","\n","Epoch 00193: val_loss did not improve from 0.46185\n","Epoch 194/1000\n"," - 8s - loss: 0.3382 - accuracy: 0.8524 - val_loss: 1.0334 - val_accuracy: 0.4970\n","\n","Epoch 00194: val_loss did not improve from 0.46185\n","Epoch 195/1000\n"," - 8s - loss: 0.3478 - accuracy: 0.8499 - val_loss: 1.1337 - val_accuracy: 0.4776\n","\n","Epoch 00195: val_loss did not improve from 0.46185\n","Epoch 196/1000\n"," - 8s - loss: 0.3396 - accuracy: 0.8432 - val_loss: 1.1689 - val_accuracy: 0.4950\n","\n","Epoch 00196: val_loss did not improve from 0.46185\n","Epoch 197/1000\n"," - 8s - loss: 0.3300 - accuracy: 0.8562 - val_loss: 1.9084 - val_accuracy: 0.5010\n","\n","Epoch 00197: val_loss did not improve from 0.46185\n","Epoch 198/1000\n"," - 8s - loss: 0.3392 - accuracy: 0.8512 - val_loss: 0.7232 - val_accuracy: 0.4980\n","\n","Epoch 00198: val_loss did not improve from 0.46185\n","Epoch 199/1000\n"," - 8s - loss: 0.3458 - accuracy: 0.8472 - val_loss: 1.6830 - val_accuracy: 0.4985\n","\n","Epoch 00199: val_loss did not improve from 0.46185\n","Epoch 200/1000\n"," - 8s - loss: 0.3302 - accuracy: 0.8593 - val_loss: 1.3258 - val_accuracy: 0.4900\n","\n","Epoch 00200: val_loss did not improve from 0.46185\n","Epoch 201/1000\n"," - 8s - loss: 0.3270 - accuracy: 0.8631 - val_loss: 0.8578 - val_accuracy: 0.4920\n","\n","Epoch 00201: val_loss did not improve from 0.46185\n","Epoch 202/1000\n"," - 8s - loss: 0.3425 - accuracy: 0.8517 - val_loss: 1.7307 - val_accuracy: 0.4935\n","\n","Epoch 00202: val_loss did not improve from 0.46185\n","Epoch 203/1000\n"," - 8s - loss: 0.3204 - accuracy: 0.8630 - val_loss: 1.4504 - val_accuracy: 0.4940\n","\n","Epoch 00203: val_loss did not improve from 0.46185\n","Epoch 204/1000\n"," - 8s - loss: 0.3310 - accuracy: 0.8572 - val_loss: 2.8386 - val_accuracy: 0.5035\n","\n","Epoch 00204: val_loss did not improve from 0.46185\n","Epoch 205/1000\n"," - 8s - loss: 0.3277 - accuracy: 0.8560 - val_loss: 1.1424 - val_accuracy: 0.5104\n","\n","Epoch 00205: val_loss did not improve from 0.46185\n","Epoch 206/1000\n"," - 8s - loss: 0.3295 - accuracy: 0.8547 - val_loss: 1.0320 - val_accuracy: 0.4975\n","\n","Epoch 00206: val_loss did not improve from 0.46185\n","Epoch 207/1000\n"," - 8s - loss: 0.3277 - accuracy: 0.8620 - val_loss: 1.3696 - val_accuracy: 0.5010\n","\n","Epoch 00207: val_loss did not improve from 0.46185\n","Epoch 208/1000\n"," - 8s - loss: 0.3223 - accuracy: 0.8590 - val_loss: 1.3120 - val_accuracy: 0.5035\n","\n","Epoch 00208: val_loss did not improve from 0.46185\n","Epoch 209/1000\n"," - 8s - loss: 0.3146 - accuracy: 0.8681 - val_loss: 1.2658 - val_accuracy: 0.5109\n","\n","Epoch 00209: val_loss did not improve from 0.46185\n","Epoch 210/1000\n"," - 8s - loss: 0.3094 - accuracy: 0.8655 - val_loss: 0.9672 - val_accuracy: 0.4945\n","\n","Epoch 00210: val_loss did not improve from 0.46185\n","Epoch 211/1000\n"," - 8s - loss: 0.3086 - accuracy: 0.8645 - val_loss: 1.5435 - val_accuracy: 0.5010\n","\n","Epoch 00211: val_loss did not improve from 0.46185\n","Epoch 212/1000\n"," - 8s - loss: 0.3152 - accuracy: 0.8602 - val_loss: 1.6468 - val_accuracy: 0.4900\n","\n","Epoch 00212: val_loss did not improve from 0.46185\n","Epoch 213/1000\n"," - 8s - loss: 0.3212 - accuracy: 0.8616 - val_loss: 0.8015 - val_accuracy: 0.4975\n","\n","Epoch 00213: val_loss did not improve from 0.46185\n","Epoch 214/1000\n"," - 8s - loss: 0.3146 - accuracy: 0.8628 - val_loss: 1.0050 - val_accuracy: 0.4970\n","\n","Epoch 00214: val_loss did not improve from 0.46185\n","Epoch 215/1000\n"," - 8s - loss: 0.3040 - accuracy: 0.8728 - val_loss: 0.8825 - val_accuracy: 0.4970\n","\n","Epoch 00215: val_loss did not improve from 0.46185\n","Epoch 216/1000\n"," - 8s - loss: 0.2937 - accuracy: 0.8811 - val_loss: 0.5995 - val_accuracy: 0.4990\n","\n","Epoch 00216: val_loss did not improve from 0.46185\n","Epoch 217/1000\n"," - 8s - loss: 0.2986 - accuracy: 0.8749 - val_loss: 1.1525 - val_accuracy: 0.4910\n","\n","Epoch 00217: val_loss did not improve from 0.46185\n","Epoch 218/1000\n"," - 8s - loss: 0.3029 - accuracy: 0.8676 - val_loss: 2.5464 - val_accuracy: 0.5025\n","\n","Epoch 00218: val_loss did not improve from 0.46185\n","Epoch 219/1000\n"," - 8s - loss: 0.2984 - accuracy: 0.8797 - val_loss: 1.8734 - val_accuracy: 0.5010\n","\n","Epoch 00219: val_loss did not improve from 0.46185\n","Epoch 220/1000\n"," - 8s - loss: 0.2967 - accuracy: 0.8759 - val_loss: 1.2754 - val_accuracy: 0.4970\n","\n","Epoch 00220: val_loss did not improve from 0.46185\n","Epoch 221/1000\n"," - 8s - loss: 0.2944 - accuracy: 0.8792 - val_loss: 1.8471 - val_accuracy: 0.5030\n","\n","Epoch 00221: val_loss did not improve from 0.46185\n","Epoch 222/1000\n"," - 8s - loss: 0.2965 - accuracy: 0.8772 - val_loss: 1.0536 - val_accuracy: 0.5010\n","\n","Epoch 00222: val_loss did not improve from 0.46185\n","Epoch 223/1000\n"," - 8s - loss: 0.2959 - accuracy: 0.8731 - val_loss: 0.9731 - val_accuracy: 0.5030\n","\n","Epoch 00223: val_loss did not improve from 0.46185\n","Epoch 224/1000\n"," - 8s - loss: 0.3004 - accuracy: 0.8744 - val_loss: 1.7145 - val_accuracy: 0.5075\n","\n","Epoch 00224: val_loss did not improve from 0.46185\n","Epoch 225/1000\n"," - 8s - loss: 0.2933 - accuracy: 0.8777 - val_loss: 1.6303 - val_accuracy: 0.5015\n","\n","Epoch 00225: val_loss did not improve from 0.46185\n","Epoch 226/1000\n"," - 8s - loss: 0.2880 - accuracy: 0.8777 - val_loss: 1.2660 - val_accuracy: 0.5030\n","\n","Epoch 00226: val_loss did not improve from 0.46185\n","Epoch 227/1000\n"," - 8s - loss: 0.2842 - accuracy: 0.8835 - val_loss: 2.3713 - val_accuracy: 0.4851\n","\n","Epoch 00227: val_loss did not improve from 0.46185\n","Epoch 228/1000\n"," - 8s - loss: 0.2923 - accuracy: 0.8781 - val_loss: 1.8699 - val_accuracy: 0.4945\n","\n","Epoch 00228: val_loss did not improve from 0.46185\n","Epoch 229/1000\n"," - 8s - loss: 0.2765 - accuracy: 0.8842 - val_loss: 1.4921 - val_accuracy: 0.5045\n","\n","Epoch 00229: val_loss did not improve from 0.46185\n","Epoch 230/1000\n"," - 8s - loss: 0.2839 - accuracy: 0.8839 - val_loss: 1.5491 - val_accuracy: 0.5030\n","\n","Epoch 00230: val_loss did not improve from 0.46185\n","Epoch 231/1000\n"," - 8s - loss: 0.2761 - accuracy: 0.8864 - val_loss: 1.2690 - val_accuracy: 0.4970\n","\n","Epoch 00231: val_loss did not improve from 0.46185\n","Epoch 232/1000\n"," - 8s - loss: 0.2824 - accuracy: 0.8774 - val_loss: 2.2743 - val_accuracy: 0.4995\n","\n","Epoch 00232: val_loss did not improve from 0.46185\n","Epoch 233/1000\n"," - 8s - loss: 0.2750 - accuracy: 0.8862 - val_loss: 2.0557 - val_accuracy: 0.4975\n","\n","Epoch 00233: val_loss did not improve from 0.46185\n","Epoch 234/1000\n"," - 8s - loss: 0.2734 - accuracy: 0.8859 - val_loss: 0.8909 - val_accuracy: 0.4935\n","\n","Epoch 00234: val_loss did not improve from 0.46185\n","Epoch 235/1000\n"," - 8s - loss: 0.2718 - accuracy: 0.8885 - val_loss: 2.4196 - val_accuracy: 0.4970\n","\n","Epoch 00235: val_loss did not improve from 0.46185\n","Epoch 236/1000\n"," - 8s - loss: 0.2778 - accuracy: 0.8824 - val_loss: 2.2216 - val_accuracy: 0.4990\n","\n","Epoch 00236: val_loss did not improve from 0.46185\n","Epoch 237/1000\n"," - 8s - loss: 0.2725 - accuracy: 0.8882 - val_loss: 2.4035 - val_accuracy: 0.4915\n","\n","Epoch 00237: val_loss did not improve from 0.46185\n","Epoch 238/1000\n"," - 8s - loss: 0.2723 - accuracy: 0.8900 - val_loss: 1.9778 - val_accuracy: 0.4776\n","\n","Epoch 00238: val_loss did not improve from 0.46185\n","Epoch 239/1000\n"," - 8s - loss: 0.2670 - accuracy: 0.8839 - val_loss: 1.2211 - val_accuracy: 0.4881\n","\n","Epoch 00239: val_loss did not improve from 0.46185\n","Epoch 240/1000\n"," - 8s - loss: 0.2615 - accuracy: 0.8932 - val_loss: 2.8521 - val_accuracy: 0.5045\n","\n","Epoch 00240: val_loss did not improve from 0.46185\n","Epoch 241/1000\n"," - 8s - loss: 0.2643 - accuracy: 0.8889 - val_loss: 1.9904 - val_accuracy: 0.4905\n","\n","Epoch 00241: val_loss did not improve from 0.46185\n","Epoch 242/1000\n"," - 8s - loss: 0.2569 - accuracy: 0.8927 - val_loss: 1.5497 - val_accuracy: 0.4960\n","\n","Epoch 00242: val_loss did not improve from 0.46185\n","Epoch 243/1000\n"," - 8s - loss: 0.2655 - accuracy: 0.8880 - val_loss: 1.0246 - val_accuracy: 0.5020\n","\n","Epoch 00243: val_loss did not improve from 0.46185\n","Epoch 244/1000\n"," - 8s - loss: 0.2654 - accuracy: 0.8912 - val_loss: 1.6952 - val_accuracy: 0.5010\n","\n","Epoch 00244: val_loss did not improve from 0.46185\n","Epoch 245/1000\n"," - 8s - loss: 0.2624 - accuracy: 0.8915 - val_loss: 2.0656 - val_accuracy: 0.4990\n","\n","Epoch 00245: val_loss did not improve from 0.46185\n","Epoch 246/1000\n"," - 8s - loss: 0.2612 - accuracy: 0.8870 - val_loss: 1.1619 - val_accuracy: 0.4891\n","\n","Epoch 00246: val_loss did not improve from 0.46185\n","Epoch 247/1000\n"," - 8s - loss: 0.2458 - accuracy: 0.9033 - val_loss: 0.5980 - val_accuracy: 0.4891\n","\n","Epoch 00247: val_loss did not improve from 0.46185\n","Epoch 248/1000\n"," - 8s - loss: 0.2536 - accuracy: 0.8968 - val_loss: 1.7150 - val_accuracy: 0.4965\n","\n","Epoch 00248: val_loss did not improve from 0.46185\n","Epoch 249/1000\n"," - 8s - loss: 0.2528 - accuracy: 0.9010 - val_loss: 1.7139 - val_accuracy: 0.5005\n","\n","Epoch 00249: val_loss did not improve from 0.46185\n","Epoch 250/1000\n"," - 8s - loss: 0.2484 - accuracy: 0.8983 - val_loss: 2.0592 - val_accuracy: 0.4960\n","\n","Epoch 00250: val_loss did not improve from 0.46185\n","Epoch 251/1000\n"," - 8s - loss: 0.2402 - accuracy: 0.9028 - val_loss: 1.1426 - val_accuracy: 0.4955\n","\n","Epoch 00251: val_loss did not improve from 0.46185\n","Epoch 252/1000\n"," - 8s - loss: 0.2478 - accuracy: 0.9036 - val_loss: 0.7687 - val_accuracy: 0.4990\n","\n","Epoch 00252: val_loss did not improve from 0.46185\n","Epoch 253/1000\n"," - 8s - loss: 0.2495 - accuracy: 0.9023 - val_loss: 2.9103 - val_accuracy: 0.5005\n","\n","Epoch 00253: val_loss did not improve from 0.46185\n","Epoch 254/1000\n"," - 8s - loss: 0.2478 - accuracy: 0.8975 - val_loss: 0.4400 - val_accuracy: 0.4910\n","\n","Epoch 00254: val_loss improved from 0.46185 to 0.43998, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 255/1000\n"," - 8s - loss: 0.2339 - accuracy: 0.9035 - val_loss: 1.9157 - val_accuracy: 0.4881\n","\n","Epoch 00255: val_loss did not improve from 0.43998\n","Epoch 256/1000\n"," - 8s - loss: 0.2519 - accuracy: 0.8985 - val_loss: 1.6957 - val_accuracy: 0.4945\n","\n","Epoch 00256: val_loss did not improve from 0.43998\n","Epoch 257/1000\n"," - 8s - loss: 0.2424 - accuracy: 0.9033 - val_loss: 2.5105 - val_accuracy: 0.4950\n","\n","Epoch 00257: val_loss did not improve from 0.43998\n","Epoch 258/1000\n"," - 8s - loss: 0.2324 - accuracy: 0.9059 - val_loss: 1.6406 - val_accuracy: 0.5010\n","\n","Epoch 00258: val_loss did not improve from 0.43998\n","Epoch 259/1000\n"," - 8s - loss: 0.2448 - accuracy: 0.8986 - val_loss: 3.2415 - val_accuracy: 0.4925\n","\n","Epoch 00259: val_loss did not improve from 0.43998\n","Epoch 260/1000\n"," - 8s - loss: 0.2369 - accuracy: 0.9016 - val_loss: 1.0876 - val_accuracy: 0.4945\n","\n","Epoch 00260: val_loss did not improve from 0.43998\n","Epoch 261/1000\n"," - 8s - loss: 0.2314 - accuracy: 0.9063 - val_loss: 1.9031 - val_accuracy: 0.4980\n","\n","Epoch 00261: val_loss did not improve from 0.43998\n","Epoch 262/1000\n"," - 8s - loss: 0.2390 - accuracy: 0.9021 - val_loss: 0.9867 - val_accuracy: 0.5035\n","\n","Epoch 00262: val_loss did not improve from 0.43998\n","Epoch 263/1000\n"," - 8s - loss: 0.2284 - accuracy: 0.9079 - val_loss: 0.8817 - val_accuracy: 0.5050\n","\n","Epoch 00263: val_loss did not improve from 0.43998\n","Epoch 264/1000\n"," - 8s - loss: 0.2305 - accuracy: 0.9071 - val_loss: 2.2898 - val_accuracy: 0.4995\n","\n","Epoch 00264: val_loss did not improve from 0.43998\n","Epoch 265/1000\n"," - 8s - loss: 0.2306 - accuracy: 0.9117 - val_loss: 1.6152 - val_accuracy: 0.5030\n","\n","Epoch 00265: val_loss did not improve from 0.43998\n","Epoch 266/1000\n"," - 8s - loss: 0.2356 - accuracy: 0.9036 - val_loss: 3.2586 - val_accuracy: 0.4945\n","\n","Epoch 00266: val_loss did not improve from 0.43998\n","Epoch 267/1000\n"," - 8s - loss: 0.2275 - accuracy: 0.9076 - val_loss: 1.4618 - val_accuracy: 0.4995\n","\n","Epoch 00267: val_loss did not improve from 0.43998\n","Epoch 268/1000\n"," - 8s - loss: 0.2243 - accuracy: 0.9126 - val_loss: 1.7488 - val_accuracy: 0.5020\n","\n","Epoch 00268: val_loss did not improve from 0.43998\n","Epoch 269/1000\n"," - 8s - loss: 0.2224 - accuracy: 0.9146 - val_loss: 0.8970 - val_accuracy: 0.5005\n","\n","Epoch 00269: val_loss did not improve from 0.43998\n","Epoch 270/1000\n"," - 8s - loss: 0.2152 - accuracy: 0.9177 - val_loss: 2.5524 - val_accuracy: 0.4930\n","\n","Epoch 00270: val_loss did not improve from 0.43998\n","Epoch 271/1000\n"," - 8s - loss: 0.2231 - accuracy: 0.9083 - val_loss: 1.2429 - val_accuracy: 0.4975\n","\n","Epoch 00271: val_loss did not improve from 0.43998\n","Epoch 272/1000\n"," - 8s - loss: 0.2154 - accuracy: 0.9152 - val_loss: 1.5996 - val_accuracy: 0.5060\n","\n","Epoch 00272: val_loss did not improve from 0.43998\n","Epoch 273/1000\n"," - 8s - loss: 0.2172 - accuracy: 0.9141 - val_loss: 3.1656 - val_accuracy: 0.5025\n","\n","Epoch 00273: val_loss did not improve from 0.43998\n","Epoch 274/1000\n"," - 8s - loss: 0.2186 - accuracy: 0.9117 - val_loss: 1.2779 - val_accuracy: 0.4990\n","\n","Epoch 00274: val_loss did not improve from 0.43998\n","Epoch 275/1000\n"," - 8s - loss: 0.2196 - accuracy: 0.9144 - val_loss: 1.6632 - val_accuracy: 0.5095\n","\n","Epoch 00275: val_loss did not improve from 0.43998\n","Epoch 276/1000\n"," - 8s - loss: 0.2135 - accuracy: 0.9144 - val_loss: 3.3280 - val_accuracy: 0.4950\n","\n","Epoch 00276: val_loss did not improve from 0.43998\n","Epoch 277/1000\n"," - 8s - loss: 0.2154 - accuracy: 0.9127 - val_loss: 2.7648 - val_accuracy: 0.5050\n","\n","Epoch 00277: val_loss did not improve from 0.43998\n","Epoch 278/1000\n"," - 8s - loss: 0.2107 - accuracy: 0.9182 - val_loss: 1.8752 - val_accuracy: 0.4920\n","\n","Epoch 00278: val_loss did not improve from 0.43998\n","Epoch 279/1000\n"," - 8s - loss: 0.2114 - accuracy: 0.9142 - val_loss: 1.2781 - val_accuracy: 0.4985\n","\n","Epoch 00279: val_loss did not improve from 0.43998\n","Epoch 280/1000\n"," - 8s - loss: 0.2097 - accuracy: 0.9192 - val_loss: 1.3661 - val_accuracy: 0.4900\n","\n","Epoch 00280: val_loss did not improve from 0.43998\n","Epoch 281/1000\n"," - 8s - loss: 0.2060 - accuracy: 0.9252 - val_loss: 1.9704 - val_accuracy: 0.4960\n","\n","Epoch 00281: val_loss did not improve from 0.43998\n","Epoch 282/1000\n"," - 8s - loss: 0.2053 - accuracy: 0.9215 - val_loss: 1.6683 - val_accuracy: 0.4940\n","\n","Epoch 00282: val_loss did not improve from 0.43998\n","Epoch 283/1000\n"," - 8s - loss: 0.1990 - accuracy: 0.9224 - val_loss: 2.9770 - val_accuracy: 0.4960\n","\n","Epoch 00283: val_loss did not improve from 0.43998\n","Epoch 284/1000\n"," - 8s - loss: 0.2089 - accuracy: 0.9205 - val_loss: 0.1931 - val_accuracy: 0.4846\n","\n","Epoch 00284: val_loss improved from 0.43998 to 0.19308, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 285/1000\n"," - 8s - loss: 0.2063 - accuracy: 0.9151 - val_loss: 1.6673 - val_accuracy: 0.4970\n","\n","Epoch 00285: val_loss did not improve from 0.19308\n","Epoch 286/1000\n"," - 8s - loss: 0.2006 - accuracy: 0.9260 - val_loss: 2.0778 - val_accuracy: 0.4955\n","\n","Epoch 00286: val_loss did not improve from 0.19308\n","Epoch 287/1000\n"," - 8s - loss: 0.2032 - accuracy: 0.9212 - val_loss: 1.9324 - val_accuracy: 0.4960\n","\n","Epoch 00287: val_loss did not improve from 0.19308\n","Epoch 288/1000\n"," - 8s - loss: 0.1980 - accuracy: 0.9225 - val_loss: 1.9739 - val_accuracy: 0.5025\n","\n","Epoch 00288: val_loss did not improve from 0.19308\n","Epoch 289/1000\n"," - 8s - loss: 0.1999 - accuracy: 0.9217 - val_loss: 0.8371 - val_accuracy: 0.4960\n","\n","Epoch 00289: val_loss did not improve from 0.19308\n","Epoch 290/1000\n"," - 8s - loss: 0.1933 - accuracy: 0.9267 - val_loss: 1.2896 - val_accuracy: 0.5119\n","\n","Epoch 00290: val_loss did not improve from 0.19308\n","Epoch 291/1000\n"," - 8s - loss: 0.1999 - accuracy: 0.9219 - val_loss: 2.3982 - val_accuracy: 0.5030\n","\n","Epoch 00291: val_loss did not improve from 0.19308\n","Epoch 292/1000\n"," - 8s - loss: 0.1887 - accuracy: 0.9247 - val_loss: 1.3624 - val_accuracy: 0.5020\n","\n","Epoch 00292: val_loss did not improve from 0.19308\n","Epoch 293/1000\n"," - 8s - loss: 0.1992 - accuracy: 0.9235 - val_loss: 1.3996 - val_accuracy: 0.4945\n","\n","Epoch 00293: val_loss did not improve from 0.19308\n","Epoch 294/1000\n"," - 8s - loss: 0.1941 - accuracy: 0.9247 - val_loss: 2.0389 - val_accuracy: 0.4985\n","\n","Epoch 00294: val_loss did not improve from 0.19308\n","Epoch 295/1000\n"," - 8s - loss: 0.1884 - accuracy: 0.9273 - val_loss: 3.6160 - val_accuracy: 0.4970\n","\n","Epoch 00295: val_loss did not improve from 0.19308\n","Epoch 296/1000\n"," - 8s - loss: 0.1919 - accuracy: 0.9253 - val_loss: 1.4308 - val_accuracy: 0.4930\n","\n","Epoch 00296: val_loss did not improve from 0.19308\n","Epoch 297/1000\n"," - 8s - loss: 0.1946 - accuracy: 0.9277 - val_loss: 1.8055 - val_accuracy: 0.5090\n","\n","Epoch 00297: val_loss did not improve from 0.19308\n","Epoch 298/1000\n"," - 8s - loss: 0.1972 - accuracy: 0.9225 - val_loss: 3.4889 - val_accuracy: 0.4975\n","\n","Epoch 00298: val_loss did not improve from 0.19308\n","Epoch 299/1000\n"," - 8s - loss: 0.1922 - accuracy: 0.9282 - val_loss: 1.9873 - val_accuracy: 0.4940\n","\n","Epoch 00299: val_loss did not improve from 0.19308\n","Epoch 300/1000\n"," - 8s - loss: 0.1849 - accuracy: 0.9317 - val_loss: 1.6046 - val_accuracy: 0.4940\n","\n","Epoch 00300: val_loss did not improve from 0.19308\n","Epoch 301/1000\n"," - 8s - loss: 0.1863 - accuracy: 0.9298 - val_loss: 3.4323 - val_accuracy: 0.4826\n","\n","Epoch 00301: val_loss did not improve from 0.19308\n","Epoch 302/1000\n"," - 8s - loss: 0.1735 - accuracy: 0.9376 - val_loss: 2.4535 - val_accuracy: 0.4955\n","\n","Epoch 00302: val_loss did not improve from 0.19308\n","Epoch 303/1000\n"," - 8s - loss: 0.1858 - accuracy: 0.9250 - val_loss: 2.0268 - val_accuracy: 0.5010\n","\n","Epoch 00303: val_loss did not improve from 0.19308\n","Epoch 304/1000\n"," - 8s - loss: 0.1824 - accuracy: 0.9341 - val_loss: 0.6021 - val_accuracy: 0.4995\n","\n","Epoch 00304: val_loss did not improve from 0.19308\n","Epoch 305/1000\n"," - 8s - loss: 0.1827 - accuracy: 0.9283 - val_loss: 1.2021 - val_accuracy: 0.5060\n","\n","Epoch 00305: val_loss did not improve from 0.19308\n","Epoch 306/1000\n"," - 8s - loss: 0.1726 - accuracy: 0.9353 - val_loss: 1.5331 - val_accuracy: 0.5050\n","\n","Epoch 00306: val_loss did not improve from 0.19308\n","Epoch 307/1000\n"," - 8s - loss: 0.1835 - accuracy: 0.9308 - val_loss: 3.8915 - val_accuracy: 0.4980\n","\n","Epoch 00307: val_loss did not improve from 0.19308\n","Epoch 308/1000\n"," - 8s - loss: 0.1785 - accuracy: 0.9318 - val_loss: 2.5659 - val_accuracy: 0.5025\n","\n","Epoch 00308: val_loss did not improve from 0.19308\n","Epoch 309/1000\n"," - 8s - loss: 0.1826 - accuracy: 0.9315 - val_loss: 1.4041 - val_accuracy: 0.5045\n","\n","Epoch 00309: val_loss did not improve from 0.19308\n","Epoch 310/1000\n"," - 8s - loss: 0.1729 - accuracy: 0.9355 - val_loss: 0.5176 - val_accuracy: 0.4985\n","\n","Epoch 00310: val_loss did not improve from 0.19308\n","Epoch 311/1000\n"," - 8s - loss: 0.1785 - accuracy: 0.9356 - val_loss: 2.3700 - val_accuracy: 0.4900\n","\n","Epoch 00311: val_loss did not improve from 0.19308\n","Epoch 312/1000\n"," - 8s - loss: 0.1658 - accuracy: 0.9391 - val_loss: 1.8599 - val_accuracy: 0.4980\n","\n","Epoch 00312: val_loss did not improve from 0.19308\n","Epoch 313/1000\n"," - 8s - loss: 0.1760 - accuracy: 0.9302 - val_loss: 2.4241 - val_accuracy: 0.4905\n","\n","Epoch 00313: val_loss did not improve from 0.19308\n","Epoch 314/1000\n"," - 8s - loss: 0.1698 - accuracy: 0.9361 - val_loss: 2.6636 - val_accuracy: 0.4891\n","\n","Epoch 00314: val_loss did not improve from 0.19308\n","Epoch 315/1000\n"," - 8s - loss: 0.1743 - accuracy: 0.9351 - val_loss: 2.0033 - val_accuracy: 0.4975\n","\n","Epoch 00315: val_loss did not improve from 0.19308\n","Epoch 316/1000\n"," - 8s - loss: 0.1716 - accuracy: 0.9363 - val_loss: 2.2103 - val_accuracy: 0.4930\n","\n","Epoch 00316: val_loss did not improve from 0.19308\n","Epoch 317/1000\n"," - 8s - loss: 0.1736 - accuracy: 0.9351 - val_loss: 1.6529 - val_accuracy: 0.4975\n","\n","Epoch 00317: val_loss did not improve from 0.19308\n","Epoch 318/1000\n"," - 8s - loss: 0.1692 - accuracy: 0.9368 - val_loss: 0.9794 - val_accuracy: 0.4920\n","\n","Epoch 00318: val_loss did not improve from 0.19308\n","Epoch 319/1000\n"," - 8s - loss: 0.1663 - accuracy: 0.9394 - val_loss: 1.1285 - val_accuracy: 0.4905\n","\n","Epoch 00319: val_loss did not improve from 0.19308\n","Epoch 320/1000\n"," - 8s - loss: 0.1654 - accuracy: 0.9391 - val_loss: 2.8659 - val_accuracy: 0.4965\n","\n","Epoch 00320: val_loss did not improve from 0.19308\n","Epoch 321/1000\n"," - 8s - loss: 0.1626 - accuracy: 0.9391 - val_loss: 2.1236 - val_accuracy: 0.4970\n","\n","Epoch 00321: val_loss did not improve from 0.19308\n","Epoch 322/1000\n"," - 8s - loss: 0.1620 - accuracy: 0.9418 - val_loss: 1.1505 - val_accuracy: 0.5030\n","\n","Epoch 00322: val_loss did not improve from 0.19308\n","Epoch 323/1000\n"," - 8s - loss: 0.1612 - accuracy: 0.9385 - val_loss: 2.7592 - val_accuracy: 0.4980\n","\n","Epoch 00323: val_loss did not improve from 0.19308\n","Epoch 324/1000\n"," - 8s - loss: 0.1647 - accuracy: 0.9406 - val_loss: 1.5736 - val_accuracy: 0.5030\n","\n","Epoch 00324: val_loss did not improve from 0.19308\n","Epoch 325/1000\n"," - 8s - loss: 0.1669 - accuracy: 0.9366 - val_loss: 1.8208 - val_accuracy: 0.4965\n","\n","Epoch 00325: val_loss did not improve from 0.19308\n","Epoch 326/1000\n"," - 8s - loss: 0.1653 - accuracy: 0.9386 - val_loss: 2.2038 - val_accuracy: 0.4876\n","\n","Epoch 00326: val_loss did not improve from 0.19308\n","Epoch 327/1000\n"," - 8s - loss: 0.1678 - accuracy: 0.9373 - val_loss: 1.6113 - val_accuracy: 0.4930\n","\n","Epoch 00327: val_loss did not improve from 0.19308\n","Epoch 328/1000\n"," - 8s - loss: 0.1599 - accuracy: 0.9423 - val_loss: 3.8680 - val_accuracy: 0.4935\n","\n","Epoch 00328: val_loss did not improve from 0.19308\n","Epoch 329/1000\n"," - 8s - loss: 0.1613 - accuracy: 0.9401 - val_loss: 3.2598 - val_accuracy: 0.4925\n","\n","Epoch 00329: val_loss did not improve from 0.19308\n","Epoch 330/1000\n"," - 8s - loss: 0.1595 - accuracy: 0.9433 - val_loss: 2.2359 - val_accuracy: 0.5050\n","\n","Epoch 00330: val_loss did not improve from 0.19308\n","Epoch 331/1000\n"," - 8s - loss: 0.1524 - accuracy: 0.9423 - val_loss: 0.6140 - val_accuracy: 0.4871\n","\n","Epoch 00331: val_loss did not improve from 0.19308\n","Epoch 332/1000\n"," - 8s - loss: 0.1504 - accuracy: 0.9443 - val_loss: 2.8023 - val_accuracy: 0.5020\n","\n","Epoch 00332: val_loss did not improve from 0.19308\n","Epoch 333/1000\n"," - 8s - loss: 0.1507 - accuracy: 0.9434 - val_loss: 0.5632 - val_accuracy: 0.5030\n","\n","Epoch 00333: val_loss did not improve from 0.19308\n","Epoch 334/1000\n"," - 8s - loss: 0.1476 - accuracy: 0.9413 - val_loss: 1.1491 - val_accuracy: 0.4965\n","\n","Epoch 00334: val_loss did not improve from 0.19308\n","Epoch 335/1000\n"," - 8s - loss: 0.1512 - accuracy: 0.9433 - val_loss: 3.2489 - val_accuracy: 0.4990\n","\n","Epoch 00335: val_loss did not improve from 0.19308\n","Epoch 336/1000\n"," - 8s - loss: 0.1487 - accuracy: 0.9476 - val_loss: 1.2240 - val_accuracy: 0.4861\n","\n","Epoch 00336: val_loss did not improve from 0.19308\n","Epoch 337/1000\n"," - 8s - loss: 0.1458 - accuracy: 0.9504 - val_loss: 1.7374 - val_accuracy: 0.4905\n","\n","Epoch 00337: val_loss did not improve from 0.19308\n","Epoch 338/1000\n"," - 8s - loss: 0.1493 - accuracy: 0.9456 - val_loss: 1.8584 - val_accuracy: 0.5045\n","\n","Epoch 00338: val_loss did not improve from 0.19308\n","Epoch 339/1000\n"," - 8s - loss: 0.1462 - accuracy: 0.9444 - val_loss: 3.3771 - val_accuracy: 0.4915\n","\n","Epoch 00339: val_loss did not improve from 0.19308\n","Epoch 340/1000\n"," - 8s - loss: 0.1470 - accuracy: 0.9454 - val_loss: 1.8718 - val_accuracy: 0.4990\n","\n","Epoch 00340: val_loss did not improve from 0.19308\n","Epoch 341/1000\n"," - 8s - loss: 0.1499 - accuracy: 0.9448 - val_loss: 0.7826 - val_accuracy: 0.4980\n","\n","Epoch 00341: val_loss did not improve from 0.19308\n","Epoch 342/1000\n"," - 8s - loss: 0.1431 - accuracy: 0.9453 - val_loss: 1.8581 - val_accuracy: 0.4990\n","\n","Epoch 00342: val_loss did not improve from 0.19308\n","Epoch 343/1000\n"," - 8s - loss: 0.1463 - accuracy: 0.9466 - val_loss: 2.0522 - val_accuracy: 0.4930\n","\n","Epoch 00343: val_loss did not improve from 0.19308\n","Epoch 344/1000\n"," - 8s - loss: 0.1499 - accuracy: 0.9484 - val_loss: 0.8392 - val_accuracy: 0.4980\n","\n","Epoch 00344: val_loss did not improve from 0.19308\n","Epoch 345/1000\n"," - 8s - loss: 0.1478 - accuracy: 0.9448 - val_loss: 2.8928 - val_accuracy: 0.4950\n","\n","Epoch 00345: val_loss did not improve from 0.19308\n","Epoch 346/1000\n"," - 8s - loss: 0.1483 - accuracy: 0.9429 - val_loss: 2.6777 - val_accuracy: 0.4935\n","\n","Epoch 00346: val_loss did not improve from 0.19308\n","Epoch 347/1000\n"," - 8s - loss: 0.1416 - accuracy: 0.9482 - val_loss: 1.4938 - val_accuracy: 0.4950\n","\n","Epoch 00347: val_loss did not improve from 0.19308\n","Epoch 348/1000\n"," - 8s - loss: 0.1396 - accuracy: 0.9509 - val_loss: 1.0435 - val_accuracy: 0.5015\n","\n","Epoch 00348: val_loss did not improve from 0.19308\n","Epoch 349/1000\n"," - 8s - loss: 0.1335 - accuracy: 0.9524 - val_loss: 4.3735 - val_accuracy: 0.4995\n","\n","Epoch 00349: val_loss did not improve from 0.19308\n","Epoch 350/1000\n"," - 8s - loss: 0.1350 - accuracy: 0.9511 - val_loss: 1.6801 - val_accuracy: 0.4886\n","\n","Epoch 00350: val_loss did not improve from 0.19308\n","Epoch 351/1000\n"," - 8s - loss: 0.1486 - accuracy: 0.9454 - val_loss: 0.7913 - val_accuracy: 0.5010\n","\n","Epoch 00351: val_loss did not improve from 0.19308\n","Epoch 352/1000\n"," - 8s - loss: 0.1362 - accuracy: 0.9477 - val_loss: 2.3148 - val_accuracy: 0.4910\n","\n","Epoch 00352: val_loss did not improve from 0.19308\n","Epoch 353/1000\n"," - 8s - loss: 0.1434 - accuracy: 0.9486 - val_loss: 3.2829 - val_accuracy: 0.4920\n","\n","Epoch 00353: val_loss did not improve from 0.19308\n","Epoch 354/1000\n"," - 8s - loss: 0.1429 - accuracy: 0.9482 - val_loss: 4.8178 - val_accuracy: 0.4970\n","\n","Epoch 00354: val_loss did not improve from 0.19308\n","Epoch 355/1000\n"," - 8s - loss: 0.1380 - accuracy: 0.9522 - val_loss: 1.8793 - val_accuracy: 0.5050\n","\n","Epoch 00355: val_loss did not improve from 0.19308\n","Epoch 356/1000\n"," - 8s - loss: 0.1409 - accuracy: 0.9474 - val_loss: 4.1927 - val_accuracy: 0.5035\n","\n","Epoch 00356: val_loss did not improve from 0.19308\n","Epoch 357/1000\n"," - 8s - loss: 0.1290 - accuracy: 0.9539 - val_loss: 1.8627 - val_accuracy: 0.4965\n","\n","Epoch 00357: val_loss did not improve from 0.19308\n","Epoch 358/1000\n"," - 8s - loss: 0.1296 - accuracy: 0.9539 - val_loss: 3.2797 - val_accuracy: 0.5015\n","\n","Epoch 00358: val_loss did not improve from 0.19308\n","Epoch 359/1000\n"," - 8s - loss: 0.1305 - accuracy: 0.9559 - val_loss: 4.7238 - val_accuracy: 0.5020\n","\n","Epoch 00359: val_loss did not improve from 0.19308\n","Epoch 360/1000\n"," - 8s - loss: 0.1301 - accuracy: 0.9524 - val_loss: 1.8841 - val_accuracy: 0.4905\n","\n","Epoch 00360: val_loss did not improve from 0.19308\n","Epoch 361/1000\n"," - 8s - loss: 0.1257 - accuracy: 0.9559 - val_loss: 2.8855 - val_accuracy: 0.4876\n","\n","Epoch 00361: val_loss did not improve from 0.19308\n","Epoch 362/1000\n"," - 8s - loss: 0.1330 - accuracy: 0.9552 - val_loss: 6.4731 - val_accuracy: 0.4925\n","\n","Epoch 00362: val_loss did not improve from 0.19308\n","Epoch 363/1000\n"," - 8s - loss: 0.1360 - accuracy: 0.9514 - val_loss: 2.8604 - val_accuracy: 0.5030\n","\n","Epoch 00363: val_loss did not improve from 0.19308\n","Epoch 364/1000\n"," - 8s - loss: 0.1336 - accuracy: 0.9496 - val_loss: 3.9397 - val_accuracy: 0.4970\n","\n","Epoch 00364: val_loss did not improve from 0.19308\n","Epoch 365/1000\n"," - 8s - loss: 0.1255 - accuracy: 0.9565 - val_loss: 2.9366 - val_accuracy: 0.4935\n","\n","Epoch 00365: val_loss did not improve from 0.19308\n","Epoch 366/1000\n"," - 8s - loss: 0.1269 - accuracy: 0.9544 - val_loss: 5.3652 - val_accuracy: 0.5080\n","\n","Epoch 00366: val_loss did not improve from 0.19308\n","Epoch 367/1000\n"," - 8s - loss: 0.1229 - accuracy: 0.9569 - val_loss: 1.8519 - val_accuracy: 0.4990\n","\n","Epoch 00367: val_loss did not improve from 0.19308\n","Epoch 368/1000\n"," - 8s - loss: 0.1237 - accuracy: 0.9557 - val_loss: 3.8041 - val_accuracy: 0.4990\n","\n","Epoch 00368: val_loss did not improve from 0.19308\n","Epoch 369/1000\n"," - 8s - loss: 0.1207 - accuracy: 0.9607 - val_loss: 3.7169 - val_accuracy: 0.5020\n","\n","Epoch 00369: val_loss did not improve from 0.19308\n","Epoch 370/1000\n"," - 8s - loss: 0.1263 - accuracy: 0.9572 - val_loss: 0.8779 - val_accuracy: 0.5134\n","\n","Epoch 00370: val_loss did not improve from 0.19308\n","Epoch 371/1000\n"," - 8s - loss: 0.1255 - accuracy: 0.9537 - val_loss: 1.7808 - val_accuracy: 0.4955\n","\n","Epoch 00371: val_loss did not improve from 0.19308\n","Epoch 372/1000\n"," - 8s - loss: 0.1199 - accuracy: 0.9607 - val_loss: 2.4542 - val_accuracy: 0.5075\n","\n","Epoch 00372: val_loss did not improve from 0.19308\n","Epoch 373/1000\n"," - 8s - loss: 0.1275 - accuracy: 0.9540 - val_loss: 1.8890 - val_accuracy: 0.4960\n","\n","Epoch 00373: val_loss did not improve from 0.19308\n","Epoch 374/1000\n"," - 8s - loss: 0.1250 - accuracy: 0.9564 - val_loss: 2.6094 - val_accuracy: 0.5035\n","\n","Epoch 00374: val_loss did not improve from 0.19308\n","Epoch 375/1000\n"," - 8s - loss: 0.1171 - accuracy: 0.9610 - val_loss: 2.9531 - val_accuracy: 0.4950\n","\n","Epoch 00375: val_loss did not improve from 0.19308\n","Epoch 376/1000\n"," - 8s - loss: 0.1232 - accuracy: 0.9547 - val_loss: 2.5154 - val_accuracy: 0.5000\n","\n","Epoch 00376: val_loss did not improve from 0.19308\n","Epoch 377/1000\n"," - 8s - loss: 0.1215 - accuracy: 0.9572 - val_loss: 2.1973 - val_accuracy: 0.4846\n","\n","Epoch 00377: val_loss did not improve from 0.19308\n","Epoch 378/1000\n"," - 8s - loss: 0.1238 - accuracy: 0.9585 - val_loss: 1.2742 - val_accuracy: 0.4920\n","\n","Epoch 00378: val_loss did not improve from 0.19308\n","Epoch 379/1000\n"," - 8s - loss: 0.1232 - accuracy: 0.9542 - val_loss: 0.6570 - val_accuracy: 0.5015\n","\n","Epoch 00379: val_loss did not improve from 0.19308\n","Epoch 380/1000\n"," - 8s - loss: 0.1097 - accuracy: 0.9627 - val_loss: 5.6203 - val_accuracy: 0.5139\n","\n","Epoch 00380: val_loss did not improve from 0.19308\n","Epoch 381/1000\n"," - 8s - loss: 0.1148 - accuracy: 0.9637 - val_loss: 3.8688 - val_accuracy: 0.4990\n","\n","Epoch 00381: val_loss did not improve from 0.19308\n","Epoch 382/1000\n"," - 8s - loss: 0.1168 - accuracy: 0.9590 - val_loss: 1.6149 - val_accuracy: 0.4995\n","\n","Epoch 00382: val_loss did not improve from 0.19308\n","Epoch 383/1000\n"," - 8s - loss: 0.1079 - accuracy: 0.9628 - val_loss: 2.3865 - val_accuracy: 0.5104\n","\n","Epoch 00383: val_loss did not improve from 0.19308\n","Epoch 384/1000\n"," - 8s - loss: 0.1129 - accuracy: 0.9617 - val_loss: 1.4814 - val_accuracy: 0.4990\n","\n","Epoch 00384: val_loss did not improve from 0.19308\n","Epoch 385/1000\n"," - 8s - loss: 0.1162 - accuracy: 0.9570 - val_loss: 2.2504 - val_accuracy: 0.4985\n","\n","Epoch 00385: val_loss did not improve from 0.19308\n","Epoch 386/1000\n"," - 8s - loss: 0.1077 - accuracy: 0.9637 - val_loss: 1.7658 - val_accuracy: 0.5025\n","\n","Epoch 00386: val_loss did not improve from 0.19308\n","Epoch 387/1000\n"," - 8s - loss: 0.1088 - accuracy: 0.9628 - val_loss: 1.2102 - val_accuracy: 0.4995\n","\n","Epoch 00387: val_loss did not improve from 0.19308\n","Epoch 388/1000\n"," - 8s - loss: 0.1128 - accuracy: 0.9615 - val_loss: 1.1941 - val_accuracy: 0.5045\n","\n","Epoch 00388: val_loss did not improve from 0.19308\n","Epoch 389/1000\n"," - 8s - loss: 0.1162 - accuracy: 0.9587 - val_loss: 2.9245 - val_accuracy: 0.4975\n","\n","Epoch 00389: val_loss did not improve from 0.19308\n","Epoch 390/1000\n"," - 8s - loss: 0.1107 - accuracy: 0.9623 - val_loss: 3.6106 - val_accuracy: 0.5000\n","\n","Epoch 00390: val_loss did not improve from 0.19308\n","Epoch 391/1000\n"," - 8s - loss: 0.1102 - accuracy: 0.9623 - val_loss: 2.1487 - val_accuracy: 0.5035\n","\n","Epoch 00391: val_loss did not improve from 0.19308\n","Epoch 392/1000\n"," - 8s - loss: 0.1149 - accuracy: 0.9602 - val_loss: 3.2930 - val_accuracy: 0.5085\n","\n","Epoch 00392: val_loss did not improve from 0.19308\n","Epoch 393/1000\n"," - 8s - loss: 0.1062 - accuracy: 0.9627 - val_loss: 4.1835 - val_accuracy: 0.4980\n","\n","Epoch 00393: val_loss did not improve from 0.19308\n","Epoch 394/1000\n"," - 8s - loss: 0.1142 - accuracy: 0.9589 - val_loss: 2.5227 - val_accuracy: 0.4995\n","\n","Epoch 00394: val_loss did not improve from 0.19308\n","Epoch 395/1000\n"," - 8s - loss: 0.1091 - accuracy: 0.9615 - val_loss: 4.4128 - val_accuracy: 0.5114\n","\n","Epoch 00395: val_loss did not improve from 0.19308\n","Epoch 396/1000\n"," - 8s - loss: 0.1031 - accuracy: 0.9672 - val_loss: 0.8929 - val_accuracy: 0.4985\n","\n","Epoch 00396: val_loss did not improve from 0.19308\n","Epoch 397/1000\n"," - 8s - loss: 0.1077 - accuracy: 0.9630 - val_loss: 2.8648 - val_accuracy: 0.5035\n","\n","Epoch 00397: val_loss did not improve from 0.19308\n","Epoch 398/1000\n"," - 8s - loss: 0.1024 - accuracy: 0.9655 - val_loss: 1.6357 - val_accuracy: 0.5030\n","\n","Epoch 00398: val_loss did not improve from 0.19308\n","Epoch 399/1000\n"," - 8s - loss: 0.1015 - accuracy: 0.9667 - val_loss: 3.0511 - val_accuracy: 0.5065\n","\n","Epoch 00399: val_loss did not improve from 0.19308\n","Epoch 400/1000\n"," - 8s - loss: 0.1028 - accuracy: 0.9665 - val_loss: 3.2847 - val_accuracy: 0.4960\n","\n","Epoch 00400: val_loss did not improve from 0.19308\n","Epoch 401/1000\n"," - 8s - loss: 0.1041 - accuracy: 0.9652 - val_loss: 4.7009 - val_accuracy: 0.5075\n","\n","Epoch 00401: val_loss did not improve from 0.19308\n","Epoch 402/1000\n"," - 8s - loss: 0.1050 - accuracy: 0.9650 - val_loss: 0.7135 - val_accuracy: 0.5060\n","\n","Epoch 00402: val_loss did not improve from 0.19308\n","Epoch 403/1000\n"," - 8s - loss: 0.1040 - accuracy: 0.9632 - val_loss: 5.1319 - val_accuracy: 0.5055\n","\n","Epoch 00403: val_loss did not improve from 0.19308\n","Epoch 404/1000\n"," - 8s - loss: 0.1082 - accuracy: 0.9615 - val_loss: 3.1587 - val_accuracy: 0.4930\n","\n","Epoch 00404: val_loss did not improve from 0.19308\n","Epoch 405/1000\n"," - 8s - loss: 0.0991 - accuracy: 0.9647 - val_loss: 3.8696 - val_accuracy: 0.5045\n","\n","Epoch 00405: val_loss did not improve from 0.19308\n","Epoch 406/1000\n"," - 8s - loss: 0.0959 - accuracy: 0.9665 - val_loss: 3.2401 - val_accuracy: 0.4990\n","\n","Epoch 00406: val_loss did not improve from 0.19308\n","Epoch 407/1000\n"," - 8s - loss: 0.1017 - accuracy: 0.9672 - val_loss: 1.3716 - val_accuracy: 0.4900\n","\n","Epoch 00407: val_loss did not improve from 0.19308\n","Epoch 408/1000\n"," - 8s - loss: 0.1021 - accuracy: 0.9660 - val_loss: 2.5106 - val_accuracy: 0.5035\n","\n","Epoch 00408: val_loss did not improve from 0.19308\n","Epoch 409/1000\n"," - 8s - loss: 0.0947 - accuracy: 0.9691 - val_loss: 0.9433 - val_accuracy: 0.5045\n","\n","Epoch 00409: val_loss did not improve from 0.19308\n","Epoch 410/1000\n"," - 8s - loss: 0.1033 - accuracy: 0.9658 - val_loss: 3.3219 - val_accuracy: 0.4910\n","\n","Epoch 00410: val_loss did not improve from 0.19308\n","Epoch 411/1000\n"," - 8s - loss: 0.1005 - accuracy: 0.9658 - val_loss: 1.9302 - val_accuracy: 0.4975\n","\n","Epoch 00411: val_loss did not improve from 0.19308\n","Epoch 412/1000\n"," - 8s - loss: 0.0946 - accuracy: 0.9688 - val_loss: 1.2486 - val_accuracy: 0.4980\n","\n","Epoch 00412: val_loss did not improve from 0.19308\n","Epoch 413/1000\n"," - 8s - loss: 0.1060 - accuracy: 0.9645 - val_loss: 0.4323 - val_accuracy: 0.5020\n","\n","Epoch 00413: val_loss did not improve from 0.19308\n","Epoch 414/1000\n"," - 8s - loss: 0.0938 - accuracy: 0.9696 - val_loss: 2.9567 - val_accuracy: 0.5015\n","\n","Epoch 00414: val_loss did not improve from 0.19308\n","Epoch 415/1000\n"," - 8s - loss: 0.0972 - accuracy: 0.9691 - val_loss: 2.5664 - val_accuracy: 0.5055\n","\n","Epoch 00415: val_loss did not improve from 0.19308\n","Epoch 416/1000\n"," - 8s - loss: 0.0928 - accuracy: 0.9728 - val_loss: 2.1988 - val_accuracy: 0.4900\n","\n","Epoch 00416: val_loss did not improve from 0.19308\n","Epoch 417/1000\n"," - 8s - loss: 0.0969 - accuracy: 0.9670 - val_loss: 2.5436 - val_accuracy: 0.4905\n","\n","Epoch 00417: val_loss did not improve from 0.19308\n","Epoch 418/1000\n"," - 8s - loss: 0.1010 - accuracy: 0.9635 - val_loss: 3.0741 - val_accuracy: 0.4886\n","\n","Epoch 00418: val_loss did not improve from 0.19308\n","Epoch 419/1000\n"," - 8s - loss: 0.0957 - accuracy: 0.9667 - val_loss: 2.3843 - val_accuracy: 0.5030\n","\n","Epoch 00419: val_loss did not improve from 0.19308\n","Epoch 420/1000\n"," - 8s - loss: 0.0980 - accuracy: 0.9657 - val_loss: 1.9014 - val_accuracy: 0.5000\n","\n","Epoch 00420: val_loss did not improve from 0.19308\n","Epoch 421/1000\n"," - 8s - loss: 0.0922 - accuracy: 0.9705 - val_loss: 1.6563 - val_accuracy: 0.4811\n","\n","Epoch 00421: val_loss did not improve from 0.19308\n","Epoch 422/1000\n"," - 8s - loss: 0.0889 - accuracy: 0.9718 - val_loss: 3.7949 - val_accuracy: 0.5015\n","\n","Epoch 00422: val_loss did not improve from 0.19308\n","Epoch 423/1000\n"," - 8s - loss: 0.0938 - accuracy: 0.9696 - val_loss: 4.7525 - val_accuracy: 0.5010\n","\n","Epoch 00423: val_loss did not improve from 0.19308\n","Epoch 424/1000\n"," - 8s - loss: 0.0909 - accuracy: 0.9691 - val_loss: 1.2097 - val_accuracy: 0.5015\n","\n","Epoch 00424: val_loss did not improve from 0.19308\n","Epoch 425/1000\n"," - 8s - loss: 0.0900 - accuracy: 0.9698 - val_loss: 1.4381 - val_accuracy: 0.5015\n","\n","Epoch 00425: val_loss did not improve from 0.19308\n","Epoch 426/1000\n"," - 8s - loss: 0.0871 - accuracy: 0.9713 - val_loss: 1.9922 - val_accuracy: 0.4910\n","\n","Epoch 00426: val_loss did not improve from 0.19308\n","Epoch 427/1000\n"," - 8s - loss: 0.0841 - accuracy: 0.9726 - val_loss: 3.2998 - val_accuracy: 0.4940\n","\n","Epoch 00427: val_loss did not improve from 0.19308\n","Epoch 428/1000\n"," - 8s - loss: 0.0884 - accuracy: 0.9711 - val_loss: 2.6586 - val_accuracy: 0.4995\n","\n","Epoch 00428: val_loss did not improve from 0.19308\n","Epoch 429/1000\n"," - 8s - loss: 0.0848 - accuracy: 0.9738 - val_loss: 3.0070 - val_accuracy: 0.5005\n","\n","Epoch 00429: val_loss did not improve from 0.19308\n","Epoch 430/1000\n"," - 8s - loss: 0.0929 - accuracy: 0.9672 - val_loss: 2.7397 - val_accuracy: 0.4900\n","\n","Epoch 00430: val_loss did not improve from 0.19308\n","Epoch 431/1000\n"," - 8s - loss: 0.0871 - accuracy: 0.9725 - val_loss: 2.7504 - val_accuracy: 0.4905\n","\n","Epoch 00431: val_loss did not improve from 0.19308\n","Epoch 432/1000\n"," - 8s - loss: 0.0861 - accuracy: 0.9738 - val_loss: 0.8328 - val_accuracy: 0.4985\n","\n","Epoch 00432: val_loss did not improve from 0.19308\n","Epoch 433/1000\n"," - 8s - loss: 0.0918 - accuracy: 0.9686 - val_loss: 1.8063 - val_accuracy: 0.4881\n","\n","Epoch 00433: val_loss did not improve from 0.19308\n","Epoch 434/1000\n"," - 8s - loss: 0.0837 - accuracy: 0.9736 - val_loss: 2.2910 - val_accuracy: 0.4861\n","\n","Epoch 00434: val_loss did not improve from 0.19308\n","Epoch 435/1000\n"," - 8s - loss: 0.0924 - accuracy: 0.9685 - val_loss: 4.8209 - val_accuracy: 0.4925\n","\n","Epoch 00435: val_loss did not improve from 0.19308\n","Epoch 436/1000\n"," - 8s - loss: 0.0878 - accuracy: 0.9706 - val_loss: 2.8603 - val_accuracy: 0.4905\n","\n","Epoch 00436: val_loss did not improve from 0.19308\n","Epoch 437/1000\n"," - 8s - loss: 0.0840 - accuracy: 0.9715 - val_loss: 1.8541 - val_accuracy: 0.4930\n","\n","Epoch 00437: val_loss did not improve from 0.19308\n","Epoch 438/1000\n"," - 8s - loss: 0.0859 - accuracy: 0.9705 - val_loss: 2.0663 - val_accuracy: 0.4856\n","\n","Epoch 00438: val_loss did not improve from 0.19308\n","Epoch 439/1000\n"," - 8s - loss: 0.0866 - accuracy: 0.9701 - val_loss: 2.6136 - val_accuracy: 0.4925\n","\n","Epoch 00439: val_loss did not improve from 0.19308\n","Epoch 440/1000\n"," - 8s - loss: 0.0826 - accuracy: 0.9723 - val_loss: 1.5317 - val_accuracy: 0.4861\n","\n","Epoch 00440: val_loss did not improve from 0.19308\n","Epoch 441/1000\n"," - 8s - loss: 0.0787 - accuracy: 0.9768 - val_loss: 2.8294 - val_accuracy: 0.4935\n","\n","Epoch 00441: val_loss did not improve from 0.19308\n","Epoch 442/1000\n"," - 8s - loss: 0.0816 - accuracy: 0.9715 - val_loss: 1.1088 - val_accuracy: 0.4871\n","\n","Epoch 00442: val_loss did not improve from 0.19308\n","Epoch 443/1000\n"," - 8s - loss: 0.0875 - accuracy: 0.9703 - val_loss: 1.7682 - val_accuracy: 0.4915\n","\n","Epoch 00443: val_loss did not improve from 0.19308\n","Epoch 444/1000\n"," - 8s - loss: 0.0843 - accuracy: 0.9746 - val_loss: 1.9781 - val_accuracy: 0.4950\n","\n","Epoch 00444: val_loss did not improve from 0.19308\n","Epoch 445/1000\n"," - 8s - loss: 0.0867 - accuracy: 0.9713 - val_loss: 5.3745 - val_accuracy: 0.4831\n","\n","Epoch 00445: val_loss did not improve from 0.19308\n","Epoch 446/1000\n"," - 8s - loss: 0.0819 - accuracy: 0.9736 - val_loss: 6.5210 - val_accuracy: 0.4905\n","\n","Epoch 00446: val_loss did not improve from 0.19308\n","Epoch 447/1000\n"," - 8s - loss: 0.0746 - accuracy: 0.9754 - val_loss: 4.0645 - val_accuracy: 0.4970\n","\n","Epoch 00447: val_loss did not improve from 0.19308\n","Epoch 448/1000\n"," - 8s - loss: 0.0837 - accuracy: 0.9716 - val_loss: 3.5180 - val_accuracy: 0.4940\n","\n","Epoch 00448: val_loss did not improve from 0.19308\n","Epoch 449/1000\n"," - 8s - loss: 0.0827 - accuracy: 0.9708 - val_loss: 2.8219 - val_accuracy: 0.5090\n","\n","Epoch 00449: val_loss did not improve from 0.19308\n","Epoch 450/1000\n"," - 8s - loss: 0.0743 - accuracy: 0.9759 - val_loss: 3.5029 - val_accuracy: 0.4940\n","\n","Epoch 00450: val_loss did not improve from 0.19308\n","Epoch 451/1000\n"," - 8s - loss: 0.0805 - accuracy: 0.9754 - val_loss: 4.6104 - val_accuracy: 0.5010\n","\n","Epoch 00451: val_loss did not improve from 0.19308\n","Epoch 452/1000\n"," - 8s - loss: 0.0806 - accuracy: 0.9735 - val_loss: 5.2244 - val_accuracy: 0.4995\n","\n","Epoch 00452: val_loss did not improve from 0.19308\n","Epoch 453/1000\n"," - 8s - loss: 0.0882 - accuracy: 0.9703 - val_loss: 2.7562 - val_accuracy: 0.5060\n","\n","Epoch 00453: val_loss did not improve from 0.19308\n","Epoch 454/1000\n"," - 8s - loss: 0.0745 - accuracy: 0.9743 - val_loss: 4.4795 - val_accuracy: 0.5000\n","\n","Epoch 00454: val_loss did not improve from 0.19308\n","Epoch 455/1000\n"," - 8s - loss: 0.0716 - accuracy: 0.9816 - val_loss: 1.3513 - val_accuracy: 0.4876\n","\n","Epoch 00455: val_loss did not improve from 0.19308\n","Epoch 456/1000\n"," - 8s - loss: 0.0813 - accuracy: 0.9713 - val_loss: 2.8247 - val_accuracy: 0.5045\n","\n","Epoch 00456: val_loss did not improve from 0.19308\n","Epoch 457/1000\n"," - 8s - loss: 0.0765 - accuracy: 0.9754 - val_loss: 0.8903 - val_accuracy: 0.5085\n","\n","Epoch 00457: val_loss did not improve from 0.19308\n","Epoch 458/1000\n"," - 8s - loss: 0.0840 - accuracy: 0.9703 - val_loss: 5.4985 - val_accuracy: 0.4940\n","\n","Epoch 00458: val_loss did not improve from 0.19308\n","Epoch 459/1000\n"," - 8s - loss: 0.0736 - accuracy: 0.9756 - val_loss: 4.4407 - val_accuracy: 0.4920\n","\n","Epoch 00459: val_loss did not improve from 0.19308\n","Epoch 460/1000\n"," - 8s - loss: 0.0785 - accuracy: 0.9735 - val_loss: 2.4850 - val_accuracy: 0.5030\n","\n","Epoch 00460: val_loss did not improve from 0.19308\n","Epoch 461/1000\n"," - 8s - loss: 0.0807 - accuracy: 0.9728 - val_loss: 4.1617 - val_accuracy: 0.4940\n","\n","Epoch 00461: val_loss did not improve from 0.19308\n","Epoch 462/1000\n"," - 8s - loss: 0.0766 - accuracy: 0.9748 - val_loss: 8.7190 - val_accuracy: 0.4970\n","\n","Epoch 00462: val_loss did not improve from 0.19308\n","Epoch 463/1000\n"," - 8s - loss: 0.0762 - accuracy: 0.9773 - val_loss: 1.5974 - val_accuracy: 0.4896\n","\n","Epoch 00463: val_loss did not improve from 0.19308\n","Epoch 464/1000\n"," - 8s - loss: 0.0794 - accuracy: 0.9733 - val_loss: 0.7903 - val_accuracy: 0.4955\n","\n","Epoch 00464: val_loss did not improve from 0.19308\n","Epoch 465/1000\n"," - 8s - loss: 0.0758 - accuracy: 0.9746 - val_loss: 3.6887 - val_accuracy: 0.4960\n","\n","Epoch 00465: val_loss did not improve from 0.19308\n","Epoch 466/1000\n"," - 8s - loss: 0.0710 - accuracy: 0.9779 - val_loss: 6.3684 - val_accuracy: 0.4876\n","\n","Epoch 00466: val_loss did not improve from 0.19308\n","Epoch 467/1000\n"," - 8s - loss: 0.0713 - accuracy: 0.9769 - val_loss: 3.5921 - val_accuracy: 0.4975\n","\n","Epoch 00467: val_loss did not improve from 0.19308\n","Epoch 468/1000\n"," - 8s - loss: 0.0814 - accuracy: 0.9723 - val_loss: 5.5665 - val_accuracy: 0.4935\n","\n","Epoch 00468: val_loss did not improve from 0.19308\n","Epoch 469/1000\n"," - 8s - loss: 0.0718 - accuracy: 0.9783 - val_loss: 3.7047 - val_accuracy: 0.4841\n","\n","Epoch 00469: val_loss did not improve from 0.19308\n","Epoch 470/1000\n"," - 8s - loss: 0.0775 - accuracy: 0.9753 - val_loss: 1.9807 - val_accuracy: 0.4851\n","\n","Epoch 00470: val_loss did not improve from 0.19308\n","Epoch 471/1000\n"," - 8s - loss: 0.0798 - accuracy: 0.9745 - val_loss: 2.5566 - val_accuracy: 0.5030\n","\n","Epoch 00471: val_loss did not improve from 0.19308\n","Epoch 472/1000\n"," - 8s - loss: 0.0710 - accuracy: 0.9766 - val_loss: 4.0073 - val_accuracy: 0.5070\n","\n","Epoch 00472: val_loss did not improve from 0.19308\n","Epoch 473/1000\n"," - 8s - loss: 0.0727 - accuracy: 0.9801 - val_loss: 4.1506 - val_accuracy: 0.5060\n","\n","Epoch 00473: val_loss did not improve from 0.19308\n","Epoch 474/1000\n"," - 8s - loss: 0.0698 - accuracy: 0.9794 - val_loss: 2.2711 - val_accuracy: 0.4985\n","\n","Epoch 00474: val_loss did not improve from 0.19308\n","Epoch 475/1000\n"," - 8s - loss: 0.0674 - accuracy: 0.9793 - val_loss: 2.6600 - val_accuracy: 0.5080\n","\n","Epoch 00475: val_loss did not improve from 0.19308\n","Epoch 476/1000\n"," - 8s - loss: 0.0730 - accuracy: 0.9753 - val_loss: 2.5507 - val_accuracy: 0.5010\n","\n","Epoch 00476: val_loss did not improve from 0.19308\n","Epoch 477/1000\n"," - 8s - loss: 0.0715 - accuracy: 0.9788 - val_loss: 1.1468 - val_accuracy: 0.4965\n","\n","Epoch 00477: val_loss did not improve from 0.19308\n","Epoch 478/1000\n"," - 8s - loss: 0.0655 - accuracy: 0.9808 - val_loss: 1.5233 - val_accuracy: 0.5050\n","\n","Epoch 00478: val_loss did not improve from 0.19308\n","Epoch 479/1000\n"," - 8s - loss: 0.0651 - accuracy: 0.9822 - val_loss: 4.5294 - val_accuracy: 0.5090\n","\n","Epoch 00479: val_loss did not improve from 0.19308\n","Epoch 480/1000\n"," - 8s - loss: 0.0656 - accuracy: 0.9806 - val_loss: 2.2700 - val_accuracy: 0.5035\n","\n","Epoch 00480: val_loss did not improve from 0.19308\n","Epoch 481/1000\n"," - 8s - loss: 0.0708 - accuracy: 0.9768 - val_loss: 2.9684 - val_accuracy: 0.4896\n","\n","Epoch 00481: val_loss did not improve from 0.19308\n","Epoch 482/1000\n"," - 8s - loss: 0.0686 - accuracy: 0.9769 - val_loss: 1.7191 - val_accuracy: 0.5025\n","\n","Epoch 00482: val_loss did not improve from 0.19308\n","Epoch 483/1000\n"," - 8s - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.1311 - val_accuracy: 0.4945\n","\n","Epoch 00483: val_loss improved from 0.19308 to 0.13110, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 484/1000\n"," - 8s - loss: 0.0688 - accuracy: 0.9776 - val_loss: 1.2696 - val_accuracy: 0.5020\n","\n","Epoch 00484: val_loss did not improve from 0.13110\n","Epoch 485/1000\n"," - 8s - loss: 0.0674 - accuracy: 0.9801 - val_loss: 2.7600 - val_accuracy: 0.4905\n","\n","Epoch 00485: val_loss did not improve from 0.13110\n","Epoch 486/1000\n"," - 8s - loss: 0.0645 - accuracy: 0.9816 - val_loss: 2.5770 - val_accuracy: 0.4935\n","\n","Epoch 00486: val_loss did not improve from 0.13110\n","Epoch 487/1000\n"," - 8s - loss: 0.0630 - accuracy: 0.9788 - val_loss: 5.3715 - val_accuracy: 0.4856\n","\n","Epoch 00487: val_loss did not improve from 0.13110\n","Epoch 488/1000\n"," - 8s - loss: 0.0653 - accuracy: 0.9799 - val_loss: 1.5923 - val_accuracy: 0.4955\n","\n","Epoch 00488: val_loss did not improve from 0.13110\n","Epoch 489/1000\n"," - 8s - loss: 0.0595 - accuracy: 0.9834 - val_loss: 2.7126 - val_accuracy: 0.5025\n","\n","Epoch 00489: val_loss did not improve from 0.13110\n","Epoch 490/1000\n"," - 8s - loss: 0.0655 - accuracy: 0.9799 - val_loss: 1.5813 - val_accuracy: 0.4965\n","\n","Epoch 00490: val_loss did not improve from 0.13110\n","Epoch 491/1000\n"," - 8s - loss: 0.0660 - accuracy: 0.9789 - val_loss: 3.9982 - val_accuracy: 0.4856\n","\n","Epoch 00491: val_loss did not improve from 0.13110\n","Epoch 492/1000\n"," - 8s - loss: 0.0653 - accuracy: 0.9811 - val_loss: 3.8697 - val_accuracy: 0.4886\n","\n","Epoch 00492: val_loss did not improve from 0.13110\n","Epoch 493/1000\n"," - 8s - loss: 0.0683 - accuracy: 0.9763 - val_loss: 4.2439 - val_accuracy: 0.4905\n","\n","Epoch 00493: val_loss did not improve from 0.13110\n","Epoch 494/1000\n"," - 8s - loss: 0.0674 - accuracy: 0.9781 - val_loss: 1.8104 - val_accuracy: 0.4861\n","\n","Epoch 00494: val_loss did not improve from 0.13110\n","Epoch 495/1000\n"," - 8s - loss: 0.0648 - accuracy: 0.9783 - val_loss: 1.3081 - val_accuracy: 0.4970\n","\n","Epoch 00495: val_loss did not improve from 0.13110\n","Epoch 496/1000\n"," - 8s - loss: 0.0689 - accuracy: 0.9771 - val_loss: 2.7093 - val_accuracy: 0.4821\n","\n","Epoch 00496: val_loss did not improve from 0.13110\n","Epoch 497/1000\n"," - 8s - loss: 0.0658 - accuracy: 0.9794 - val_loss: 2.2433 - val_accuracy: 0.4945\n","\n","Epoch 00497: val_loss did not improve from 0.13110\n","Epoch 498/1000\n"," - 8s - loss: 0.0682 - accuracy: 0.9776 - val_loss: 0.9682 - val_accuracy: 0.4900\n","\n","Epoch 00498: val_loss did not improve from 0.13110\n","Epoch 499/1000\n"," - 8s - loss: 0.0633 - accuracy: 0.9793 - val_loss: 1.4829 - val_accuracy: 0.4846\n","\n","Epoch 00499: val_loss did not improve from 0.13110\n","Epoch 500/1000\n"," - 8s - loss: 0.0603 - accuracy: 0.9827 - val_loss: 3.0674 - val_accuracy: 0.4920\n","\n","Epoch 00500: val_loss did not improve from 0.13110\n","Epoch 501/1000\n"," - 8s - loss: 0.0568 - accuracy: 0.9852 - val_loss: 8.0570 - val_accuracy: 0.4866\n","\n","Epoch 00501: val_loss did not improve from 0.13110\n","Epoch 502/1000\n"," - 8s - loss: 0.0602 - accuracy: 0.9814 - val_loss: 0.7367 - val_accuracy: 0.4876\n","\n","Epoch 00502: val_loss did not improve from 0.13110\n","Epoch 503/1000\n"," - 8s - loss: 0.0553 - accuracy: 0.9844 - val_loss: 2.9734 - val_accuracy: 0.4910\n","\n","Epoch 00503: val_loss did not improve from 0.13110\n","Epoch 504/1000\n"," - 8s - loss: 0.0654 - accuracy: 0.9798 - val_loss: 2.6144 - val_accuracy: 0.4930\n","\n","Epoch 00504: val_loss did not improve from 0.13110\n","Epoch 505/1000\n"," - 8s - loss: 0.0630 - accuracy: 0.9799 - val_loss: 4.0004 - val_accuracy: 0.4995\n","\n","Epoch 00505: val_loss did not improve from 0.13110\n","Epoch 506/1000\n"," - 8s - loss: 0.0630 - accuracy: 0.9798 - val_loss: 5.5153 - val_accuracy: 0.4950\n","\n","Epoch 00506: val_loss did not improve from 0.13110\n","Epoch 507/1000\n"," - 8s - loss: 0.0599 - accuracy: 0.9813 - val_loss: 2.8721 - val_accuracy: 0.4935\n","\n","Epoch 00507: val_loss did not improve from 0.13110\n","Epoch 508/1000\n"," - 8s - loss: 0.0595 - accuracy: 0.9827 - val_loss: 3.6317 - val_accuracy: 0.4881\n","\n","Epoch 00508: val_loss did not improve from 0.13110\n","Epoch 509/1000\n"," - 8s - loss: 0.0602 - accuracy: 0.9811 - val_loss: 6.9203 - val_accuracy: 0.4950\n","\n","Epoch 00509: val_loss did not improve from 0.13110\n","Epoch 510/1000\n"," - 8s - loss: 0.0561 - accuracy: 0.9816 - val_loss: 2.9291 - val_accuracy: 0.4866\n","\n","Epoch 00510: val_loss did not improve from 0.13110\n","Epoch 511/1000\n"," - 8s - loss: 0.0592 - accuracy: 0.9799 - val_loss: 3.3000 - val_accuracy: 0.4861\n","\n","Epoch 00511: val_loss did not improve from 0.13110\n","Epoch 512/1000\n"," - 8s - loss: 0.0568 - accuracy: 0.9826 - val_loss: 3.3235 - val_accuracy: 0.4955\n","\n","Epoch 00512: val_loss did not improve from 0.13110\n","Epoch 513/1000\n"," - 8s - loss: 0.0574 - accuracy: 0.9836 - val_loss: 2.1514 - val_accuracy: 0.4950\n","\n","Epoch 00513: val_loss did not improve from 0.13110\n","Epoch 514/1000\n"," - 8s - loss: 0.0601 - accuracy: 0.9819 - val_loss: 2.6841 - val_accuracy: 0.4965\n","\n","Epoch 00514: val_loss did not improve from 0.13110\n","Epoch 515/1000\n"," - 8s - loss: 0.0580 - accuracy: 0.9808 - val_loss: 4.5665 - val_accuracy: 0.4980\n","\n","Epoch 00515: val_loss did not improve from 0.13110\n","Epoch 516/1000\n"," - 8s - loss: 0.0584 - accuracy: 0.9819 - val_loss: 3.8351 - val_accuracy: 0.4905\n","\n","Epoch 00516: val_loss did not improve from 0.13110\n","Epoch 517/1000\n"," - 8s - loss: 0.0534 - accuracy: 0.9861 - val_loss: 2.7804 - val_accuracy: 0.5055\n","\n","Epoch 00517: val_loss did not improve from 0.13110\n","Epoch 518/1000\n"," - 8s - loss: 0.0519 - accuracy: 0.9857 - val_loss: 2.0704 - val_accuracy: 0.4940\n","\n","Epoch 00518: val_loss did not improve from 0.13110\n","Epoch 519/1000\n"," - 8s - loss: 0.0598 - accuracy: 0.9803 - val_loss: 2.9219 - val_accuracy: 0.4945\n","\n","Epoch 00519: val_loss did not improve from 0.13110\n","Epoch 520/1000\n"," - 8s - loss: 0.0597 - accuracy: 0.9829 - val_loss: 5.7195 - val_accuracy: 0.4975\n","\n","Epoch 00520: val_loss did not improve from 0.13110\n","Epoch 521/1000\n"," - 8s - loss: 0.0484 - accuracy: 0.9862 - val_loss: 1.8558 - val_accuracy: 0.4985\n","\n","Epoch 00521: val_loss did not improve from 0.13110\n","Epoch 522/1000\n"," - 8s - loss: 0.0481 - accuracy: 0.9866 - val_loss: 2.5952 - val_accuracy: 0.4826\n","\n","Epoch 00522: val_loss did not improve from 0.13110\n","Epoch 523/1000\n"," - 8s - loss: 0.0584 - accuracy: 0.9816 - val_loss: 2.1132 - val_accuracy: 0.4801\n","\n","Epoch 00523: val_loss did not improve from 0.13110\n","Epoch 524/1000\n"," - 8s - loss: 0.0521 - accuracy: 0.9851 - val_loss: 3.0368 - val_accuracy: 0.4975\n","\n","Epoch 00524: val_loss did not improve from 0.13110\n","Epoch 525/1000\n"," - 8s - loss: 0.0581 - accuracy: 0.9834 - val_loss: 1.2001 - val_accuracy: 0.4910\n","\n","Epoch 00525: val_loss did not improve from 0.13110\n","Epoch 526/1000\n"," - 8s - loss: 0.0545 - accuracy: 0.9839 - val_loss: 5.4454 - val_accuracy: 0.4940\n","\n","Epoch 00526: val_loss did not improve from 0.13110\n","Epoch 527/1000\n"," - 8s - loss: 0.0529 - accuracy: 0.9839 - val_loss: 1.8791 - val_accuracy: 0.4935\n","\n","Epoch 00527: val_loss did not improve from 0.13110\n","Epoch 528/1000\n"," - 8s - loss: 0.0555 - accuracy: 0.9827 - val_loss: 9.1903 - val_accuracy: 0.4935\n","\n","Epoch 00528: val_loss did not improve from 0.13110\n","Epoch 529/1000\n"," - 8s - loss: 0.0547 - accuracy: 0.9846 - val_loss: 6.8802 - val_accuracy: 0.4905\n","\n","Epoch 00529: val_loss did not improve from 0.13110\n","Epoch 530/1000\n"," - 8s - loss: 0.0593 - accuracy: 0.9806 - val_loss: 4.4173 - val_accuracy: 0.4950\n","\n","Epoch 00530: val_loss did not improve from 0.13110\n","Epoch 531/1000\n"," - 8s - loss: 0.0543 - accuracy: 0.9822 - val_loss: 6.1384 - val_accuracy: 0.4985\n","\n","Epoch 00531: val_loss did not improve from 0.13110\n","Epoch 532/1000\n"," - 8s - loss: 0.0516 - accuracy: 0.9841 - val_loss: 4.0351 - val_accuracy: 0.4955\n","\n","Epoch 00532: val_loss did not improve from 0.13110\n","Epoch 533/1000\n"," - 8s - loss: 0.0526 - accuracy: 0.9854 - val_loss: 1.5615 - val_accuracy: 0.4925\n","\n","Epoch 00533: val_loss did not improve from 0.13110\n","Epoch 534/1000\n"," - 8s - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.8577 - val_accuracy: 0.4960\n","\n","Epoch 00534: val_loss did not improve from 0.13110\n","Epoch 535/1000\n"," - 8s - loss: 0.0528 - accuracy: 0.9851 - val_loss: 5.8979 - val_accuracy: 0.4856\n","\n","Epoch 00535: val_loss did not improve from 0.13110\n","Epoch 536/1000\n"," - 8s - loss: 0.0552 - accuracy: 0.9819 - val_loss: 2.0688 - val_accuracy: 0.4910\n","\n","Epoch 00536: val_loss did not improve from 0.13110\n","Epoch 537/1000\n"," - 8s - loss: 0.0573 - accuracy: 0.9818 - val_loss: 4.7488 - val_accuracy: 0.5025\n","\n","Epoch 00537: val_loss did not improve from 0.13110\n","Epoch 538/1000\n"," - 8s - loss: 0.0530 - accuracy: 0.9841 - val_loss: 2.4786 - val_accuracy: 0.4960\n","\n","Epoch 00538: val_loss did not improve from 0.13110\n","Epoch 539/1000\n"," - 8s - loss: 0.0494 - accuracy: 0.9862 - val_loss: 1.4015 - val_accuracy: 0.4910\n","\n","Epoch 00539: val_loss did not improve from 0.13110\n","Epoch 540/1000\n"," - 8s - loss: 0.0538 - accuracy: 0.9827 - val_loss: 2.5376 - val_accuracy: 0.4910\n","\n","Epoch 00540: val_loss did not improve from 0.13110\n","Epoch 541/1000\n"," - 8s - loss: 0.0488 - accuracy: 0.9859 - val_loss: 3.5482 - val_accuracy: 0.4831\n","\n","Epoch 00541: val_loss did not improve from 0.13110\n","Epoch 542/1000\n"," - 8s - loss: 0.0488 - accuracy: 0.9847 - val_loss: 4.0916 - val_accuracy: 0.4796\n","\n","Epoch 00542: val_loss did not improve from 0.13110\n","Epoch 543/1000\n"," - 8s - loss: 0.0509 - accuracy: 0.9844 - val_loss: 7.0570 - val_accuracy: 0.4900\n","\n","Epoch 00543: val_loss did not improve from 0.13110\n","Epoch 544/1000\n"," - 8s - loss: 0.0488 - accuracy: 0.9866 - val_loss: 1.6037 - val_accuracy: 0.4866\n","\n","Epoch 00544: val_loss did not improve from 0.13110\n","Epoch 545/1000\n"," - 8s - loss: 0.0459 - accuracy: 0.9879 - val_loss: 2.2083 - val_accuracy: 0.4831\n","\n","Epoch 00545: val_loss did not improve from 0.13110\n","Epoch 546/1000\n"," - 8s - loss: 0.0474 - accuracy: 0.9859 - val_loss: 1.9983 - val_accuracy: 0.4896\n","\n","Epoch 00546: val_loss did not improve from 0.13110\n","Epoch 547/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9879 - val_loss: 1.5500 - val_accuracy: 0.4856\n","\n","Epoch 00547: val_loss did not improve from 0.13110\n","Epoch 548/1000\n"," - 8s - loss: 0.0542 - accuracy: 0.9829 - val_loss: 2.3680 - val_accuracy: 0.4950\n","\n","Epoch 00548: val_loss did not improve from 0.13110\n","Epoch 549/1000\n"," - 8s - loss: 0.0504 - accuracy: 0.9854 - val_loss: 5.6965 - val_accuracy: 0.4975\n","\n","Epoch 00549: val_loss did not improve from 0.13110\n","Epoch 550/1000\n"," - 8s - loss: 0.0507 - accuracy: 0.9834 - val_loss: 2.1136 - val_accuracy: 0.4876\n","\n","Epoch 00550: val_loss did not improve from 0.13110\n","Epoch 551/1000\n"," - 8s - loss: 0.0436 - accuracy: 0.9879 - val_loss: 2.4521 - val_accuracy: 0.4950\n","\n","Epoch 00551: val_loss did not improve from 0.13110\n","Epoch 552/1000\n"," - 8s - loss: 0.0501 - accuracy: 0.9861 - val_loss: 6.6028 - val_accuracy: 0.4841\n","\n","Epoch 00552: val_loss did not improve from 0.13110\n","Epoch 553/1000\n"," - 8s - loss: 0.0511 - accuracy: 0.9846 - val_loss: 4.3737 - val_accuracy: 0.4975\n","\n","Epoch 00553: val_loss did not improve from 0.13110\n","Epoch 554/1000\n"," - 8s - loss: 0.0462 - accuracy: 0.9866 - val_loss: 5.3471 - val_accuracy: 0.4846\n","\n","Epoch 00554: val_loss did not improve from 0.13110\n","Epoch 555/1000\n"," - 8s - loss: 0.0454 - accuracy: 0.9877 - val_loss: 1.6837 - val_accuracy: 0.4866\n","\n","Epoch 00555: val_loss did not improve from 0.13110\n","Epoch 556/1000\n"," - 8s - loss: 0.0475 - accuracy: 0.9854 - val_loss: 5.9351 - val_accuracy: 0.4881\n","\n","Epoch 00556: val_loss did not improve from 0.13110\n","Epoch 557/1000\n"," - 8s - loss: 0.0485 - accuracy: 0.9856 - val_loss: 3.1247 - val_accuracy: 0.4905\n","\n","Epoch 00557: val_loss did not improve from 0.13110\n","Epoch 558/1000\n"," - 8s - loss: 0.0453 - accuracy: 0.9851 - val_loss: 5.6845 - val_accuracy: 0.4776\n","\n","Epoch 00558: val_loss did not improve from 0.13110\n","Epoch 559/1000\n"," - 8s - loss: 0.0455 - accuracy: 0.9869 - val_loss: 4.5249 - val_accuracy: 0.4900\n","\n","Epoch 00559: val_loss did not improve from 0.13110\n","Epoch 560/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9884 - val_loss: 6.0285 - val_accuracy: 0.4910\n","\n","Epoch 00560: val_loss did not improve from 0.13110\n","Epoch 561/1000\n"," - 8s - loss: 0.0485 - accuracy: 0.9854 - val_loss: 5.1151 - val_accuracy: 0.4930\n","\n","Epoch 00561: val_loss did not improve from 0.13110\n","Epoch 562/1000\n"," - 8s - loss: 0.0486 - accuracy: 0.9846 - val_loss: 2.4613 - val_accuracy: 0.4930\n","\n","Epoch 00562: val_loss did not improve from 0.13110\n","Epoch 563/1000\n"," - 8s - loss: 0.0411 - accuracy: 0.9897 - val_loss: 4.3147 - val_accuracy: 0.4915\n","\n","Epoch 00563: val_loss did not improve from 0.13110\n","Epoch 564/1000\n"," - 8s - loss: 0.0454 - accuracy: 0.9854 - val_loss: 4.8963 - val_accuracy: 0.4975\n","\n","Epoch 00564: val_loss did not improve from 0.13110\n","Epoch 565/1000\n"," - 8s - loss: 0.0428 - accuracy: 0.9871 - val_loss: 3.7732 - val_accuracy: 0.4955\n","\n","Epoch 00565: val_loss did not improve from 0.13110\n","Epoch 566/1000\n"," - 8s - loss: 0.0452 - accuracy: 0.9856 - val_loss: 5.0754 - val_accuracy: 0.4920\n","\n","Epoch 00566: val_loss did not improve from 0.13110\n","Epoch 567/1000\n"," - 8s - loss: 0.0426 - accuracy: 0.9884 - val_loss: 4.0735 - val_accuracy: 0.4871\n","\n","Epoch 00567: val_loss did not improve from 0.13110\n","Epoch 568/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9857 - val_loss: 4.0471 - val_accuracy: 0.4871\n","\n","Epoch 00568: val_loss did not improve from 0.13110\n","Epoch 569/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9851 - val_loss: 6.5646 - val_accuracy: 0.4841\n","\n","Epoch 00569: val_loss did not improve from 0.13110\n","Epoch 570/1000\n"," - 8s - loss: 0.0423 - accuracy: 0.9891 - val_loss: 3.0323 - val_accuracy: 0.4960\n","\n","Epoch 00570: val_loss did not improve from 0.13110\n","Epoch 571/1000\n"," - 8s - loss: 0.0416 - accuracy: 0.9897 - val_loss: 4.4186 - val_accuracy: 0.4940\n","\n","Epoch 00571: val_loss did not improve from 0.13110\n","Epoch 572/1000\n"," - 8s - loss: 0.0424 - accuracy: 0.9877 - val_loss: 6.4750 - val_accuracy: 0.4920\n","\n","Epoch 00572: val_loss did not improve from 0.13110\n","Epoch 573/1000\n"," - 8s - loss: 0.0418 - accuracy: 0.9887 - val_loss: 3.0144 - val_accuracy: 0.4915\n","\n","Epoch 00573: val_loss did not improve from 0.13110\n","Epoch 574/1000\n"," - 8s - loss: 0.0473 - accuracy: 0.9837 - val_loss: 2.9352 - val_accuracy: 0.4945\n","\n","Epoch 00574: val_loss did not improve from 0.13110\n","Epoch 575/1000\n"," - 8s - loss: 0.0386 - accuracy: 0.9899 - val_loss: 3.4369 - val_accuracy: 0.4960\n","\n","Epoch 00575: val_loss did not improve from 0.13110\n","Epoch 576/1000\n"," - 8s - loss: 0.0457 - accuracy: 0.9859 - val_loss: 3.3497 - val_accuracy: 0.4891\n","\n","Epoch 00576: val_loss did not improve from 0.13110\n","Epoch 577/1000\n"," - 8s - loss: 0.0445 - accuracy: 0.9861 - val_loss: 2.1847 - val_accuracy: 0.5010\n","\n","Epoch 00577: val_loss did not improve from 0.13110\n","Epoch 578/1000\n"," - 8s - loss: 0.0469 - accuracy: 0.9854 - val_loss: 4.4149 - val_accuracy: 0.4955\n","\n","Epoch 00578: val_loss did not improve from 0.13110\n","Epoch 579/1000\n"," - 8s - loss: 0.0466 - accuracy: 0.9854 - val_loss: 3.6880 - val_accuracy: 0.4925\n","\n","Epoch 00579: val_loss did not improve from 0.13110\n","Epoch 580/1000\n"," - 8s - loss: 0.0408 - accuracy: 0.9894 - val_loss: 3.0551 - val_accuracy: 0.4891\n","\n","Epoch 00580: val_loss did not improve from 0.13110\n","Epoch 581/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9877 - val_loss: 2.1231 - val_accuracy: 0.4975\n","\n","Epoch 00581: val_loss did not improve from 0.13110\n","Epoch 582/1000\n"," - 8s - loss: 0.0432 - accuracy: 0.9869 - val_loss: 5.1532 - val_accuracy: 0.4905\n","\n","Epoch 00582: val_loss did not improve from 0.13110\n","Epoch 583/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9866 - val_loss: 5.2725 - val_accuracy: 0.4940\n","\n","Epoch 00583: val_loss did not improve from 0.13110\n","Epoch 584/1000\n"," - 8s - loss: 0.0469 - accuracy: 0.9879 - val_loss: 3.3503 - val_accuracy: 0.4955\n","\n","Epoch 00584: val_loss did not improve from 0.13110\n","Epoch 585/1000\n"," - 8s - loss: 0.0456 - accuracy: 0.9862 - val_loss: 4.4251 - val_accuracy: 0.4821\n","\n","Epoch 00585: val_loss did not improve from 0.13110\n","Epoch 586/1000\n"," - 8s - loss: 0.0443 - accuracy: 0.9859 - val_loss: 2.9973 - val_accuracy: 0.4925\n","\n","Epoch 00586: val_loss did not improve from 0.13110\n","Epoch 587/1000\n"," - 8s - loss: 0.0412 - accuracy: 0.9882 - val_loss: 1.6467 - val_accuracy: 0.4990\n","\n","Epoch 00587: val_loss did not improve from 0.13110\n","Epoch 588/1000\n"," - 8s - loss: 0.0427 - accuracy: 0.9871 - val_loss: 4.1325 - val_accuracy: 0.4886\n","\n","Epoch 00588: val_loss did not improve from 0.13110\n","Epoch 589/1000\n"," - 8s - loss: 0.0355 - accuracy: 0.9912 - val_loss: 2.9373 - val_accuracy: 0.5000\n","\n","Epoch 00589: val_loss did not improve from 0.13110\n","Epoch 590/1000\n"," - 8s - loss: 0.0316 - accuracy: 0.9917 - val_loss: 5.0478 - val_accuracy: 0.4930\n","\n","Epoch 00590: val_loss did not improve from 0.13110\n","Epoch 591/1000\n"," - 8s - loss: 0.0362 - accuracy: 0.9907 - val_loss: 6.4553 - val_accuracy: 0.4950\n","\n","Epoch 00591: val_loss did not improve from 0.13110\n","Epoch 592/1000\n"," - 8s - loss: 0.0389 - accuracy: 0.9879 - val_loss: 2.0686 - val_accuracy: 0.4980\n","\n","Epoch 00592: val_loss did not improve from 0.13110\n","Epoch 593/1000\n"," - 8s - loss: 0.0447 - accuracy: 0.9869 - val_loss: 1.5884 - val_accuracy: 0.5005\n","\n","Epoch 00593: val_loss did not improve from 0.13110\n","Epoch 594/1000\n"," - 8s - loss: 0.0441 - accuracy: 0.9871 - val_loss: 5.8214 - val_accuracy: 0.4896\n","\n","Epoch 00594: val_loss did not improve from 0.13110\n","Epoch 595/1000\n"," - 8s - loss: 0.0450 - accuracy: 0.9869 - val_loss: 2.1507 - val_accuracy: 0.4891\n","\n","Epoch 00595: val_loss did not improve from 0.13110\n","Epoch 596/1000\n"," - 8s - loss: 0.0386 - accuracy: 0.9900 - val_loss: 7.1388 - val_accuracy: 0.4950\n","\n","Epoch 00596: val_loss did not improve from 0.13110\n","Epoch 597/1000\n"," - 8s - loss: 0.0385 - accuracy: 0.9892 - val_loss: 4.7968 - val_accuracy: 0.4881\n","\n","Epoch 00597: val_loss did not improve from 0.13110\n","Epoch 598/1000\n"," - 8s - loss: 0.0410 - accuracy: 0.9874 - val_loss: 4.8948 - val_accuracy: 0.4955\n","\n","Epoch 00598: val_loss did not improve from 0.13110\n","Epoch 599/1000\n"," - 8s - loss: 0.0367 - accuracy: 0.9915 - val_loss: 2.6865 - val_accuracy: 0.4930\n","\n","Epoch 00599: val_loss did not improve from 0.13110\n","Epoch 600/1000\n"," - 8s - loss: 0.0336 - accuracy: 0.9909 - val_loss: 1.1650 - val_accuracy: 0.4960\n","\n","Epoch 00600: val_loss did not improve from 0.13110\n","Epoch 601/1000\n"," - 8s - loss: 0.0395 - accuracy: 0.9876 - val_loss: 3.2399 - val_accuracy: 0.4881\n","\n","Epoch 00601: val_loss did not improve from 0.13110\n","Epoch 602/1000\n"," - 8s - loss: 0.0416 - accuracy: 0.9881 - val_loss: 1.3338 - val_accuracy: 0.4900\n","\n","Epoch 00602: val_loss did not improve from 0.13110\n","Epoch 603/1000\n"," - 8s - loss: 0.0374 - accuracy: 0.9895 - val_loss: 1.7234 - val_accuracy: 0.4856\n","\n","Epoch 00603: val_loss did not improve from 0.13110\n","Epoch 604/1000\n"," - 8s - loss: 0.0395 - accuracy: 0.9891 - val_loss: 4.1282 - val_accuracy: 0.4920\n","\n","Epoch 00604: val_loss did not improve from 0.13110\n","Epoch 605/1000\n"," - 8s - loss: 0.0349 - accuracy: 0.9912 - val_loss: 3.8610 - val_accuracy: 0.4920\n","\n","Epoch 00605: val_loss did not improve from 0.13110\n","Epoch 606/1000\n"," - 8s - loss: 0.0429 - accuracy: 0.9871 - val_loss: 1.1919 - val_accuracy: 0.4980\n","\n","Epoch 00606: val_loss did not improve from 0.13110\n","Epoch 607/1000\n"," - 8s - loss: 0.0350 - accuracy: 0.9917 - val_loss: 4.0236 - val_accuracy: 0.4871\n","\n","Epoch 00607: val_loss did not improve from 0.13110\n","Epoch 608/1000\n"," - 8s - loss: 0.0344 - accuracy: 0.9905 - val_loss: 5.0863 - val_accuracy: 0.4886\n","\n","Epoch 00608: val_loss did not improve from 0.13110\n","Epoch 609/1000\n"," - 8s - loss: 0.0413 - accuracy: 0.9876 - val_loss: 2.8549 - val_accuracy: 0.4816\n","\n","Epoch 00609: val_loss did not improve from 0.13110\n","Epoch 610/1000\n"," - 8s - loss: 0.0411 - accuracy: 0.9874 - val_loss: 6.5846 - val_accuracy: 0.4881\n","\n","Epoch 00610: val_loss did not improve from 0.13110\n","Epoch 611/1000\n"," - 8s - loss: 0.0384 - accuracy: 0.9889 - val_loss: 2.1872 - val_accuracy: 0.4945\n","\n","Epoch 00611: val_loss did not improve from 0.13110\n","Epoch 612/1000\n"," - 8s - loss: 0.0399 - accuracy: 0.9892 - val_loss: 2.6798 - val_accuracy: 0.4881\n","\n","Epoch 00612: val_loss did not improve from 0.13110\n","Epoch 613/1000\n"," - 8s - loss: 0.0380 - accuracy: 0.9881 - val_loss: 4.3877 - val_accuracy: 0.4970\n","\n","Epoch 00613: val_loss did not improve from 0.13110\n","Epoch 614/1000\n"," - 8s - loss: 0.0408 - accuracy: 0.9876 - val_loss: 3.4794 - val_accuracy: 0.4935\n","\n","Epoch 00614: val_loss did not improve from 0.13110\n","Epoch 615/1000\n"," - 8s - loss: 0.0400 - accuracy: 0.9884 - val_loss: 8.7097 - val_accuracy: 0.4935\n","\n","Epoch 00615: val_loss did not improve from 0.13110\n","Epoch 616/1000\n"," - 8s - loss: 0.0346 - accuracy: 0.9902 - val_loss: 5.6093 - val_accuracy: 0.4910\n","\n","Epoch 00616: val_loss did not improve from 0.13110\n","Epoch 617/1000\n"," - 8s - loss: 0.0361 - accuracy: 0.9887 - val_loss: 2.7700 - val_accuracy: 0.4940\n","\n","Epoch 00617: val_loss did not improve from 0.13110\n","Epoch 618/1000\n"," - 8s - loss: 0.0334 - accuracy: 0.9910 - val_loss: 6.2383 - val_accuracy: 0.4886\n","\n","Epoch 00618: val_loss did not improve from 0.13110\n","Epoch 619/1000\n"," - 8s - loss: 0.0370 - accuracy: 0.9887 - val_loss: 2.9301 - val_accuracy: 0.4995\n","\n","Epoch 00619: val_loss did not improve from 0.13110\n","Epoch 620/1000\n"," - 8s - loss: 0.0330 - accuracy: 0.9920 - val_loss: 1.8666 - val_accuracy: 0.4970\n","\n","Epoch 00620: val_loss did not improve from 0.13110\n","Epoch 621/1000\n"," - 8s - loss: 0.0335 - accuracy: 0.9912 - val_loss: 3.8380 - val_accuracy: 0.4940\n","\n","Epoch 00621: val_loss did not improve from 0.13110\n","Epoch 622/1000\n"," - 8s - loss: 0.0339 - accuracy: 0.9909 - val_loss: 3.4837 - val_accuracy: 0.4891\n","\n","Epoch 00622: val_loss did not improve from 0.13110\n","Epoch 623/1000\n"," - 8s - loss: 0.0359 - accuracy: 0.9894 - val_loss: 11.2360 - val_accuracy: 0.4925\n","\n","Epoch 00623: val_loss did not improve from 0.13110\n","Epoch 624/1000\n"," - 8s - loss: 0.0365 - accuracy: 0.9902 - val_loss: 6.0917 - val_accuracy: 0.4856\n","\n","Epoch 00624: val_loss did not improve from 0.13110\n","Epoch 625/1000\n"," - 8s - loss: 0.0304 - accuracy: 0.9932 - val_loss: 4.0406 - val_accuracy: 0.4905\n","\n","Epoch 00625: val_loss did not improve from 0.13110\n","Epoch 626/1000\n"," - 8s - loss: 0.0420 - accuracy: 0.9877 - val_loss: 6.4253 - val_accuracy: 0.4915\n","\n","Epoch 00626: val_loss did not improve from 0.13110\n","Epoch 627/1000\n"," - 8s - loss: 0.0339 - accuracy: 0.9914 - val_loss: 3.6951 - val_accuracy: 0.4960\n","\n","Epoch 00627: val_loss did not improve from 0.13110\n","Epoch 628/1000\n"," - 8s - loss: 0.0368 - accuracy: 0.9894 - val_loss: 4.4962 - val_accuracy: 0.4930\n","\n","Epoch 00628: val_loss did not improve from 0.13110\n","Epoch 629/1000\n"," - 8s - loss: 0.0370 - accuracy: 0.9891 - val_loss: 5.5613 - val_accuracy: 0.4990\n","\n","Epoch 00629: val_loss did not improve from 0.13110\n","Epoch 630/1000\n"," - 8s - loss: 0.0304 - accuracy: 0.9932 - val_loss: 4.6978 - val_accuracy: 0.4975\n","\n","Epoch 00630: val_loss did not improve from 0.13110\n","Epoch 631/1000\n"," - 8s - loss: 0.0326 - accuracy: 0.9922 - val_loss: 2.3861 - val_accuracy: 0.4891\n","\n","Epoch 00631: val_loss did not improve from 0.13110\n","Epoch 632/1000\n"," - 8s - loss: 0.0288 - accuracy: 0.9927 - val_loss: 4.8461 - val_accuracy: 0.4915\n","\n","Epoch 00632: val_loss did not improve from 0.13110\n","Epoch 633/1000\n"," - 8s - loss: 0.0294 - accuracy: 0.9927 - val_loss: 3.5988 - val_accuracy: 0.4985\n","\n","Epoch 00633: val_loss did not improve from 0.13110\n","Epoch 634/1000\n"," - 8s - loss: 0.0323 - accuracy: 0.9905 - val_loss: 5.5936 - val_accuracy: 0.4876\n","\n","Epoch 00634: val_loss did not improve from 0.13110\n","Epoch 635/1000\n"," - 8s - loss: 0.0334 - accuracy: 0.9900 - val_loss: 2.7610 - val_accuracy: 0.4886\n","\n","Epoch 00635: val_loss did not improve from 0.13110\n","Epoch 636/1000\n"," - 8s - loss: 0.0352 - accuracy: 0.9897 - val_loss: 4.5068 - val_accuracy: 0.4900\n","\n","Epoch 00636: val_loss did not improve from 0.13110\n","Epoch 637/1000\n"," - 8s - loss: 0.0313 - accuracy: 0.9905 - val_loss: 4.5547 - val_accuracy: 0.4990\n","\n","Epoch 00637: val_loss did not improve from 0.13110\n","Epoch 638/1000\n"," - 8s - loss: 0.0298 - accuracy: 0.9922 - val_loss: 4.3230 - val_accuracy: 0.4910\n","\n","Epoch 00638: val_loss did not improve from 0.13110\n","Epoch 639/1000\n"," - 8s - loss: 0.0356 - accuracy: 0.9874 - val_loss: 5.6184 - val_accuracy: 0.4876\n","\n","Epoch 00639: val_loss did not improve from 0.13110\n","Epoch 640/1000\n"," - 8s - loss: 0.0288 - accuracy: 0.9934 - val_loss: 1.7476 - val_accuracy: 0.4935\n","\n","Epoch 00640: val_loss did not improve from 0.13110\n","Epoch 641/1000\n"," - 8s - loss: 0.0313 - accuracy: 0.9920 - val_loss: 1.7083 - val_accuracy: 0.4856\n","\n","Epoch 00641: val_loss did not improve from 0.13110\n","Epoch 642/1000\n"," - 8s - loss: 0.0327 - accuracy: 0.9907 - val_loss: 2.8993 - val_accuracy: 0.4935\n","\n","Epoch 00642: val_loss did not improve from 0.13110\n","Epoch 643/1000\n"," - 8s - loss: 0.0337 - accuracy: 0.9886 - val_loss: 6.7726 - val_accuracy: 0.4910\n","\n","Epoch 00643: val_loss did not improve from 0.13110\n","Epoch 644/1000\n"," - 8s - loss: 0.0371 - accuracy: 0.9887 - val_loss: 6.4495 - val_accuracy: 0.4846\n","\n","Epoch 00644: val_loss did not improve from 0.13110\n","Epoch 645/1000\n"," - 8s - loss: 0.0333 - accuracy: 0.9915 - val_loss: 3.4861 - val_accuracy: 0.4861\n","\n","Epoch 00645: val_loss did not improve from 0.13110\n","Epoch 646/1000\n"," - 8s - loss: 0.0315 - accuracy: 0.9922 - val_loss: 10.0492 - val_accuracy: 0.4861\n","\n","Epoch 00646: val_loss did not improve from 0.13110\n","Epoch 647/1000\n"," - 8s - loss: 0.0351 - accuracy: 0.9892 - val_loss: 2.8697 - val_accuracy: 0.4930\n","\n","Epoch 00647: val_loss did not improve from 0.13110\n","Epoch 648/1000\n"," - 8s - loss: 0.0304 - accuracy: 0.9917 - val_loss: 1.4456 - val_accuracy: 0.4886\n","\n","Epoch 00648: val_loss did not improve from 0.13110\n","Epoch 649/1000\n"," - 8s - loss: 0.0326 - accuracy: 0.9912 - val_loss: 7.1210 - val_accuracy: 0.4811\n","\n","Epoch 00649: val_loss did not improve from 0.13110\n","Epoch 650/1000\n"," - 8s - loss: 0.0285 - accuracy: 0.9934 - val_loss: 4.4539 - val_accuracy: 0.4841\n","\n","Epoch 00650: val_loss did not improve from 0.13110\n","Epoch 651/1000\n"," - 8s - loss: 0.0360 - accuracy: 0.9900 - val_loss: 3.8278 - val_accuracy: 0.4771\n","\n","Epoch 00651: val_loss did not improve from 0.13110\n","Epoch 652/1000\n"," - 8s - loss: 0.0327 - accuracy: 0.9910 - val_loss: 5.2065 - val_accuracy: 0.4900\n","\n","Epoch 00652: val_loss did not improve from 0.13110\n","Epoch 653/1000\n"," - 8s - loss: 0.0310 - accuracy: 0.9917 - val_loss: 2.6465 - val_accuracy: 0.4801\n","\n","Epoch 00653: val_loss did not improve from 0.13110\n","Epoch 654/1000\n"," - 8s - loss: 0.0295 - accuracy: 0.9944 - val_loss: 5.0875 - val_accuracy: 0.4791\n","\n","Epoch 00654: val_loss did not improve from 0.13110\n","Epoch 655/1000\n"," - 8s - loss: 0.0312 - accuracy: 0.9925 - val_loss: 4.8080 - val_accuracy: 0.4816\n","\n","Epoch 00655: val_loss did not improve from 0.13110\n","Epoch 656/1000\n"," - 8s - loss: 0.0294 - accuracy: 0.9925 - val_loss: 3.3810 - val_accuracy: 0.4791\n","\n","Epoch 00656: val_loss did not improve from 0.13110\n","Epoch 657/1000\n"," - 8s - loss: 0.0336 - accuracy: 0.9909 - val_loss: 6.1597 - val_accuracy: 0.4871\n","\n","Epoch 00657: val_loss did not improve from 0.13110\n","Epoch 658/1000\n"," - 8s - loss: 0.0352 - accuracy: 0.9905 - val_loss: 4.2495 - val_accuracy: 0.4891\n","\n","Epoch 00658: val_loss did not improve from 0.13110\n","Epoch 659/1000\n"," - 8s - loss: 0.0288 - accuracy: 0.9940 - val_loss: 2.1154 - val_accuracy: 0.4900\n","\n","Epoch 00659: val_loss did not improve from 0.13110\n","Epoch 660/1000\n"," - 8s - loss: 0.0282 - accuracy: 0.9929 - val_loss: 3.8320 - val_accuracy: 0.4891\n","\n","Epoch 00660: val_loss did not improve from 0.13110\n","Epoch 661/1000\n"," - 8s - loss: 0.0273 - accuracy: 0.9925 - val_loss: 5.0914 - val_accuracy: 0.5005\n","\n","Epoch 00661: val_loss did not improve from 0.13110\n","Epoch 662/1000\n"," - 8s - loss: 0.0299 - accuracy: 0.9917 - val_loss: 4.2423 - val_accuracy: 0.4861\n","\n","Epoch 00662: val_loss did not improve from 0.13110\n","Epoch 663/1000\n"," - 8s - loss: 0.0306 - accuracy: 0.9927 - val_loss: 0.6728 - val_accuracy: 0.4950\n","\n","Epoch 00663: val_loss did not improve from 0.13110\n","Epoch 664/1000\n"," - 8s - loss: 0.0258 - accuracy: 0.9934 - val_loss: 4.9921 - val_accuracy: 0.4940\n","\n","Epoch 00664: val_loss did not improve from 0.13110\n","Epoch 665/1000\n"," - 8s - loss: 0.0265 - accuracy: 0.9932 - val_loss: 2.8830 - val_accuracy: 0.4786\n","\n","Epoch 00665: val_loss did not improve from 0.13110\n","Epoch 666/1000\n"," - 8s - loss: 0.0297 - accuracy: 0.9927 - val_loss: 5.1037 - val_accuracy: 0.4910\n","\n","Epoch 00666: val_loss did not improve from 0.13110\n","Epoch 667/1000\n"," - 8s - loss: 0.0268 - accuracy: 0.9937 - val_loss: 2.5711 - val_accuracy: 0.4990\n","\n","Epoch 00667: val_loss did not improve from 0.13110\n","Epoch 668/1000\n"," - 8s - loss: 0.0251 - accuracy: 0.9942 - val_loss: 2.3779 - val_accuracy: 0.4851\n","\n","Epoch 00668: val_loss did not improve from 0.13110\n","Epoch 669/1000\n"," - 8s - loss: 0.0334 - accuracy: 0.9900 - val_loss: 1.8952 - val_accuracy: 0.4886\n","\n","Epoch 00669: val_loss did not improve from 0.13110\n","Epoch 670/1000\n"," - 8s - loss: 0.0331 - accuracy: 0.9912 - val_loss: 4.9219 - val_accuracy: 0.4920\n","\n","Epoch 00670: val_loss did not improve from 0.13110\n","Epoch 671/1000\n"," - 8s - loss: 0.0265 - accuracy: 0.9935 - val_loss: 7.9630 - val_accuracy: 0.4841\n","\n","Epoch 00671: val_loss did not improve from 0.13110\n","Epoch 672/1000\n"," - 8s - loss: 0.0285 - accuracy: 0.9927 - val_loss: 2.2138 - val_accuracy: 0.4791\n","\n","Epoch 00672: val_loss did not improve from 0.13110\n","Epoch 673/1000\n"," - 8s - loss: 0.0290 - accuracy: 0.9925 - val_loss: 5.1867 - val_accuracy: 0.4861\n","\n","Epoch 00673: val_loss did not improve from 0.13110\n","Epoch 674/1000\n"," - 8s - loss: 0.0306 - accuracy: 0.9912 - val_loss: 4.4936 - val_accuracy: 0.4846\n","\n","Epoch 00674: val_loss did not improve from 0.13110\n","Epoch 675/1000\n"," - 8s - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.9993 - val_accuracy: 0.4945\n","\n","Epoch 00675: val_loss did not improve from 0.13110\n","Epoch 676/1000\n"," - 8s - loss: 0.0266 - accuracy: 0.9935 - val_loss: 3.4590 - val_accuracy: 0.4881\n","\n","Epoch 00676: val_loss did not improve from 0.13110\n","Epoch 677/1000\n"," - 8s - loss: 0.0258 - accuracy: 0.9939 - val_loss: 2.9676 - val_accuracy: 0.4851\n","\n","Epoch 00677: val_loss did not improve from 0.13110\n","Epoch 678/1000\n"," - 8s - loss: 0.0275 - accuracy: 0.9925 - val_loss: 4.7040 - val_accuracy: 0.4930\n","\n","Epoch 00678: val_loss did not improve from 0.13110\n","Epoch 679/1000\n"," - 8s - loss: 0.0266 - accuracy: 0.9935 - val_loss: 5.8199 - val_accuracy: 0.4826\n","\n","Epoch 00679: val_loss did not improve from 0.13110\n","Epoch 680/1000\n"," - 8s - loss: 0.0305 - accuracy: 0.9920 - val_loss: 6.0436 - val_accuracy: 0.4965\n","\n","Epoch 00680: val_loss did not improve from 0.13110\n","Epoch 681/1000\n"," - 8s - loss: 0.0280 - accuracy: 0.9924 - val_loss: 4.9043 - val_accuracy: 0.4891\n","\n","Epoch 00681: val_loss did not improve from 0.13110\n","Epoch 682/1000\n"," - 8s - loss: 0.0245 - accuracy: 0.9944 - val_loss: 3.4066 - val_accuracy: 0.4841\n","\n","Epoch 00682: val_loss did not improve from 0.13110\n","Epoch 683/1000\n"," - 8s - loss: 0.0257 - accuracy: 0.9937 - val_loss: 4.4320 - val_accuracy: 0.4945\n","\n","Epoch 00683: val_loss did not improve from 0.13110\n","Epoch 684/1000\n"," - 8s - loss: 0.0275 - accuracy: 0.9924 - val_loss: 4.9020 - val_accuracy: 0.4881\n","\n","Epoch 00684: val_loss did not improve from 0.13110\n","Epoch 685/1000\n"," - 8s - loss: 0.0303 - accuracy: 0.9917 - val_loss: 5.4633 - val_accuracy: 0.4796\n","\n","Epoch 00685: val_loss did not improve from 0.13110\n","Epoch 686/1000\n"," - 8s - loss: 0.0273 - accuracy: 0.9919 - val_loss: 5.8700 - val_accuracy: 0.4771\n","\n","Epoch 00686: val_loss did not improve from 0.13110\n","Epoch 687/1000\n"," - 8s - loss: 0.0287 - accuracy: 0.9922 - val_loss: 3.3572 - val_accuracy: 0.4876\n","\n","Epoch 00687: val_loss did not improve from 0.13110\n","Epoch 688/1000\n"," - 8s - loss: 0.0247 - accuracy: 0.9935 - val_loss: 8.8346 - val_accuracy: 0.4930\n","\n","Epoch 00688: val_loss did not improve from 0.13110\n","Epoch 689/1000\n"," - 8s - loss: 0.0281 - accuracy: 0.9925 - val_loss: 6.5359 - val_accuracy: 0.4950\n","\n","Epoch 00689: val_loss did not improve from 0.13110\n","Epoch 690/1000\n"," - 8s - loss: 0.0231 - accuracy: 0.9945 - val_loss: 6.0975 - val_accuracy: 0.4915\n","\n","Epoch 00690: val_loss did not improve from 0.13110\n","Epoch 691/1000\n"," - 8s - loss: 0.0241 - accuracy: 0.9945 - val_loss: 2.6366 - val_accuracy: 0.5000\n","\n","Epoch 00691: val_loss did not improve from 0.13110\n","Epoch 692/1000\n"," - 8s - loss: 0.0274 - accuracy: 0.9910 - val_loss: 2.9177 - val_accuracy: 0.4985\n","\n","Epoch 00692: val_loss did not improve from 0.13110\n","Epoch 693/1000\n"," - 8s - loss: 0.0308 - accuracy: 0.9919 - val_loss: 6.8789 - val_accuracy: 0.4955\n","\n","Epoch 00693: val_loss did not improve from 0.13110\n","Epoch 694/1000\n"," - 8s - loss: 0.0271 - accuracy: 0.9929 - val_loss: 3.8982 - val_accuracy: 0.4821\n","\n","Epoch 00694: val_loss did not improve from 0.13110\n","Epoch 695/1000\n"," - 8s - loss: 0.0249 - accuracy: 0.9939 - val_loss: 1.8428 - val_accuracy: 0.4925\n","\n","Epoch 00695: val_loss did not improve from 0.13110\n","Epoch 696/1000\n"," - 8s - loss: 0.0235 - accuracy: 0.9952 - val_loss: 1.6138 - val_accuracy: 0.4935\n","\n","Epoch 00696: val_loss did not improve from 0.13110\n","Epoch 697/1000\n"," - 8s - loss: 0.0263 - accuracy: 0.9932 - val_loss: 3.1139 - val_accuracy: 0.4925\n","\n","Epoch 00697: val_loss did not improve from 0.13110\n","Epoch 698/1000\n"," - 8s - loss: 0.0242 - accuracy: 0.9939 - val_loss: 5.8359 - val_accuracy: 0.4841\n","\n","Epoch 00698: val_loss did not improve from 0.13110\n","Epoch 699/1000\n"," - 8s - loss: 0.0250 - accuracy: 0.9939 - val_loss: 6.3598 - val_accuracy: 0.4771\n","\n","Epoch 00699: val_loss did not improve from 0.13110\n","Epoch 700/1000\n"," - 8s - loss: 0.0260 - accuracy: 0.9932 - val_loss: 4.6477 - val_accuracy: 0.5000\n","\n","Epoch 00700: val_loss did not improve from 0.13110\n","Epoch 701/1000\n"," - 8s - loss: 0.0323 - accuracy: 0.9897 - val_loss: 1.3331 - val_accuracy: 0.4905\n","\n","Epoch 00701: val_loss did not improve from 0.13110\n","Epoch 702/1000\n"," - 8s - loss: 0.0286 - accuracy: 0.9920 - val_loss: 3.7599 - val_accuracy: 0.4891\n","\n","Epoch 00702: val_loss did not improve from 0.13110\n","Epoch 703/1000\n"," - 8s - loss: 0.0231 - accuracy: 0.9944 - val_loss: 5.2906 - val_accuracy: 0.4905\n","\n","Epoch 00703: val_loss did not improve from 0.13110\n","Epoch 704/1000\n"," - 8s - loss: 0.0231 - accuracy: 0.9947 - val_loss: 7.4087 - val_accuracy: 0.4831\n","\n","Epoch 00704: val_loss did not improve from 0.13110\n","Epoch 705/1000\n"," - 8s - loss: 0.0260 - accuracy: 0.9937 - val_loss: 1.4108 - val_accuracy: 0.4866\n","\n","Epoch 00705: val_loss did not improve from 0.13110\n","Epoch 706/1000\n"," - 8s - loss: 0.0223 - accuracy: 0.9940 - val_loss: 6.0419 - val_accuracy: 0.4950\n","\n","Epoch 00706: val_loss did not improve from 0.13110\n","Epoch 707/1000\n"," - 8s - loss: 0.0303 - accuracy: 0.9900 - val_loss: 3.6785 - val_accuracy: 0.4861\n","\n","Epoch 00707: val_loss did not improve from 0.13110\n","Epoch 708/1000\n"," - 8s - loss: 0.0216 - accuracy: 0.9947 - val_loss: 8.1005 - val_accuracy: 0.4836\n","\n","Epoch 00708: val_loss did not improve from 0.13110\n","Epoch 709/1000\n"," - 8s - loss: 0.0243 - accuracy: 0.9935 - val_loss: 2.9154 - val_accuracy: 0.4796\n","\n","Epoch 00709: val_loss did not improve from 0.13110\n","Epoch 710/1000\n"," - 8s - loss: 0.0213 - accuracy: 0.9944 - val_loss: 3.9797 - val_accuracy: 0.4821\n","\n","Epoch 00710: val_loss did not improve from 0.13110\n","Epoch 711/1000\n"," - 8s - loss: 0.0274 - accuracy: 0.9919 - val_loss: 7.2764 - val_accuracy: 0.4876\n","\n","Epoch 00711: val_loss did not improve from 0.13110\n","Epoch 712/1000\n"," - 8s - loss: 0.0251 - accuracy: 0.9940 - val_loss: 8.0989 - val_accuracy: 0.4876\n","\n","Epoch 00712: val_loss did not improve from 0.13110\n","Epoch 713/1000\n"," - 8s - loss: 0.0241 - accuracy: 0.9935 - val_loss: 6.0894 - val_accuracy: 0.4955\n","\n","Epoch 00713: val_loss did not improve from 0.13110\n","Epoch 714/1000\n"," - 8s - loss: 0.0300 - accuracy: 0.9905 - val_loss: 2.8491 - val_accuracy: 0.4896\n","\n","Epoch 00714: val_loss did not improve from 0.13110\n","Epoch 715/1000\n"," - 8s - loss: 0.0228 - accuracy: 0.9937 - val_loss: 4.4309 - val_accuracy: 0.4851\n","\n","Epoch 00715: val_loss did not improve from 0.13110\n","Epoch 716/1000\n"," - 8s - loss: 0.0192 - accuracy: 0.9965 - val_loss: 3.6397 - val_accuracy: 0.4846\n","\n","Epoch 00716: val_loss did not improve from 0.13110\n","Epoch 717/1000\n"," - 8s - loss: 0.0224 - accuracy: 0.9950 - val_loss: 6.5958 - val_accuracy: 0.4771\n","\n","Epoch 00717: val_loss did not improve from 0.13110\n","Epoch 718/1000\n"," - 8s - loss: 0.0285 - accuracy: 0.9907 - val_loss: 3.7606 - val_accuracy: 0.4861\n","\n","Epoch 00718: val_loss did not improve from 0.13110\n","Epoch 719/1000\n"," - 8s - loss: 0.0243 - accuracy: 0.9940 - val_loss: 3.6563 - val_accuracy: 0.4826\n","\n","Epoch 00719: val_loss did not improve from 0.13110\n","Epoch 720/1000\n"," - 8s - loss: 0.0259 - accuracy: 0.9939 - val_loss: 8.1663 - val_accuracy: 0.4866\n","\n","Epoch 00720: val_loss did not improve from 0.13110\n","Epoch 721/1000\n"," - 8s - loss: 0.0195 - accuracy: 0.9964 - val_loss: 5.0689 - val_accuracy: 0.4801\n","\n","Epoch 00721: val_loss did not improve from 0.13110\n","Epoch 722/1000\n"," - 8s - loss: 0.0199 - accuracy: 0.9960 - val_loss: 7.1269 - val_accuracy: 0.4935\n","\n","Epoch 00722: val_loss did not improve from 0.13110\n","Epoch 723/1000\n"," - 8s - loss: 0.0254 - accuracy: 0.9927 - val_loss: 1.8064 - val_accuracy: 0.4841\n","\n","Epoch 00723: val_loss did not improve from 0.13110\n","Epoch 724/1000\n"," - 8s - loss: 0.0196 - accuracy: 0.9967 - val_loss: 1.6385 - val_accuracy: 0.4871\n","\n","Epoch 00724: val_loss did not improve from 0.13110\n","Epoch 725/1000\n"," - 8s - loss: 0.0202 - accuracy: 0.9962 - val_loss: 2.5666 - val_accuracy: 0.4866\n","\n","Epoch 00725: val_loss did not improve from 0.13110\n","Epoch 726/1000\n"," - 8s - loss: 0.0299 - accuracy: 0.9915 - val_loss: 3.0451 - val_accuracy: 0.4861\n","\n","Epoch 00726: val_loss did not improve from 0.13110\n","Epoch 727/1000\n"," - 8s - loss: 0.0220 - accuracy: 0.9944 - val_loss: 2.6843 - val_accuracy: 0.4796\n","\n","Epoch 00727: val_loss did not improve from 0.13110\n","Epoch 728/1000\n"," - 8s - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.0998 - val_accuracy: 0.4945\n","\n","Epoch 00728: val_loss improved from 0.13110 to 0.09976, saving model to /content/drive/My Drive/Colab Notebooks/Project_Stock/ckpt/classifier_45_close_updown_pr_theta_shuffle_without_back.h5\n","Epoch 729/1000\n"," - 8s - loss: 0.0219 - accuracy: 0.9947 - val_loss: 2.2427 - val_accuracy: 0.4945\n","\n","Epoch 00729: val_loss did not improve from 0.09976\n","Epoch 730/1000\n"," - 8s - loss: 0.0241 - accuracy: 0.9944 - val_loss: 1.9437 - val_accuracy: 0.4925\n","\n","Epoch 00730: val_loss did not improve from 0.09976\n","Epoch 731/1000\n"," - 8s - loss: 0.0256 - accuracy: 0.9935 - val_loss: 4.4116 - val_accuracy: 0.4876\n","\n","Epoch 00731: val_loss did not improve from 0.09976\n","Epoch 732/1000\n"," - 8s - loss: 0.0197 - accuracy: 0.9962 - val_loss: 3.2034 - val_accuracy: 0.4945\n","\n","Epoch 00732: val_loss did not improve from 0.09976\n","Epoch 733/1000\n"," - 8s - loss: 0.0239 - accuracy: 0.9944 - val_loss: 4.8387 - val_accuracy: 0.4925\n","\n","Epoch 00733: val_loss did not improve from 0.09976\n","Epoch 734/1000\n"," - 8s - loss: 0.0203 - accuracy: 0.9954 - val_loss: 3.8541 - val_accuracy: 0.4876\n","\n","Epoch 00734: val_loss did not improve from 0.09976\n","Epoch 735/1000\n"," - 8s - loss: 0.0194 - accuracy: 0.9945 - val_loss: 2.1662 - val_accuracy: 0.4920\n","\n","Epoch 00735: val_loss did not improve from 0.09976\n","Epoch 736/1000\n"," - 8s - loss: 0.0213 - accuracy: 0.9949 - val_loss: 5.7103 - val_accuracy: 0.4856\n","\n","Epoch 00736: val_loss did not improve from 0.09976\n","Epoch 737/1000\n"," - 8s - loss: 0.0232 - accuracy: 0.9932 - val_loss: 3.6911 - val_accuracy: 0.4856\n","\n","Epoch 00737: val_loss did not improve from 0.09976\n","Epoch 738/1000\n"," - 8s - loss: 0.0211 - accuracy: 0.9954 - val_loss: 2.8506 - val_accuracy: 0.4866\n","\n","Epoch 00738: val_loss did not improve from 0.09976\n","Epoch 739/1000\n"," - 8s - loss: 0.0199 - accuracy: 0.9957 - val_loss: 3.6573 - val_accuracy: 0.4876\n","\n","Epoch 00739: val_loss did not improve from 0.09976\n","Epoch 740/1000\n"," - 8s - loss: 0.0266 - accuracy: 0.9922 - val_loss: 5.8589 - val_accuracy: 0.5070\n","\n","Epoch 00740: val_loss did not improve from 0.09976\n","Epoch 741/1000\n"," - 8s - loss: 0.0215 - accuracy: 0.9942 - val_loss: 2.6411 - val_accuracy: 0.4876\n","\n","Epoch 00741: val_loss did not improve from 0.09976\n","Epoch 742/1000\n"," - 8s - loss: 0.0225 - accuracy: 0.9939 - val_loss: 6.5012 - val_accuracy: 0.4975\n","\n","Epoch 00742: val_loss did not improve from 0.09976\n","Epoch 743/1000\n"," - 8s - loss: 0.0217 - accuracy: 0.9942 - val_loss: 3.8714 - val_accuracy: 0.4930\n","\n","Epoch 00743: val_loss did not improve from 0.09976\n","Epoch 744/1000\n"," - 8s - loss: 0.0200 - accuracy: 0.9957 - val_loss: 1.3203 - val_accuracy: 0.4881\n","\n","Epoch 00744: val_loss did not improve from 0.09976\n","Epoch 745/1000\n"," - 8s - loss: 0.0211 - accuracy: 0.9947 - val_loss: 8.5771 - val_accuracy: 0.4871\n","\n","Epoch 00745: val_loss did not improve from 0.09976\n","Epoch 746/1000\n"," - 8s - loss: 0.0281 - accuracy: 0.9920 - val_loss: 6.6419 - val_accuracy: 0.4940\n","\n","Epoch 00746: val_loss did not improve from 0.09976\n","Epoch 747/1000\n"," - 8s - loss: 0.0229 - accuracy: 0.9944 - val_loss: 4.8117 - val_accuracy: 0.4866\n","\n","Epoch 00747: val_loss did not improve from 0.09976\n","Epoch 748/1000\n"," - 8s - loss: 0.0201 - accuracy: 0.9959 - val_loss: 1.4135 - val_accuracy: 0.4826\n","\n","Epoch 00748: val_loss did not improve from 0.09976\n","Epoch 749/1000\n"," - 8s - loss: 0.0183 - accuracy: 0.9959 - val_loss: 7.2371 - val_accuracy: 0.4886\n","\n","Epoch 00749: val_loss did not improve from 0.09976\n","Epoch 750/1000\n"," - 8s - loss: 0.0216 - accuracy: 0.9934 - val_loss: 6.8057 - val_accuracy: 0.4970\n","\n","Epoch 00750: val_loss did not improve from 0.09976\n","Epoch 751/1000\n"," - 8s - loss: 0.0211 - accuracy: 0.9942 - val_loss: 4.1302 - val_accuracy: 0.4965\n","\n","Epoch 00751: val_loss did not improve from 0.09976\n","Epoch 752/1000\n"," - 8s - loss: 0.0192 - accuracy: 0.9959 - val_loss: 3.2145 - val_accuracy: 0.4871\n","\n","Epoch 00752: val_loss did not improve from 0.09976\n","Epoch 753/1000\n"," - 8s - loss: 0.0214 - accuracy: 0.9942 - val_loss: 3.4584 - val_accuracy: 0.4881\n","\n","Epoch 00753: val_loss did not improve from 0.09976\n","Epoch 754/1000\n"," - 8s - loss: 0.0214 - accuracy: 0.9947 - val_loss: 5.0897 - val_accuracy: 0.4896\n","\n","Epoch 00754: val_loss did not improve from 0.09976\n","Epoch 755/1000\n"," - 8s - loss: 0.0229 - accuracy: 0.9925 - val_loss: 3.4980 - val_accuracy: 0.4856\n","\n","Epoch 00755: val_loss did not improve from 0.09976\n","Epoch 756/1000\n"," - 8s - loss: 0.0205 - accuracy: 0.9960 - val_loss: 3.7393 - val_accuracy: 0.4900\n","\n","Epoch 00756: val_loss did not improve from 0.09976\n","Epoch 757/1000\n"," - 8s - loss: 0.0187 - accuracy: 0.9945 - val_loss: 4.8221 - val_accuracy: 0.4910\n","\n","Epoch 00757: val_loss did not improve from 0.09976\n","Epoch 758/1000\n"," - 8s - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.3662 - val_accuracy: 0.4920\n","\n","Epoch 00758: val_loss did not improve from 0.09976\n","Epoch 759/1000\n"," - 8s - loss: 0.0233 - accuracy: 0.9927 - val_loss: 3.6024 - val_accuracy: 0.4930\n","\n","Epoch 00759: val_loss did not improve from 0.09976\n","Epoch 760/1000\n"," - 8s - loss: 0.0224 - accuracy: 0.9940 - val_loss: 3.0654 - val_accuracy: 0.4886\n","\n","Epoch 00760: val_loss did not improve from 0.09976\n","Epoch 761/1000\n"," - 8s - loss: 0.0183 - accuracy: 0.9955 - val_loss: 7.1187 - val_accuracy: 0.4975\n","\n","Epoch 00761: val_loss did not improve from 0.09976\n","Epoch 762/1000\n"," - 8s - loss: 0.0200 - accuracy: 0.9954 - val_loss: 3.1443 - val_accuracy: 0.4930\n","\n","Epoch 00762: val_loss did not improve from 0.09976\n","Epoch 763/1000\n"," - 8s - loss: 0.0234 - accuracy: 0.9934 - val_loss: 2.7532 - val_accuracy: 0.4871\n","\n","Epoch 00763: val_loss did not improve from 0.09976\n","Epoch 764/1000\n"," - 8s - loss: 0.0215 - accuracy: 0.9942 - val_loss: 4.4084 - val_accuracy: 0.4856\n","\n","Epoch 00764: val_loss did not improve from 0.09976\n","Epoch 765/1000\n"," - 8s - loss: 0.0192 - accuracy: 0.9959 - val_loss: 6.2483 - val_accuracy: 0.4866\n","\n","Epoch 00765: val_loss did not improve from 0.09976\n","Epoch 766/1000\n"," - 8s - loss: 0.0203 - accuracy: 0.9949 - val_loss: 5.7030 - val_accuracy: 0.4886\n","\n","Epoch 00766: val_loss did not improve from 0.09976\n","Epoch 767/1000\n"," - 8s - loss: 0.0207 - accuracy: 0.9947 - val_loss: 2.5672 - val_accuracy: 0.4776\n","\n","Epoch 00767: val_loss did not improve from 0.09976\n","Epoch 768/1000\n"," - 8s - loss: 0.0206 - accuracy: 0.9944 - val_loss: 4.8291 - val_accuracy: 0.4881\n","\n","Epoch 00768: val_loss did not improve from 0.09976\n","Epoch 769/1000\n"," - 8s - loss: 0.0221 - accuracy: 0.9942 - val_loss: 4.4196 - val_accuracy: 0.5025\n","\n","Epoch 00769: val_loss did not improve from 0.09976\n","Epoch 770/1000\n"," - 8s - loss: 0.0187 - accuracy: 0.9950 - val_loss: 3.2249 - val_accuracy: 0.4935\n","\n","Epoch 00770: val_loss did not improve from 0.09976\n","Epoch 771/1000\n"," - 8s - loss: 0.0163 - accuracy: 0.9968 - val_loss: 4.0620 - val_accuracy: 0.4945\n","\n","Epoch 00771: val_loss did not improve from 0.09976\n","Epoch 772/1000\n"," - 8s - loss: 0.0182 - accuracy: 0.9967 - val_loss: 2.2785 - val_accuracy: 0.5035\n","\n","Epoch 00772: val_loss did not improve from 0.09976\n","Epoch 773/1000\n"," - 8s - loss: 0.0193 - accuracy: 0.9960 - val_loss: 5.0490 - val_accuracy: 0.4940\n","\n","Epoch 00773: val_loss did not improve from 0.09976\n","Epoch 774/1000\n"," - 8s - loss: 0.0206 - accuracy: 0.9954 - val_loss: 5.6456 - val_accuracy: 0.4950\n","\n","Epoch 00774: val_loss did not improve from 0.09976\n","Epoch 775/1000\n"," - 8s - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.9554 - val_accuracy: 0.4900\n","\n","Epoch 00775: val_loss did not improve from 0.09976\n","Epoch 776/1000\n"," - 8s - loss: 0.0212 - accuracy: 0.9947 - val_loss: 1.7413 - val_accuracy: 0.4915\n","\n","Epoch 00776: val_loss did not improve from 0.09976\n","Epoch 777/1000\n"," - 8s - loss: 0.0207 - accuracy: 0.9947 - val_loss: 3.3200 - val_accuracy: 0.4881\n","\n","Epoch 00777: val_loss did not improve from 0.09976\n","Epoch 778/1000\n"," - 8s - loss: 0.0185 - accuracy: 0.9950 - val_loss: 0.3920 - val_accuracy: 0.4876\n","\n","Epoch 00778: val_loss did not improve from 0.09976\n","Epoch 779/1000\n"," - 8s - loss: 0.0197 - accuracy: 0.9955 - val_loss: 10.1771 - val_accuracy: 0.4935\n","\n","Epoch 00779: val_loss did not improve from 0.09976\n","Epoch 780/1000\n"," - 8s - loss: 0.0170 - accuracy: 0.9962 - val_loss: 4.8518 - val_accuracy: 0.4925\n","\n","Epoch 00780: val_loss did not improve from 0.09976\n","Epoch 781/1000\n"," - 8s - loss: 0.0196 - accuracy: 0.9955 - val_loss: 5.7325 - val_accuracy: 0.4871\n","\n","Epoch 00781: val_loss did not improve from 0.09976\n","Epoch 782/1000\n"," - 8s - loss: 0.0227 - accuracy: 0.9934 - val_loss: 10.0875 - val_accuracy: 0.4965\n","\n","Epoch 00782: val_loss did not improve from 0.09976\n","Epoch 783/1000\n"," - 8s - loss: 0.0169 - accuracy: 0.9965 - val_loss: 4.9663 - val_accuracy: 0.4955\n","\n","Epoch 00783: val_loss did not improve from 0.09976\n","Epoch 784/1000\n"," - 8s - loss: 0.0167 - accuracy: 0.9962 - val_loss: 4.4831 - val_accuracy: 0.5005\n","\n","Epoch 00784: val_loss did not improve from 0.09976\n","Epoch 785/1000\n"," - 8s - loss: 0.0176 - accuracy: 0.9964 - val_loss: 3.7945 - val_accuracy: 0.4896\n","\n","Epoch 00785: val_loss did not improve from 0.09976\n","Epoch 786/1000\n"," - 8s - loss: 0.0195 - accuracy: 0.9944 - val_loss: 6.5040 - val_accuracy: 0.4985\n","\n","Epoch 00786: val_loss did not improve from 0.09976\n","Epoch 787/1000\n"," - 8s - loss: 0.0173 - accuracy: 0.9964 - val_loss: 4.6790 - val_accuracy: 0.4955\n","\n","Epoch 00787: val_loss did not improve from 0.09976\n","Epoch 788/1000\n"," - 8s - loss: 0.0177 - accuracy: 0.9964 - val_loss: 7.4458 - val_accuracy: 0.4876\n","\n","Epoch 00788: val_loss did not improve from 0.09976\n","Epoch 789/1000\n"," - 8s - loss: 0.0175 - accuracy: 0.9970 - val_loss: 4.8149 - val_accuracy: 0.4841\n","\n","Epoch 00789: val_loss did not improve from 0.09976\n","Epoch 790/1000\n"," - 8s - loss: 0.0197 - accuracy: 0.9955 - val_loss: 3.9550 - val_accuracy: 0.4871\n","\n","Epoch 00790: val_loss did not improve from 0.09976\n","Epoch 791/1000\n"," - 8s - loss: 0.0188 - accuracy: 0.9952 - val_loss: 9.6503 - val_accuracy: 0.4900\n","\n","Epoch 00791: val_loss did not improve from 0.09976\n","Epoch 792/1000\n"," - 8s - loss: 0.0166 - accuracy: 0.9954 - val_loss: 7.7025 - val_accuracy: 0.4900\n","\n","Epoch 00792: val_loss did not improve from 0.09976\n","Epoch 793/1000\n"," - 8s - loss: 0.0171 - accuracy: 0.9970 - val_loss: 4.1030 - val_accuracy: 0.4955\n","\n","Epoch 00793: val_loss did not improve from 0.09976\n","Epoch 794/1000\n"," - 8s - loss: 0.0192 - accuracy: 0.9954 - val_loss: 6.2902 - val_accuracy: 0.4910\n","\n","Epoch 00794: val_loss did not improve from 0.09976\n","Epoch 795/1000\n"," - 8s - loss: 0.0174 - accuracy: 0.9952 - val_loss: 4.9922 - val_accuracy: 0.4975\n","\n","Epoch 00795: val_loss did not improve from 0.09976\n","Epoch 796/1000\n"," - 8s - loss: 0.0173 - accuracy: 0.9962 - val_loss: 3.5967 - val_accuracy: 0.4915\n","\n","Epoch 00796: val_loss did not improve from 0.09976\n","Epoch 797/1000\n"," - 8s - loss: 0.0174 - accuracy: 0.9959 - val_loss: 2.4953 - val_accuracy: 0.4940\n","\n","Epoch 00797: val_loss did not improve from 0.09976\n","Epoch 798/1000\n"," - 8s - loss: 0.0156 - accuracy: 0.9968 - val_loss: 5.5180 - val_accuracy: 0.4861\n","\n","Epoch 00798: val_loss did not improve from 0.09976\n","Epoch 799/1000\n"," - 8s - loss: 0.0143 - accuracy: 0.9977 - val_loss: 9.0442 - val_accuracy: 0.5010\n","\n","Epoch 00799: val_loss did not improve from 0.09976\n","Epoch 800/1000\n"," - 8s - loss: 0.0174 - accuracy: 0.9947 - val_loss: 3.9333 - val_accuracy: 0.4866\n","\n","Epoch 00800: val_loss did not improve from 0.09976\n","Epoch 801/1000\n"," - 8s - loss: 0.0184 - accuracy: 0.9964 - val_loss: 3.8525 - val_accuracy: 0.4846\n","\n","Epoch 00801: val_loss did not improve from 0.09976\n","Epoch 802/1000\n"," - 8s - loss: 0.0193 - accuracy: 0.9950 - val_loss: 6.7180 - val_accuracy: 0.4905\n","\n","Epoch 00802: val_loss did not improve from 0.09976\n","Epoch 803/1000\n"," - 8s - loss: 0.0217 - accuracy: 0.9939 - val_loss: 10.5522 - val_accuracy: 0.4891\n","\n","Epoch 00803: val_loss did not improve from 0.09976\n","Epoch 804/1000\n"," - 8s - loss: 0.0147 - accuracy: 0.9972 - val_loss: 3.7541 - val_accuracy: 0.4900\n","\n","Epoch 00804: val_loss did not improve from 0.09976\n","Epoch 805/1000\n"," - 8s - loss: 0.0189 - accuracy: 0.9950 - val_loss: 3.9572 - val_accuracy: 0.5010\n","\n","Epoch 00805: val_loss did not improve from 0.09976\n","Epoch 806/1000\n"," - 8s - loss: 0.0177 - accuracy: 0.9954 - val_loss: 9.2301 - val_accuracy: 0.4965\n","\n","Epoch 00806: val_loss did not improve from 0.09976\n","Epoch 807/1000\n"," - 8s - loss: 0.0171 - accuracy: 0.9959 - val_loss: 7.5071 - val_accuracy: 0.4985\n","\n","Epoch 00807: val_loss did not improve from 0.09976\n","Epoch 808/1000\n"," - 8s - loss: 0.0152 - accuracy: 0.9975 - val_loss: 4.6632 - val_accuracy: 0.4925\n","\n","Epoch 00808: val_loss did not improve from 0.09976\n","Epoch 809/1000\n"," - 8s - loss: 0.0145 - accuracy: 0.9972 - val_loss: 6.7641 - val_accuracy: 0.4905\n","\n","Epoch 00809: val_loss did not improve from 0.09976\n","Epoch 810/1000\n"," - 8s - loss: 0.0205 - accuracy: 0.9940 - val_loss: 2.5768 - val_accuracy: 0.4955\n","\n","Epoch 00810: val_loss did not improve from 0.09976\n","Epoch 811/1000\n"," - 8s - loss: 0.0159 - accuracy: 0.9965 - val_loss: 6.6482 - val_accuracy: 0.4950\n","\n","Epoch 00811: val_loss did not improve from 0.09976\n","Epoch 812/1000\n"," - 8s - loss: 0.0162 - accuracy: 0.9970 - val_loss: 5.3328 - val_accuracy: 0.4831\n","\n","Epoch 00812: val_loss did not improve from 0.09976\n","Epoch 813/1000\n"," - 8s - loss: 0.0170 - accuracy: 0.9965 - val_loss: 1.9874 - val_accuracy: 0.4821\n","\n","Epoch 00813: val_loss did not improve from 0.09976\n","Epoch 814/1000\n"," - 8s - loss: 0.0146 - accuracy: 0.9970 - val_loss: 5.7024 - val_accuracy: 0.4905\n","\n","Epoch 00814: val_loss did not improve from 0.09976\n","Epoch 815/1000\n"," - 8s - loss: 0.0136 - accuracy: 0.9973 - val_loss: 4.3941 - val_accuracy: 0.4861\n","\n","Epoch 00815: val_loss did not improve from 0.09976\n","Epoch 816/1000\n"," - 8s - loss: 0.0170 - accuracy: 0.9960 - val_loss: 1.8107 - val_accuracy: 0.4891\n","\n","Epoch 00816: val_loss did not improve from 0.09976\n","Epoch 817/1000\n"," - 8s - loss: 0.0159 - accuracy: 0.9962 - val_loss: 3.9634 - val_accuracy: 0.4826\n","\n","Epoch 00817: val_loss did not improve from 0.09976\n","Epoch 818/1000\n"," - 8s - loss: 0.0166 - accuracy: 0.9959 - val_loss: 7.5164 - val_accuracy: 0.4910\n","\n","Epoch 00818: val_loss did not improve from 0.09976\n","Epoch 819/1000\n"," - 8s - loss: 0.0178 - accuracy: 0.9959 - val_loss: 1.6472 - val_accuracy: 0.5020\n","\n","Epoch 00819: val_loss did not improve from 0.09976\n","Epoch 820/1000\n"," - 8s - loss: 0.0183 - accuracy: 0.9967 - val_loss: 2.8119 - val_accuracy: 0.4950\n","\n","Epoch 00820: val_loss did not improve from 0.09976\n","Epoch 821/1000\n"," - 8s - loss: 0.0189 - accuracy: 0.9959 - val_loss: 8.6647 - val_accuracy: 0.4925\n","\n","Epoch 00821: val_loss did not improve from 0.09976\n","Epoch 822/1000\n"," - 8s - loss: 0.0154 - accuracy: 0.9978 - val_loss: 5.1280 - val_accuracy: 0.4811\n","\n","Epoch 00822: val_loss did not improve from 0.09976\n","Epoch 823/1000\n"," - 8s - loss: 0.0218 - accuracy: 0.9944 - val_loss: 6.9111 - val_accuracy: 0.4900\n","\n","Epoch 00823: val_loss did not improve from 0.09976\n","Epoch 824/1000\n"," - 8s - loss: 0.0164 - accuracy: 0.9959 - val_loss: 5.2915 - val_accuracy: 0.4796\n","\n","Epoch 00824: val_loss did not improve from 0.09976\n","Epoch 825/1000\n"," - 8s - loss: 0.0135 - accuracy: 0.9968 - val_loss: 11.4222 - val_accuracy: 0.4871\n","\n","Epoch 00825: val_loss did not improve from 0.09976\n","Epoch 826/1000\n"," - 8s - loss: 0.0176 - accuracy: 0.9952 - val_loss: 3.3708 - val_accuracy: 0.4930\n","\n","Epoch 00826: val_loss did not improve from 0.09976\n","Epoch 827/1000\n"," - 8s - loss: 0.0143 - accuracy: 0.9973 - val_loss: 7.7479 - val_accuracy: 0.4896\n","\n","Epoch 00827: val_loss did not improve from 0.09976\n","Epoch 828/1000\n"," - 8s - loss: 0.0134 - accuracy: 0.9973 - val_loss: 6.5876 - val_accuracy: 0.4930\n","\n","Epoch 00828: val_loss did not improve from 0.09976\n","Epoch 829/1000\n"," - 8s - loss: 0.0146 - accuracy: 0.9968 - val_loss: 2.9362 - val_accuracy: 0.4856\n","\n","Epoch 00829: val_loss did not improve from 0.09976\n","Epoch 830/1000\n"," - 8s - loss: 0.0180 - accuracy: 0.9944 - val_loss: 3.0859 - val_accuracy: 0.4881\n","\n","Epoch 00830: val_loss did not improve from 0.09976\n","Epoch 831/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9978 - val_loss: 7.6021 - val_accuracy: 0.4866\n","\n","Epoch 00831: val_loss did not improve from 0.09976\n","Epoch 832/1000\n"," - 8s - loss: 0.0170 - accuracy: 0.9955 - val_loss: 11.2136 - val_accuracy: 0.4965\n","\n","Epoch 00832: val_loss did not improve from 0.09976\n","Epoch 833/1000\n"," - 8s - loss: 0.0136 - accuracy: 0.9972 - val_loss: 3.3668 - val_accuracy: 0.4900\n","\n","Epoch 00833: val_loss did not improve from 0.09976\n","Epoch 834/1000\n"," - 8s - loss: 0.0157 - accuracy: 0.9957 - val_loss: 3.5427 - val_accuracy: 0.4910\n","\n","Epoch 00834: val_loss did not improve from 0.09976\n","Epoch 835/1000\n"," - 8s - loss: 0.0145 - accuracy: 0.9967 - val_loss: 1.3616 - val_accuracy: 0.4836\n","\n","Epoch 00835: val_loss did not improve from 0.09976\n","Epoch 836/1000\n"," - 8s - loss: 0.0200 - accuracy: 0.9942 - val_loss: 4.2586 - val_accuracy: 0.4960\n","\n","Epoch 00836: val_loss did not improve from 0.09976\n","Epoch 837/1000\n"," - 8s - loss: 0.0147 - accuracy: 0.9972 - val_loss: 5.6158 - val_accuracy: 0.4930\n","\n","Epoch 00837: val_loss did not improve from 0.09976\n","Epoch 838/1000\n"," - 8s - loss: 0.0161 - accuracy: 0.9957 - val_loss: 5.8878 - val_accuracy: 0.4925\n","\n","Epoch 00838: val_loss did not improve from 0.09976\n","Epoch 839/1000\n"," - 8s - loss: 0.0200 - accuracy: 0.9947 - val_loss: 12.6412 - val_accuracy: 0.4930\n","\n","Epoch 00839: val_loss did not improve from 0.09976\n","Epoch 840/1000\n"," - 8s - loss: 0.0143 - accuracy: 0.9970 - val_loss: 2.2984 - val_accuracy: 0.4861\n","\n","Epoch 00840: val_loss did not improve from 0.09976\n","Epoch 841/1000\n"," - 8s - loss: 0.0136 - accuracy: 0.9973 - val_loss: 4.1217 - val_accuracy: 0.4891\n","\n","Epoch 00841: val_loss did not improve from 0.09976\n","Epoch 842/1000\n"," - 8s - loss: 0.0141 - accuracy: 0.9977 - val_loss: 3.2778 - val_accuracy: 0.4900\n","\n","Epoch 00842: val_loss did not improve from 0.09976\n","Epoch 843/1000\n"," - 8s - loss: 0.0138 - accuracy: 0.9978 - val_loss: 3.6912 - val_accuracy: 0.4876\n","\n","Epoch 00843: val_loss did not improve from 0.09976\n","Epoch 844/1000\n"," - 8s - loss: 0.0115 - accuracy: 0.9982 - val_loss: 2.8623 - val_accuracy: 0.4970\n","\n","Epoch 00844: val_loss did not improve from 0.09976\n","Epoch 845/1000\n"," - 8s - loss: 0.0154 - accuracy: 0.9965 - val_loss: 7.1852 - val_accuracy: 0.4841\n","\n","Epoch 00845: val_loss did not improve from 0.09976\n","Epoch 846/1000\n"," - 8s - loss: 0.0191 - accuracy: 0.9947 - val_loss: 4.0991 - val_accuracy: 0.4811\n","\n","Epoch 00846: val_loss did not improve from 0.09976\n","Epoch 847/1000\n"," - 8s - loss: 0.0144 - accuracy: 0.9967 - val_loss: 6.1012 - val_accuracy: 0.4831\n","\n","Epoch 00847: val_loss did not improve from 0.09976\n","Epoch 848/1000\n"," - 8s - loss: 0.0152 - accuracy: 0.9965 - val_loss: 3.6407 - val_accuracy: 0.4925\n","\n","Epoch 00848: val_loss did not improve from 0.09976\n","Epoch 849/1000\n"," - 8s - loss: 0.0148 - accuracy: 0.9967 - val_loss: 1.5709 - val_accuracy: 0.4925\n","\n","Epoch 00849: val_loss did not improve from 0.09976\n","Epoch 850/1000\n"," - 8s - loss: 0.0153 - accuracy: 0.9964 - val_loss: 6.0523 - val_accuracy: 0.4876\n","\n","Epoch 00850: val_loss did not improve from 0.09976\n","Epoch 851/1000\n"," - 8s - loss: 0.0157 - accuracy: 0.9960 - val_loss: 5.6057 - val_accuracy: 0.4900\n","\n","Epoch 00851: val_loss did not improve from 0.09976\n","Epoch 852/1000\n"," - 8s - loss: 0.0164 - accuracy: 0.9955 - val_loss: 6.6267 - val_accuracy: 0.4851\n","\n","Epoch 00852: val_loss did not improve from 0.09976\n","Epoch 853/1000\n"," - 8s - loss: 0.0149 - accuracy: 0.9959 - val_loss: 3.3189 - val_accuracy: 0.4841\n","\n","Epoch 00853: val_loss did not improve from 0.09976\n","Epoch 854/1000\n"," - 8s - loss: 0.0150 - accuracy: 0.9960 - val_loss: 3.5072 - val_accuracy: 0.4881\n","\n","Epoch 00854: val_loss did not improve from 0.09976\n","Epoch 855/1000\n"," - 8s - loss: 0.0159 - accuracy: 0.9959 - val_loss: 1.1039 - val_accuracy: 0.4905\n","\n","Epoch 00855: val_loss did not improve from 0.09976\n","Epoch 856/1000\n"," - 8s - loss: 0.0141 - accuracy: 0.9973 - val_loss: 3.0381 - val_accuracy: 0.4891\n","\n","Epoch 00856: val_loss did not improve from 0.09976\n","Epoch 857/1000\n"," - 8s - loss: 0.0152 - accuracy: 0.9973 - val_loss: 5.9741 - val_accuracy: 0.4896\n","\n","Epoch 00857: val_loss did not improve from 0.09976\n","Epoch 858/1000\n"," - 8s - loss: 0.0144 - accuracy: 0.9968 - val_loss: 2.4123 - val_accuracy: 0.4846\n","\n","Epoch 00858: val_loss did not improve from 0.09976\n","Epoch 859/1000\n"," - 8s - loss: 0.0168 - accuracy: 0.9959 - val_loss: 3.9053 - val_accuracy: 0.4920\n","\n","Epoch 00859: val_loss did not improve from 0.09976\n","Epoch 860/1000\n"," - 8s - loss: 0.0159 - accuracy: 0.9972 - val_loss: 3.9896 - val_accuracy: 0.4915\n","\n","Epoch 00860: val_loss did not improve from 0.09976\n","Epoch 861/1000\n"," - 8s - loss: 0.0171 - accuracy: 0.9955 - val_loss: 1.9528 - val_accuracy: 0.4945\n","\n","Epoch 00861: val_loss did not improve from 0.09976\n","Epoch 862/1000\n"," - 8s - loss: 0.0113 - accuracy: 0.9987 - val_loss: 1.9018 - val_accuracy: 0.4851\n","\n","Epoch 00862: val_loss did not improve from 0.09976\n","Epoch 863/1000\n"," - 8s - loss: 0.0139 - accuracy: 0.9968 - val_loss: 5.0601 - val_accuracy: 0.4955\n","\n","Epoch 00863: val_loss did not improve from 0.09976\n","Epoch 864/1000\n"," - 8s - loss: 0.0139 - accuracy: 0.9977 - val_loss: 4.7198 - val_accuracy: 0.4920\n","\n","Epoch 00864: val_loss did not improve from 0.09976\n","Epoch 865/1000\n"," - 8s - loss: 0.0128 - accuracy: 0.9973 - val_loss: 10.3233 - val_accuracy: 0.4965\n","\n","Epoch 00865: val_loss did not improve from 0.09976\n","Epoch 866/1000\n"," - 8s - loss: 0.0137 - accuracy: 0.9978 - val_loss: 1.9911 - val_accuracy: 0.4876\n","\n","Epoch 00866: val_loss did not improve from 0.09976\n","Epoch 867/1000\n"," - 8s - loss: 0.0129 - accuracy: 0.9980 - val_loss: 4.8516 - val_accuracy: 0.4960\n","\n","Epoch 00867: val_loss did not improve from 0.09976\n","Epoch 868/1000\n"," - 8s - loss: 0.0132 - accuracy: 0.9973 - val_loss: 7.3451 - val_accuracy: 0.4886\n","\n","Epoch 00868: val_loss did not improve from 0.09976\n","Epoch 869/1000\n"," - 8s - loss: 0.0118 - accuracy: 0.9978 - val_loss: 2.0025 - val_accuracy: 0.4861\n","\n","Epoch 00869: val_loss did not improve from 0.09976\n","Epoch 870/1000\n"," - 8s - loss: 0.0118 - accuracy: 0.9978 - val_loss: 2.8127 - val_accuracy: 0.4881\n","\n","Epoch 00870: val_loss did not improve from 0.09976\n","Epoch 871/1000\n"," - 8s - loss: 0.0134 - accuracy: 0.9973 - val_loss: 4.4916 - val_accuracy: 0.4955\n","\n","Epoch 00871: val_loss did not improve from 0.09976\n","Epoch 872/1000\n"," - 8s - loss: 0.0152 - accuracy: 0.9965 - val_loss: 4.6682 - val_accuracy: 0.4910\n","\n","Epoch 00872: val_loss did not improve from 0.09976\n","Epoch 873/1000\n"," - 8s - loss: 0.0123 - accuracy: 0.9972 - val_loss: 4.4649 - val_accuracy: 0.4891\n","\n","Epoch 00873: val_loss did not improve from 0.09976\n","Epoch 874/1000\n"," - 8s - loss: 0.0159 - accuracy: 0.9957 - val_loss: 5.7025 - val_accuracy: 0.4935\n","\n","Epoch 00874: val_loss did not improve from 0.09976\n","Epoch 875/1000\n"," - 8s - loss: 0.0149 - accuracy: 0.9972 - val_loss: 7.8149 - val_accuracy: 0.4970\n","\n","Epoch 00875: val_loss did not improve from 0.09976\n","Epoch 876/1000\n"," - 8s - loss: 0.0143 - accuracy: 0.9972 - val_loss: 2.0213 - val_accuracy: 0.4896\n","\n","Epoch 00876: val_loss did not improve from 0.09976\n","Epoch 877/1000\n"," - 8s - loss: 0.0152 - accuracy: 0.9968 - val_loss: 2.3161 - val_accuracy: 0.5005\n","\n","Epoch 00877: val_loss did not improve from 0.09976\n","Epoch 878/1000\n"," - 8s - loss: 0.0132 - accuracy: 0.9973 - val_loss: 6.6104 - val_accuracy: 0.4995\n","\n","Epoch 00878: val_loss did not improve from 0.09976\n","Epoch 879/1000\n"," - 8s - loss: 0.0120 - accuracy: 0.9978 - val_loss: 5.8649 - val_accuracy: 0.4821\n","\n","Epoch 00879: val_loss did not improve from 0.09976\n","Epoch 880/1000\n"," - 8s - loss: 0.0120 - accuracy: 0.9977 - val_loss: 2.6507 - val_accuracy: 0.4876\n","\n","Epoch 00880: val_loss did not improve from 0.09976\n","Epoch 881/1000\n"," - 8s - loss: 0.0105 - accuracy: 0.9978 - val_loss: 5.5725 - val_accuracy: 0.5045\n","\n","Epoch 00881: val_loss did not improve from 0.09976\n","Epoch 882/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9972 - val_loss: 10.8228 - val_accuracy: 0.4896\n","\n","Epoch 00882: val_loss did not improve from 0.09976\n","Epoch 883/1000\n"," - 8s - loss: 0.0143 - accuracy: 0.9964 - val_loss: 7.4361 - val_accuracy: 0.4930\n","\n","Epoch 00883: val_loss did not improve from 0.09976\n","Epoch 884/1000\n"," - 8s - loss: 0.0115 - accuracy: 0.9982 - val_loss: 3.9733 - val_accuracy: 0.4930\n","\n","Epoch 00884: val_loss did not improve from 0.09976\n","Epoch 885/1000\n"," - 8s - loss: 0.0147 - accuracy: 0.9964 - val_loss: 11.7912 - val_accuracy: 0.4811\n","\n","Epoch 00885: val_loss did not improve from 0.09976\n","Epoch 886/1000\n"," - 8s - loss: 0.0167 - accuracy: 0.9945 - val_loss: 4.0259 - val_accuracy: 0.4930\n","\n","Epoch 00886: val_loss did not improve from 0.09976\n","Epoch 887/1000\n"," - 8s - loss: 0.0125 - accuracy: 0.9970 - val_loss: 4.7630 - val_accuracy: 0.4975\n","\n","Epoch 00887: val_loss did not improve from 0.09976\n","Epoch 888/1000\n"," - 8s - loss: 0.0131 - accuracy: 0.9967 - val_loss: 13.6008 - val_accuracy: 0.4871\n","\n","Epoch 00888: val_loss did not improve from 0.09976\n","Epoch 889/1000\n"," - 8s - loss: 0.0184 - accuracy: 0.9950 - val_loss: 6.9009 - val_accuracy: 0.4851\n","\n","Epoch 00889: val_loss did not improve from 0.09976\n","Epoch 890/1000\n"," - 8s - loss: 0.0176 - accuracy: 0.9965 - val_loss: 4.7082 - val_accuracy: 0.4861\n","\n","Epoch 00890: val_loss did not improve from 0.09976\n","Epoch 891/1000\n"," - 8s - loss: 0.0150 - accuracy: 0.9967 - val_loss: 5.5384 - val_accuracy: 0.4955\n","\n","Epoch 00891: val_loss did not improve from 0.09976\n","Epoch 892/1000\n"," - 8s - loss: 0.0138 - accuracy: 0.9965 - val_loss: 11.1047 - val_accuracy: 0.5000\n","\n","Epoch 00892: val_loss did not improve from 0.09976\n","Epoch 893/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9973 - val_loss: 8.5284 - val_accuracy: 0.4935\n","\n","Epoch 00893: val_loss did not improve from 0.09976\n","Epoch 894/1000\n"," - 8s - loss: 0.0133 - accuracy: 0.9972 - val_loss: 4.1601 - val_accuracy: 0.4940\n","\n","Epoch 00894: val_loss did not improve from 0.09976\n","Epoch 895/1000\n"," - 8s - loss: 0.0130 - accuracy: 0.9968 - val_loss: 8.9428 - val_accuracy: 0.4955\n","\n","Epoch 00895: val_loss did not improve from 0.09976\n","Epoch 896/1000\n"," - 8s - loss: 0.0116 - accuracy: 0.9975 - val_loss: 1.8509 - val_accuracy: 0.4915\n","\n","Epoch 00896: val_loss did not improve from 0.09976\n","Epoch 897/1000\n"," - 8s - loss: 0.0113 - accuracy: 0.9978 - val_loss: 6.9917 - val_accuracy: 0.4965\n","\n","Epoch 00897: val_loss did not improve from 0.09976\n","Epoch 898/1000\n"," - 8s - loss: 0.0153 - accuracy: 0.9960 - val_loss: 1.8288 - val_accuracy: 0.4771\n","\n","Epoch 00898: val_loss did not improve from 0.09976\n","Epoch 899/1000\n"," - 8s - loss: 0.0122 - accuracy: 0.9980 - val_loss: 2.2004 - val_accuracy: 0.4995\n","\n","Epoch 00899: val_loss did not improve from 0.09976\n","Epoch 900/1000\n"," - 8s - loss: 0.0106 - accuracy: 0.9980 - val_loss: 7.4907 - val_accuracy: 0.4970\n","\n","Epoch 00900: val_loss did not improve from 0.09976\n","Epoch 901/1000\n"," - 8s - loss: 0.0110 - accuracy: 0.9980 - val_loss: 7.1137 - val_accuracy: 0.4891\n","\n","Epoch 00901: val_loss did not improve from 0.09976\n","Epoch 902/1000\n"," - 8s - loss: 0.0117 - accuracy: 0.9973 - val_loss: 11.6732 - val_accuracy: 0.4796\n","\n","Epoch 00902: val_loss did not improve from 0.09976\n","Epoch 903/1000\n"," - 8s - loss: 0.0103 - accuracy: 0.9977 - val_loss: 2.9677 - val_accuracy: 0.4801\n","\n","Epoch 00903: val_loss did not improve from 0.09976\n","Epoch 904/1000\n"," - 8s - loss: 0.0125 - accuracy: 0.9982 - val_loss: 2.2653 - val_accuracy: 0.4886\n","\n","Epoch 00904: val_loss did not improve from 0.09976\n","Epoch 905/1000\n"," - 8s - loss: 0.0110 - accuracy: 0.9975 - val_loss: 7.8712 - val_accuracy: 0.4861\n","\n","Epoch 00905: val_loss did not improve from 0.09976\n","Epoch 906/1000\n"," - 8s - loss: 0.0132 - accuracy: 0.9967 - val_loss: 12.4431 - val_accuracy: 0.4950\n","\n","Epoch 00906: val_loss did not improve from 0.09976\n","Epoch 907/1000\n"," - 8s - loss: 0.0119 - accuracy: 0.9982 - val_loss: 6.5578 - val_accuracy: 0.4945\n","\n","Epoch 00907: val_loss did not improve from 0.09976\n","Epoch 908/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9972 - val_loss: 10.2976 - val_accuracy: 0.4876\n","\n","Epoch 00908: val_loss did not improve from 0.09976\n","Epoch 909/1000\n"," - 8s - loss: 0.0114 - accuracy: 0.9970 - val_loss: 6.0757 - val_accuracy: 0.4980\n","\n","Epoch 00909: val_loss did not improve from 0.09976\n","Epoch 910/1000\n"," - 8s - loss: 0.0146 - accuracy: 0.9960 - val_loss: 3.9832 - val_accuracy: 0.4905\n","\n","Epoch 00910: val_loss did not improve from 0.09976\n","Epoch 911/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9970 - val_loss: 4.5993 - val_accuracy: 0.4980\n","\n","Epoch 00911: val_loss did not improve from 0.09976\n","Epoch 912/1000\n"," - 8s - loss: 0.0131 - accuracy: 0.9959 - val_loss: 7.2963 - val_accuracy: 0.4915\n","\n","Epoch 00912: val_loss did not improve from 0.09976\n","Epoch 913/1000\n"," - 8s - loss: 0.0116 - accuracy: 0.9980 - val_loss: 4.2915 - val_accuracy: 0.4856\n","\n","Epoch 00913: val_loss did not improve from 0.09976\n","Epoch 914/1000\n"," - 8s - loss: 0.0126 - accuracy: 0.9972 - val_loss: 2.9361 - val_accuracy: 0.4925\n","\n","Epoch 00914: val_loss did not improve from 0.09976\n","Epoch 915/1000\n"," - 8s - loss: 0.0137 - accuracy: 0.9967 - val_loss: 12.8745 - val_accuracy: 0.4791\n","\n","Epoch 00915: val_loss did not improve from 0.09976\n","Epoch 916/1000\n"," - 8s - loss: 0.0142 - accuracy: 0.9967 - val_loss: 7.6734 - val_accuracy: 0.4910\n","\n","Epoch 00916: val_loss did not improve from 0.09976\n","Epoch 917/1000\n"," - 8s - loss: 0.0135 - accuracy: 0.9972 - val_loss: 4.9551 - val_accuracy: 0.4881\n","\n","Epoch 00917: val_loss did not improve from 0.09976\n","Epoch 918/1000\n"," - 8s - loss: 0.0132 - accuracy: 0.9964 - val_loss: 3.8877 - val_accuracy: 0.4920\n","\n","Epoch 00918: val_loss did not improve from 0.09976\n","Epoch 919/1000\n"," - 8s - loss: 0.0087 - accuracy: 0.9988 - val_loss: 7.3786 - val_accuracy: 0.4950\n","\n","Epoch 00919: val_loss did not improve from 0.09976\n","Epoch 920/1000\n"," - 8s - loss: 0.0109 - accuracy: 0.9973 - val_loss: 6.6147 - val_accuracy: 0.5020\n","\n","Epoch 00920: val_loss did not improve from 0.09976\n","Epoch 921/1000\n"," - 8s - loss: 0.0108 - accuracy: 0.9973 - val_loss: 14.9356 - val_accuracy: 0.4990\n","\n","Epoch 00921: val_loss did not improve from 0.09976\n","Epoch 922/1000\n"," - 8s - loss: 0.0142 - accuracy: 0.9962 - val_loss: 1.9724 - val_accuracy: 0.4930\n","\n","Epoch 00922: val_loss did not improve from 0.09976\n","Epoch 923/1000\n"," - 8s - loss: 0.0110 - accuracy: 0.9977 - val_loss: 7.2463 - val_accuracy: 0.4980\n","\n","Epoch 00923: val_loss did not improve from 0.09976\n","Epoch 924/1000\n"," - 8s - loss: 0.0116 - accuracy: 0.9973 - val_loss: 8.9191 - val_accuracy: 0.4990\n","\n","Epoch 00924: val_loss did not improve from 0.09976\n","Epoch 925/1000\n"," - 8s - loss: 0.0113 - accuracy: 0.9975 - val_loss: 3.3906 - val_accuracy: 0.4925\n","\n","Epoch 00925: val_loss did not improve from 0.09976\n","Epoch 926/1000\n"," - 8s - loss: 0.0134 - accuracy: 0.9962 - val_loss: 5.2170 - val_accuracy: 0.4965\n","\n","Epoch 00926: val_loss did not improve from 0.09976\n","Epoch 927/1000\n"," - 8s - loss: 0.0163 - accuracy: 0.9952 - val_loss: 8.3323 - val_accuracy: 0.5035\n","\n","Epoch 00927: val_loss did not improve from 0.09976\n","Epoch 928/1000\n"," - 8s - loss: 0.0121 - accuracy: 0.9973 - val_loss: 3.6450 - val_accuracy: 0.4985\n","\n","Epoch 00928: val_loss did not improve from 0.09976\n","Epoch 929/1000\n"," - 8s - loss: 0.0129 - accuracy: 0.9970 - val_loss: 3.8661 - val_accuracy: 0.4896\n","\n","Epoch 00929: val_loss did not improve from 0.09976\n","Epoch 930/1000\n"," - 8s - loss: 0.0105 - accuracy: 0.9983 - val_loss: 3.3908 - val_accuracy: 0.4905\n","\n","Epoch 00930: val_loss did not improve from 0.09976\n","Epoch 931/1000\n"," - 8s - loss: 0.0102 - accuracy: 0.9975 - val_loss: 2.7130 - val_accuracy: 0.4925\n","\n","Epoch 00931: val_loss did not improve from 0.09976\n","Epoch 932/1000\n"," - 8s - loss: 0.0124 - accuracy: 0.9970 - val_loss: 3.1330 - val_accuracy: 0.4915\n","\n","Epoch 00932: val_loss did not improve from 0.09976\n","Epoch 933/1000\n"," - 8s - loss: 0.0078 - accuracy: 0.9992 - val_loss: 9.7752 - val_accuracy: 0.5005\n","\n","Epoch 00933: val_loss did not improve from 0.09976\n","Epoch 934/1000\n"," - 8s - loss: 0.0102 - accuracy: 0.9977 - val_loss: 7.7283 - val_accuracy: 0.4950\n","\n","Epoch 00934: val_loss did not improve from 0.09976\n","Epoch 935/1000\n"," - 8s - loss: 0.0120 - accuracy: 0.9973 - val_loss: 8.0953 - val_accuracy: 0.5045\n","\n","Epoch 00935: val_loss did not improve from 0.09976\n","Epoch 936/1000\n"," - 8s - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.7246 - val_accuracy: 0.5030\n","\n","Epoch 00936: val_loss did not improve from 0.09976\n","Epoch 937/1000\n"," - 8s - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.8633 - val_accuracy: 0.4970\n","\n","Epoch 00937: val_loss did not improve from 0.09976\n","Epoch 938/1000\n"," - 8s - loss: 0.0130 - accuracy: 0.9964 - val_loss: 6.9363 - val_accuracy: 0.4970\n","\n","Epoch 00938: val_loss did not improve from 0.09976\n","Epoch 939/1000\n"," - 8s - loss: 0.0088 - accuracy: 0.9985 - val_loss: 7.9326 - val_accuracy: 0.4980\n","\n","Epoch 00939: val_loss did not improve from 0.09976\n","Epoch 940/1000\n"," - 8s - loss: 0.0099 - accuracy: 0.9980 - val_loss: 2.6403 - val_accuracy: 0.4915\n","\n","Epoch 00940: val_loss did not improve from 0.09976\n","Epoch 941/1000\n"," - 8s - loss: 0.0162 - accuracy: 0.9950 - val_loss: 1.3560 - val_accuracy: 0.5035\n","\n","Epoch 00941: val_loss did not improve from 0.09976\n","Epoch 942/1000\n"," - 8s - loss: 0.0098 - accuracy: 0.9990 - val_loss: 2.3344 - val_accuracy: 0.4950\n","\n","Epoch 00942: val_loss did not improve from 0.09976\n","Epoch 943/1000\n"," - 8s - loss: 0.0113 - accuracy: 0.9978 - val_loss: 3.2201 - val_accuracy: 0.4975\n","\n","Epoch 00943: val_loss did not improve from 0.09976\n","Epoch 944/1000\n"," - 8s - loss: 0.0127 - accuracy: 0.9975 - val_loss: 3.7238 - val_accuracy: 0.5060\n","\n","Epoch 00944: val_loss did not improve from 0.09976\n","Epoch 945/1000\n"," - 8s - loss: 0.0069 - accuracy: 0.9993 - val_loss: 5.9512 - val_accuracy: 0.5010\n","\n","Epoch 00945: val_loss did not improve from 0.09976\n","Epoch 946/1000\n"," - 8s - loss: 0.0088 - accuracy: 0.9985 - val_loss: 8.0065 - val_accuracy: 0.4950\n","\n","Epoch 00946: val_loss did not improve from 0.09976\n","Epoch 947/1000\n"," - 8s - loss: 0.0106 - accuracy: 0.9975 - val_loss: 8.8087 - val_accuracy: 0.4915\n","\n","Epoch 00947: val_loss did not improve from 0.09976\n","Epoch 948/1000\n"," - 8s - loss: 0.0102 - accuracy: 0.9980 - val_loss: 2.7196 - val_accuracy: 0.4935\n","\n","Epoch 00948: val_loss did not improve from 0.09976\n","Epoch 949/1000\n"," - 8s - loss: 0.0134 - accuracy: 0.9977 - val_loss: 3.7084 - val_accuracy: 0.4980\n","\n","Epoch 00949: val_loss did not improve from 0.09976\n","Epoch 950/1000\n"," - 8s - loss: 0.0148 - accuracy: 0.9954 - val_loss: 11.2997 - val_accuracy: 0.4995\n","\n","Epoch 00950: val_loss did not improve from 0.09976\n","Epoch 951/1000\n"," - 8s - loss: 0.0165 - accuracy: 0.9944 - val_loss: 4.6866 - val_accuracy: 0.4970\n","\n","Epoch 00951: val_loss did not improve from 0.09976\n","Epoch 952/1000\n"," - 8s - loss: 0.0121 - accuracy: 0.9965 - val_loss: 5.2862 - val_accuracy: 0.4985\n","\n","Epoch 00952: val_loss did not improve from 0.09976\n","Epoch 953/1000\n"," - 8s - loss: 0.0103 - accuracy: 0.9980 - val_loss: 1.8453 - val_accuracy: 0.4970\n","\n","Epoch 00953: val_loss did not improve from 0.09976\n","Epoch 954/1000\n"," - 8s - loss: 0.0096 - accuracy: 0.9987 - val_loss: 4.9922 - val_accuracy: 0.4896\n","\n","Epoch 00954: val_loss did not improve from 0.09976\n","Epoch 955/1000\n"," - 8s - loss: 0.0096 - accuracy: 0.9982 - val_loss: 10.2738 - val_accuracy: 0.4945\n","\n","Epoch 00955: val_loss did not improve from 0.09976\n","Epoch 956/1000\n"," - 8s - loss: 0.0111 - accuracy: 0.9972 - val_loss: 6.9168 - val_accuracy: 0.4920\n","\n","Epoch 00956: val_loss did not improve from 0.09976\n","Epoch 957/1000\n"," - 8s - loss: 0.0081 - accuracy: 0.9993 - val_loss: 5.5636 - val_accuracy: 0.5020\n","\n","Epoch 00957: val_loss did not improve from 0.09976\n","Epoch 958/1000\n"," - 8s - loss: 0.0120 - accuracy: 0.9975 - val_loss: 10.2464 - val_accuracy: 0.5015\n","\n","Epoch 00958: val_loss did not improve from 0.09976\n","Epoch 959/1000\n"," - 8s - loss: 0.0149 - accuracy: 0.9957 - val_loss: 9.2457 - val_accuracy: 0.4866\n","\n","Epoch 00959: val_loss did not improve from 0.09976\n","Epoch 960/1000\n"," - 8s - loss: 0.0127 - accuracy: 0.9967 - val_loss: 1.5167 - val_accuracy: 0.5000\n","\n","Epoch 00960: val_loss did not improve from 0.09976\n","Epoch 961/1000\n"," - 8s - loss: 0.0130 - accuracy: 0.9972 - val_loss: 7.7243 - val_accuracy: 0.5005\n","\n","Epoch 00961: val_loss did not improve from 0.09976\n","Epoch 962/1000\n"," - 8s - loss: 0.0125 - accuracy: 0.9973 - val_loss: 5.5419 - val_accuracy: 0.4990\n","\n","Epoch 00962: val_loss did not improve from 0.09976\n","Epoch 963/1000\n"," - 8s - loss: 0.0110 - accuracy: 0.9975 - val_loss: 8.1488 - val_accuracy: 0.4975\n","\n","Epoch 00963: val_loss did not improve from 0.09976\n","Epoch 964/1000\n"," - 8s - loss: 0.0095 - accuracy: 0.9977 - val_loss: 2.1110 - val_accuracy: 0.4985\n","\n","Epoch 00964: val_loss did not improve from 0.09976\n","Epoch 965/1000\n"," - 8s - loss: 0.0074 - accuracy: 0.9990 - val_loss: 8.3853 - val_accuracy: 0.4965\n","\n","Epoch 00965: val_loss did not improve from 0.09976\n","Epoch 966/1000\n"," - 8s - loss: 0.0104 - accuracy: 0.9973 - val_loss: 8.2469 - val_accuracy: 0.4910\n","\n","Epoch 00966: val_loss did not improve from 0.09976\n","Epoch 967/1000\n"," - 8s - loss: 0.0088 - accuracy: 0.9985 - val_loss: 6.3271 - val_accuracy: 0.4950\n","\n","Epoch 00967: val_loss did not improve from 0.09976\n","Epoch 968/1000\n"," - 8s - loss: 0.0112 - accuracy: 0.9973 - val_loss: 10.8666 - val_accuracy: 0.4836\n","\n","Epoch 00968: val_loss did not improve from 0.09976\n","Epoch 969/1000\n"," - 8s - loss: 0.0146 - accuracy: 0.9960 - val_loss: 3.2008 - val_accuracy: 0.4955\n","\n","Epoch 00969: val_loss did not improve from 0.09976\n","Epoch 970/1000\n"," - 8s - loss: 0.0117 - accuracy: 0.9967 - val_loss: 4.7546 - val_accuracy: 0.4876\n","\n","Epoch 00970: val_loss did not improve from 0.09976\n","Epoch 971/1000\n"," - 8s - loss: 0.0158 - accuracy: 0.9955 - val_loss: 12.5012 - val_accuracy: 0.4841\n","\n","Epoch 00971: val_loss did not improve from 0.09976\n","Epoch 972/1000\n"," - 8s - loss: 0.0092 - accuracy: 0.9980 - val_loss: 4.9915 - val_accuracy: 0.4831\n","\n","Epoch 00972: val_loss did not improve from 0.09976\n","Epoch 973/1000\n"," - 8s - loss: 0.0118 - accuracy: 0.9972 - val_loss: 4.5585 - val_accuracy: 0.4910\n","\n","Epoch 00973: val_loss did not improve from 0.09976\n","Epoch 974/1000\n"," - 8s - loss: 0.0078 - accuracy: 0.9988 - val_loss: 5.6148 - val_accuracy: 0.4930\n","\n","Epoch 00974: val_loss did not improve from 0.09976\n","Epoch 975/1000\n"," - 8s - loss: 0.0076 - accuracy: 0.9993 - val_loss: 4.7698 - val_accuracy: 0.4821\n","\n","Epoch 00975: val_loss did not improve from 0.09976\n","Epoch 976/1000\n"," - 8s - loss: 0.0076 - accuracy: 0.9990 - val_loss: 4.1705 - val_accuracy: 0.4876\n","\n","Epoch 00976: val_loss did not improve from 0.09976\n","Epoch 977/1000\n"," - 8s - loss: 0.0082 - accuracy: 0.9988 - val_loss: 9.4946 - val_accuracy: 0.4950\n","\n","Epoch 00977: val_loss did not improve from 0.09976\n","Epoch 978/1000\n"," - 8s - loss: 0.0065 - accuracy: 0.9995 - val_loss: 9.3186 - val_accuracy: 0.4940\n","\n","Epoch 00978: val_loss did not improve from 0.09976\n","Epoch 979/1000\n"," - 8s - loss: 0.0098 - accuracy: 0.9968 - val_loss: 6.9166 - val_accuracy: 0.4975\n","\n","Epoch 00979: val_loss did not improve from 0.09976\n","Epoch 980/1000\n"," - 8s - loss: 0.0105 - accuracy: 0.9977 - val_loss: 3.9304 - val_accuracy: 0.4856\n","\n","Epoch 00980: val_loss did not improve from 0.09976\n","Epoch 981/1000\n"," - 8s - loss: 0.0103 - accuracy: 0.9985 - val_loss: 2.8113 - val_accuracy: 0.4886\n","\n","Epoch 00981: val_loss did not improve from 0.09976\n","Epoch 982/1000\n"," - 8s - loss: 0.0091 - accuracy: 0.9983 - val_loss: 5.8603 - val_accuracy: 0.4940\n","\n","Epoch 00982: val_loss did not improve from 0.09976\n","Epoch 983/1000\n"," - 8s - loss: 0.0129 - accuracy: 0.9962 - val_loss: 6.3534 - val_accuracy: 0.4846\n","\n","Epoch 00983: val_loss did not improve from 0.09976\n","Epoch 984/1000\n"," - 8s - loss: 0.0126 - accuracy: 0.9972 - val_loss: 7.3175 - val_accuracy: 0.4950\n","\n","Epoch 00984: val_loss did not improve from 0.09976\n","Epoch 985/1000\n"," - 8s - loss: 0.0100 - accuracy: 0.9980 - val_loss: 9.6535 - val_accuracy: 0.4970\n","\n","Epoch 00985: val_loss did not improve from 0.09976\n","Epoch 986/1000\n"," - 8s - loss: 0.0106 - accuracy: 0.9975 - val_loss: 5.9152 - val_accuracy: 0.4866\n","\n","Epoch 00986: val_loss did not improve from 0.09976\n","Epoch 987/1000\n"," - 8s - loss: 0.0074 - accuracy: 0.9992 - val_loss: 2.7494 - val_accuracy: 0.4910\n","\n","Epoch 00987: val_loss did not improve from 0.09976\n","Epoch 988/1000\n"," - 8s - loss: 0.0108 - accuracy: 0.9973 - val_loss: 7.4376 - val_accuracy: 0.4965\n","\n","Epoch 00988: val_loss did not improve from 0.09976\n","Epoch 989/1000\n"," - 8s - loss: 0.0089 - accuracy: 0.9987 - val_loss: 5.4218 - val_accuracy: 0.4896\n","\n","Epoch 00989: val_loss did not improve from 0.09976\n","Epoch 990/1000\n"," - 8s - loss: 0.0084 - accuracy: 0.9978 - val_loss: 6.8816 - val_accuracy: 0.4910\n","\n","Epoch 00990: val_loss did not improve from 0.09976\n","Epoch 991/1000\n"," - 8s - loss: 0.0104 - accuracy: 0.9967 - val_loss: 4.2520 - val_accuracy: 0.4905\n","\n","Epoch 00991: val_loss did not improve from 0.09976\n","Epoch 992/1000\n"," - 8s - loss: 0.0101 - accuracy: 0.9982 - val_loss: 8.0349 - val_accuracy: 0.4831\n","\n","Epoch 00992: val_loss did not improve from 0.09976\n","Epoch 993/1000\n"," - 8s - loss: 0.0087 - accuracy: 0.9987 - val_loss: 6.6159 - val_accuracy: 0.4955\n","\n","Epoch 00993: val_loss did not improve from 0.09976\n","Epoch 994/1000\n"," - 8s - loss: 0.0114 - accuracy: 0.9977 - val_loss: 3.4874 - val_accuracy: 0.4935\n","\n","Epoch 00994: val_loss did not improve from 0.09976\n","Epoch 995/1000\n"," - 8s - loss: 0.0104 - accuracy: 0.9972 - val_loss: 9.8642 - val_accuracy: 0.4881\n","\n","Epoch 00995: val_loss did not improve from 0.09976\n","Epoch 996/1000\n"," - 8s - loss: 0.0099 - accuracy: 0.9978 - val_loss: 4.8335 - val_accuracy: 0.4935\n","\n","Epoch 00996: val_loss did not improve from 0.09976\n","Epoch 997/1000\n"," - 8s - loss: 0.0091 - accuracy: 0.9985 - val_loss: 2.7925 - val_accuracy: 0.5020\n","\n","Epoch 00997: val_loss did not improve from 0.09976\n","Epoch 998/1000\n"," - 8s - loss: 0.0099 - accuracy: 0.9990 - val_loss: 2.2297 - val_accuracy: 0.5015\n","\n","Epoch 00998: val_loss did not improve from 0.09976\n","Epoch 999/1000\n"," - 8s - loss: 0.0076 - accuracy: 0.9983 - val_loss: 5.3913 - val_accuracy: 0.4990\n","\n","Epoch 00999: val_loss did not improve from 0.09976\n","Epoch 1000/1000\n"," - 8s - loss: 0.0085 - accuracy: 0.9990 - val_loss: 13.1723 - val_accuracy: 0.4816\n","\n","Epoch 01000: val_loss did not improve from 0.09976\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfPMGMvm0rGu","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1619101673521,"user_tz":-540,"elapsed":1325,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"831a7b0b-02c4-4a11-939b-94864aa9a318"},"source":["ckpt_path = current_path + 'ckpt/'\n","board_path = current_path + 'graph/'\n","# model_name = 'classifier_45_close_updown_pr_theta_non_shuffle_ex_02008.h5'\n","# model_name = 'classifier_45_close_updown_pr_theta.h5'\n","\n","model = keras.models.load_model(ckpt_path + model_name)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ecc436cf3ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model_name = 'classifier_45_close_updown_pr_theta.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read-only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot create group in read-only mode."]}]},{"cell_type":"code","metadata":{"id":"zhRu2BIK792m","colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"status":"error","timestamp":1619101676605,"user_tz":-540,"elapsed":2127,"user":{"displayName":"7th June","photoUrl":"","userId":"08178289703395036410"}},"outputId":"0955ab4c-dd28-4c8f-d924-60d586e50e8d"},"source":["test_result = model.predict(x_test)\n","# test_result = model.predict(test_set)\n","\n","print('test_result.shape :', test_result.shape)\n","print('pr_val.shape :', pr_val.shape)\n","\n","y_score = test_result[:, [1]]\n","print('y_test[:5] :', y_test.reshape(-1,)[:5])\n","# print('np.unique(y_test) :', np.unique(y_test, return_counts=True))\n","print('y_score[:5] :', y_score[:5])\n","# print('np.unique(y_score) :', np.unique(y_score, return_counts=True))\n","\n","print('y_test.shape :', y_test.shape)\n","print('y_score.shape :', y_score.shape)\n","\n","print('len(y_test) :', len(y_test))\n","\n","#     precision recall curve   #\n","precision, recall, threshold = precision_recall_curve(y_test, y_score)\n","precision, recall = precision[:-1], recall[:-1]\n","\n","plt.plot(threshold, precision, label='precision')\n","plt.plot(threshold, recall, label='recall')\n","plt.legend()\n","plt.title('precision recall')\n","plt.show()\n","# print(y_pred)\n","\n","\n","threshold = [0.9]\n","# print('threshold :', threshold)\n","break\n","\n","acc_pr_bythr = []\n","for thresh in threshold:\n","\n","  y_pred = np.where(y_score[:, -1] > thresh, 1, 0)\n","  print('y_pred.shape :', y_pred.shape)\n","  # print('y_pred :', y_pred)\n","\n","  #     compare precision     #\n","\n","  print('precision :', precision_score(y_test, y_pred))\n","  print('recall :', recall_score(y_test, y_pred))\n","  print()\n","\n","  print('np.isnan(np.sum(x_test)) :', np.isnan(np.sum(x_test)))\n","  print('np.isnan(np.sum(y_test)) :', np.isnan(np.sum(y_test)))\n","\n","  # plot_confusion_matrix(best_model, x_test, y_test, normalize=None)\n","  # plt.show()  \n","  print()\n","\n","  #     check win-ratio improvement     #\n","  cmat = confusion_matrix(y_test, y_pred)\n","  # print(cmat)\n","  # print(np.sum(cmat, axis=1))\n","\n","  test_size = len(y_test)\n","  test_pr_list = pr_test\n","  print('origin ac_pr :', np.cumprod(test_pr_list)[-1])\n","\n","  org_wr = np.sum(cmat, axis=1)[-1] / sum(np.sum(cmat, axis=1))\n","  ml_wr = cmat[1][1] / np.sum(cmat, axis=0)[-1]\n","  print('win ratio improvement %.2f --> %.2f' % (org_wr, ml_wr))\n","\n","  # print('pr_test.shape :', pr_test.shape)\n","\n","  # print(y_pred)\n","  # print(test_pr_list)\n","  pred_pr_list = np.where(y_pred == 1, test_pr_list.reshape(-1, ), 1.0)\n","  # print('pred_pr_list.shape :', pred_pr_list.shape)\n","\n","  if np.cumprod(test_pr_list)[-1] < np.cumprod(pred_pr_list)[-1]:\n","    print('accum_pr increased ! : %.3f --> %.3f' % (np.cumprod(test_pr_list)[-1], np.cumprod(pred_pr_list)[-1]))\n","    print('thresh :', thresh)\n","    \n","  # if len(threshold) == 1:\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(121)\n","    plt.plot(np.cumprod(test_pr_list))\n","    plt.title('%.3f' % (np.cumprod(test_pr_list)[-1]))\n","  # plt.show()\n","\n","    plt.subplot(122)\n","    plt.plot(np.cumprod(pred_pr_list))\n","    plt.title('%.3f' % (np.cumprod(pred_pr_list)[-1]))\n","    plt.show()\n","\n","\n","  acc_pr_bythr.append(np.cumprod(pred_pr_list)[-1])\n","\n","print('acc_pr_bythr :', acc_pr_bythr)\n","\n","plt.figure(figsize=(10, 5))\n","plt.subplot(121)\n","plt.plot(threshold, precision, label='precision')\n","plt.plot(threshold, recall, label='recall')\n","plt.legend()\n","plt.title('precision recall')\n","# plt.show()\n","plt.subplot(122)\n","plt.plot(threshold, acc_pr_bythr)\n","plt.axhline(np.cumprod(test_pr_list)[-1], linestyle='--', color='r')\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["test_result.shape : (2010, 2)\n","pr_val.shape : (2010, 1)\n","y_test[:5] : [0 0 1 0 1]\n","y_score[:5] : [[0.01404386]\n"," [0.4792828 ]\n"," [0.9999995 ]\n"," [0.99463814]\n"," [0.2928881 ]]\n","y_test.shape : (2010, 1)\n","y_score.shape : (2010, 1)\n","len(y_test) : 2010\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-9a30a70226ee>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"]}]},{"cell_type":"markdown","metadata":{"id":"-jo3k5MdhFyg"},"source":["#### **clustering output**"]},{"cell_type":"code","metadata":{"id":"njxxm-TJ-RP-"},"source":["# x_train_for_k = test_result.flatten().reshape(-1, 1)\n","x_train_for_k = test_result\n","print(x_train_for_k[:10])\n","# x_train_for_k = test_result[:, [1]]\n","pr_train = pr_test\n","\n","print('x_train_for_k.shape :', x_train_for_k.shape)\n","print('pr_train.shape :', pr_train.shape)\n","\n","K = range(2, 10)\n","s_dist = []\n","sil = []\n","for k in K:\n","  # if cen_data.shape[0] < k:\n","  #   break\n","\n","  km = KMeans(n_clusters=k)\n","  km = km.fit(x_train_for_k)\n","\n","  labels = km.labels_\n","  # print('len(labels) :', len(labels))\n","  # print('labels[:10] :', labels[:10])\n","  sil.append(silhouette_score(x_train_for_k, labels, metric='euclidean'))\n","\n","  # inertia = km.inertia_\n","  # s_dist.append(inertia)\n","\n","best_k = K[np.argmax(np.array(sil))]\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(K, sil)\n","plt.axvline(best_k, linestyle='--')\n","# plt.plot(K, s_dist)\n","plt.show()\n","\n","\n","\n","\n","\n","#   with best_k, label 별 pr_list 확인\n","km = KMeans(n_clusters=best_k)\n","km = km.fit(x_train_for_k)\n","\n","labels = km.labels_\n","\n","print(km.score(x_train_for_k))\n","print(len(labels), len(pr_train))\n","\n","\n","\n","\n","\n","#   label 별로 profit 을 저장, 승률을 확인한다\n","label_types = np.unique(labels, return_counts=False)\n","\n","label_pr_dict = {}\n","#   init dict   #\n","for label in label_types:\n","  label_pr_dict[label] = []\n","print(label_pr_dict)\n","# break\n","\n","for i, (label, pr) in enumerate(zip(labels, pr_train)):\n","  label_pr_dict[label].append(pr[0])\n","\n","  \n","# for label in label_types:\n","print(label_pr_dict)\n","\n","\n","\n","\n","\n","def win_ratio(list_x):\n","\n","  win_cnt = np.sum(np.array(list_x) > 1)\n","  return win_cnt / len(list_x)\n","\n","\n","def acc_pr(list_x):\n","\n","  return np.cumprod(np.array(list_x))[-1]\n","\n","\n","for key in label_pr_dict:\n","  \n","  print(key, ':', 'win_ratio : %.2f' % (win_ratio(label_pr_dict[key])), 'acc_pr : %.2f' % (acc_pr(label_pr_dict[key])))\n","\n","\n","\n","\n","\n","#     predict test && test 의 라벨에 따른 win_ratio 확인\n","# test_labels = km.predict(x_test)\n","# # print(test_labels)\n","\n","# label_pr_dict = {}\n","# #   init dict   #\n","# for label in label_types:\n","#   label_pr_dict[label] = []\n","# print(label_pr_dict)\n","# # break\n","\n","# for i, (label, pr) in enumerate(zip(test_labels, pr_test)):\n","#   label_pr_dict[label].append(pr[0])\n","\n","# for key in label_pr_dict:\n","\n","#   print(key, ':', 'win_ratio : %.2f' % (win_ratio(label_pr_dict[key])), 'acc_pr : %.2f' % (acc_pr(label_pr_dict[key])))\n","\n"],"execution_count":null,"outputs":[]}]}