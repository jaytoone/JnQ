{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tensorflow2_p36]","language":"python","name":"conda-env-tensorflow2_p36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Make_model_macd.ipynb","provenance":[{"file_id":"1WEMU-VCj-p8mZvMxqBpQAdViCsHXpo20","timestamp":1587198572851},{"file_id":"1z4z_KLPzc6RWsxo3X_dHbpByxUAgjoMJ","timestamp":1583754134002}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8s5fopqwFUf9","colab_type":"code","outputId":"f1b583cc-6da9-476d-acbf-55d5f96b1277","executionInfo":{"status":"ok","timestamp":1587198656445,"user_tz":-540,"elapsed":28674,"user":{"displayName":"JJANGJAE","photoUrl":"","userId":"08178289703395036410"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2iYLNSeSEp7p","colab_type":"code","outputId":"a059e6f4-7ee0-42b1-d9c0-7b39fbf72187","executionInfo":{"status":"error","timestamp":1587201805492,"user_tz":-540,"elapsed":3124821,"user":{"displayName":"JJANGJAE","photoUrl":"","userId":"08178289703395036410"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot\n","import scipy.misc \n","from math import sqrt \n","import itertools\n","from IPython.display import display\n","%tensorflow_version 1.x\n","%matplotlib inline\n","\n","input_data_length = 54\n","model_num = 120\n","num_classes = 3\n","\n","gdrive_path = '/content/gdrive/My Drive/Colab Notebooks/'\n","\n","Made_X = np.load(gdrive_path + 'Made_X/Made_X %s_%s.npy' % (input_data_length, model_num))\n","Made_Y = np.load(gdrive_path + 'Made_X/Made_Y %s_%s.npy' % (input_data_length, model_num)).reshape(-1, 1)\n","\n","\n","#       dataset 분리      #\n","# dataX 구성 : VOLUME, MA, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC, zero\n","# dataX 구성 : VOLUME, EMA1, EMA2, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC \n","Made_X = Made_X[:, :, [-2]]\n","print(Made_X.shape)\n","print(Made_Y.shape)\n","\n","row = Made_X.shape[1]\n","col = Made_X.shape[2]\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, Y_train, Y_val = train_test_split(Made_X, Made_Y, test_size=0.3,\n","                                                   shuffle=False)\n","\n","X_train = X_train.astype('float32').reshape(-1, input_data_length, col, 1)\n","X_val = X_val.astype('float32').reshape(-1, input_data_length, col, 1)\n","print(X_train.shape)\n","print(X_val.shape)\n","\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator \n","\n","# Data Class Weight\n","from sklearn.utils import class_weight\n","\n","print(Y_train[:, 0])\n","class_weights = class_weight.compute_class_weight('balanced', \n","                                                  np.unique(Y_train[:, 0]),\n","                                                  Y_train[:, 0])\n","class_weights = dict(enumerate(class_weights))\n","print(class_weights)\n","# quit()\n","\n","Y_train = Y_train.astype('float32')\n","Y_val = Y_val.astype('float32')\n","Y_train = np_utils.to_categorical(Y_train, num_classes)\n","Y_val = np_utils.to_categorical(Y_val, num_classes)\n","print(Y_train.shape)\n","print(Y_val.shape)\n","\n","datagen = ImageDataGenerator( \n","#     rotation_range = 60,\n","#     zoom_range = 0.6,\n","#     shear_range = 0.6,\n","#     horizontal_flip = True,\n","#     width_shift_range=0.6,\n","#     height_shift_range=0.6,\n","    fill_mode = 'nearest'\n","    )\n","\n","testgen = ImageDataGenerator( \n","    )\n","datagen.fit(X_train)\n","batch_size = 128\n","\n","for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n","    for i in range(0, 9): \n","        pyplot.axis('off') \n","        pyplot.subplot(330 + 1 + i) \n","        pyplot.imshow(X_batch[i].reshape(input_data_length, col))\n","    pyplot.axis('off') \n","    pyplot.show() \n","    break\n","    \n","    \n","train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n","val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n","\n","\n","from keras.utils import plot_model\n","import keras.backend as K\n","from keras.models import Model, Sequential\n","import keras.layers as layers\n","from keras.optimizers import Adam, SGD\n","from keras.regularizers import l1, l2\n","from sklearn.metrics import confusion_matrix\n","\n","def FER_Model(input_shape=(row, col, 1)):\n","    # first input model\n","    visible = layers.Input(shape=input_shape, name='input')\n","    \n","    net = layers.Conv2D(64, kernel_size=3, padding='same')(visible)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    shortcut_1 = net\n","\n","    net = layers.Conv2D(128, kernel_size=3, padding='same')(net)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    shortcut_2 = net\n","\n","#     net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","#     shortcut_3 = net\n","\n","#     net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    net = layers.Flatten()(net)\n","    net = layers.Dense(64)(net)\n","    net = layers.LeakyReLU()(net)\n","    net = layers.Dense(num_classes, activation='softmax')(net)\n","\n","    # create model \n","    model = Model(inputs =visible, outputs = net)\n","    # summary layers\n","    print(model.summary())\n","    \n","    return model\n","\n","model = FER_Model()\n","# from keras.models import load_model\n","# model = load_model(gdrive_path + 'model/rapid_ascending %s_%s_ohlc.hdf5' % (input_data_length, model_num))\n","opt = Adam(lr=0.0001, decay=1e-6)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  \n","    \n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","filepath = gdrive_path + \"model/rapid_ascending %s_%s_macd.hdf5\" % (input_data_length, model_num)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n","                          histogram_freq=0,\n","                          write_graph=True,\n","                          write_images=True)\n","checkpoint3 = EarlyStopping(monitor='val_loss', patience=100)\n","callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n","\n","# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n","\n","# we iterate 200 times over the entire training set\n","num_epochs = 500\n","history = model.fit_generator(train_flow, \n","                    steps_per_epoch=len(X_train) / batch_size, \n","                    epochs=num_epochs,  \n","                    verbose=2,  \n","                    callbacks=callbacks_list,\n","                    class_weight=class_weights,\n","                    validation_data=val_flow,  \n","                    validation_steps=len(X_val) / batch_size,\n","                    shuffle=False)\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","(316342, 54, 1)\n","(316342, 1)\n","(221439, 54, 1, 1)\n","(94903, 54, 1, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","{0: 0.3396058873056697, 1: 36.46887351778656, 2: 35.727492739593416}\n","(221439, 3)\n","(94903, 3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (InputLayer)           (None, 54, 1, 1)          0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 54, 1, 64)         640       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 54, 1, 64)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 54, 1, 128)        73856     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 54, 1, 128)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6912)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                442432    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 517,123\n","Trainable params: 517,123\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/500\n"," - 21s - loss: 0.9166 - accuracy: 0.2782 - val_loss: 1.1558 - val_accuracy: 0.2420\n","\n","Epoch 00001: val_loss improved from inf to 1.15575, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/500\n"," - 15s - loss: 0.8447 - accuracy: 0.2937 - val_loss: 1.2050 - val_accuracy: 0.2454\n","\n","Epoch 00002: val_loss did not improve from 1.15575\n","Epoch 3/500\n"," - 14s - loss: 0.8263 - accuracy: 0.2893 - val_loss: 0.9936 - val_accuracy: 0.3499\n","\n","Epoch 00003: val_loss improved from 1.15575 to 0.99365, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 4/500\n"," - 14s - loss: 0.8162 - accuracy: 0.2817 - val_loss: 1.1172 - val_accuracy: 0.2132\n","\n","Epoch 00004: val_loss did not improve from 0.99365\n","Epoch 5/500\n"," - 15s - loss: 0.8108 - accuracy: 0.2681 - val_loss: 1.0395 - val_accuracy: 0.2855\n","\n","Epoch 00005: val_loss did not improve from 0.99365\n","Epoch 6/500\n"," - 15s - loss: 0.8021 - accuracy: 0.2623 - val_loss: 1.1580 - val_accuracy: 0.1892\n","\n","Epoch 00006: val_loss did not improve from 0.99365\n","Epoch 7/500\n"," - 14s - loss: 0.7993 - accuracy: 0.2515 - val_loss: 1.1437 - val_accuracy: 0.2433\n","\n","Epoch 00007: val_loss did not improve from 0.99365\n","Epoch 8/500\n"," - 14s - loss: 0.7924 - accuracy: 0.2491 - val_loss: 1.0444 - val_accuracy: 0.2367\n","\n","Epoch 00008: val_loss did not improve from 0.99365\n","Epoch 9/500\n"," - 14s - loss: 0.7882 - accuracy: 0.2450 - val_loss: 1.1096 - val_accuracy: 0.1879\n","\n","Epoch 00009: val_loss did not improve from 0.99365\n","Epoch 10/500\n"," - 14s - loss: 0.7860 - accuracy: 0.2378 - val_loss: 1.0852 - val_accuracy: 0.2944\n","\n","Epoch 00010: val_loss did not improve from 0.99365\n","Epoch 11/500\n"," - 14s - loss: 0.7816 - accuracy: 0.2406 - val_loss: 1.1228 - val_accuracy: 0.2130\n","\n","Epoch 00011: val_loss did not improve from 0.99365\n","Epoch 12/500\n"," - 14s - loss: 0.7789 - accuracy: 0.2305 - val_loss: 1.1712 - val_accuracy: 0.2259\n","\n","Epoch 00012: val_loss did not improve from 0.99365\n","Epoch 13/500\n"," - 14s - loss: 0.7755 - accuracy: 0.2340 - val_loss: 1.0018 - val_accuracy: 0.2252\n","\n","Epoch 00013: val_loss did not improve from 0.99365\n","Epoch 14/500\n"," - 14s - loss: 0.7748 - accuracy: 0.2284 - val_loss: 1.0159 - val_accuracy: 0.2636\n","\n","Epoch 00014: val_loss did not improve from 0.99365\n","Epoch 15/500\n"," - 14s - loss: 0.7723 - accuracy: 0.2301 - val_loss: 1.0657 - val_accuracy: 0.1842\n","\n","Epoch 00015: val_loss did not improve from 0.99365\n","Epoch 16/500\n"," - 14s - loss: 0.7714 - accuracy: 0.2146 - val_loss: 0.9538 - val_accuracy: 0.2492\n","\n","Epoch 00016: val_loss improved from 0.99365 to 0.95379, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 17/500\n"," - 14s - loss: 0.7653 - accuracy: 0.2258 - val_loss: 1.0525 - val_accuracy: 0.2035\n","\n","Epoch 00017: val_loss did not improve from 0.95379\n","Epoch 18/500\n"," - 14s - loss: 0.7647 - accuracy: 0.2186 - val_loss: 1.0317 - val_accuracy: 0.2194\n","\n","Epoch 00018: val_loss did not improve from 0.95379\n","Epoch 19/500\n"," - 14s - loss: 0.7648 - accuracy: 0.2103 - val_loss: 1.0772 - val_accuracy: 0.2469\n","\n","Epoch 00019: val_loss did not improve from 0.95379\n","Epoch 20/500\n"," - 14s - loss: 0.7607 - accuracy: 0.2140 - val_loss: 1.1041 - val_accuracy: 0.1946\n","\n","Epoch 00020: val_loss did not improve from 0.95379\n","Epoch 21/500\n"," - 14s - loss: 0.7624 - accuracy: 0.2133 - val_loss: 1.1233 - val_accuracy: 0.1625\n","\n","Epoch 00021: val_loss did not improve from 0.95379\n","Epoch 22/500\n"," - 14s - loss: 0.7595 - accuracy: 0.2094 - val_loss: 1.0787 - val_accuracy: 0.1627\n","\n","Epoch 00022: val_loss did not improve from 0.95379\n","Epoch 23/500\n"," - 14s - loss: 0.7563 - accuracy: 0.2071 - val_loss: 1.0690 - val_accuracy: 0.2426\n","\n","Epoch 00023: val_loss did not improve from 0.95379\n","Epoch 24/500\n"," - 14s - loss: 0.7571 - accuracy: 0.2121 - val_loss: 1.0308 - val_accuracy: 0.2061\n","\n","Epoch 00024: val_loss did not improve from 0.95379\n","Epoch 25/500\n"," - 14s - loss: 0.7553 - accuracy: 0.2118 - val_loss: 1.0633 - val_accuracy: 0.1498\n","\n","Epoch 00025: val_loss did not improve from 0.95379\n","Epoch 26/500\n"," - 14s - loss: 0.7555 - accuracy: 0.2039 - val_loss: 1.2337 - val_accuracy: 0.1584\n","\n","Epoch 00026: val_loss did not improve from 0.95379\n","Epoch 27/500\n"," - 14s - loss: 0.7542 - accuracy: 0.2082 - val_loss: 1.0995 - val_accuracy: 0.1427\n","\n","Epoch 00027: val_loss did not improve from 0.95379\n","Epoch 28/500\n"," - 14s - loss: 0.7525 - accuracy: 0.2059 - val_loss: 1.0428 - val_accuracy: 0.2196\n","\n","Epoch 00028: val_loss did not improve from 0.95379\n","Epoch 29/500\n"," - 14s - loss: 0.7518 - accuracy: 0.2115 - val_loss: 1.0485 - val_accuracy: 0.2771\n","\n","Epoch 00029: val_loss did not improve from 0.95379\n","Epoch 30/500\n"," - 14s - loss: 0.7500 - accuracy: 0.2098 - val_loss: 1.0814 - val_accuracy: 0.1572\n","\n","Epoch 00030: val_loss did not improve from 0.95379\n","Epoch 31/500\n"," - 14s - loss: 0.7482 - accuracy: 0.2083 - val_loss: 1.0132 - val_accuracy: 0.2184\n","\n","Epoch 00031: val_loss did not improve from 0.95379\n","Epoch 32/500\n"," - 14s - loss: 0.7481 - accuracy: 0.2124 - val_loss: 1.0683 - val_accuracy: 0.2078\n","\n","Epoch 00032: val_loss did not improve from 0.95379\n","Epoch 33/500\n"," - 14s - loss: 0.7464 - accuracy: 0.2067 - val_loss: 1.0640 - val_accuracy: 0.2389\n","\n","Epoch 00033: val_loss did not improve from 0.95379\n","Epoch 34/500\n"," - 14s - loss: 0.7468 - accuracy: 0.2115 - val_loss: 1.0203 - val_accuracy: 0.2284\n","\n","Epoch 00034: val_loss did not improve from 0.95379\n","Epoch 35/500\n"," - 14s - loss: 0.7457 - accuracy: 0.2091 - val_loss: 1.0942 - val_accuracy: 0.2214\n","\n","Epoch 00035: val_loss did not improve from 0.95379\n","Epoch 36/500\n"," - 14s - loss: 0.7448 - accuracy: 0.2095 - val_loss: 1.1184 - val_accuracy: 0.1767\n","\n","Epoch 00036: val_loss did not improve from 0.95379\n","Epoch 37/500\n"," - 14s - loss: 0.7437 - accuracy: 0.2114 - val_loss: 1.1186 - val_accuracy: 0.2010\n","\n","Epoch 00037: val_loss did not improve from 0.95379\n","Epoch 38/500\n"," - 14s - loss: 0.7437 - accuracy: 0.2081 - val_loss: 1.0368 - val_accuracy: 0.2010\n","\n","Epoch 00038: val_loss did not improve from 0.95379\n","Epoch 39/500\n"," - 14s - loss: 0.7430 - accuracy: 0.2130 - val_loss: 1.0937 - val_accuracy: 0.1644\n","\n","Epoch 00039: val_loss did not improve from 0.95379\n","Epoch 40/500\n"," - 14s - loss: 0.7421 - accuracy: 0.2091 - val_loss: 1.0017 - val_accuracy: 0.2438\n","\n","Epoch 00040: val_loss did not improve from 0.95379\n","Epoch 41/500\n"," - 14s - loss: 0.7416 - accuracy: 0.2150 - val_loss: 1.0647 - val_accuracy: 0.1803\n","\n","Epoch 00041: val_loss did not improve from 0.95379\n","Epoch 42/500\n"," - 14s - loss: 0.7412 - accuracy: 0.2143 - val_loss: 1.0997 - val_accuracy: 0.1799\n","\n","Epoch 00042: val_loss did not improve from 0.95379\n","Epoch 43/500\n"," - 14s - loss: 0.7400 - accuracy: 0.2187 - val_loss: 1.0515 - val_accuracy: 0.2020\n","\n","Epoch 00043: val_loss did not improve from 0.95379\n","Epoch 44/500\n"," - 14s - loss: 0.7407 - accuracy: 0.2136 - val_loss: 0.9950 - val_accuracy: 0.2177\n","\n","Epoch 00044: val_loss did not improve from 0.95379\n","Epoch 45/500\n"," - 14s - loss: 0.7386 - accuracy: 0.2172 - val_loss: 1.0592 - val_accuracy: 0.2284\n","\n","Epoch 00045: val_loss did not improve from 0.95379\n","Epoch 46/500\n"," - 14s - loss: 0.7377 - accuracy: 0.2146 - val_loss: 1.0350 - val_accuracy: 0.2324\n","\n","Epoch 00046: val_loss did not improve from 0.95379\n","Epoch 47/500\n"," - 14s - loss: 0.7378 - accuracy: 0.2162 - val_loss: 1.0853 - val_accuracy: 0.1730\n","\n","Epoch 00047: val_loss did not improve from 0.95379\n","Epoch 48/500\n"," - 14s - loss: 0.7372 - accuracy: 0.2168 - val_loss: 1.0605 - val_accuracy: 0.1778\n","\n","Epoch 00048: val_loss did not improve from 0.95379\n","Epoch 49/500\n"," - 14s - loss: 0.7367 - accuracy: 0.2166 - val_loss: 1.1524 - val_accuracy: 0.1584\n","\n","Epoch 00049: val_loss did not improve from 0.95379\n","Epoch 50/500\n"," - 14s - loss: 0.7358 - accuracy: 0.2142 - val_loss: 1.0727 - val_accuracy: 0.2064\n","\n","Epoch 00050: val_loss did not improve from 0.95379\n","Epoch 51/500\n"," - 14s - loss: 0.7346 - accuracy: 0.2212 - val_loss: 0.8896 - val_accuracy: 0.3054\n","\n","Epoch 00051: val_loss improved from 0.95379 to 0.88955, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 52/500\n"," - 14s - loss: 0.7348 - accuracy: 0.2241 - val_loss: 1.1704 - val_accuracy: 0.1970\n","\n","Epoch 00052: val_loss did not improve from 0.88955\n","Epoch 53/500\n"," - 14s - loss: 0.7343 - accuracy: 0.2173 - val_loss: 1.0822 - val_accuracy: 0.2071\n","\n","Epoch 00053: val_loss did not improve from 0.88955\n","Epoch 54/500\n"," - 14s - loss: 0.7337 - accuracy: 0.2193 - val_loss: 1.0822 - val_accuracy: 0.2020\n","\n","Epoch 00054: val_loss did not improve from 0.88955\n","Epoch 55/500\n"," - 14s - loss: 0.7335 - accuracy: 0.2219 - val_loss: 1.0776 - val_accuracy: 0.2086\n","\n","Epoch 00055: val_loss did not improve from 0.88955\n","Epoch 56/500\n"," - 14s - loss: 0.7332 - accuracy: 0.2191 - val_loss: 1.0776 - val_accuracy: 0.2270\n","\n","Epoch 00056: val_loss did not improve from 0.88955\n","Epoch 57/500\n"," - 14s - loss: 0.7317 - accuracy: 0.2226 - val_loss: 1.0199 - val_accuracy: 0.2000\n","\n","Epoch 00057: val_loss did not improve from 0.88955\n","Epoch 58/500\n"," - 14s - loss: 0.7324 - accuracy: 0.2179 - val_loss: 1.1327 - val_accuracy: 0.2065\n","\n","Epoch 00058: val_loss did not improve from 0.88955\n","Epoch 59/500\n"," - 14s - loss: 0.7310 - accuracy: 0.2237 - val_loss: 1.1265 - val_accuracy: 0.2017\n","\n","Epoch 00059: val_loss did not improve from 0.88955\n","Epoch 60/500\n"," - 14s - loss: 0.7298 - accuracy: 0.2234 - val_loss: 0.9634 - val_accuracy: 0.2391\n","\n","Epoch 00060: val_loss did not improve from 0.88955\n","Epoch 61/500\n"," - 14s - loss: 0.7294 - accuracy: 0.2284 - val_loss: 1.0290 - val_accuracy: 0.2075\n","\n","Epoch 00061: val_loss did not improve from 0.88955\n","Epoch 62/500\n"," - 14s - loss: 0.7283 - accuracy: 0.2216 - val_loss: 1.0013 - val_accuracy: 0.2681\n","\n","Epoch 00062: val_loss did not improve from 0.88955\n","Epoch 63/500\n"," - 14s - loss: 0.7280 - accuracy: 0.2284 - val_loss: 0.9147 - val_accuracy: 0.2327\n","\n","Epoch 00063: val_loss did not improve from 0.88955\n","Epoch 64/500\n"," - 14s - loss: 0.7276 - accuracy: 0.2271 - val_loss: 0.9973 - val_accuracy: 0.2595\n","\n","Epoch 00064: val_loss did not improve from 0.88955\n","Epoch 65/500\n"," - 14s - loss: 0.7265 - accuracy: 0.2289 - val_loss: 0.9923 - val_accuracy: 0.2533\n","\n","Epoch 00065: val_loss did not improve from 0.88955\n","Epoch 66/500\n"," - 14s - loss: 0.7268 - accuracy: 0.2301 - val_loss: 1.0837 - val_accuracy: 0.1792\n","\n","Epoch 00066: val_loss did not improve from 0.88955\n","Epoch 67/500\n"," - 14s - loss: 0.7262 - accuracy: 0.2254 - val_loss: 1.0248 - val_accuracy: 0.2203\n","\n","Epoch 00067: val_loss did not improve from 0.88955\n","Epoch 68/500\n"," - 14s - loss: 0.7251 - accuracy: 0.2248 - val_loss: 0.9531 - val_accuracy: 0.2687\n","\n","Epoch 00068: val_loss did not improve from 0.88955\n","Epoch 69/500\n"," - 14s - loss: 0.7250 - accuracy: 0.2327 - val_loss: 1.0115 - val_accuracy: 0.2400\n","\n","Epoch 00069: val_loss did not improve from 0.88955\n","Epoch 70/500\n"," - 14s - loss: 0.7246 - accuracy: 0.2266 - val_loss: 1.1069 - val_accuracy: 0.2675\n","\n","Epoch 00070: val_loss did not improve from 0.88955\n","Epoch 71/500\n"," - 14s - loss: 0.7238 - accuracy: 0.2295 - val_loss: 0.9686 - val_accuracy: 0.2552\n","\n","Epoch 00071: val_loss did not improve from 0.88955\n","Epoch 72/500\n"," - 14s - loss: 0.7231 - accuracy: 0.2353 - val_loss: 1.0445 - val_accuracy: 0.2089\n","\n","Epoch 00072: val_loss did not improve from 0.88955\n","Epoch 73/500\n"," - 14s - loss: 0.7231 - accuracy: 0.2266 - val_loss: 0.9833 - val_accuracy: 0.2676\n","\n","Epoch 00073: val_loss did not improve from 0.88955\n","Epoch 74/500\n"," - 14s - loss: 0.7224 - accuracy: 0.2358 - val_loss: 0.9759 - val_accuracy: 0.2630\n","\n","Epoch 00074: val_loss did not improve from 0.88955\n","Epoch 75/500\n"," - 14s - loss: 0.7228 - accuracy: 0.2289 - val_loss: 1.0440 - val_accuracy: 0.2402\n","\n","Epoch 00075: val_loss did not improve from 0.88955\n","Epoch 76/500\n"," - 14s - loss: 0.7205 - accuracy: 0.2327 - val_loss: 1.0295 - val_accuracy: 0.2631\n","\n","Epoch 00076: val_loss did not improve from 0.88955\n","Epoch 77/500\n"," - 14s - loss: 0.7208 - accuracy: 0.2359 - val_loss: 1.0390 - val_accuracy: 0.1954\n","\n","Epoch 00077: val_loss did not improve from 0.88955\n","Epoch 78/500\n"," - 14s - loss: 0.7202 - accuracy: 0.2346 - val_loss: 1.0266 - val_accuracy: 0.2157\n","\n","Epoch 00078: val_loss did not improve from 0.88955\n","Epoch 79/500\n"," - 14s - loss: 0.7195 - accuracy: 0.2345 - val_loss: 0.9695 - val_accuracy: 0.2467\n","\n","Epoch 00079: val_loss did not improve from 0.88955\n","Epoch 80/500\n"," - 14s - loss: 0.7205 - accuracy: 0.2393 - val_loss: 1.1238 - val_accuracy: 0.1918\n","\n","Epoch 00080: val_loss did not improve from 0.88955\n","Epoch 81/500\n"," - 14s - loss: 0.7189 - accuracy: 0.2340 - val_loss: 1.0890 - val_accuracy: 0.2246\n","\n","Epoch 00081: val_loss did not improve from 0.88955\n","Epoch 82/500\n"," - 14s - loss: 0.7174 - accuracy: 0.2373 - val_loss: 1.0877 - val_accuracy: 0.2462\n","\n","Epoch 00082: val_loss did not improve from 0.88955\n","Epoch 83/500\n"," - 14s - loss: 0.7179 - accuracy: 0.2366 - val_loss: 1.0896 - val_accuracy: 0.2327\n","\n","Epoch 00083: val_loss did not improve from 0.88955\n","Epoch 84/500\n"," - 14s - loss: 0.7173 - accuracy: 0.2413 - val_loss: 1.0667 - val_accuracy: 0.2059\n","\n","Epoch 00084: val_loss did not improve from 0.88955\n","Epoch 85/500\n"," - 14s - loss: 0.7162 - accuracy: 0.2360 - val_loss: 0.9493 - val_accuracy: 0.2743\n","\n","Epoch 00085: val_loss did not improve from 0.88955\n","Epoch 86/500\n"," - 14s - loss: 0.7159 - accuracy: 0.2423 - val_loss: 1.0196 - val_accuracy: 0.2475\n","\n","Epoch 00086: val_loss did not improve from 0.88955\n","Epoch 87/500\n"," - 14s - loss: 0.7165 - accuracy: 0.2383 - val_loss: 1.0949 - val_accuracy: 0.2306\n","\n","Epoch 00087: val_loss did not improve from 0.88955\n","Epoch 88/500\n"," - 14s - loss: 0.7156 - accuracy: 0.2423 - val_loss: 0.9934 - val_accuracy: 0.2708\n","\n","Epoch 00088: val_loss did not improve from 0.88955\n","Epoch 89/500\n"," - 14s - loss: 0.7148 - accuracy: 0.2449 - val_loss: 1.0806 - val_accuracy: 0.2248\n","\n","Epoch 00089: val_loss did not improve from 0.88955\n","Epoch 90/500\n"," - 14s - loss: 0.7135 - accuracy: 0.2455 - val_loss: 1.0003 - val_accuracy: 0.2531\n","\n","Epoch 00090: val_loss did not improve from 0.88955\n","Epoch 91/500\n"," - 14s - loss: 0.7136 - accuracy: 0.2410 - val_loss: 0.9710 - val_accuracy: 0.2815\n","\n","Epoch 00091: val_loss did not improve from 0.88955\n","Epoch 92/500\n"," - 14s - loss: 0.7121 - accuracy: 0.2473 - val_loss: 1.0915 - val_accuracy: 0.2350\n","\n","Epoch 00092: val_loss did not improve from 0.88955\n","Epoch 93/500\n"," - 14s - loss: 0.7120 - accuracy: 0.2429 - val_loss: 1.0210 - val_accuracy: 0.2808\n","\n","Epoch 00093: val_loss did not improve from 0.88955\n","Epoch 94/500\n"," - 14s - loss: 0.7131 - accuracy: 0.2446 - val_loss: 1.1298 - val_accuracy: 0.2108\n","\n","Epoch 00094: val_loss did not improve from 0.88955\n","Epoch 95/500\n"," - 14s - loss: 0.7122 - accuracy: 0.2469 - val_loss: 1.0104 - val_accuracy: 0.2461\n","\n","Epoch 00095: val_loss did not improve from 0.88955\n","Epoch 96/500\n"," - 14s - loss: 0.7110 - accuracy: 0.2453 - val_loss: 0.9655 - val_accuracy: 0.3065\n","\n","Epoch 00096: val_loss did not improve from 0.88955\n","Epoch 97/500\n"," - 14s - loss: 0.7110 - accuracy: 0.2448 - val_loss: 1.0965 - val_accuracy: 0.2706\n","\n","Epoch 00097: val_loss did not improve from 0.88955\n","Epoch 98/500\n"," - 14s - loss: 0.7098 - accuracy: 0.2495 - val_loss: 1.0392 - val_accuracy: 0.2563\n","\n","Epoch 00098: val_loss did not improve from 0.88955\n","Epoch 99/500\n"," - 14s - loss: 0.7092 - accuracy: 0.2494 - val_loss: 1.1410 - val_accuracy: 0.2026\n","\n","Epoch 00099: val_loss did not improve from 0.88955\n","Epoch 100/500\n"," - 14s - loss: 0.7077 - accuracy: 0.2468 - val_loss: 1.0152 - val_accuracy: 0.2249\n","\n","Epoch 00100: val_loss did not improve from 0.88955\n","Epoch 101/500\n"," - 14s - loss: 0.7079 - accuracy: 0.2501 - val_loss: 1.0019 - val_accuracy: 0.2519\n","\n","Epoch 00101: val_loss did not improve from 0.88955\n","Epoch 102/500\n"," - 14s - loss: 0.7077 - accuracy: 0.2493 - val_loss: 0.9501 - val_accuracy: 0.3160\n","\n","Epoch 00102: val_loss did not improve from 0.88955\n","Epoch 103/500\n"," - 14s - loss: 0.7077 - accuracy: 0.2552 - val_loss: 1.0109 - val_accuracy: 0.2578\n","\n","Epoch 00103: val_loss did not improve from 0.88955\n","Epoch 104/500\n"," - 14s - loss: 0.7074 - accuracy: 0.2540 - val_loss: 0.9746 - val_accuracy: 0.2384\n","\n","Epoch 00104: val_loss did not improve from 0.88955\n","Epoch 105/500\n"," - 14s - loss: 0.7055 - accuracy: 0.2527 - val_loss: 1.0121 - val_accuracy: 0.2970\n","\n","Epoch 00105: val_loss did not improve from 0.88955\n","Epoch 106/500\n"," - 14s - loss: 0.7067 - accuracy: 0.2581 - val_loss: 1.0972 - val_accuracy: 0.2366\n","\n","Epoch 00106: val_loss did not improve from 0.88955\n","Epoch 107/500\n"," - 14s - loss: 0.7054 - accuracy: 0.2527 - val_loss: 1.0670 - val_accuracy: 0.2259\n","\n","Epoch 00107: val_loss did not improve from 0.88955\n","Epoch 108/500\n"," - 14s - loss: 0.7041 - accuracy: 0.2564 - val_loss: 1.0131 - val_accuracy: 0.2983\n","\n","Epoch 00108: val_loss did not improve from 0.88955\n","Epoch 109/500\n"," - 14s - loss: 0.7033 - accuracy: 0.2608 - val_loss: 0.9803 - val_accuracy: 0.2702\n","\n","Epoch 00109: val_loss did not improve from 0.88955\n","Epoch 110/500\n"," - 14s - loss: 0.7035 - accuracy: 0.2618 - val_loss: 1.1628 - val_accuracy: 0.2089\n","\n","Epoch 00110: val_loss did not improve from 0.88955\n","Epoch 111/500\n"," - 14s - loss: 0.7019 - accuracy: 0.2596 - val_loss: 1.0359 - val_accuracy: 0.2590\n","\n","Epoch 00111: val_loss did not improve from 0.88955\n","Epoch 112/500\n"," - 14s - loss: 0.7011 - accuracy: 0.2596 - val_loss: 1.0716 - val_accuracy: 0.2544\n","\n","Epoch 00112: val_loss did not improve from 0.88955\n","Epoch 113/500\n"," - 14s - loss: 0.7014 - accuracy: 0.2607 - val_loss: 1.0052 - val_accuracy: 0.2688\n","\n","Epoch 00113: val_loss did not improve from 0.88955\n","Epoch 114/500\n"," - 14s - loss: 0.7014 - accuracy: 0.2630 - val_loss: 1.1225 - val_accuracy: 0.2308\n","\n","Epoch 00114: val_loss did not improve from 0.88955\n","Epoch 115/500\n"," - 14s - loss: 0.7008 - accuracy: 0.2610 - val_loss: 0.9170 - val_accuracy: 0.3139\n","\n","Epoch 00115: val_loss did not improve from 0.88955\n","Epoch 116/500\n"," - 14s - loss: 0.6982 - accuracy: 0.2707 - val_loss: 1.0207 - val_accuracy: 0.2202\n","\n","Epoch 00116: val_loss did not improve from 0.88955\n","Epoch 117/500\n"," - 14s - loss: 0.6993 - accuracy: 0.2657 - val_loss: 1.0505 - val_accuracy: 0.2602\n","\n","Epoch 00117: val_loss did not improve from 0.88955\n","Epoch 118/500\n"," - 14s - loss: 0.6976 - accuracy: 0.2683 - val_loss: 0.9796 - val_accuracy: 0.2009\n","\n","Epoch 00118: val_loss did not improve from 0.88955\n","Epoch 119/500\n"," - 14s - loss: 0.6986 - accuracy: 0.2652 - val_loss: 0.9225 - val_accuracy: 0.2986\n","\n","Epoch 00119: val_loss did not improve from 0.88955\n","Epoch 120/500\n"," - 14s - loss: 0.6972 - accuracy: 0.2688 - val_loss: 0.9548 - val_accuracy: 0.3278\n","\n","Epoch 00120: val_loss did not improve from 0.88955\n","Epoch 121/500\n"," - 14s - loss: 0.6968 - accuracy: 0.2683 - val_loss: 1.0715 - val_accuracy: 0.2586\n","\n","Epoch 00121: val_loss did not improve from 0.88955\n","Epoch 122/500\n"," - 14s - loss: 0.6964 - accuracy: 0.2710 - val_loss: 1.0555 - val_accuracy: 0.2354\n","\n","Epoch 00122: val_loss did not improve from 0.88955\n","Epoch 123/500\n"," - 14s - loss: 0.6954 - accuracy: 0.2708 - val_loss: 1.0908 - val_accuracy: 0.2379\n","\n","Epoch 00123: val_loss did not improve from 0.88955\n","Epoch 124/500\n"," - 14s - loss: 0.6952 - accuracy: 0.2683 - val_loss: 0.9811 - val_accuracy: 0.3076\n","\n","Epoch 00124: val_loss did not improve from 0.88955\n","Epoch 125/500\n"," - 14s - loss: 0.6939 - accuracy: 0.2728 - val_loss: 1.0555 - val_accuracy: 0.2248\n","\n","Epoch 00125: val_loss did not improve from 0.88955\n","Epoch 126/500\n"," - 14s - loss: 0.6940 - accuracy: 0.2717 - val_loss: 1.0201 - val_accuracy: 0.2900\n","\n","Epoch 00126: val_loss did not improve from 0.88955\n","Epoch 127/500\n"," - 14s - loss: 0.6927 - accuracy: 0.2706 - val_loss: 0.9102 - val_accuracy: 0.3677\n","\n","Epoch 00127: val_loss did not improve from 0.88955\n","Epoch 128/500\n"," - 14s - loss: 0.6934 - accuracy: 0.2802 - val_loss: 1.0616 - val_accuracy: 0.2214\n","\n","Epoch 00128: val_loss did not improve from 0.88955\n","Epoch 129/500\n"," - 14s - loss: 0.6918 - accuracy: 0.2728 - val_loss: 1.0632 - val_accuracy: 0.2840\n","\n","Epoch 00129: val_loss did not improve from 0.88955\n","Epoch 130/500\n"," - 14s - loss: 0.6926 - accuracy: 0.2778 - val_loss: 1.0546 - val_accuracy: 0.2361\n","\n","Epoch 00130: val_loss did not improve from 0.88955\n","Epoch 131/500\n"," - 14s - loss: 0.6925 - accuracy: 0.2751 - val_loss: 0.8862 - val_accuracy: 0.3321\n","\n","Epoch 00131: val_loss improved from 0.88955 to 0.88622, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 132/500\n"," - 14s - loss: 0.6906 - accuracy: 0.2751 - val_loss: 0.9570 - val_accuracy: 0.2969\n","\n","Epoch 00132: val_loss did not improve from 0.88622\n","Epoch 133/500\n"," - 14s - loss: 0.6890 - accuracy: 0.2811 - val_loss: 1.0639 - val_accuracy: 0.2518\n","\n","Epoch 00133: val_loss did not improve from 0.88622\n","Epoch 134/500\n"," - 14s - loss: 0.6891 - accuracy: 0.2782 - val_loss: 1.0337 - val_accuracy: 0.2992\n","\n","Epoch 00134: val_loss did not improve from 0.88622\n","Epoch 135/500\n"," - 14s - loss: 0.6888 - accuracy: 0.2837 - val_loss: 1.0037 - val_accuracy: 0.2917\n","\n","Epoch 00135: val_loss did not improve from 0.88622\n","Epoch 136/500\n"," - 14s - loss: 0.6884 - accuracy: 0.2798 - val_loss: 1.0095 - val_accuracy: 0.2849\n","\n","Epoch 00136: val_loss did not improve from 0.88622\n","Epoch 137/500\n"," - 14s - loss: 0.6873 - accuracy: 0.2847 - val_loss: 1.1079 - val_accuracy: 0.2765\n","\n","Epoch 00137: val_loss did not improve from 0.88622\n","Epoch 138/500\n"," - 14s - loss: 0.6875 - accuracy: 0.2833 - val_loss: 0.9399 - val_accuracy: 0.2702\n","\n","Epoch 00138: val_loss did not improve from 0.88622\n","Epoch 139/500\n"," - 14s - loss: 0.6855 - accuracy: 0.2874 - val_loss: 1.0222 - val_accuracy: 0.3223\n","\n","Epoch 00139: val_loss did not improve from 0.88622\n","Epoch 140/500\n"," - 14s - loss: 0.6859 - accuracy: 0.2823 - val_loss: 0.9744 - val_accuracy: 0.3091\n","\n","Epoch 00140: val_loss did not improve from 0.88622\n","Epoch 141/500\n"," - 14s - loss: 0.6847 - accuracy: 0.2865 - val_loss: 0.9337 - val_accuracy: 0.3109\n","\n","Epoch 00141: val_loss did not improve from 0.88622\n","Epoch 142/500\n"," - 14s - loss: 0.6839 - accuracy: 0.2895 - val_loss: 1.0508 - val_accuracy: 0.3211\n","\n","Epoch 00142: val_loss did not improve from 0.88622\n","Epoch 143/500\n"," - 14s - loss: 0.6829 - accuracy: 0.2890 - val_loss: 0.9790 - val_accuracy: 0.3271\n","\n","Epoch 00143: val_loss did not improve from 0.88622\n","Epoch 144/500\n"," - 14s - loss: 0.6830 - accuracy: 0.2916 - val_loss: 1.1293 - val_accuracy: 0.2700\n","\n","Epoch 00144: val_loss did not improve from 0.88622\n","Epoch 145/500\n"," - 14s - loss: 0.6817 - accuracy: 0.2931 - val_loss: 1.1296 - val_accuracy: 0.2616\n","\n","Epoch 00145: val_loss did not improve from 0.88622\n","Epoch 146/500\n"," - 14s - loss: 0.6820 - accuracy: 0.2919 - val_loss: 0.9689 - val_accuracy: 0.3294\n","\n","Epoch 00146: val_loss did not improve from 0.88622\n","Epoch 147/500\n"," - 14s - loss: 0.6809 - accuracy: 0.2930 - val_loss: 1.0010 - val_accuracy: 0.3422\n","\n","Epoch 00147: val_loss did not improve from 0.88622\n","Epoch 148/500\n"," - 14s - loss: 0.6811 - accuracy: 0.2920 - val_loss: 1.0060 - val_accuracy: 0.3028\n","\n","Epoch 00148: val_loss did not improve from 0.88622\n","Epoch 149/500\n"," - 14s - loss: 0.6801 - accuracy: 0.2964 - val_loss: 1.0867 - val_accuracy: 0.2796\n","\n","Epoch 00149: val_loss did not improve from 0.88622\n","Epoch 150/500\n"," - 14s - loss: 0.6798 - accuracy: 0.2935 - val_loss: 0.9824 - val_accuracy: 0.2673\n","\n","Epoch 00150: val_loss did not improve from 0.88622\n","Epoch 151/500\n"," - 14s - loss: 0.6793 - accuracy: 0.2957 - val_loss: 1.0213 - val_accuracy: 0.2835\n","\n","Epoch 00151: val_loss did not improve from 0.88622\n","Epoch 152/500\n"," - 14s - loss: 0.6772 - accuracy: 0.2991 - val_loss: 1.0749 - val_accuracy: 0.2508\n","\n","Epoch 00152: val_loss did not improve from 0.88622\n","Epoch 153/500\n"," - 14s - loss: 0.6770 - accuracy: 0.2994 - val_loss: 1.0552 - val_accuracy: 0.3025\n","\n","Epoch 00153: val_loss did not improve from 0.88622\n","Epoch 154/500\n"," - 14s - loss: 0.6774 - accuracy: 0.2971 - val_loss: 0.9217 - val_accuracy: 0.3625\n","\n","Epoch 00154: val_loss did not improve from 0.88622\n","Epoch 155/500\n"," - 14s - loss: 0.6769 - accuracy: 0.2989 - val_loss: 0.9843 - val_accuracy: 0.3253\n","\n","Epoch 00155: val_loss did not improve from 0.88622\n","Epoch 156/500\n"," - 14s - loss: 0.6768 - accuracy: 0.2978 - val_loss: 1.0654 - val_accuracy: 0.3371\n","\n","Epoch 00156: val_loss did not improve from 0.88622\n","Epoch 157/500\n"," - 14s - loss: 0.6748 - accuracy: 0.3026 - val_loss: 0.8957 - val_accuracy: 0.3599\n","\n","Epoch 00157: val_loss did not improve from 0.88622\n","Epoch 158/500\n"," - 14s - loss: 0.6742 - accuracy: 0.3064 - val_loss: 1.0077 - val_accuracy: 0.3184\n","\n","Epoch 00158: val_loss did not improve from 0.88622\n","Epoch 159/500\n"," - 14s - loss: 0.6749 - accuracy: 0.3019 - val_loss: 0.9299 - val_accuracy: 0.3008\n","\n","Epoch 00159: val_loss did not improve from 0.88622\n","Epoch 160/500\n"," - 14s - loss: 0.6723 - accuracy: 0.3041 - val_loss: 1.0911 - val_accuracy: 0.2779\n","\n","Epoch 00160: val_loss did not improve from 0.88622\n","Epoch 161/500\n"," - 14s - loss: 0.6716 - accuracy: 0.3080 - val_loss: 0.8802 - val_accuracy: 0.3450\n","\n","Epoch 00161: val_loss improved from 0.88622 to 0.88015, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 162/500\n"," - 14s - loss: 0.6709 - accuracy: 0.3086 - val_loss: 0.8161 - val_accuracy: 0.3802\n","\n","Epoch 00162: val_loss improved from 0.88015 to 0.81607, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 163/500\n"," - 14s - loss: 0.6711 - accuracy: 0.3095 - val_loss: 0.9527 - val_accuracy: 0.2944\n","\n","Epoch 00163: val_loss did not improve from 0.81607\n","Epoch 164/500\n"," - 14s - loss: 0.6706 - accuracy: 0.3095 - val_loss: 0.9493 - val_accuracy: 0.3301\n","\n","Epoch 00164: val_loss did not improve from 0.81607\n","Epoch 165/500\n"," - 14s - loss: 0.6707 - accuracy: 0.3078 - val_loss: 1.1264 - val_accuracy: 0.2441\n","\n","Epoch 00165: val_loss did not improve from 0.81607\n","Epoch 166/500\n"," - 14s - loss: 0.6701 - accuracy: 0.3082 - val_loss: 0.9196 - val_accuracy: 0.3404\n","\n","Epoch 00166: val_loss did not improve from 0.81607\n","Epoch 167/500\n"," - 14s - loss: 0.6699 - accuracy: 0.3097 - val_loss: 0.9845 - val_accuracy: 0.3231\n","\n","Epoch 00167: val_loss did not improve from 0.81607\n","Epoch 168/500\n"," - 15s - loss: 0.6686 - accuracy: 0.3124 - val_loss: 1.0095 - val_accuracy: 0.3050\n","\n","Epoch 00168: val_loss did not improve from 0.81607\n","Epoch 169/500\n"," - 14s - loss: 0.6671 - accuracy: 0.3140 - val_loss: 1.0376 - val_accuracy: 0.2764\n","\n","Epoch 00169: val_loss did not improve from 0.81607\n","Epoch 170/500\n"," - 14s - loss: 0.6676 - accuracy: 0.3109 - val_loss: 0.8835 - val_accuracy: 0.3544\n","\n","Epoch 00170: val_loss did not improve from 0.81607\n","Epoch 171/500\n"," - 14s - loss: 0.6663 - accuracy: 0.3157 - val_loss: 0.9598 - val_accuracy: 0.3147\n","\n","Epoch 00171: val_loss did not improve from 0.81607\n","Epoch 172/500\n"," - 14s - loss: 0.6661 - accuracy: 0.3155 - val_loss: 0.9992 - val_accuracy: 0.3312\n","\n","Epoch 00172: val_loss did not improve from 0.81607\n","Epoch 173/500\n"," - 14s - loss: 0.6641 - accuracy: 0.3175 - val_loss: 1.0283 - val_accuracy: 0.3516\n","\n","Epoch 00173: val_loss did not improve from 0.81607\n","Epoch 174/500\n"," - 14s - loss: 0.6644 - accuracy: 0.3178 - val_loss: 0.9903 - val_accuracy: 0.3155\n","\n","Epoch 00174: val_loss did not improve from 0.81607\n","Epoch 175/500\n"," - 14s - loss: 0.6643 - accuracy: 0.3176 - val_loss: 0.9101 - val_accuracy: 0.3490\n","\n","Epoch 00175: val_loss did not improve from 0.81607\n","Epoch 176/500\n"," - 14s - loss: 0.6641 - accuracy: 0.3175 - val_loss: 0.9666 - val_accuracy: 0.3864\n","\n","Epoch 00176: val_loss did not improve from 0.81607\n","Epoch 177/500\n"," - 15s - loss: 0.6624 - accuracy: 0.3214 - val_loss: 0.9678 - val_accuracy: 0.3320\n","\n","Epoch 00177: val_loss did not improve from 0.81607\n","Epoch 178/500\n"," - 15s - loss: 0.6613 - accuracy: 0.3226 - val_loss: 1.0414 - val_accuracy: 0.3060\n","\n","Epoch 00178: val_loss did not improve from 0.81607\n","Epoch 179/500\n"," - 14s - loss: 0.6613 - accuracy: 0.3195 - val_loss: 0.8305 - val_accuracy: 0.4063\n","\n","Epoch 00179: val_loss did not improve from 0.81607\n","Epoch 180/500\n"," - 14s - loss: 0.6598 - accuracy: 0.3255 - val_loss: 0.7298 - val_accuracy: 0.3703\n","\n","Epoch 00180: val_loss improved from 0.81607 to 0.72985, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_120_macd.hdf5\n","Epoch 181/500\n"," - 14s - loss: 0.6600 - accuracy: 0.3259 - val_loss: 1.0410 - val_accuracy: 0.3255\n","\n","Epoch 00181: val_loss did not improve from 0.72985\n","Epoch 182/500\n"," - 14s - loss: 0.6580 - accuracy: 0.3252 - val_loss: 0.9412 - val_accuracy: 0.4043\n","\n","Epoch 00182: val_loss did not improve from 0.72985\n","Epoch 183/500\n"," - 14s - loss: 0.6592 - accuracy: 0.3277 - val_loss: 0.8950 - val_accuracy: 0.3982\n","\n","Epoch 00183: val_loss did not improve from 0.72985\n","Epoch 184/500\n"," - 14s - loss: 0.6578 - accuracy: 0.3283 - val_loss: 0.9607 - val_accuracy: 0.3296\n","\n","Epoch 00184: val_loss did not improve from 0.72985\n","Epoch 185/500\n"," - 14s - loss: 0.6564 - accuracy: 0.3291 - val_loss: 0.9721 - val_accuracy: 0.3331\n","\n","Epoch 00185: val_loss did not improve from 0.72985\n","Epoch 186/500\n"," - 14s - loss: 0.6567 - accuracy: 0.3302 - val_loss: 0.9771 - val_accuracy: 0.3310\n","\n","Epoch 00186: val_loss did not improve from 0.72985\n","Epoch 187/500\n"," - 14s - loss: 0.6560 - accuracy: 0.3281 - val_loss: 0.9376 - val_accuracy: 0.4061\n","\n","Epoch 00187: val_loss did not improve from 0.72985\n","Epoch 188/500\n"," - 14s - loss: 0.6551 - accuracy: 0.3342 - val_loss: 1.1015 - val_accuracy: 0.3173\n","\n","Epoch 00188: val_loss did not improve from 0.72985\n","Epoch 189/500\n"," - 15s - loss: 0.6561 - accuracy: 0.3338 - val_loss: 0.9053 - val_accuracy: 0.3076\n","\n","Epoch 00189: val_loss did not improve from 0.72985\n","Epoch 190/500\n"," - 14s - loss: 0.6536 - accuracy: 0.3332 - val_loss: 1.0678 - val_accuracy: 0.2941\n","\n","Epoch 00190: val_loss did not improve from 0.72985\n","Epoch 191/500\n"," - 14s - loss: 0.6532 - accuracy: 0.3345 - val_loss: 0.9940 - val_accuracy: 0.3323\n","\n","Epoch 00191: val_loss did not improve from 0.72985\n","Epoch 192/500\n"," - 14s - loss: 0.6514 - accuracy: 0.3373 - val_loss: 0.9208 - val_accuracy: 0.3797\n","\n","Epoch 00192: val_loss did not improve from 0.72985\n","Epoch 193/500\n"," - 14s - loss: 0.6512 - accuracy: 0.3426 - val_loss: 1.1616 - val_accuracy: 0.2994\n","\n","Epoch 00193: val_loss did not improve from 0.72985\n","Epoch 194/500\n"," - 14s - loss: 0.6507 - accuracy: 0.3400 - val_loss: 0.9342 - val_accuracy: 0.3910\n","\n","Epoch 00194: val_loss did not improve from 0.72985\n","Epoch 195/500\n"," - 14s - loss: 0.6495 - accuracy: 0.3435 - val_loss: 0.8810 - val_accuracy: 0.3271\n","\n","Epoch 00195: val_loss did not improve from 0.72985\n","Epoch 196/500\n"," - 14s - loss: 0.6494 - accuracy: 0.3393 - val_loss: 0.8796 - val_accuracy: 0.4202\n","\n","Epoch 00196: val_loss did not improve from 0.72985\n","Epoch 197/500\n"," - 14s - loss: 0.6465 - accuracy: 0.3433 - val_loss: 0.8962 - val_accuracy: 0.3898\n","\n","Epoch 00197: val_loss did not improve from 0.72985\n","Epoch 198/500\n"," - 14s - loss: 0.6474 - accuracy: 0.3454 - val_loss: 0.9199 - val_accuracy: 0.3648\n","\n","Epoch 00198: val_loss did not improve from 0.72985\n","Epoch 199/500\n"," - 14s - loss: 0.6475 - accuracy: 0.3446 - val_loss: 0.9436 - val_accuracy: 0.3198\n","\n","Epoch 00199: val_loss did not improve from 0.72985\n","Epoch 200/500\n"," - 14s - loss: 0.6465 - accuracy: 0.3486 - val_loss: 1.1469 - val_accuracy: 0.2936\n","\n","Epoch 00200: val_loss did not improve from 0.72985\n","Epoch 201/500\n"," - 14s - loss: 0.6458 - accuracy: 0.3449 - val_loss: 0.9555 - val_accuracy: 0.3999\n","\n","Epoch 00201: val_loss did not improve from 0.72985\n","Epoch 202/500\n"," - 14s - loss: 0.6457 - accuracy: 0.3482 - val_loss: 0.8011 - val_accuracy: 0.4093\n","\n","Epoch 00202: val_loss did not improve from 0.72985\n","Epoch 203/500\n"," - 14s - loss: 0.6443 - accuracy: 0.3498 - val_loss: 1.0915 - val_accuracy: 0.3812\n","\n","Epoch 00203: val_loss did not improve from 0.72985\n","Epoch 204/500\n"," - 14s - loss: 0.6440 - accuracy: 0.3494 - val_loss: 0.9764 - val_accuracy: 0.3650\n","\n","Epoch 00204: val_loss did not improve from 0.72985\n","Epoch 205/500\n"," - 14s - loss: 0.6425 - accuracy: 0.3512 - val_loss: 0.8896 - val_accuracy: 0.3603\n","\n","Epoch 00205: val_loss did not improve from 0.72985\n","Epoch 206/500\n"," - 14s - loss: 0.6417 - accuracy: 0.3525 - val_loss: 0.8612 - val_accuracy: 0.3851\n","\n","Epoch 00206: val_loss did not improve from 0.72985\n","Epoch 207/500\n"," - 14s - loss: 0.6423 - accuracy: 0.3534 - val_loss: 1.0561 - val_accuracy: 0.3225\n","\n","Epoch 00207: val_loss did not improve from 0.72985\n","Epoch 208/500\n"," - 14s - loss: 0.6413 - accuracy: 0.3541 - val_loss: 1.0367 - val_accuracy: 0.3569\n","\n","Epoch 00208: val_loss did not improve from 0.72985\n","Epoch 209/500\n"," - 14s - loss: 0.6409 - accuracy: 0.3552 - val_loss: 1.0253 - val_accuracy: 0.3166\n","\n","Epoch 00209: val_loss did not improve from 0.72985\n","Epoch 210/500\n"," - 14s - loss: 0.6405 - accuracy: 0.3533 - val_loss: 0.8484 - val_accuracy: 0.4087\n","\n","Epoch 00210: val_loss did not improve from 0.72985\n","Epoch 211/500\n"," - 15s - loss: 0.6402 - accuracy: 0.3598 - val_loss: 0.9335 - val_accuracy: 0.3607\n","\n","Epoch 00211: val_loss did not improve from 0.72985\n","Epoch 212/500\n"," - 14s - loss: 0.6384 - accuracy: 0.3561 - val_loss: 0.9154 - val_accuracy: 0.3754\n","\n","Epoch 00212: val_loss did not improve from 0.72985\n","Epoch 213/500\n"," - 14s - loss: 0.6380 - accuracy: 0.3611 - val_loss: 0.8988 - val_accuracy: 0.3956\n","\n","Epoch 00213: val_loss did not improve from 0.72985\n","Epoch 214/500\n"," - 14s - loss: 0.6376 - accuracy: 0.3585 - val_loss: 0.8221 - val_accuracy: 0.3942\n","\n","Epoch 00214: val_loss did not improve from 0.72985\n","Epoch 215/500\n"," - 14s - loss: 0.6364 - accuracy: 0.3628 - val_loss: 0.9187 - val_accuracy: 0.3667\n","\n","Epoch 00215: val_loss did not improve from 0.72985\n","Epoch 216/500\n"," - 14s - loss: 0.6364 - accuracy: 0.3608 - val_loss: 0.9498 - val_accuracy: 0.4059\n","\n","Epoch 00216: val_loss did not improve from 0.72985\n","Epoch 217/500\n"," - 14s - loss: 0.6357 - accuracy: 0.3628 - val_loss: 1.1010 - val_accuracy: 0.3851\n","\n","Epoch 00217: val_loss did not improve from 0.72985\n","Epoch 218/500\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-0332cf160157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     shuffle=False)\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"a01LFE7QEp70","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}