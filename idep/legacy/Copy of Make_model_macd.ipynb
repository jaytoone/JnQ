{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tensorflow2_p36]","language":"python","name":"conda-env-tensorflow2_p36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Copy of Make_model_macd.ipynb","provenance":[{"file_id":"14ngvY1K8mx8-8asieCWdh0eFXYZi-dsU","timestamp":1587199530114},{"file_id":"1WEMU-VCj-p8mZvMxqBpQAdViCsHXpo20","timestamp":1587198572851},{"file_id":"1z4z_KLPzc6RWsxo3X_dHbpByxUAgjoMJ","timestamp":1583754134002}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8s5fopqwFUf9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1587199571735,"user_tz":-540,"elapsed":22785,"user":{"displayName":"JJANGJAE","photoUrl":"","userId":"08178289703395036410"}},"outputId":"fc31a821-2113-4a20-ed7e-6cfbf3cf3594"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2iYLNSeSEp7p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1587201800775,"user_tz":-540,"elapsed":2226093,"user":{"displayName":"JJANGJAE","photoUrl":"","userId":"08178289703395036410"}},"outputId":"8d7f949c-e661-4e5e-8737-36b2534fb748"},"source":["import os\n","# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot\n","import scipy.misc \n","from math import sqrt \n","import itertools\n","from IPython.display import display\n","%tensorflow_version 1.x\n","%matplotlib inline\n","\n","input_data_length = 54\n","model_num = 115\n","num_classes = 3\n","\n","gdrive_path = '/content/gdrive/My Drive/Colab Notebooks/'\n","\n","Made_X = np.load(gdrive_path + 'Made_X/Made_X %s_%s.npy' % (input_data_length, model_num))\n","Made_Y = np.load(gdrive_path + 'Made_X/Made_Y %s_%s.npy' % (input_data_length, model_num)).reshape(-1, 1)\n","\n","\n","#       dataset 분리      #\n","# dataX 구성 : VOLUME, MA, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC, zero\n","# dataX 구성 : VOLUME, EMA1, EMA2, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC \n","Made_X = Made_X[:, :, [-2]]\n","print(Made_X.shape)\n","print(Made_Y.shape)\n","\n","row = Made_X.shape[1]\n","col = Made_X.shape[2]\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, Y_train, Y_val = train_test_split(Made_X, Made_Y, test_size=0.3,\n","                                                   shuffle=False)\n","\n","X_train = X_train.astype('float32').reshape(-1, input_data_length, col, 1)\n","X_val = X_val.astype('float32').reshape(-1, input_data_length, col, 1)\n","print(X_train.shape)\n","print(X_val.shape)\n","\n","from keras.utils import np_utils\n","from keras.preprocessing.image import ImageDataGenerator \n","\n","# Data Class Weight\n","from sklearn.utils import class_weight\n","\n","print(Y_train[:, 0])\n","class_weights = class_weight.compute_class_weight('balanced', \n","                                                  np.unique(Y_train[:, 0]),\n","                                                  Y_train[:, 0])\n","class_weights = dict(enumerate(class_weights))\n","print(class_weights)\n","# quit()\n","\n","Y_train = Y_train.astype('float32')\n","Y_val = Y_val.astype('float32')\n","Y_train = np_utils.to_categorical(Y_train, num_classes)\n","Y_val = np_utils.to_categorical(Y_val, num_classes)\n","print(Y_train.shape)\n","print(Y_val.shape)\n","\n","datagen = ImageDataGenerator( \n","#     rotation_range = 60,\n","#     zoom_range = 0.6,\n","#     shear_range = 0.6,\n","#     horizontal_flip = True,\n","#     width_shift_range=0.6,\n","#     height_shift_range=0.6,\n","    fill_mode = 'nearest'\n","    )\n","\n","testgen = ImageDataGenerator( \n","    )\n","datagen.fit(X_train)\n","batch_size = 128\n","\n","for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n","    for i in range(0, 9): \n","        pyplot.axis('off') \n","        pyplot.subplot(330 + 1 + i) \n","        pyplot.imshow(X_batch[i].reshape(input_data_length, col))\n","    pyplot.axis('off') \n","    pyplot.show() \n","    break\n","    \n","    \n","train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n","val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n","\n","\n","from keras.utils import plot_model\n","import keras.backend as K\n","from keras.models import Model, Sequential\n","import keras.layers as layers\n","from keras.optimizers import Adam, SGD\n","from keras.regularizers import l1, l2\n","from sklearn.metrics import confusion_matrix\n","\n","def FER_Model(input_shape=(row, col, 1)):\n","    # first input model\n","    visible = layers.Input(shape=input_shape, name='input')\n","    \n","    net = layers.Conv2D(64, kernel_size=3, padding='same')(visible)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    shortcut_1 = net\n","\n","    net = layers.Conv2D(128, kernel_size=3, padding='same')(net)\n","    # net = layers.Activation('relu')(net)\n","    net = layers.LeakyReLU()(net)\n","    # net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    shortcut_2 = net\n","\n","#     net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","#     shortcut_3 = net\n","\n","#     net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n","#     # net = layers.Activation('relu')(net)\n","#     net = layers.LeakyReLU()(net)\n","#     net = layers.MaxPool2D(pool_size=2)(net)\n","\n","    net = layers.Flatten()(net)\n","    net = layers.Dense(64)(net)\n","    net = layers.LeakyReLU()(net)\n","    net = layers.Dense(num_classes, activation='softmax')(net)\n","\n","    # create model \n","    model = Model(inputs =visible, outputs = net)\n","    # summary layers\n","    print(model.summary())\n","    \n","    return model\n","\n","model = FER_Model()\n","# from keras.models import load_model\n","# model = load_model(gdrive_path + 'model/rapid_ascending %s_%s_ohlc.hdf5' % (input_data_length, model_num))\n","opt = Adam(lr=0.0001, decay=1e-6)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  \n","    \n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","filepath = gdrive_path + \"model/rapid_ascending %s_%s_macd.hdf5\" % (input_data_length, model_num)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n","                          histogram_freq=0,\n","                          write_graph=True,\n","                          write_images=True)\n","checkpoint3 = EarlyStopping(monitor='val_loss', patience=100)\n","callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n","\n","# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n","\n","# we iterate 200 times over the entire training set\n","num_epochs = 500\n","history = model.fit_generator(train_flow, \n","                    steps_per_epoch=len(X_train) / batch_size, \n","                    epochs=num_epochs,  \n","                    verbose=2,  \n","                    callbacks=callbacks_list,\n","                    class_weight=class_weights,\n","                    validation_data=val_flow,  \n","                    validation_steps=len(X_val) / batch_size,\n","                    shuffle=False)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","(316342, 54, 1)\n","(316342, 1)\n","(221439, 54, 1, 1)\n","(94903, 54, 1, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[0. 0. 0. ... 0. 0. 0.]\n","{0: 0.3396058873056697, 1: 36.46887351778656, 2: 35.727492739593416}\n","(221439, 3)\n","(94903, 3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAADnCAYAAADYZiBGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAANMklEQVR4nO3dS48cVxnG8VPVVd09Mz09F9txbEKwcYxIggRYTogQCyLiJUICWcqGRRZRvkXWWfkzIPEZ+BYghLJIiBTlYptMLjZz6Z6+VHUVi2E55x3lqMrV9dT/tz0a6ZVqnj6nTp1LVJalA6AvbroAAM8GYQc6grADHUHYgY4g7EBHmGG/F98v78X3ma4Xc+e9B+Wd9x7wXAW9+dYH5ZtvfXDus02sP+z95FY9FaFZxFxWmUTeNjPs8xt7lReD5kVF0xWgLnHmf7hm2CfX0sqLQfMIu654GRj22VX/kADtRdh1xYvc22YP4y/xcqcozniuqqJlYNgdHbukOCfsqqJs5W0zw771iLQrisi6rGi28LbZYT/g5U5R5P/xR8uVs7m3zQx7OuG/QlFU0LXLCg172WMYr4h3dl3FInAYP9vvVV4M1gBvZ7qMUZsZ9nhFD6DIWmWFditef8XbZoadxReaGMbrevrKhrfNDPvosX/8j/aKcn7FVR295G+zh/ELZuMVMRuvq/zhzNtmD+N5Z5dE2HXduvqdt81eLgtJDON1/WL/kbfN3gjz3LDyYtA8wq7rxcETb5sZ9lWfI+oUWZsl0G7bceA7O59oROWEXdWni6veNjPsRcpyWUkrwq7q0cx/lJw9jCfskiJ6dlm76am37YKevfJasA4Iu6xXNv/jbTPDnm/Qsysqs6zpElCT24MDb5sZ9lMOnNS0JOyqPl5cd84599tz2sywZ9vMxisqc/+hhGi314efedvsCbohYZfEMF7Wy8baGPukmgErrRSVK56rqkf52U7V2+e02WvjU/4pFJV8Z5f1MB875wLCHhF2TSXPVdW07Hvb7OWyPd7ZJZU8V1V/n/7YOefc789pM8O+vzupox40LeKTqqp/HL7obTPD/sL2YeXFYA1E7GZU9fBw19tmhj2JebdTFMX07KqOjja9bfba+JJ/CkXRYNB0CahJufDf9WCvjS+4JEJRtMEJRLJyfwdt3wiTs+1NUbTlH+qh3dKjwJ59mvm/2aG9ip2tpktATdKjwJ797pUvKy8GzcvHDONV9Y/8bRwl3UHZNq9nqkpjmo0Jug7KN/nOrsq6n9EM+6Kg41eUEXZZvUXglc3TnAk6Rctt1k+o6k8Cw75kGC9p6V9RiZYLHsZPMlZaKVrssetN1fCJ/xQiM+w/33tceTFo3mqHM+hUJSdLf5v1h49njPcU9UacQaeqNw0M++fH+5UXg+Ztbi6aLgE1iWb+Z2uvjc/49KZoPCTssow7Acw0v3rZf7sE2uu5zZOmS0BdUn+kzbCPE3oARdc3jpsuATUp+/6l0GbYfzP+pPJi0LznB8ZuCbRatAicoHtt+LDyYtC8ywnDeFXlIPAo6Ws9lssq2k84NVhVOQwcxj8tzoYEo2rrQcPG8bzpElCTYiMw7H85vOucc+79F6otCM0aRiyqUbUaBs7G/+3xq845597/WbUFoVmbMV9ZVC32Anv2m+OnlReD5g0jLnZUtdwOvLL5XwfXKy8GzduP2QijajkKPUr6gKk5RVtc/yRrteFvs69sXnKiiaJBxJ4HVXlo2Isxwz1FPW5xlbXaCDyWKh4wkaNoEHGUtKrcCHtUlhxRBHQBMzVARxB2oCMIO9ARhB3oCMIOdARhBzqCsAMdQdiBjiDsQEcQdqAjCDvQEYQd6Agz7MXB7bI4uM1OGTF333lQ3n3nAc9V0J13H5R33j3/2ZpbXD/Nzs4Xv11DUWhOwQ5XWbGxK92+sjnfcc4RdjWzKxxeoSoq/G1m2B9ml6quBWtguccIXlVUBJ5U88XicuXFoHn5mBOIVAX37F/O9quuBWsgGftv+kS7hYd9uld1LVgDu+PTpktATeI8cBj/9Qnnxiu6tn3cdAmoSZwFhn1ybBxCjda6tnHUdAmoSXDPXk64TEDR9QFhlxX6zp5MelWXgjVwc/BN0yWgJsGf3tJjFl8o+ungq6ZLQE2iVWjYTyqvBWvgEvezywr+9JaestJK0X7MZkdV8cqfdvuuN9ZeSNqM2QmjqjfNvG1m2HvGNzu0V+KYeFUVzwLDbn2gR3sdF3PnnHNsc9ITzfzzMXbPviTsiv6dDZxzzv264TpQg4X/3dv+zj4zpvbQWh8vrznnCLuiMs+9bXbYT/zjf7TXh9MXmi4BNYki/9oYexhvvOyjvR7O2M2oavrLF71tZtijBWFX9O2M3YyqDl/yf1Yl7B10NBs2XQJqMr8SuFzWrTi+SNF0Nmi6BNQkG4WGPSfsirIZK+hUlWnofvYlw3hJR4RdVZQFzsa7jMXxitITti7LMh6t3bPP2QqpKJ0QdlmhYS8YxktKJ01XgNpcClwb7wom6BQlU/Y8qBqPZ942O+zG0ju0V3/CngdVw37gFteox75nRf0Twq7q5vipt+2Cnp3jixQlE+ZiVP1u/yNvmz0bz6c3SWXCj3gX8c7eQUXCc1V1JfFf7cU7ewdZVwSh3XZ7/ks77Z6dsEtKJryeqeoZ9z/Rs3dQfDhtugTUZFr4dzTSs3fRk8OmK0BNbqX/9bZd0LMzayuJ5yrrVuo/hcju2dN+1bVgHTBik3VUnC2XPe+UQbtnHxB2ScZxw2i3p/8/Xep7h931OeRAEseNyfp6teGcc+7WOW32CroBYQfa5GC1422zw867HdAq/zz9kXPOuT+e02YP45m01VSwgk7Vt8ttb9sFh1dUXQrWQszaeFWfHl/2ttlhh6Ri6j/NBO327XTL28YwHhByMtnwtl0QdtKuKB75f/3Rbvk08K63MmU2XlG06f/1R7vFJ/7MmmHPt/jOrqjc4K43VdadAGbYV0N6dkmsjJSVTAPDnm/yzq6I1zNdif+gmgvCPuB7rCIOnNSVzANvcV0Rdkkl+9ll9YzrGS8Ie9WlYB0Qdl29RWjP3qdnl8RyWVn9iX/7sn2LK2dXAK2STvwHk9gr6NgcpankwapKngTe4lryhUbSasj+J1XxJPCSiIL/CUmnV1lUo6o0djTaPTuTtpIOb/NgVZVT/wUgbHHtoMWtedMloCbFqX8YH5VM1gCdQN8NdARhBzqCsAMdQdiBjiDsQEcQdqAjCDvQEYQd6AjCDnQEYQc6grADHUHYgY4ww34vvl/ei++zU0bMveTt8l7yNs9V0OyrG+XsqxvnPltzi+v0T7+qpyIAtTgpls455867zc8M+9OXOZdKUlk0XQFqcmpsWTfDPruxrLwYrAHOMJB1UgTe4rp/9bjyYrAGIs6NV3VinP9uhr2f+A+cR3tFfS4EUPWk2PK2mWGPI4Z7iiJ6dlnTwn9nmxn20wU9gCJ69m4yw749NK6ERHsNuLFTVT8KvOtt1CfsiqIBPbuqYZR528ywbyZ8epPU50YYVZuxv4O2h/EpPbuiMuVeL1XBPftO6r83Cu1VDunZVfWdf3WkGfbXRp9VXgyaV/bp2VVdTwLvZ7/dP6i8GDSPK5t1jSL/qM0Oe+If/6O9VgOOMVA1iPyRNsOeOVbQKSoIu6xe5H+2Ztg/XI6dc849X209aBg9ezeZYT/Id59VHXiG8gFr47vIDPtfH7/hnHPuz7efSS14RoqUsKtalGfzbN/7pJpPHl6tox40rGAyXlZsHCtpb3H9jjXUikpOG5MVO/+ozf6NZzJe0qrPMF5V7s52vZ33td0OO/8TkoyTi9By8/JsBd33fmdPT/hEo2jFdnZZR8VZz753TpsZ9lWfcbyifJPnqurg/7/kN85pM8M+fMI4XhE9u66H2SXnnHNvnNNmny57TA+gaLXFJRGqnqxG3jYz7L155bVgDZSbHBGuarIaetvssGf07IqSoX/PM9ptXgRucY1WhF3RcIOzBVUtysAtrkXCBJ2iEUeEd5L96Y3dUZL2hpwtqOp0FXjXW0nWJe32Cbuqwgit/c7OFxpJ2ymfWVRNjEUUdtiZn5M06vHOruokC/z0xr5nTaOEsKt6utj0ttkHTm7x0q5oxGopWYfz8/a7nbEn6DjkQNJOjwk6VSezwHf2bLvyWrAGdnvTpktATbJl4KIaPr1p2jJu+kS75YvAsHNSjaatiOWyqspF4IGTEfslJFl3eKPdojww7Olp5bVgDezG9Oyy8sAVdCmHV0gaslpKVmzcxWqGffwFPYCiYcRkjKo4C+zZB9/wiUbRwLjpE+1mzbPZE3QLZugUpY7VUqp6y9Bdb3NmbRWlEWFXZc292otqJgzjFVn3gaHdEuML2gWLavinUNTjnV1WMvN/abF79h88V3kxAOqTngaGfXqTnTBAmyTzwLAvtpnIAdokPfZ/QbPDvss7O9Amvbn/th8z7MudymsBUKN4GRh2rvYF2iXK/EdC22EfcZY0oML+zr5jbKFBa2Xl2VCPa9r1xKf+Va9m2C9dmlReDJpXOEZsqqKlv4M2w767wSmkilYlczGyssBPby9sHVZeC4D6lHP/nQBm2O+OP6+6FqwBhvG6yllg2P8w+qjyYgDUp5j6d6pGJe9vQCew1xHoCMIOdARhBzqCsAMdQdiBjiDsQEf8D2qNKo1crk8+AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (InputLayer)           (None, 54, 1, 1)          0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 54, 1, 64)         640       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 54, 1, 64)         0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 54, 1, 128)        73856     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 54, 1, 128)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6912)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                442432    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 517,123\n","Trainable params: 517,123\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/500\n"," - 17s - loss: 0.9187 - accuracy: 0.2641 - val_loss: 1.0475 - val_accuracy: 0.2776\n","\n","Epoch 00001: val_loss improved from inf to 1.04747, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/500\n"," - 10s - loss: 0.8415 - accuracy: 0.3010 - val_loss: 1.2449 - val_accuracy: 0.2394\n","\n","Epoch 00002: val_loss did not improve from 1.04747\n","Epoch 3/500\n"," - 10s - loss: 0.8227 - accuracy: 0.2935 - val_loss: 1.0621 - val_accuracy: 0.3256\n","\n","Epoch 00003: val_loss did not improve from 1.04747\n","Epoch 4/500\n"," - 10s - loss: 0.8153 - accuracy: 0.2830 - val_loss: 1.2211 - val_accuracy: 0.2568\n","\n","Epoch 00004: val_loss did not improve from 1.04747\n","Epoch 5/500\n"," - 10s - loss: 0.8085 - accuracy: 0.2721 - val_loss: 1.0234 - val_accuracy: 0.3539\n","\n","Epoch 00005: val_loss improved from 1.04747 to 1.02341, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 6/500\n"," - 10s - loss: 0.8017 - accuracy: 0.2695 - val_loss: 1.0768 - val_accuracy: 0.2220\n","\n","Epoch 00006: val_loss did not improve from 1.02341\n","Epoch 7/500\n"," - 10s - loss: 0.7958 - accuracy: 0.2581 - val_loss: 1.1576 - val_accuracy: 0.1818\n","\n","Epoch 00007: val_loss did not improve from 1.02341\n","Epoch 8/500\n"," - 11s - loss: 0.7913 - accuracy: 0.2448 - val_loss: 1.0163 - val_accuracy: 0.2738\n","\n","Epoch 00008: val_loss improved from 1.02341 to 1.01625, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 9/500\n"," - 10s - loss: 0.7871 - accuracy: 0.2384 - val_loss: 1.0422 - val_accuracy: 0.2602\n","\n","Epoch 00009: val_loss did not improve from 1.01625\n","Epoch 10/500\n"," - 10s - loss: 0.7833 - accuracy: 0.2367 - val_loss: 1.1267 - val_accuracy: 0.2247\n","\n","Epoch 00010: val_loss did not improve from 1.01625\n","Epoch 11/500\n"," - 10s - loss: 0.7793 - accuracy: 0.2267 - val_loss: 1.0825 - val_accuracy: 0.2700\n","\n","Epoch 00011: val_loss did not improve from 1.01625\n","Epoch 12/500\n"," - 10s - loss: 0.7754 - accuracy: 0.2296 - val_loss: 1.1196 - val_accuracy: 0.1612\n","\n","Epoch 00012: val_loss did not improve from 1.01625\n","Epoch 13/500\n"," - 10s - loss: 0.7727 - accuracy: 0.2247 - val_loss: 1.1530 - val_accuracy: 0.1744\n","\n","Epoch 00013: val_loss did not improve from 1.01625\n","Epoch 14/500\n"," - 10s - loss: 0.7689 - accuracy: 0.2214 - val_loss: 1.0348 - val_accuracy: 0.2428\n","\n","Epoch 00014: val_loss did not improve from 1.01625\n","Epoch 15/500\n"," - 11s - loss: 0.7679 - accuracy: 0.2238 - val_loss: 1.1653 - val_accuracy: 0.1479\n","\n","Epoch 00015: val_loss did not improve from 1.01625\n","Epoch 16/500\n"," - 10s - loss: 0.7663 - accuracy: 0.2152 - val_loss: 1.1059 - val_accuracy: 0.1838\n","\n","Epoch 00016: val_loss did not improve from 1.01625\n","Epoch 17/500\n"," - 10s - loss: 0.7635 - accuracy: 0.2102 - val_loss: 1.1548 - val_accuracy: 0.1796\n","\n","Epoch 00017: val_loss did not improve from 1.01625\n","Epoch 18/500\n"," - 10s - loss: 0.7634 - accuracy: 0.2066 - val_loss: 1.0110 - val_accuracy: 0.2733\n","\n","Epoch 00018: val_loss improved from 1.01625 to 1.01102, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 19/500\n"," - 10s - loss: 0.7605 - accuracy: 0.2044 - val_loss: 1.0690 - val_accuracy: 0.2218\n","\n","Epoch 00019: val_loss did not improve from 1.01102\n","Epoch 20/500\n"," - 10s - loss: 0.7600 - accuracy: 0.2100 - val_loss: 1.1469 - val_accuracy: 0.1747\n","\n","Epoch 00020: val_loss did not improve from 1.01102\n","Epoch 21/500\n"," - 10s - loss: 0.7573 - accuracy: 0.2011 - val_loss: 1.1079 - val_accuracy: 0.1846\n","\n","Epoch 00021: val_loss did not improve from 1.01102\n","Epoch 22/500\n"," - 10s - loss: 0.7570 - accuracy: 0.2043 - val_loss: 1.0278 - val_accuracy: 0.1794\n","\n","Epoch 00022: val_loss did not improve from 1.01102\n","Epoch 23/500\n"," - 10s - loss: 0.7550 - accuracy: 0.2002 - val_loss: 1.0990 - val_accuracy: 0.1964\n","\n","Epoch 00023: val_loss did not improve from 1.01102\n","Epoch 24/500\n"," - 10s - loss: 0.7543 - accuracy: 0.2033 - val_loss: 1.0441 - val_accuracy: 0.1965\n","\n","Epoch 00024: val_loss did not improve from 1.01102\n","Epoch 25/500\n"," - 10s - loss: 0.7506 - accuracy: 0.2092 - val_loss: 1.2040 - val_accuracy: 0.1591\n","\n","Epoch 00025: val_loss did not improve from 1.01102\n","Epoch 26/500\n"," - 10s - loss: 0.7503 - accuracy: 0.2050 - val_loss: 1.0548 - val_accuracy: 0.2059\n","\n","Epoch 00026: val_loss did not improve from 1.01102\n","Epoch 27/500\n"," - 10s - loss: 0.7496 - accuracy: 0.2072 - val_loss: 1.0394 - val_accuracy: 0.1943\n","\n","Epoch 00027: val_loss did not improve from 1.01102\n","Epoch 28/500\n"," - 10s - loss: 0.7481 - accuracy: 0.2080 - val_loss: 1.0574 - val_accuracy: 0.1709\n","\n","Epoch 00028: val_loss did not improve from 1.01102\n","Epoch 29/500\n"," - 10s - loss: 0.7484 - accuracy: 0.2080 - val_loss: 1.1217 - val_accuracy: 0.1257\n","\n","Epoch 00029: val_loss did not improve from 1.01102\n","Epoch 30/500\n"," - 10s - loss: 0.7458 - accuracy: 0.2047 - val_loss: 1.0638 - val_accuracy: 0.2061\n","\n","Epoch 00030: val_loss did not improve from 1.01102\n","Epoch 31/500\n"," - 10s - loss: 0.7455 - accuracy: 0.2089 - val_loss: 1.0206 - val_accuracy: 0.2046\n","\n","Epoch 00031: val_loss did not improve from 1.01102\n","Epoch 32/500\n"," - 10s - loss: 0.7451 - accuracy: 0.2026 - val_loss: 0.9898 - val_accuracy: 0.2249\n","\n","Epoch 00032: val_loss improved from 1.01102 to 0.98975, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 33/500\n"," - 10s - loss: 0.7450 - accuracy: 0.2040 - val_loss: 1.1218 - val_accuracy: 0.2238\n","\n","Epoch 00033: val_loss did not improve from 0.98975\n","Epoch 34/500\n"," - 10s - loss: 0.7431 - accuracy: 0.2038 - val_loss: 1.1696 - val_accuracy: 0.1585\n","\n","Epoch 00034: val_loss did not improve from 0.98975\n","Epoch 35/500\n"," - 10s - loss: 0.7434 - accuracy: 0.2046 - val_loss: 1.0288 - val_accuracy: 0.1877\n","\n","Epoch 00035: val_loss did not improve from 0.98975\n","Epoch 36/500\n"," - 10s - loss: 0.7409 - accuracy: 0.2067 - val_loss: 1.0885 - val_accuracy: 0.2230\n","\n","Epoch 00036: val_loss did not improve from 0.98975\n","Epoch 37/500\n"," - 10s - loss: 0.7421 - accuracy: 0.2092 - val_loss: 1.0750 - val_accuracy: 0.2179\n","\n","Epoch 00037: val_loss did not improve from 0.98975\n","Epoch 38/500\n"," - 11s - loss: 0.7404 - accuracy: 0.2157 - val_loss: 1.1417 - val_accuracy: 0.1472\n","\n","Epoch 00038: val_loss did not improve from 0.98975\n","Epoch 39/500\n"," - 10s - loss: 0.7394 - accuracy: 0.2092 - val_loss: 1.0579 - val_accuracy: 0.2175\n","\n","Epoch 00039: val_loss did not improve from 0.98975\n","Epoch 40/500\n"," - 10s - loss: 0.7384 - accuracy: 0.2109 - val_loss: 0.9928 - val_accuracy: 0.2320\n","\n","Epoch 00040: val_loss did not improve from 0.98975\n","Epoch 41/500\n"," - 11s - loss: 0.7379 - accuracy: 0.2105 - val_loss: 1.0715 - val_accuracy: 0.2188\n","\n","Epoch 00041: val_loss did not improve from 0.98975\n","Epoch 42/500\n"," - 10s - loss: 0.7381 - accuracy: 0.2138 - val_loss: 1.1626 - val_accuracy: 0.1409\n","\n","Epoch 00042: val_loss did not improve from 0.98975\n","Epoch 43/500\n"," - 10s - loss: 0.7377 - accuracy: 0.2157 - val_loss: 1.0401 - val_accuracy: 0.2093\n","\n","Epoch 00043: val_loss did not improve from 0.98975\n","Epoch 44/500\n"," - 10s - loss: 0.7370 - accuracy: 0.2142 - val_loss: 1.0283 - val_accuracy: 0.1862\n","\n","Epoch 00044: val_loss did not improve from 0.98975\n","Epoch 45/500\n"," - 10s - loss: 0.7355 - accuracy: 0.2143 - val_loss: 1.0723 - val_accuracy: 0.2194\n","\n","Epoch 00045: val_loss did not improve from 0.98975\n","Epoch 46/500\n"," - 11s - loss: 0.7350 - accuracy: 0.2181 - val_loss: 1.0463 - val_accuracy: 0.2056\n","\n","Epoch 00046: val_loss did not improve from 0.98975\n","Epoch 47/500\n"," - 10s - loss: 0.7347 - accuracy: 0.2165 - val_loss: 1.0507 - val_accuracy: 0.2303\n","\n","Epoch 00047: val_loss did not improve from 0.98975\n","Epoch 48/500\n"," - 10s - loss: 0.7338 - accuracy: 0.2166 - val_loss: 1.1507 - val_accuracy: 0.1865\n","\n","Epoch 00048: val_loss did not improve from 0.98975\n","Epoch 49/500\n"," - 10s - loss: 0.7337 - accuracy: 0.2139 - val_loss: 0.9254 - val_accuracy: 0.2600\n","\n","Epoch 00049: val_loss improved from 0.98975 to 0.92544, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 50/500\n"," - 10s - loss: 0.7328 - accuracy: 0.2173 - val_loss: 1.0566 - val_accuracy: 0.1639\n","\n","Epoch 00050: val_loss did not improve from 0.92544\n","Epoch 51/500\n"," - 10s - loss: 0.7316 - accuracy: 0.2144 - val_loss: 1.0281 - val_accuracy: 0.2552\n","\n","Epoch 00051: val_loss did not improve from 0.92544\n","Epoch 52/500\n"," - 10s - loss: 0.7331 - accuracy: 0.2189 - val_loss: 1.0128 - val_accuracy: 0.1953\n","\n","Epoch 00052: val_loss did not improve from 0.92544\n","Epoch 53/500\n"," - 10s - loss: 0.7308 - accuracy: 0.2200 - val_loss: 1.0636 - val_accuracy: 0.1829\n","\n","Epoch 00053: val_loss did not improve from 0.92544\n","Epoch 54/500\n"," - 10s - loss: 0.7306 - accuracy: 0.2178 - val_loss: 1.0076 - val_accuracy: 0.2464\n","\n","Epoch 00054: val_loss did not improve from 0.92544\n","Epoch 55/500\n"," - 10s - loss: 0.7296 - accuracy: 0.2236 - val_loss: 1.0185 - val_accuracy: 0.2111\n","\n","Epoch 00055: val_loss did not improve from 0.92544\n","Epoch 56/500\n"," - 10s - loss: 0.7301 - accuracy: 0.2200 - val_loss: 1.1157 - val_accuracy: 0.1974\n","\n","Epoch 00056: val_loss did not improve from 0.92544\n","Epoch 57/500\n"," - 10s - loss: 0.7283 - accuracy: 0.2220 - val_loss: 1.1590 - val_accuracy: 0.1412\n","\n","Epoch 00057: val_loss did not improve from 0.92544\n","Epoch 58/500\n"," - 10s - loss: 0.7284 - accuracy: 0.2191 - val_loss: 0.9911 - val_accuracy: 0.2493\n","\n","Epoch 00058: val_loss did not improve from 0.92544\n","Epoch 59/500\n"," - 10s - loss: 0.7272 - accuracy: 0.2274 - val_loss: 1.0287 - val_accuracy: 0.2062\n","\n","Epoch 00059: val_loss did not improve from 0.92544\n","Epoch 60/500\n"," - 10s - loss: 0.7261 - accuracy: 0.2243 - val_loss: 1.0937 - val_accuracy: 0.2440\n","\n","Epoch 00060: val_loss did not improve from 0.92544\n","Epoch 61/500\n"," - 10s - loss: 0.7275 - accuracy: 0.2245 - val_loss: 1.1773 - val_accuracy: 0.1622\n","\n","Epoch 00061: val_loss did not improve from 0.92544\n","Epoch 62/500\n"," - 10s - loss: 0.7263 - accuracy: 0.2223 - val_loss: 1.0593 - val_accuracy: 0.2612\n","\n","Epoch 00062: val_loss did not improve from 0.92544\n","Epoch 63/500\n"," - 10s - loss: 0.7245 - accuracy: 0.2251 - val_loss: 1.0072 - val_accuracy: 0.2346\n","\n","Epoch 00063: val_loss did not improve from 0.92544\n","Epoch 64/500\n"," - 10s - loss: 0.7245 - accuracy: 0.2233 - val_loss: 1.0641 - val_accuracy: 0.2096\n","\n","Epoch 00064: val_loss did not improve from 0.92544\n","Epoch 65/500\n"," - 10s - loss: 0.7245 - accuracy: 0.2239 - val_loss: 1.0115 - val_accuracy: 0.2467\n","\n","Epoch 00065: val_loss did not improve from 0.92544\n","Epoch 66/500\n"," - 10s - loss: 0.7232 - accuracy: 0.2257 - val_loss: 1.0087 - val_accuracy: 0.2648\n","\n","Epoch 00066: val_loss did not improve from 0.92544\n","Epoch 67/500\n"," - 10s - loss: 0.7231 - accuracy: 0.2302 - val_loss: 1.0420 - val_accuracy: 0.1962\n","\n","Epoch 00067: val_loss did not improve from 0.92544\n","Epoch 68/500\n"," - 10s - loss: 0.7229 - accuracy: 0.2323 - val_loss: 1.0259 - val_accuracy: 0.2071\n","\n","Epoch 00068: val_loss did not improve from 0.92544\n","Epoch 69/500\n"," - 10s - loss: 0.7224 - accuracy: 0.2295 - val_loss: 1.0301 - val_accuracy: 0.2392\n","\n","Epoch 00069: val_loss did not improve from 0.92544\n","Epoch 70/500\n"," - 10s - loss: 0.7219 - accuracy: 0.2314 - val_loss: 1.0567 - val_accuracy: 0.2158\n","\n","Epoch 00070: val_loss did not improve from 0.92544\n","Epoch 71/500\n"," - 10s - loss: 0.7220 - accuracy: 0.2294 - val_loss: 1.0961 - val_accuracy: 0.2080\n","\n","Epoch 00071: val_loss did not improve from 0.92544\n","Epoch 72/500\n"," - 10s - loss: 0.7204 - accuracy: 0.2274 - val_loss: 0.9967 - val_accuracy: 0.2876\n","\n","Epoch 00072: val_loss did not improve from 0.92544\n","Epoch 73/500\n"," - 10s - loss: 0.7205 - accuracy: 0.2315 - val_loss: 1.2068 - val_accuracy: 0.1976\n","\n","Epoch 00073: val_loss did not improve from 0.92544\n","Epoch 74/500\n"," - 10s - loss: 0.7191 - accuracy: 0.2359 - val_loss: 1.0810 - val_accuracy: 0.1749\n","\n","Epoch 00074: val_loss did not improve from 0.92544\n","Epoch 75/500\n"," - 11s - loss: 0.7193 - accuracy: 0.2312 - val_loss: 0.9584 - val_accuracy: 0.2591\n","\n","Epoch 00075: val_loss did not improve from 0.92544\n","Epoch 76/500\n"," - 11s - loss: 0.7174 - accuracy: 0.2357 - val_loss: 1.0072 - val_accuracy: 0.2309\n","\n","Epoch 00076: val_loss did not improve from 0.92544\n","Epoch 77/500\n"," - 10s - loss: 0.7175 - accuracy: 0.2366 - val_loss: 1.1455 - val_accuracy: 0.1856\n","\n","Epoch 00077: val_loss did not improve from 0.92544\n","Epoch 78/500\n"," - 10s - loss: 0.7174 - accuracy: 0.2367 - val_loss: 0.9992 - val_accuracy: 0.2384\n","\n","Epoch 00078: val_loss did not improve from 0.92544\n","Epoch 79/500\n"," - 10s - loss: 0.7159 - accuracy: 0.2340 - val_loss: 1.0481 - val_accuracy: 0.2395\n","\n","Epoch 00079: val_loss did not improve from 0.92544\n","Epoch 80/500\n"," - 10s - loss: 0.7161 - accuracy: 0.2372 - val_loss: 1.0686 - val_accuracy: 0.2481\n","\n","Epoch 00080: val_loss did not improve from 0.92544\n","Epoch 81/500\n"," - 10s - loss: 0.7151 - accuracy: 0.2385 - val_loss: 1.1225 - val_accuracy: 0.2006\n","\n","Epoch 00081: val_loss did not improve from 0.92544\n","Epoch 82/500\n"," - 10s - loss: 0.7154 - accuracy: 0.2350 - val_loss: 1.0628 - val_accuracy: 0.2357\n","\n","Epoch 00082: val_loss did not improve from 0.92544\n","Epoch 83/500\n"," - 10s - loss: 0.7147 - accuracy: 0.2397 - val_loss: 1.1387 - val_accuracy: 0.1862\n","\n","Epoch 00083: val_loss did not improve from 0.92544\n","Epoch 84/500\n"," - 10s - loss: 0.7145 - accuracy: 0.2406 - val_loss: 1.0838 - val_accuracy: 0.1831\n","\n","Epoch 00084: val_loss did not improve from 0.92544\n","Epoch 85/500\n"," - 10s - loss: 0.7132 - accuracy: 0.2334 - val_loss: 0.9761 - val_accuracy: 0.3443\n","\n","Epoch 00085: val_loss did not improve from 0.92544\n","Epoch 86/500\n"," - 10s - loss: 0.7133 - accuracy: 0.2448 - val_loss: 0.9817 - val_accuracy: 0.2792\n","\n","Epoch 00086: val_loss did not improve from 0.92544\n","Epoch 87/500\n"," - 10s - loss: 0.7122 - accuracy: 0.2404 - val_loss: 0.9523 - val_accuracy: 0.3028\n","\n","Epoch 00087: val_loss did not improve from 0.92544\n","Epoch 88/500\n"," - 11s - loss: 0.7123 - accuracy: 0.2442 - val_loss: 1.0498 - val_accuracy: 0.2876\n","\n","Epoch 00088: val_loss did not improve from 0.92544\n","Epoch 89/500\n"," - 10s - loss: 0.7125 - accuracy: 0.2460 - val_loss: 1.0186 - val_accuracy: 0.2378\n","\n","Epoch 00089: val_loss did not improve from 0.92544\n","Epoch 90/500\n"," - 11s - loss: 0.7109 - accuracy: 0.2468 - val_loss: 0.9901 - val_accuracy: 0.2343\n","\n","Epoch 00090: val_loss did not improve from 0.92544\n","Epoch 91/500\n"," - 10s - loss: 0.7112 - accuracy: 0.2461 - val_loss: 1.1210 - val_accuracy: 0.2217\n","\n","Epoch 00091: val_loss did not improve from 0.92544\n","Epoch 92/500\n"," - 10s - loss: 0.7099 - accuracy: 0.2476 - val_loss: 0.9908 - val_accuracy: 0.2429\n","\n","Epoch 00092: val_loss did not improve from 0.92544\n","Epoch 93/500\n"," - 10s - loss: 0.7101 - accuracy: 0.2432 - val_loss: 1.0085 - val_accuracy: 0.2249\n","\n","Epoch 00093: val_loss did not improve from 0.92544\n","Epoch 94/500\n"," - 10s - loss: 0.7090 - accuracy: 0.2473 - val_loss: 1.1822 - val_accuracy: 0.2118\n","\n","Epoch 00094: val_loss did not improve from 0.92544\n","Epoch 95/500\n"," - 10s - loss: 0.7094 - accuracy: 0.2491 - val_loss: 0.9712 - val_accuracy: 0.2426\n","\n","Epoch 00095: val_loss did not improve from 0.92544\n","Epoch 96/500\n"," - 11s - loss: 0.7089 - accuracy: 0.2500 - val_loss: 0.9957 - val_accuracy: 0.2632\n","\n","Epoch 00096: val_loss did not improve from 0.92544\n","Epoch 97/500\n"," - 10s - loss: 0.7076 - accuracy: 0.2545 - val_loss: 1.1120 - val_accuracy: 0.1930\n","\n","Epoch 00097: val_loss did not improve from 0.92544\n","Epoch 98/500\n"," - 10s - loss: 0.7065 - accuracy: 0.2494 - val_loss: 1.0067 - val_accuracy: 0.2814\n","\n","Epoch 00098: val_loss did not improve from 0.92544\n","Epoch 99/500\n"," - 10s - loss: 0.7068 - accuracy: 0.2544 - val_loss: 1.0573 - val_accuracy: 0.2273\n","\n","Epoch 00099: val_loss did not improve from 0.92544\n","Epoch 100/500\n"," - 10s - loss: 0.7052 - accuracy: 0.2507 - val_loss: 0.8977 - val_accuracy: 0.3396\n","\n","Epoch 00100: val_loss improved from 0.92544 to 0.89769, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 101/500\n"," - 10s - loss: 0.7045 - accuracy: 0.2576 - val_loss: 1.0493 - val_accuracy: 0.2587\n","\n","Epoch 00101: val_loss did not improve from 0.89769\n","Epoch 102/500\n"," - 10s - loss: 0.7056 - accuracy: 0.2550 - val_loss: 1.0254 - val_accuracy: 0.2493\n","\n","Epoch 00102: val_loss did not improve from 0.89769\n","Epoch 103/500\n"," - 10s - loss: 0.7034 - accuracy: 0.2565 - val_loss: 0.9895 - val_accuracy: 0.2501\n","\n","Epoch 00103: val_loss did not improve from 0.89769\n","Epoch 104/500\n"," - 10s - loss: 0.7048 - accuracy: 0.2550 - val_loss: 0.9671 - val_accuracy: 0.2940\n","\n","Epoch 00104: val_loss did not improve from 0.89769\n","Epoch 105/500\n"," - 10s - loss: 0.7035 - accuracy: 0.2569 - val_loss: 0.9646 - val_accuracy: 0.2550\n","\n","Epoch 00105: val_loss did not improve from 0.89769\n","Epoch 106/500\n"," - 11s - loss: 0.7024 - accuracy: 0.2625 - val_loss: 1.0211 - val_accuracy: 0.2098\n","\n","Epoch 00106: val_loss did not improve from 0.89769\n","Epoch 107/500\n"," - 10s - loss: 0.7028 - accuracy: 0.2558 - val_loss: 0.9956 - val_accuracy: 0.2447\n","\n","Epoch 00107: val_loss did not improve from 0.89769\n","Epoch 108/500\n"," - 10s - loss: 0.7016 - accuracy: 0.2574 - val_loss: 0.9804 - val_accuracy: 0.2462\n","\n","Epoch 00108: val_loss did not improve from 0.89769\n","Epoch 109/500\n"," - 10s - loss: 0.7011 - accuracy: 0.2581 - val_loss: 1.0078 - val_accuracy: 0.2592\n","\n","Epoch 00109: val_loss did not improve from 0.89769\n","Epoch 110/500\n"," - 10s - loss: 0.7008 - accuracy: 0.2618 - val_loss: 0.9159 - val_accuracy: 0.2629\n","\n","Epoch 00110: val_loss did not improve from 0.89769\n","Epoch 111/500\n"," - 10s - loss: 0.7001 - accuracy: 0.2618 - val_loss: 1.1075 - val_accuracy: 0.2406\n","\n","Epoch 00111: val_loss did not improve from 0.89769\n","Epoch 112/500\n"," - 10s - loss: 0.6997 - accuracy: 0.2634 - val_loss: 0.8865 - val_accuracy: 0.3167\n","\n","Epoch 00112: val_loss improved from 0.89769 to 0.88651, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 113/500\n"," - 10s - loss: 0.6983 - accuracy: 0.2637 - val_loss: 0.9968 - val_accuracy: 0.2890\n","\n","Epoch 00113: val_loss did not improve from 0.88651\n","Epoch 114/500\n"," - 10s - loss: 0.6992 - accuracy: 0.2674 - val_loss: 1.0728 - val_accuracy: 0.2256\n","\n","Epoch 00114: val_loss did not improve from 0.88651\n","Epoch 115/500\n"," - 10s - loss: 0.6973 - accuracy: 0.2634 - val_loss: 1.0301 - val_accuracy: 0.2745\n","\n","Epoch 00115: val_loss did not improve from 0.88651\n","Epoch 116/500\n"," - 10s - loss: 0.6972 - accuracy: 0.2653 - val_loss: 0.8888 - val_accuracy: 0.2826\n","\n","Epoch 00116: val_loss did not improve from 0.88651\n","Epoch 117/500\n"," - 10s - loss: 0.6989 - accuracy: 0.2663 - val_loss: 0.9648 - val_accuracy: 0.2705\n","\n","Epoch 00117: val_loss did not improve from 0.88651\n","Epoch 118/500\n"," - 10s - loss: 0.6958 - accuracy: 0.2704 - val_loss: 1.0115 - val_accuracy: 0.3216\n","\n","Epoch 00118: val_loss did not improve from 0.88651\n","Epoch 119/500\n"," - 10s - loss: 0.6964 - accuracy: 0.2692 - val_loss: 1.0971 - val_accuracy: 0.2213\n","\n","Epoch 00119: val_loss did not improve from 0.88651\n","Epoch 120/500\n"," - 10s - loss: 0.6958 - accuracy: 0.2681 - val_loss: 0.9442 - val_accuracy: 0.3144\n","\n","Epoch 00120: val_loss did not improve from 0.88651\n","Epoch 121/500\n"," - 10s - loss: 0.6952 - accuracy: 0.2698 - val_loss: 1.0212 - val_accuracy: 0.2764\n","\n","Epoch 00121: val_loss did not improve from 0.88651\n","Epoch 122/500\n"," - 10s - loss: 0.6946 - accuracy: 0.2706 - val_loss: 0.9546 - val_accuracy: 0.3065\n","\n","Epoch 00122: val_loss did not improve from 0.88651\n","Epoch 123/500\n"," - 10s - loss: 0.6931 - accuracy: 0.2750 - val_loss: 1.0930 - val_accuracy: 0.2043\n","\n","Epoch 00123: val_loss did not improve from 0.88651\n","Epoch 124/500\n"," - 10s - loss: 0.6937 - accuracy: 0.2697 - val_loss: 1.1356 - val_accuracy: 0.2748\n","\n","Epoch 00124: val_loss did not improve from 0.88651\n","Epoch 125/500\n"," - 10s - loss: 0.6934 - accuracy: 0.2719 - val_loss: 0.8891 - val_accuracy: 0.3319\n","\n","Epoch 00125: val_loss did not improve from 0.88651\n","Epoch 126/500\n"," - 10s - loss: 0.6926 - accuracy: 0.2716 - val_loss: 0.9895 - val_accuracy: 0.2775\n","\n","Epoch 00126: val_loss did not improve from 0.88651\n","Epoch 127/500\n"," - 10s - loss: 0.6923 - accuracy: 0.2734 - val_loss: 1.0970 - val_accuracy: 0.3007\n","\n","Epoch 00127: val_loss did not improve from 0.88651\n","Epoch 128/500\n"," - 10s - loss: 0.6910 - accuracy: 0.2754 - val_loss: 0.9775 - val_accuracy: 0.3104\n","\n","Epoch 00128: val_loss did not improve from 0.88651\n","Epoch 129/500\n"," - 10s - loss: 0.6905 - accuracy: 0.2802 - val_loss: 0.9140 - val_accuracy: 0.2876\n","\n","Epoch 00129: val_loss did not improve from 0.88651\n","Epoch 130/500\n"," - 10s - loss: 0.6905 - accuracy: 0.2781 - val_loss: 1.0563 - val_accuracy: 0.2748\n","\n","Epoch 00130: val_loss did not improve from 0.88651\n","Epoch 131/500\n"," - 10s - loss: 0.6890 - accuracy: 0.2823 - val_loss: 0.9248 - val_accuracy: 0.2482\n","\n","Epoch 00131: val_loss did not improve from 0.88651\n","Epoch 132/500\n"," - 10s - loss: 0.6885 - accuracy: 0.2820 - val_loss: 1.1030 - val_accuracy: 0.2514\n","\n","Epoch 00132: val_loss did not improve from 0.88651\n","Epoch 133/500\n"," - 10s - loss: 0.6883 - accuracy: 0.2806 - val_loss: 1.0369 - val_accuracy: 0.2675\n","\n","Epoch 00133: val_loss did not improve from 0.88651\n","Epoch 134/500\n"," - 10s - loss: 0.6882 - accuracy: 0.2807 - val_loss: 0.9953 - val_accuracy: 0.2936\n","\n","Epoch 00134: val_loss did not improve from 0.88651\n","Epoch 135/500\n"," - 10s - loss: 0.6876 - accuracy: 0.2827 - val_loss: 1.0985 - val_accuracy: 0.3066\n","\n","Epoch 00135: val_loss did not improve from 0.88651\n","Epoch 136/500\n"," - 11s - loss: 0.6866 - accuracy: 0.2861 - val_loss: 1.0705 - val_accuracy: 0.2831\n","\n","Epoch 00136: val_loss did not improve from 0.88651\n","Epoch 137/500\n"," - 10s - loss: 0.6857 - accuracy: 0.2847 - val_loss: 0.9615 - val_accuracy: 0.3078\n","\n","Epoch 00137: val_loss did not improve from 0.88651\n","Epoch 138/500\n"," - 10s - loss: 0.6865 - accuracy: 0.2807 - val_loss: 0.8941 - val_accuracy: 0.3369\n","\n","Epoch 00138: val_loss did not improve from 0.88651\n","Epoch 139/500\n"," - 10s - loss: 0.6847 - accuracy: 0.2835 - val_loss: 0.9305 - val_accuracy: 0.2987\n","\n","Epoch 00139: val_loss did not improve from 0.88651\n","Epoch 140/500\n"," - 10s - loss: 0.6853 - accuracy: 0.2868 - val_loss: 1.0111 - val_accuracy: 0.2512\n","\n","Epoch 00140: val_loss did not improve from 0.88651\n","Epoch 141/500\n"," - 10s - loss: 0.6835 - accuracy: 0.2865 - val_loss: 0.9237 - val_accuracy: 0.3490\n","\n","Epoch 00141: val_loss did not improve from 0.88651\n","Epoch 142/500\n"," - 10s - loss: 0.6836 - accuracy: 0.2881 - val_loss: 0.9774 - val_accuracy: 0.3534\n","\n","Epoch 00142: val_loss did not improve from 0.88651\n","Epoch 143/500\n"," - 10s - loss: 0.6834 - accuracy: 0.2885 - val_loss: 1.0345 - val_accuracy: 0.2839\n","\n","Epoch 00143: val_loss did not improve from 0.88651\n","Epoch 144/500\n"," - 10s - loss: 0.6829 - accuracy: 0.2903 - val_loss: 0.9876 - val_accuracy: 0.2608\n","\n","Epoch 00144: val_loss did not improve from 0.88651\n","Epoch 145/500\n"," - 10s - loss: 0.6822 - accuracy: 0.2885 - val_loss: 0.9907 - val_accuracy: 0.2928\n","\n","Epoch 00145: val_loss did not improve from 0.88651\n","Epoch 146/500\n"," - 10s - loss: 0.6816 - accuracy: 0.2897 - val_loss: 0.9729 - val_accuracy: 0.2737\n","\n","Epoch 00146: val_loss did not improve from 0.88651\n","Epoch 147/500\n"," - 10s - loss: 0.6811 - accuracy: 0.2938 - val_loss: 1.1560 - val_accuracy: 0.2155\n","\n","Epoch 00147: val_loss did not improve from 0.88651\n","Epoch 148/500\n"," - 10s - loss: 0.6799 - accuracy: 0.2918 - val_loss: 0.9781 - val_accuracy: 0.3061\n","\n","Epoch 00148: val_loss did not improve from 0.88651\n","Epoch 149/500\n"," - 10s - loss: 0.6797 - accuracy: 0.2948 - val_loss: 1.0987 - val_accuracy: 0.2665\n","\n","Epoch 00149: val_loss did not improve from 0.88651\n","Epoch 150/500\n"," - 10s - loss: 0.6797 - accuracy: 0.2914 - val_loss: 1.0176 - val_accuracy: 0.2781\n","\n","Epoch 00150: val_loss did not improve from 0.88651\n","Epoch 151/500\n"," - 10s - loss: 0.6791 - accuracy: 0.2930 - val_loss: 0.9044 - val_accuracy: 0.3947\n","\n","Epoch 00151: val_loss did not improve from 0.88651\n","Epoch 152/500\n"," - 10s - loss: 0.6782 - accuracy: 0.2992 - val_loss: 0.9754 - val_accuracy: 0.2816\n","\n","Epoch 00152: val_loss did not improve from 0.88651\n","Epoch 153/500\n"," - 10s - loss: 0.6782 - accuracy: 0.2973 - val_loss: 0.9894 - val_accuracy: 0.2913\n","\n","Epoch 00153: val_loss did not improve from 0.88651\n","Epoch 154/500\n"," - 10s - loss: 0.6769 - accuracy: 0.2979 - val_loss: 0.9821 - val_accuracy: 0.3408\n","\n","Epoch 00154: val_loss did not improve from 0.88651\n","Epoch 155/500\n"," - 10s - loss: 0.6769 - accuracy: 0.2968 - val_loss: 0.8895 - val_accuracy: 0.3140\n","\n","Epoch 00155: val_loss did not improve from 0.88651\n","Epoch 156/500\n"," - 10s - loss: 0.6765 - accuracy: 0.3008 - val_loss: 0.9785 - val_accuracy: 0.3066\n","\n","Epoch 00156: val_loss did not improve from 0.88651\n","Epoch 157/500\n"," - 10s - loss: 0.6757 - accuracy: 0.3017 - val_loss: 0.9183 - val_accuracy: 0.2467\n","\n","Epoch 00157: val_loss did not improve from 0.88651\n","Epoch 158/500\n"," - 10s - loss: 0.6737 - accuracy: 0.3014 - val_loss: 0.9094 - val_accuracy: 0.3430\n","\n","Epoch 00158: val_loss did not improve from 0.88651\n","Epoch 159/500\n"," - 10s - loss: 0.6745 - accuracy: 0.3036 - val_loss: 0.9607 - val_accuracy: 0.2626\n","\n","Epoch 00159: val_loss did not improve from 0.88651\n","Epoch 160/500\n"," - 10s - loss: 0.6732 - accuracy: 0.3045 - val_loss: 1.0214 - val_accuracy: 0.3006\n","\n","Epoch 00160: val_loss did not improve from 0.88651\n","Epoch 161/500\n"," - 10s - loss: 0.6731 - accuracy: 0.3015 - val_loss: 0.9577 - val_accuracy: 0.3895\n","\n","Epoch 00161: val_loss did not improve from 0.88651\n","Epoch 162/500\n"," - 10s - loss: 0.6725 - accuracy: 0.3076 - val_loss: 0.9791 - val_accuracy: 0.3143\n","\n","Epoch 00162: val_loss did not improve from 0.88651\n","Epoch 163/500\n"," - 10s - loss: 0.6727 - accuracy: 0.3028 - val_loss: 1.0524 - val_accuracy: 0.3034\n","\n","Epoch 00163: val_loss did not improve from 0.88651\n","Epoch 164/500\n"," - 10s - loss: 0.6713 - accuracy: 0.3132 - val_loss: 1.1087 - val_accuracy: 0.2645\n","\n","Epoch 00164: val_loss did not improve from 0.88651\n","Epoch 165/500\n"," - 10s - loss: 0.6718 - accuracy: 0.3056 - val_loss: 0.9153 - val_accuracy: 0.3344\n","\n","Epoch 00165: val_loss did not improve from 0.88651\n","Epoch 166/500\n"," - 11s - loss: 0.6707 - accuracy: 0.3117 - val_loss: 0.9465 - val_accuracy: 0.2835\n","\n","Epoch 00166: val_loss did not improve from 0.88651\n","Epoch 167/500\n"," - 10s - loss: 0.6684 - accuracy: 0.3092 - val_loss: 0.8537 - val_accuracy: 0.3927\n","\n","Epoch 00167: val_loss improved from 0.88651 to 0.85372, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 168/500\n"," - 10s - loss: 0.6687 - accuracy: 0.3117 - val_loss: 0.8941 - val_accuracy: 0.3255\n","\n","Epoch 00168: val_loss did not improve from 0.85372\n","Epoch 169/500\n"," - 10s - loss: 0.6686 - accuracy: 0.3113 - val_loss: 0.8928 - val_accuracy: 0.3562\n","\n","Epoch 00169: val_loss did not improve from 0.85372\n","Epoch 170/500\n"," - 10s - loss: 0.6681 - accuracy: 0.3126 - val_loss: 0.9677 - val_accuracy: 0.3132\n","\n","Epoch 00170: val_loss did not improve from 0.85372\n","Epoch 171/500\n"," - 10s - loss: 0.6673 - accuracy: 0.3146 - val_loss: 1.0433 - val_accuracy: 0.2852\n","\n","Epoch 00171: val_loss did not improve from 0.85372\n","Epoch 172/500\n"," - 10s - loss: 0.6668 - accuracy: 0.3152 - val_loss: 1.0957 - val_accuracy: 0.3302\n","\n","Epoch 00172: val_loss did not improve from 0.85372\n","Epoch 173/500\n"," - 10s - loss: 0.6657 - accuracy: 0.3167 - val_loss: 1.0801 - val_accuracy: 0.3219\n","\n","Epoch 00173: val_loss did not improve from 0.85372\n","Epoch 174/500\n"," - 11s - loss: 0.6645 - accuracy: 0.3170 - val_loss: 1.1185 - val_accuracy: 0.3064\n","\n","Epoch 00174: val_loss did not improve from 0.85372\n","Epoch 175/500\n"," - 10s - loss: 0.6651 - accuracy: 0.3164 - val_loss: 0.9762 - val_accuracy: 0.3651\n","\n","Epoch 00175: val_loss did not improve from 0.85372\n","Epoch 176/500\n"," - 10s - loss: 0.6641 - accuracy: 0.3201 - val_loss: 0.9851 - val_accuracy: 0.2877\n","\n","Epoch 00176: val_loss did not improve from 0.85372\n","Epoch 177/500\n"," - 11s - loss: 0.6628 - accuracy: 0.3190 - val_loss: 0.9603 - val_accuracy: 0.2786\n","\n","Epoch 00177: val_loss did not improve from 0.85372\n","Epoch 178/500\n"," - 10s - loss: 0.6618 - accuracy: 0.3231 - val_loss: 1.0780 - val_accuracy: 0.2936\n","\n","Epoch 00178: val_loss did not improve from 0.85372\n","Epoch 179/500\n"," - 10s - loss: 0.6631 - accuracy: 0.3180 - val_loss: 0.9141 - val_accuracy: 0.3440\n","\n","Epoch 00179: val_loss did not improve from 0.85372\n","Epoch 180/500\n"," - 11s - loss: 0.6623 - accuracy: 0.3218 - val_loss: 0.9951 - val_accuracy: 0.3297\n","\n","Epoch 00180: val_loss did not improve from 0.85372\n","Epoch 181/500\n"," - 10s - loss: 0.6609 - accuracy: 0.3252 - val_loss: 0.9753 - val_accuracy: 0.3050\n","\n","Epoch 00181: val_loss did not improve from 0.85372\n","Epoch 182/500\n"," - 10s - loss: 0.6596 - accuracy: 0.3252 - val_loss: 1.0964 - val_accuracy: 0.2985\n","\n","Epoch 00182: val_loss did not improve from 0.85372\n","Epoch 183/500\n"," - 10s - loss: 0.6603 - accuracy: 0.3253 - val_loss: 1.0932 - val_accuracy: 0.3042\n","\n","Epoch 00183: val_loss did not improve from 0.85372\n","Epoch 184/500\n"," - 10s - loss: 0.6591 - accuracy: 0.3274 - val_loss: 1.0700 - val_accuracy: 0.2950\n","\n","Epoch 00184: val_loss did not improve from 0.85372\n","Epoch 185/500\n"," - 10s - loss: 0.6595 - accuracy: 0.3254 - val_loss: 1.0396 - val_accuracy: 0.3626\n","\n","Epoch 00185: val_loss did not improve from 0.85372\n","Epoch 186/500\n"," - 10s - loss: 0.6571 - accuracy: 0.3313 - val_loss: 1.0799 - val_accuracy: 0.3213\n","\n","Epoch 00186: val_loss did not improve from 0.85372\n","Epoch 187/500\n"," - 10s - loss: 0.6568 - accuracy: 0.3307 - val_loss: 1.1182 - val_accuracy: 0.3637\n","\n","Epoch 00187: val_loss did not improve from 0.85372\n","Epoch 188/500\n"," - 10s - loss: 0.6556 - accuracy: 0.3348 - val_loss: 1.0633 - val_accuracy: 0.2940\n","\n","Epoch 00188: val_loss did not improve from 0.85372\n","Epoch 189/500\n"," - 10s - loss: 0.6562 - accuracy: 0.3314 - val_loss: 0.9409 - val_accuracy: 0.4002\n","\n","Epoch 00189: val_loss did not improve from 0.85372\n","Epoch 190/500\n"," - 10s - loss: 0.6551 - accuracy: 0.3341 - val_loss: 1.0320 - val_accuracy: 0.3382\n","\n","Epoch 00190: val_loss did not improve from 0.85372\n","Epoch 191/500\n"," - 10s - loss: 0.6548 - accuracy: 0.3329 - val_loss: 0.8249 - val_accuracy: 0.3128\n","\n","Epoch 00191: val_loss improved from 0.85372 to 0.82493, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 192/500\n"," - 10s - loss: 0.6531 - accuracy: 0.3318 - val_loss: 0.9591 - val_accuracy: 0.3429\n","\n","Epoch 00192: val_loss did not improve from 0.82493\n","Epoch 193/500\n"," - 10s - loss: 0.6531 - accuracy: 0.3387 - val_loss: 0.9826 - val_accuracy: 0.3071\n","\n","Epoch 00193: val_loss did not improve from 0.82493\n","Epoch 194/500\n"," - 10s - loss: 0.6525 - accuracy: 0.3344 - val_loss: 0.8171 - val_accuracy: 0.3992\n","\n","Epoch 00194: val_loss improved from 0.82493 to 0.81714, saving model to /content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending 54_115_macd.hdf5\n","Epoch 195/500\n"," - 10s - loss: 0.6518 - accuracy: 0.3394 - val_loss: 0.9651 - val_accuracy: 0.3350\n","\n","Epoch 00195: val_loss did not improve from 0.81714\n","Epoch 196/500\n"," - 11s - loss: 0.6507 - accuracy: 0.3404 - val_loss: 1.0476 - val_accuracy: 0.3265\n","\n","Epoch 00196: val_loss did not improve from 0.81714\n","Epoch 197/500\n"," - 10s - loss: 0.6510 - accuracy: 0.3406 - val_loss: 0.9085 - val_accuracy: 0.3510\n","\n","Epoch 00197: val_loss did not improve from 0.81714\n","Epoch 198/500\n"," - 10s - loss: 0.6499 - accuracy: 0.3410 - val_loss: 0.9658 - val_accuracy: 0.3427\n","\n","Epoch 00198: val_loss did not improve from 0.81714\n","Epoch 199/500\n"," - 10s - loss: 0.6503 - accuracy: 0.3415 - val_loss: 0.8858 - val_accuracy: 0.3902\n","\n","Epoch 00199: val_loss did not improve from 0.81714\n","Epoch 200/500\n"," - 11s - loss: 0.6483 - accuracy: 0.3435 - val_loss: 0.8367 - val_accuracy: 0.3790\n","\n","Epoch 00200: val_loss did not improve from 0.81714\n","Epoch 201/500\n"," - 10s - loss: 0.6484 - accuracy: 0.3438 - val_loss: 0.9832 - val_accuracy: 0.3749\n","\n","Epoch 00201: val_loss did not improve from 0.81714\n","Epoch 202/500\n"," - 10s - loss: 0.6476 - accuracy: 0.3480 - val_loss: 1.0103 - val_accuracy: 0.2866\n","\n","Epoch 00202: val_loss did not improve from 0.81714\n","Epoch 203/500\n"," - 10s - loss: 0.6473 - accuracy: 0.3435 - val_loss: 0.9792 - val_accuracy: 0.3897\n","\n","Epoch 00203: val_loss did not improve from 0.81714\n","Epoch 204/500\n"," - 10s - loss: 0.6464 - accuracy: 0.3456 - val_loss: 1.0124 - val_accuracy: 0.3483\n","\n","Epoch 00204: val_loss did not improve from 0.81714\n","Epoch 205/500\n"," - 11s - loss: 0.6455 - accuracy: 0.3495 - val_loss: 1.1066 - val_accuracy: 0.3807\n","\n","Epoch 00205: val_loss did not improve from 0.81714\n","Epoch 206/500\n"," - 11s - loss: 0.6440 - accuracy: 0.3483 - val_loss: 0.8189 - val_accuracy: 0.4157\n","\n","Epoch 00206: val_loss did not improve from 0.81714\n","Epoch 207/500\n"," - 10s - loss: 0.6430 - accuracy: 0.3513 - val_loss: 0.9188 - val_accuracy: 0.3860\n","\n","Epoch 00207: val_loss did not improve from 0.81714\n","Epoch 208/500\n"," - 10s - loss: 0.6439 - accuracy: 0.3518 - val_loss: 0.8243 - val_accuracy: 0.3987\n","\n","Epoch 00208: val_loss did not improve from 0.81714\n","Epoch 209/500\n"," - 11s - loss: 0.6423 - accuracy: 0.3509 - val_loss: 0.9449 - val_accuracy: 0.3806\n","\n","Epoch 00209: val_loss did not improve from 0.81714\n","Epoch 210/500\n"," - 10s - loss: 0.6418 - accuracy: 0.3539 - val_loss: 1.1875 - val_accuracy: 0.3268\n","\n","Epoch 00210: val_loss did not improve from 0.81714\n","Epoch 211/500\n"," - 11s - loss: 0.6410 - accuracy: 0.3548 - val_loss: 0.8727 - val_accuracy: 0.3983\n","\n","Epoch 00211: val_loss did not improve from 0.81714\n","Epoch 212/500\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-34f6e6aee680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     shuffle=False)\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"a01LFE7QEp70","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}