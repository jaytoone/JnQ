{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nbasicv2.0a_backi2_vsurvey_liqd(0913_gapmodi).ipynb","provenance":[{"file_id":"1z4z_KLPzc6RWsxo3X_dHbpByxUAgjoMJ","timestamp":1583754134002}],"collapsed_sections":["Ci_jUnNTZbm9","EiXxraeZCj0c","ZnrBE3etCpIA","A4jHXvtbDSez","KdDz-s7ZwrC3","qkzeUFAyeJXK","2gxvme1PC6ha","FxJ1y8v2fkCR","VBwVaUkvfnOd"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python [conda env:tensorflow2_p36]","language":"python","name":"conda-env-tensorflow2_p36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AK9FjWwLOyay"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, sys\n","\n","current_path = '/content/drive/My Drive/Colab Notebooks/JnQ/'\n","\n","os.chdir(current_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uqYv5StTazo"},"source":["# requirements"]},{"cell_type":"code","metadata":{"id":"9qGt60DKTZmf"},"source":["!pip install mpl_finance\n","!pip install findiff\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import gridspec\n","from tqdm.notebook import tqdm\n","from funcs_indicator import *\n","from funcs_for_trade import *\n","\n","import mpl_finance as mf\n","import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","\n","import pickle\n","import shutil\n","from trendln import trendln\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ci_jUnNTZbm9"},"source":["# load data"]},{"cell_type":"code","metadata":{"id":"_bXyS2yrZYC6"},"source":["# interval = '30m'\n","interval = '1m'\n","\n","date_path = './candlestick_concated/%s/quant_v2/' % interval\n","file_list = os.listdir(date_path)\n","print((file_list))\n","\n","interval2 = '3m'\n","date_path2 = './candlestick_concated/%s/quant_v2/' % interval2\n","file_list2 = os.listdir(date_path2)\n","print((file_list2))\n","\n","interval3 = '5m'\n","date_path3 = './candlestick_concated/%s/quant_v2/' % interval3\n","file_list3 = os.listdir(date_path3)\n","print((file_list3))\n","\n","interval4 = '15m'\n","date_path4 = './candlestick_concated/%s/quant_v2/' % interval4\n","file_list4 = os.listdir(date_path4)\n","print((file_list4))\n","\n","interval5 = '30m'\n","date_path5 = './candlestick_concated/%s/quant_v2/' % interval5\n","file_list5 = os.listdir(date_path5)\n","print((file_list5))\n","\n","interval6 = '4h'\n","date_path6 = './candlestick_concated/%s/quant_v2/' % interval6\n","file_list6 = os.listdir(date_path6)\n","print((file_list6))\n","\n","interval7 = '1d'\n","date_path7 = './candlestick_concated/%s/quant_v2/' % interval7\n","file_list7 = os.listdir(date_path7)\n","print((file_list7))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EiXxraeZCj0c"},"source":["# basic_func"]},{"cell_type":"code","metadata":{"id":"mi8H188MCiaH"},"source":["def sync_check(df, second_df, third_df, fourth_df, fifth_df, sixth_df=None, seventh_df=None):\n","\n","    #           supertrend          #\n","    ha_second_df = heikinashi(second_df)\n","    ha_fifth_df = heikinashi(fifth_df)\n","    # print(ha_second_df.tail(10))\n","    # quit()\n","\n","    second_df['minor_ST1_Up'], second_df['minor_ST1_Down'], second_df['minor_ST1_Trend'] = supertrend(second_df, 10, 2)\n","    second_df['minor_ST2_Up'], second_df['minor_ST2_Down'], second_df['minor_ST2_Trend'] = supertrend(ha_second_df, 7,\n","                                                                                                      2)\n","    second_df['minor_ST3_Up'], second_df['minor_ST3_Down'], second_df['minor_ST3_Trend'] = supertrend(ha_second_df, 7,\n","                                                                                                      2.5)\n","    # print(df.head(20))\n","    # quit()\n","\n","    # startTime = time.time()\n","\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [i for i in range(-9, 0, 1)]),\n","                              columns=['minor_ST1_Up', 'minor_ST1_Down', 'minor_ST1_Trend'\n","                                  , 'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST2_Trend'\n","                                  , 'minor_ST3_Up', 'minor_ST3_Down', 'minor_ST3_Trend']))\n","\n","    fifth_df['major_ST1_Up'], fifth_df['major_ST1_Down'], fifth_df['major_ST1_Trend'] = supertrend(fifth_df, 10, 2)\n","    fifth_df['major_ST2_Up'], fifth_df['major_ST2_Down'], fifth_df['major_ST2_Trend'] = supertrend(ha_fifth_df, 7,\n","                                                                                                      2)\n","    fifth_df['major_ST3_Up'], fifth_df['major_ST3_Down'], fifth_df['major_ST3_Trend'] = supertrend(ha_fifth_df, 7,\n","                                                                                                      2.5)\n","    # print(df.head(20))\n","    # quit()\n","\n","    # startTime = time.time()\n","\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [i for i in range(-9, 0, 1)]),\n","                              columns=['major_ST1_Up', 'major_ST1_Down', 'major_ST1_Trend'\n","                                  , 'major_ST2_Up', 'major_ST2_Down', 'major_ST2_Trend'\n","                                  , 'major_ST3_Up', 'major_ST3_Down', 'major_ST3_Trend']))\n","    \n","    # print(df[[\"minor_ST1_Up\", \"minor_ST2_Up\", \"minor_ST3_Up\"]].tail())\n","    # min_upper = np.minimum(df[\"minor_ST1_Up\"], df[\"minor_ST2_Up\"], df[\"minor_ST3_Up\"])\n","    # max_lower = np.maximum(df[\"minor_ST1_Down\"], df[\"minor_ST2_Down\"], df[\"minor_ST3_Down\"])\n","    min_upper = np.min(df[[\"minor_ST1_Up\", \"minor_ST2_Up\", \"minor_ST3_Up\"]], axis=1)\n","    max_lower = np.max(df[[\"minor_ST1_Down\", \"minor_ST2_Down\", \"minor_ST3_Down\"]], axis=1)\n","\n","    df['middle_line'] = (min_upper + max_lower) / 2\n","    \n","    #          add for ep           #\n","    df['min_upper'] = min_upper\n","    df['max_lower'] = max_lower\n","\n","    print(\"supertrend phase done\")\n","\n","\n","    #           lucid sar              #\n","    df['sar1'], df['sar1_uptrend'] = lucid_sar(df, return_uptrend=True)\n","\n","    second_df['sar'], second_df['sar_uptrend'] = lucid_sar(second_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-2, -1]), columns=['sar2', 'sar2_uptrend']))\n","\n","    third_df['sar'], third_df['sar_uptrend'] = lucid_sar(third_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-2, -1]), columns=['sar3', 'sar3_uptrend']))\n","\n","    fourth_df['sar'], fourth_df['sar_uptrend'] = lucid_sar(fourth_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-2, -1]), columns=['sar4', 'sar4_uptrend']))\n","\n","    fifth_df['sar'], fifth_df['sar_uptrend'] = lucid_sar(fifth_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-2, -1]), columns=['sar5', 'sar5_uptrend']))\n","    \n","    if sixth_df is not None:\n","      sixth_df['sar'], sixth_df['sar_uptrend'] = lucid_sar(sixth_df, return_uptrend=True)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-2, -1]), columns=['sar6', 'sar6_uptrend']))\n","    \n","    if seventh_df is not None:\n","      seventh_df['sar'], seventh_df['sar_uptrend'] = lucid_sar(seventh_df, return_uptrend=True)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-2, -1]), columns=['sar7', 'sar7_uptrend']))\n","\n","    # print(df[['sar1', 'sar2']].tail(20))\n","    # print(df[['minor_ST1_Up', 'minor_ST1_Trend']].tail(20))\n","    # quit()\n","\n","    print(\"sar phase done\")\n","\n","\n","    \n","    #           ichimoku            #\n","    df['senkou_a1'], df['senkou_b1'] = ichimoku(df)\n","    \n","    second_df['senkou_a'], second_df['senkou_b'] = ichimoku(second_df)\n","    df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-2, -1]), columns=['senkou_a2', 'senkou_b2']))\n","    \n","    third_df['senkou_a'], third_df['senkou_b'] = ichimoku(third_df)\n","    df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-2, -1]), columns=['senkou_a3', 'senkou_b3']))\n","    \n","    fourth_df['senkou_a'], fourth_df['senkou_b'] = ichimoku(fourth_df)\n","    df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-2, -1]), columns=['senkou_a4', 'senkou_b4']))\n","    \n","    fifth_df['senkou_a'], fifth_df['senkou_b'] = ichimoku(fifth_df)\n","    df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-2, -1]), columns=['senkou_a5', 'senkou_b5']))\n","\n","    if sixth_df is not None:\n","      sixth_df['senkou_a'], sixth_df['senkou_b'] = ichimoku(sixth_df)\n","      df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-2, -1]), columns=['senkou_a6', 'senkou_b6']))\n","\n","    if seventh_df is not None:\n","      seventh_df['senkou_a'], seventh_df['senkou_b'] = ichimoku(seventh_df)\n","      df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-2, -1]), columns=['senkou_a7', 'senkou_b7']))\n","\n","\n","    #           1-2. displacement           #\n","    cloud_cnt = 0\n","    for col_n in df.columns:\n","      if 'senkou' in col_n:\n","        cloud_cnt += 1\n","    print(cloud_cnt)\n","\n","    # df['senkou_a1'] = df['senkou_a1'].shift(26 - 1)\n","    # df['senkou_b1'] = df['senkou_b1'].shift(26 - 1)\n","    # # df.iloc[:, -10:] = df.iloc[:, -10:].shift(26 - 1)\n","    # # df.iloc[:, -14:] = df.iloc[:, -14:].shift(26 - 1)\n","    df.iloc[:, -cloud_cnt:] = df.iloc[:, -cloud_cnt:].shift(26 - 1)\n","\n","    print(\"cloud phase done\")\n","\n","    \n","    #           macd            #\n","    df['macd_hist1'] = macd(df)\n","    \n","    second_df['macd_hist'] = macd(second_df)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['macd_hist2']))\n","\n","    third_df['macd_hist'] = macd(third_df)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['macd_hist3']))\n","\n","    fourth_df['macd_hist'] = macd(fourth_df)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['macd_hist4']))\n","\n","    fifth_df['macd_hist'] = macd(fifth_df)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['macd_hist5']))\n","    \n","    if sixth_df is not None:\n","      sixth_df['macd_hist'] = macd(sixth_df)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['macd_hist6']))\n","    \n","    if seventh_df is not None:\n","      seventh_df['macd_hist'] = macd(seventh_df)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['macd_hist7']))\n","\n","\n","    print(\"macd phase done\")\n","\n","\n","    #         trix        #\n","    df['trix1'] = trix_hist(df, 14, 1, 5)\n","    \n","    second_df['trix'] = trix_hist(second_df, 14, 1, 5)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['trix2']))\n","\n","    third_df['trix'] = trix_hist(third_df, 14, 1, 5)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['trix3']))\n","\n","    fourth_df['trix'] = trix_hist(fourth_df, 14, 1, 5)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['trix4']))\n","\n","    fifth_df['trix'] = trix_hist(fifth_df, 14, 1, 5)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['trix5']))\n","\n","    if sixth_df is not None:\n","      sixth_df['trix'] = trix_hist(sixth_df, 14, 1, 5)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['trix6']))\n","\n","    if seventh_df is not None:\n","      seventh_df['trix'] = trix_hist(seventh_df, 14, 1, 5)\n","      df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['trix7']))\n","\n","\n","    #       stochastic      #\n","    df['stoch'] = stoch(df, 5, 3, 3)\n","    print(\"stochastic phase done\")\n","\n","    #       fisher      #\n","    df['fisher30'] = fisher(df, 30)\n","    df['fisher60'] = fisher(df, 60)\n","    df['fisher120'] = fisher(df, 120)\n","    print(\"fisher phase done\")\n","\n","    #       cctbbo      #\n","    df['cctbbo'], _ = cct_bbo(df, 21, 13)\n","    print(\"cctbbo phase done\")\n","  \n","\n","    return df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnrBE3etCpIA"},"source":["# make & save res_df"]},{"cell_type":"code","metadata":{"id":"X1g9vGP0UnTT"},"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","exist_list = os.listdir(save_path)\n","\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","  \n","  # if 'btc'.upper() not in file_list[i]:\n","  #   continue\n","\n","  # if '2021-04-30'.upper() not in file_list[i]:\n","  # if '2021-05-30'.upper() not in file_list[i]:\n","  # if '2021-06-30'.upper() not in file_list[i]:\n","  # if '2021-07-03'.upper() not in file_list[i]:\n","  if '2021-07-01'.upper() not in file_list[i]:\n","    continue\n","\n","  \n","\n","  # if 'eth'.upper() in file_list[i]:\n","  # # if '2021-07-03'.upper() not in file_list[i]:\n","  # # if '2021-07-01'.upper() not in file_list[i]:\n","  #   continue\n","\n","  for key in keys:  \n","\n","    excel_name = key.replace(\".xlsx\", \"_majorst_backi2.xlsx\")\n","    excel_path = save_path + excel_name\n","\n","    if excel_name in exist_list:\n","      print(excel_name, \"already exist !\")\n","      continue\n","    \n","    \n","    df = pd.read_excel(date_path + key, index_col=0)\n","    second_df = pd.read_excel(date_path2 + key, index_col=0)\n","    third_df = pd.read_excel(date_path3 + key, index_col=0)\n","    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n","    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n","    \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","    \n","    try:\n","      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n","      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","    except Exception as e:\n","      print(e)\n","\n","\n","    res_df = sync_check(df, second_df, third_df, fourth_df, fifth_df)\n","    # res_df = sync_check(df, second_df, third_df, fourth_df, fifth_df, sixth_df, seventh_df)\n","\n","    res_df.to_excel(excel_path)\n","    print(excel_name, \"saved succesfully !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A4jHXvtbDSez"},"source":["# load res_df"]},{"cell_type":"code","metadata":{"id":"uH88bMlZDWc3"},"source":["save_path = './candlestick_concated/res_df/'\n","\n","# key = '2021-07-03 ETHUSDT.xlsx'\n","# key = '2021-07-01 ETHUSDT.xlsx'\n","key = '2021-07-01 ETHUSDT_backi2.xlsx'\n","# key = '2021-06-30 ETHUSDT_backi2.xlsx'\n","# key = '2021-06-30 BTCUSDT_backi2.xlsx'\n","# key = '2021-06-30 XRPUSDT_backi2.xlsx'\n","# key = '2021-06-30 ETHUSDT_backi1.xlsx'\n","res_df = pd.read_excel(save_path + key, index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KdDz-s7ZwrC3"},"source":["# sync check"]},{"cell_type":"code","metadata":{"id":"4r4H4DAovfsi"},"source":["plot_size = 300\n","\n","\n","#         select plot columns       #\n","basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","sar_cols = [15, 18] # 15 ~ 19\n","ichimoku_cols = [20, 21]  # 20 ~ 29\n","macd_cols = [30]  # 30 ~ 34\n","\n","input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","#         do plot       #\n","plot_df = res_df.iloc[-plot_size:, input_cols]\n","\n","fig = plt.figure(figsize=(8, 6))\n","ax = fig.add_subplot(111)\n","\n","# fig.show()\n","# fig.canvas.draw()\n","\n","temp_ohlc = plot_df.values[:, :4]\n","index = np.arange(len(temp_ohlc))\n","candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","# print(plot_df.values[:, 4:])\n","plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper\n","plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower\n","plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","\n","plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14],\n","                  where=plot_df.values[:, 13] >= plot_df.values[:, 14], facecolor='g', alpha=0.5) # ichimoku\n","plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14],\n","                  where=plot_df.values[:, 13] <= plot_df.values[:, 14], facecolor='r', alpha=0.5)\n","\n","\n","\n","plt.show()\n","# plt.draw()\n","plt.close()\n","# plt.pause(1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNGeuYuGDXfv"},"source":["# pr check with strategy"]},{"cell_type":"markdown","metadata":{"id":"qkzeUFAyeJXK"},"source":["### save sample res_dfs"]},{"cell_type":"code","metadata":{"id":"dIL0k_VEeL6B"},"source":["save_path = './candlestick_concated/res_df/'\n","res_df_files = os.listdir(save_path)\n","\n","print(res_df_files)\n","\n","res_df_dict = {}\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for k_i, key in enumerate(res_df_files):\n","  # if '2021-04-30'.upper() not in key:\n","  # if '2021-05-30'.upper() not in key:\n","  # if '2021-06-30'.upper() not in key:\n","  # if '2021-07-03'.upper() not in key:\n","  if '2021-07-01'.upper() not in key:\n","    continue\n","\n","  # if \"link\".upper() not in key:\n","  # if \"eth\".upper() not in key:\n","  #   continue\n","\n","  if \"_majorst_backi2\" not in key:\n","    continue\n","\n","  if sample_cnt == max_cnt:\n","    dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n","    print(\"dict_name :\", dict_name)\n","\n","  res_df = pd.read_excel(save_path + key, index_col=0)  \n","\n","  res_df_dict[key] = res_df\n","  print(key, \"saved to dict !\")\n","\n","  #     save with pickle    #\n","  with open(save_path + dict_name, 'wb') as f:\n","    pickle.dump(res_df_dict, f)\n","\n","  sample_cnt -= 1\n","\n","  if sample_cnt <= 0:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6HOjnZjSgzk1"},"source":["## load res_df_dict"]},{"cell_type":"code","metadata":{"id":"7FPBG5Qqg2jB"},"source":["save_path = './candlestick_concated/res_df/'\n","dict_name = \"2021-06-30 ETHUSDT_sartrend_backi2_res_dfs.pkl\"\n","dict_name = \"2021-07-01 ETHUSDT_backi2_res_dfs.pkl\"\n","dict_name = \"2021-07-01 BTCUSDT_majorst_backi2_res_dfs.pkl\"\n","\n","\n","#     load with pickle    #\n","with open(save_path + dict_name, 'rb') as f:\n","  res_df_dict = pickle.load(f)\n","\n","print(dict_name, \"loaded !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tApzvz_gK9lR"},"source":["## basic strategy"]},{"cell_type":"code","metadata":{"id":"a8aYsjEgQnGF"},"source":["org_res_df = res_df.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FaRGwR4NEop2"},"source":["### shifting"]},{"cell_type":"code","metadata":{"id":"RF3RM2G2RCb1"},"source":["#         refresh res_df      #\n","res_df = org_res_df.copy()\n","print(org_res_df.tail(5))\n","\n","# break\n","\n","\n","shift_size = -4\n","# shift_size = -1\n","# shift_size = -7\n","# shift_size = +3\n","\n","res_df['min_upper'] = res_df['min_upper'].shift(shift_size)\n","res_df['max_lower'] = res_df['max_lower'].shift(shift_size)\n","res_df['minor_ST1_Trend'] = res_df['minor_ST1_Trend'].shift(shift_size)\n","res_df['minor_ST2_Trend'] = res_df['minor_ST2_Trend'].shift(shift_size)\n","res_df['minor_ST3_Trend'] = res_df['minor_ST3_Trend'].shift(shift_size)\n","res_df['middle_line'] = res_df['middle_line'].shift(shift_size)\n","\n","print(res_df.tail(5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2gxvme1PC6ha"},"source":["### load model"]},{"cell_type":"code","metadata":{"id":"dtYdAuSsC72_"},"source":["# model_name = 'inner_tick_cnnreg_lscalemm_prefee_gpu_%s_%s_%s_%s_%s.h5'\n","\n","# model = tf.keras.models.load_model(ckpt_path + model_name)\n","\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","model = ResNet50(weights='imagenet', include_top=False)\n","# model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5la6usMOFzkX"},"source":["#### gen selected vector"]},{"cell_type":"code","metadata":{"id":"oQk3-jbKF8FB"},"source":["def min_max_scale(npy_x):\n","\n","  return (npy_x - np.min(npy_x)) / (np.max(npy_x) - np.min(npy_x))\n","\n","def expand_dims(npy_x):\n","\n","  row, col = npy_x.shape\n","  npy_x2 = np.array(npy_x).reshape(-1, row, col, 1).astype(np.float32)\n","  # input_x = np.array(data_x).reshape(-1, row, col).astype(np.float32)\n","\n","  #     1c to 3c    #\n","  npy_x3 = npy_x2 * np.ones(3, dtype=np.float32)[None, None, None, :]\n","\n","  return npy_x3\n","\n","\n","def vector_dist(f1, f2):\n","  return np.linalg.norm(f1-f2)\n","\n","\n","\n","# ------------------------ params ------------------------  #\n","selected_i = 500\n","input_size = 100\n","\n","\n","\n","#   1. 선택된 인덱스를 입력받았을 때, input generating 형태만 만들어놓고,     #\n","#   1-1. input cols 필요함    #\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","sma_list = ['sma']\n","\n","#     -------------- outer price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","\n","selected_price_colname = basic_list + senkoua_list + senkoub_list + sar_list\n","selected_outprice_colname = [macd_list]\n","\n","\n","#         global scaling for outer price data       #\n","#         1. nan 처리       #\n","\n","# # print((np.isnan(df.values)))\n","# print(\"np.sum(np.isnan(df.values), axis=0) :\", np.sum(np.isnan(df.values), axis=0))\n","\n","# max_nan = np.max(np.sum(np.isnan(df.values), axis=0))\n","# # print(max_nan)\n","\n","# df = df.iloc[max_nan:-max_nan]\n","\n","# total_gdata = []\n","# for g_col in selected_outprice_colname:\n","\n","#   temp_data = min_max_scale(res_df[g_col])\n","#   total_gdata.append(temp_data)\n","\n","\n","\n","#   1-2. cols 에 따른, scaling method 구분함    #\n","onprice_input_x = min_max_scale(res_df[selected_price_colname].iloc[selected_i - input_size:selected_i].values)\n","print(onprice_input_x.shape)\n","\n","\n","#   2. plot_check 에서 본인이 원하는 shape 의 인덱스를 선택   #\n","#   3. vertorize, \n","#   3-1. input generator 를 이용해 entry signal 발생할 때마다 dist 비교 진행    #\n","re_onprice_input_x = expand_dims(onprice_input_x)\n","print(re_onprice_input_x.shape)\n","      \n","# break\n","\n","selected_vector = model.predict(re_onprice_input_x, verbose=1)\n","print(selected_vector.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5duWn8t4BRyv"},"source":["### lastest platform"]},{"cell_type":"code","metadata":{"id":"TdAn2bHHBWMF"},"source":["fee = 0.0004\n","lvrg = 5\n","# lvrg = 2\n","\n","\n","show_log = 0\n","\n","p_qty_divider = 1.5\n","\n","# ------- ep set ------- #\n","entry_type = 'limit'\n","# entry_type = 'market'\n","\n","ep_gap = 1 / 4  # st_gap is critera\n","ep_gap = 0  # st_gap is critera\n","ep_protect_gap = 1 / 4\n","\n","# ------- out set ------- #\n","price_protect = 0\n","\n","# ------- tp set ------- #\n","non_tp = 0 # without tp set\n","\n","exit_type = 'limit'\n","# exit_type = 'market'\n","static_tp = 0\n","\n","tp_gap = 1 / 4  # st_gap is critera\n","tp_gap = 0  # st_gap is critera\n","\n","\n","# ------- lvrg set ------- #\n","\n","static_lvrg = 1\n","target_pct = 0.05\n","\n","hl_lookback = 10\n","\n","\n","# ------- inversion set ------- #\n","inversion = 0\n","\n","if inversion:\n","  short_entry = [1, 2]\n","  long_entry = [-1, -2]\n","else:\n","  short_entry = [-1, -2]\n","  long_entry = [1, 2]\n","\n","  \n","tp_cut_ratio = 0.7\n","\n","fdist_thresh = 1\n","\n","# ----------------- indicator ----------------- #\n","# ------- shift_size ------- #\n","cloud_shift_size = 1\n","sma_shift_size = 1\n","close_shift_size = 1\n","\n","\n","# ------- lb ------- #\n","# cloud_lookback = 30\n","cloud_lookback = 69\n","# cloud_lookback = 150\n","# cloud_lookback = 10\n","\n","sma_lookback = 100\n","# sma_lookback = 100\n","\n","sar_lookback = 5\n","\n","\n","# ------- indi. params ------- #\n","sma = 'sma1'\n","\n","# sma_period = 250\n","sma_period = 100\n","\n","fisher_upper = 1.5\n","fisher_lower = -1.5\n","\n","stoch_upper = 67\n","stoch_lower = 33\n","\n","cctbbo_upper = 80\n","cctbbo_lower = 20\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","for key, res_df in res_df_dict.items():\n","\n","  print(key, \"loaded !\")\n","  # print(\"res_df.columns :\", res_df.columns)  \n","  # print(res_df.tail(100))\n","  # print(\"res_df.index[0] :\", res_df.index[0])\n","  # # print(\"intmin(res_df.index[0]) :\", intmin(res_df.index[0]))\n","  # break\n","\n","  if 'eth'.upper() in key:\n","    pass\n","  else:\n","    continue\n","\n","\n","  # --------------- 2nd middle --------------- #    \n","  res_df['upper_middle'] = (res_df['middle_line'] + res_df['min_upper']) / 2\n","  res_df['lower_middle'] = (res_df['middle_line'] + res_df['max_lower']) / 2\n","\n","  # --------------- outest middle --------------- #\n","  res_df['max_upper'] = np.max(res_df[[\"minor_ST1_Up\", \"minor_ST2_Up\", \"minor_ST3_Up\"]], axis=1)\n","  res_df['min_lower'] = np.min(res_df[[\"minor_ST1_Down\", \"minor_ST2_Down\", \"minor_ST3_Down\"]], axis=1)\n","\n","  # --------------- major middle --------------- #\n","  res_df['major_min_upper'] = np.min(res_df[[\"major_ST1_Up\", \"major_ST2_Up\", \"major_ST3_Up\"]], axis=1)\n","  res_df['major_max_lower'] = np.max(res_df[[\"major_ST1_Down\", \"major_ST2_Down\", \"major_ST3_Down\"]], axis=1)\n","\n","  res_df['major_middle_line'] = (res_df['major_min_upper'] + res_df['major_max_lower']) / 2\n","\n","  # --------------- major 2nd middle --------------- #    \n","  res_df['major_upper_middle'] = (res_df['major_middle_line'] + res_df['major_min_upper']) / 2\n","  res_df['major_lower_middle'] = (res_df['major_middle_line'] + res_df['major_max_lower']) / 2\n","\n","  res_df['st_gap'] = res_df['upper_middle'] - res_df['middle_line']\n","\n","  # --------------- nearest open & close ep --------------- #    \n","  # oc_max = np.max(res_df[['open', 'close']], axis=1)\n","  # oc_min = np.min(res_df[['open', 'close']], axis=1)\n","\n","  #   #      1. oc 와 비교할 대상 리스트 : mtf st lines (on & off)\n","  # comp_target_lines = ['minor_ST1_Up', 'minor_ST1_Down',\n","  #     'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","  #     'middle_line', 'upper_middle', 'lower_middle']\n","\n","  #   #      2. short_ep -> oc 보다 크고 gap 은 최소인 line\n","  #   #      2-2 그런 ep 가 없을경우 진입하지 않음\n","  # short_col_values = res_df[comp_target_lines].values - oc_max.values.reshape(-1, 1) # target_lines cols 중, 양수 중 최소 index 찾기\n","  # short_ep = oc_max.copy()\n","\n","  # copy_short_col_values = short_col_values.copy()\n","  # for row_i in tqdm(range(len(short_col_values))):\n","\n","  #   if show_log:\n","  #     print(\"short_col_values[row_i] :\", short_col_values[row_i])\n","  #   copy_short_col_values[row_i] = np.where(short_col_values[row_i] < 0, np.inf, short_col_values[row_i])\n","    \n","  #   min_idx = np.argmin(copy_short_col_values[row_i])\n","  #   min_value = copy_short_col_values[row_i][min_idx]\n","  #   if show_log:\n","  #     print(\"copy_short_col_values[row_i] :\", copy_short_col_values[row_i])\n","  #     print(\"min_value :\", min_value)\n","  #     print()\n","    \n","  #   short_ep.iloc[row_i] = short_ep.iloc[row_i] + min_value\n","\n","  # long_col_values = oc_min.values.reshape(-1, 1) - res_df[comp_target_lines].values # target_lines cols 중, 양수 중 최소 index 찾기\n","  # long_ep = oc_min.copy()\n","\n","  # copy_long_col_values = long_col_values.copy()\n","  # for row_i in tqdm(range(len(long_col_values))):\n","\n","  #   if show_log:\n","  #     print(\"long_col_values[row_i] :\", long_col_values[row_i])\n","  #   copy_long_col_values[row_i] = np.where(long_col_values[row_i] < 0, np.inf, long_col_values[row_i])\n","    \n","  #   min_idx = np.argmin(copy_long_col_values[row_i])\n","  #   min_value = copy_long_col_values[row_i][min_idx]\n","  #   if show_log:\n","  #     print(\"copy_long_col_values[row_i] :\", copy_long_col_values[row_i])\n","  #     print(\"min_value :\", min_value)\n","  #     print()\n","    \n","  #   long_ep.iloc[row_i] = long_ep.iloc[row_i] - min_value\n","\n","  \n","  # --------------- st ep --------------- #    \n","  # short_ep = res_df['middle_line']\n","  # long_ep = res_df['middle_line']\n","\n","  # short_ep = res_df['middle_line'] - ep_gap * res_df['st_gap']\n","  # long_ep = res_df['middle_line'] + ep_gap * res_df['st_gap']\n","  \n","  short_ep = res_df['min_upper'] - ep_gap * res_df['st_gap']\n","  long_ep = res_df['max_lower'] + ep_gap * res_df['st_gap']\n","\n","\n","  # --------------- sar ep --------------- #    \n","  # short_ep = res_df['sar1'].shift(1)\n","  # long_ep = res_df['sar1'].shift(1)\n","\n","  # short_ep = (res_df['sar2'].shift(1) + res_df['sar2']) * 0.5\n","  # long_ep = (res_df['sar2'].shift(1) + res_df['sar2']) * 0.5\n","\n","\n","  # --------------- open close ep --------------- #    \n","  # short_ep = res_df['open'] * (1.037)\n","  # long_ep = res_df['open'] * (1 / 1.037)\n","\n","\n","\n","  for senkou_a, senkou_b in zip(senkoua_list, senkoub_list): \n","  # for sma4_period in range(5, 30, 2):\n","  # for sma4_period in range(13, 14, 2):\n","  # for cloud_lookback in np.arange(5, 100, 3):\n","\n","    # print(\"sma4_period :\", sma4_period)\n","    print(\"cloud_lookback :\", cloud_lookback)\n","\n","    # -------------------- additional indicators -------------------- #    \n","    senkou_a, senkou_b = 'senkou_a1', 'senkou_b1'\n","    \n","    cloud_top = np.max(res_df[[senkou_a, senkou_b]], axis=1)\n","    cloud_bottom = np.min(res_df[[senkou_a, senkou_b]], axis=1)\n","\n","    under_top = res_df['close'].shift(cloud_shift_size) <= cloud_top.shift(cloud_shift_size)\n","    over_top = res_df['close'].shift(cloud_shift_size) >= cloud_top.shift(cloud_shift_size)\n","\n","    over_bottom = res_df['close'].shift(cloud_shift_size) >= cloud_bottom.shift(cloud_shift_size)\n","    under_bottom = res_df['close'].shift(cloud_shift_size) >= cloud_bottom.shift(cloud_shift_size)\n","    \n","    # --------------- sma --------------- #    \n","    res_df['sma1'] = res_df['close'].rolling(sma_period).mean()  \n","\n","\n","    # --------------- stoch modification --------------- #    \n","    # res_df['stoch'] = stoch(res_df)\n","\n","    res_df['ema_roc'] = ema_roc(res_df['close'], 13, 9)\n","\n","    # # print(res_df['sma5'].tail())\n","\n","    # ------------------------------ htf data ------------------------------ #    \n","\n","    # fourth_df = pd.read_excel(date_path4 + key.replace(\"_4h1d_backi2\", \"\"), index_col=0)\n","    # fifth_df = pd.read_excel(date_path5 + key.replace(\"_majorst_backi2\", \"\"), index_col=0)\n","\n","    # --------------- htf sma --------------- #    \n","    # if \"sma4\" in res_df.columns:\n","    #   res_df.drop(\"sma4\", axis=1, inplace=True)\n","\n","    # fourth_df['sma'] = fourth_df['close'].rolling(sma4_period).mean()\n","    # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, fourth_df, [-1]), columns=['sma4']))\n","\n","    # --------------- htf ema --------------- #    \n","    # fifth_df['ema'] = ema(fifth_df['close'], 4)\n","    # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, fifth_df, [-1]), columns=['ema5']))\n","    \n","    \n","    # ---------------------------------------- short = -1 ---------------------------------------- #\n","\n","    # --------------- timestamp entry --------------- #    \n","    # entry = np.where((intmin(res_df.index) in [0, 30])\n","    #                       , -1, 0) \n","\n","    # --------------- ema_roc entry --------------- #\n","    # entry = np.where((res_df['ema_roc'].shift(1) >= 0) & \n","    #                       (res_df['ema_roc'] < 0)\n","    #                       , -1, 0) \n","    \n","\n","    # --------------- st entry --------------- #\n","    entry = np.where((res_df['close'].shift(1) <= short_ep) & \n","                          (res_df['high'] >= short_ep)\n","                          , -1, 0) \n","    # entry = np.where((res_df['high'].shift(1) <= upper_middle) & \n","    # entry = np.where((res_df['high'].shift(1) <= res_df['middle_line']) & \n","    #                     (res_df['high'] >= short_ep)\n","    #                     , -1, 0) \n","    \n","    entry = np.where((res_df['close'].shift(1) > short_ep)\n","                      , -2, entry) \n","    \n","    # entry = np.where((res_df['close'].shift(1) >= short_ep) & \n","    #                 # (long_ep <= res_df['high']) & \n","    #                 (res_df['close'] <= short_ep)\n","    #                 , -1, 0) \n","\n","    # --------------- sar entry --------------- #\n","    # # entry = np.where((res_df['close'] <= res_df['sar2']) & \n","    # #                   (res_df['close'].shift(1) > res_df['sar2'].shift(1))\n","    # #                   , -1, 0) \n","    # entry = np.where((res_df['close'] <= res_df['sar2']) &\n","    #                  (res_df['low'].shift(1) > res_df['sar2'].shift(1)) &\n","    #                  (res_df['low'].shift(2) > res_df['sar2'].shift(2))\n","    #                   , -1, 0) \n","    # entry = np.where((res_df['sar1'].shift(1) > res_df['low']) & \n","    #                  (res_df['sar1'].shift(2) <= res_df['low'].shift(1))\n","    #                   , -1, 0) \n","      \n","      # --------------- sar pb line : 정확한 진입시점은 아니지만 pb line 의 기준이 댐 --------------- #\n","    # entry = np.where((res_df['sar2_uptrend'].shift(1) == 1) & \n","    #                  (res_df['sar2_uptrend'] == 0)\n","    #                   , -1, 0) \n","    # entry = np.where((res_df['sar2_uptrend'].shift(1) != res_df['sar2_uptrend']) & \n","    #                  (res_df['close'].shift(1) <= res_df['sma1'].shift(1)) &\n","    #                  (res_df['close'].shift(1) <= short_ep)   # close control\n","    #                   , -1, 0) \n","    \n","    # --------------- fisher entry --------------- #    \n","    # entry = np.where((res_df['fisher30'].shift(1) >= res_df['fisher30']) & \n","    #                   (res_df['fisher30'].shift(2) <= res_df['fisher30']).shift(1) &\n","    #                   (res_df['fisher30'].shift(1) >= fisher_upper)\n","    #                   , -1, 0) \n","\n","    # --------------- stoch entry --------------- #    \n","    # entry = np.where((res_df['stoch'].shift(1) <= stoch_upper) &\n","    #                   (res_df['stoch'] > stoch_upper)\n","    #                   , -1, 0) \n","\n","    # --------------- cctbbo entry --------------- #    \n","    # entry = np.where((res_df['cctbbo'].shift(1) >= res_df['cctbbo']) & \n","    #                   (res_df['cctbbo'].shift(2) <= res_df['cctbbo']).shift(1) &\n","    #                   (res_df['cctbbo'].shift(1) >= cctbbo_upper)\n","    #                   , -1, 0) \n","\n","    # --------------- cloud entry --------------- #\n","    # cloud_bottom = np.min(res_df[[senkou_a, senkou_b]], axis=1)\n","\n","    # entry = np.where((res_df['close'] < cloud_bottom) & \n","    #                   (res_df['close'].shift(1) >= cloud_bottom.shift(1))\n","    #                   , -1, 0) \n","\n","\n","\n","    # ---------------------------------------- long = 1 ---------------------------------------- #\n","    \n","    # --------------- timestamp entry --------------- #    \n","    # entry = np.where((np.array(intmin(res_df.index)) in [0, 30])\n","    \n","    # int_min_ts = np.array(list(map(lambda x :intmin(x), res_df.index)))\n","    # # entry = np.where((intmin(res_df.index) == 0)\n","    # entry = np.where((int_min_ts == 0) | (int_min_ts == 30)\n","    #                       , 1, 0)\n","\n","    # print(\"int_min_ts :\", int_min_ts)\n","    # print(\"entry :\", entry)\n","    # break\n","\n","    \n","    # --------------- ema_roc entry --------------- #\n","    # entry = np.where((res_df['ema_roc'].shift(1) <= 0) & \n","    #                       (res_df['ema_roc'] > 0)\n","    #                       , 1, entry) \n","    \n","    \n","    # --------------- st entry --------------- #    \n","    entry = np.where((res_df['close'].shift(1) >= long_ep) & \n","                      (res_df['low'] <= long_ep)\n","                      , 1, entry) \n","    # entry = np.where((res_df['low'].shift(1) >= lower_middle) & \n","    # entry = np.where((res_df['low'].shift(1) >= res_df['middle_line']) & \n","    #                   (res_df['low'] <= long_ep)\n","    #                   , 1, entry) \n","\n","    entry = np.where((res_df['close'].shift(1) < long_ep)\n","                      , 2, entry) \n","      \n","    # entry = np.where((res_df['close'].shift(1) <= long_ep) & \n","    #                   # (long_ep <= res_df['high']) & \n","    #                   (res_df['close'] >= long_ep)\n","    #                   , 1, entry) \n","\n","    # --------------- sar entry --------------- #\n","    # # entry = np.where((res_df['close'] >= res_df['sar2']) & \n","    # #                   (res_df['close'].shift(1) < res_df['sar2'].shift(1))\n","    # #                   , 1, entry) \n","    # --------------- sar pb line : 정확한 진입시점은 아니지만 pb line 의 기준이 댐 --------------- #\n","    # entry = np.where((res_df['sar2_uptrend'].shift(1) == 0) & \n","    #                  (res_df['sar2_uptrend'] == 1)\n","    #                   , 1, entry) \n","    # entry = np.where((res_df['sar2_uptrend'].shift(1) != res_df['sar2_uptrend']) & \n","    #                  (res_df['close'].shift(1) >= res_df['sma1'].shift(1)) &\n","    #                  (res_df['close'].shift(1) >= long_ep)   # close control\n","    #                   , 1, entry) \n","\n","    # #       lb sar 이 high 보다 커야함      #     \n","    # entry = np.where((res_df['close'] >= res_df['sar2']) & \n","    #                  (res_df['high'].shift(1) < res_df['sar2'].shift(1)) & \n","    #                  (res_df['high'].shift(2) < res_df['sar2'].shift(2))\n","    #                   , 1, entry)\n","    # entry = np.where((res_df['sar1'].shift(1) < res_df['high']) &\n","    #                  (res_df['sar1'].shift(2) >= res_df['high'].shift(1))\n","    #                   , 1, entry) \n","    \n","    # --------------- fisher entry --------------- #        \n","    # entry = np.where((res_df['fisher30'].shift(1) <= res_df['fisher30']) & \n","    #                   (res_df['fisher30'].shift(2) >= res_df['fisher30']).shift(1) &\n","    #                   (res_df['fisher30'].shift(1) <= fisher_lower)\n","    #                   , 1, entry)\n","\n","    \n","    # --------------- stoch entry --------------- #    \n","    # entry = np.where((res_df['stoch'].shift(1) >= stoch_lower) &\n","    #                   (res_df['stoch'] < stoch_lower)\n","    #                  , 1, entry)\n","  \n","    # --------------- cctbbo entry --------------- #        \n","    # entry = np.where((res_df['cctbbo'].shift(1) <= res_df['cctbbo']) & \n","    #                   (res_df['cctbbo'].shift(2) >= res_df['cctbbo']).shift(1) &\n","    #                   (res_df['cctbbo'].shift(1) <= cctbbo_lower)\n","    #                   , 1, entry)\n","\n","\n","    # --------------- cloud entry --------------- #\n","    # cloud_top = np.max(res_df[[senkou_a, senkou_b]], axis=1)\n","\n","    # entry = np.where((res_df['close'] > cloud_top) & \n","    #                   (res_df['close'].shift(1) <= cloud_top.shift(1))\n","    #                   , 1, entry)\n","\n","    # print(\"len(entry) :\", len(entry))\n","    # print(\"np.sum(entry == -1) :\", np.sum(entry == -1))\n","    # print(\"np.sum(entry == 1) :\", np.sum(entry == 1))\n","    # break\n","    \n","\n","\n","\n","    #       1-2. tp line = middle line 조금 이내         #    \n","    # --------------- gap range tp --------------- #\n","    # gap_range = 0.5\n","    # gap_range = 1\n","\n","    # short_out = res_df['high'].rolling(hl_lookback).max()\n","    # long_out = res_df['low'].rolling(hl_lookback).min()\n","\n","    # short_tp = res_df['close'] - gap_range * (short_out - res_df['close'])\n","    # long_tp = res_df['close'] + gap_range * (res_df['close'] - long_out)\n","\n","    # --------------- st limit tp & out --------------- #\n","\n","    # short_tp = res_df['middle_line'] - tp_gap * res_df['st_gap']\n","    # long_tp = res_df['middle_line'] + tp_gap * res_df['st_gap']\n","    \n","    # short_tp = res_df['middle_line']\n","    # long_tp = res_df['middle_line']\n","    \n","    short_tp = res_df['lower_middle'] - tp_gap * res_df['st_gap']\n","    long_tp = res_df['upper_middle'] + tp_gap * res_df['st_gap']\n","    \n","    # short_tp = res_df['min_lower']\n","    # long_tp = res_df['max_upper']\n","\n","    # short_tp = res_df['close'] - (res_df['middle_line'] - res_df['close']) * tp_cut_ratio\n","    # long_tp = res_df['close'] + (res_df['close'] - res_df['middle_line']) * tp_cut_ratio\n","    \n","    short_tp2 = res_df['middle_line'] - tp_gap * res_df['st_gap']\n","    long_tp2 = res_df['middle_line'] + tp_gap * res_df['st_gap']\n","\n","    # short_out = res_df['upper_middle']\n","    # long_out = res_df['lower_middle']\n","\n","    # --------------- sar limit tp --------------- #\n","    # short_tp = res_df['sar2'].shift(1) - abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","    # long_tp = res_df['sar2'].shift(1) + abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","\n","    # short_tp2 = res_df['sar2'].shift(1)\n","    # long_tp2 = res_df['sar2'].shift(1)\n","\n","    # short_tp = short_ep - abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","    # long_tp = long_ep + abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","\n","    # short_out = res_df['sar2']\n","    # long_out = res_df['sar2']\n","\n","    # short_out = short_ep + abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","    # long_out = long_ep - abs(res_df['sar2'] - res_df['sar2'].shift(1)) * 0.5\n","    \n","\n","    # --------------- set partial tp --------------- #\n","\n","    short_tps = [short_tp]\n","    long_tps = [long_tp]\n","\n","    # short_tps = [short_tp2]\n","    # long_tps = [long_tp2]\n","\n","    short_tps = [short_tp2, short_tp] # org\n","    long_tps = [long_tp2, long_tp]\n","    \n","    # short_tps = [short_tp, short_tp2]\n","    # long_tps = [long_tp, long_tp2]\n","\n","\n","\n","    #       trading : 여기도 체결 결과에 대해 묘사함       #\n","    trade_list = []\n","    h_trade_list = []\n","    lvrg_list = []\n","    open_list = []\n","\n","    liqd_list = []\n","    short_liqd_list = []\n","    long_liqd_list = []\n","\n","    nontp_liqd_list = []\n","    nontp_short_liqd_list = []\n","    nontp_long_liqd_list = []\n","\n","    nontp_pr_list = []\n","    nontp_short_pr_list = []\n","    nontp_long_pr_list = []\n","\n","    nontp_short_indexs = []\n","    nontp_long_indexs = []\n","\n","    nontp_short_ep_list = []\n","    nontp_long_ep_list = []\n","\n","    pr_list = []\n","    long_list = []\n","    short_list = []\n","\n","    h_pr_list = []\n","    h_long_list = []\n","    h_short_list = []\n","\n","    ep_tp_list = []\n","    h_ep_tp_list = []\n","    tp_state_list = []\n","\n","    i = 0\n","    while 1:\n","    # for i in range(len(res_df)):        \n","\n","      if entry[i] in short_entry: \n","\n","        initial_i = i\n","\n","\n","        # -------------- ep scheduling -------------- #\n","        # # if  (res_df['close'].iloc[i] <= lower_middle.iloc[i]):\n","        # if abs(res_df['close'].iloc[i] - short_ep.iloc[i]) < ep_protect_gap * res_df['st_gap'].iloc[i]:\n","        # if res_df['close'].iloc[i] > short_ep.iloc[i] + ep_protect_gap * 3 * res_df['st_gap'].iloc[i]:\n","        # # if abs((res_df['close'].iloc[i] - upper_middle.iloc[i]) / upper_middle.iloc[i]) < ep_protect_gap:\n","        # # if abs((res_df['close'].iloc[i] - res_df['middle_line'].iloc[i]) / res_df['middle_line'].iloc[i]) < ep_protect_gap:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- distance protection -------------- #\n","        # tp_dist = (res_df['close'].iloc[i] - short_tp.iloc[i])\n","        # cut_dist = (res_df['middle_line'].iloc[i] - res_df['close'].iloc[i])\n","        # if tp_dist / cut_dist >= tp_cut_ratio:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- htf data const. -------------- #\n","        # i_min = intmin(res_df.index[i]) # 2020-09-05 00:00:59.999000\n","        # if i_min >= 30:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"59:59.999000\"\n","        # else:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"29:59.999000\"\n","          \n","        #   # -------------- ema -------------- #\n","        # if fifth_df['close'].shift(1).loc[htf_ts] < fifth_df['ema'].shift(1).loc[htf_ts]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue         \n","        \n","\n","\n","        # -------------- fisher const. -------------- #\n","        # if res_df['fisher30'].shift(1).iloc[i] < 0:\n","        # if res_df['fisher60'].shift(1).iloc[i] < 0:\n","        # if res_df['fisher120'].shift(1).iloc[i] < 0:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- ma const. -------------- #\n","        # ------- ema const. ------- #\n","        # if res_df['close'].shift(0).iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] < res_df['ema5'].shift(1).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if short_ep.iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","\n","        # ------- sma const. ------- #\n","        # if res_df['close'].iloc[i] < res_df[sma].iloc[i]: # and \\\n","        if res_df['close'].shift(1).iloc[i] < res_df['sma1'].shift(1).iloc[i]: # and \\\n","        #   short_ep.iloc[i] <= res_df['sma1'].shift(sma_shift_size).iloc[i]:\n","        # # under_sma = short_ep <= res_df['sma'].shift(sma_shift_size)\n","        # # if np.sum(under_sma.iloc[i + 1 - sma_lookback:i + 1]) == sma_lookback:\n","          pass\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        # -------------- 1d sma const. -------------- #\n","        # if res_df[sma].iloc[i] >= res_df['close'].iloc[i]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- cloud lb const.-------------- #   \n","        if i < cloud_lookback:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        if np.sum(under_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(under_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(over_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(under_top.iloc[i - cloud_lookback:i]) == cloud_lookback:\n","          pass\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","\n","        # -------------- cloud color const.-------------- #\n","        #               1. senkou_a1 < senkou_b1            #\n","        #               1-1. mutli clouds color 충분히 고려               #        \n","        # if i < cloud_lookback:        \n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # if np.sum(res_df[senkou_a].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[senkou_b].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   np.sum(res_df[\"senkou_a2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback: # and \\\n","        #   # np.sum(res_df[\"senkou_a3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","\n","        # -------------- st color const.-------------- #\n","        # if np.sum(res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) <= -1:\n","        # if np.sum(res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) <= -3:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- htf st color const.-------------- #\n","        # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) <= -1:\n","        # # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) <= -3:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- 3rd st const. : st should have 2, 3 or more -------------- #\n","        # if np.sum(res_df[['minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) <= -2:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- sar const. -------------- #\n","        # if res_df['sar1'].iloc[i] > res_df['high'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] > res_df['high'].iloc[i] and res_df['sar3'].iloc[i] > res_df['high'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] > res_df['high'].iloc[i]: # and \\\n","        # # if  res_df['sar3'].iloc[i] > res_df['high'].iloc[i]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- limit waiting const. -------------- #\n","        # entry_done = False\n","        # prev_sar = None\n","        # # for e_j in range(i, len(res_df)):\n","        # for e_j in range(i + 1, len(res_df)): # entry signal이 close 기준 일 경우\n","\n","        #   #             Todo            #\n","        #   #             1. ep 설정 \n","\n","        #   # -------------- np.inf ep -------------- #\n","        #   # if short_ep.iloc[initial_i] == np.inf:\n","        #   #   break\n","\n","        #   #             1-1. close 가 sar_change 이전 sar 을 cross 한 경우만 진입\n","        #   if res_df['high'].iloc[e_j] >= short_ep.iloc[initial_i]:\n","        #     entry_done = True\n","        #     # print(\"res_df['high'].iloc[e_j] :\", res_df['high'].iloc[e_j])\n","        #     # print(\"e_j :\", e_j)\n","\n","        #     #     이미, e_j open 이 ep 보다 높은 경우, entry[initial_i] => -2 로 변경   #\n","        #     if res_df['open'].iloc[e_j] >= short_ep.iloc[initial_i]:\n","        #       entry[initial_i] = -2\n","\n","        #     break\n","\n","        #   #             2. limit 대기 시간 설정\n","        #   #             2-1. tp 조건이 성립되는 경우 limit 취소\n","        #   # -------------- st tp -------------- #\n","        #   if res_df['low'].iloc[e_j] <= short_tp.iloc[initial_i]:\n","        #     break\n","\n","\n","        #   # -------------- period fishing -------------- #\n","        #   # if intmin(res_df.index[e_j]) in [29, 59]:\n","        #   #   break\n","          \n","        #   # -------------- sar pbline -------------- #\n","        #   # if res_df['low'].iloc[e_j] <= short_tp.iloc[initial_i]:          \n","        #   #   break\n","\n","        #   #             2-2. out 조건이 성립되는 경우 limit 취소   \n","        #   # -------------- st out -------------- #\n","        #   if res_df['close'].iloc[e_j] > short_out.iloc[e_j]:\n","        #     break\n","\n","        #   # -------------- stoch -------------- #\n","        #   # if res_df['stoch'].iloc[e_j - 2] >= res_df['stoch'].iloc[e_j - 1] and \\\n","        #   #   res_df['stoch'].iloc[e_j - 1] < res_df['stoch'].iloc[e_j] and \\\n","        #   #   res_df['stoch'].iloc[e_j - 1] <= stoch_lower:\n","        #   #   break\n","\n","        #   # -------------- sar cut -------------- #\n","        #   # if res_df['close'].iloc[e_j] > res_df['middle_line'].iloc[e_j]:\n","        #   # if res_df['close'].iloc[e_j] > short_out.iloc[initial_i]:\n","        #   #   break\n","          \n","        #   # -------------- sar prevsar cut -------------- #\n","        #   # if res_df['sar2_uptrend'].iloc[e_j] == 1:\n","\n","        #   #   if prev_sar is None:\n","        #   #     prev_sar = res_df['sar2'].iloc[e_j - 1]\n","            \n","        #   #   if res_df['close'].iloc[e_j] > prev_sar:\n","        #   #     break\n","\n","        #   # else:\n","        #   #   if res_df['close'].iloc[e_j] > res_df['sar2'].iloc[e_j]:\n","        #   #     break\n","            \n","        #   # if res_df['close'].iloc[e_j] > res_df['middle_line'].iloc[e_j]:\n","        #   # if res_df['close'].iloc[e_j] > short_out.iloc[initial_i]: # or \\\n","        #   #   # res_df['sar2_uptrend'].iloc[e_j] == 1: # or \\\n","\n","        #   # # if res_df['close'].iloc[e_j] > res_df['sar2'].iloc[e_j]:\n","        #   #   break\n","\n","        # i = e_j\n","        # # print(\"i = e_j :\", i)\n","\n","        # if entry_done:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # ----------------- end wait ----------------- #\n","\n","        # print(\"initial_i :\", initial_i)\n","        # print()\n","\n","        open_list.append(initial_i)\n","        \n","        if entry_type is 'market':\n","          try:\n","            ep_list = [res_df['close'].iloc[e_j]]\n","          except Exception as e:\n","            # print('error in ep_list (initial) :', e)\n","            ep_list = [res_df['close'].iloc[initial_i]]\n","        else:          \n","          if entry[initial_i] == -1:\n","            ep_list = [short_ep.iloc[initial_i]]\n","          else:\n","            #   e_j 가 있는 경우, \n","            try:\n","              ep_list = [res_df['open'].iloc[e_j]]\n","            except Exception as e:\n","              ep_list = [res_df['open'].iloc[initial_i]]\n","\n","        if not static_lvrg:\n","          # lvrg = target_pct / (res_df['high'].rolling(hl_lookback).max().iloc[initial_i] / res_df['close'].iloc[initial_i] - 1)\n","          lvrg = target_pct / (short_out.iloc[initial_i] / short_ep.iloc[initial_i] - 1 - fee)\n","          lvrg = int(min(50, lvrg))\n","          lvrg = max(lvrg, 1)\n","          lvrg_list.append(lvrg)\n","\n","        try:\n","          ep_idx_list = [e_j]\n","        except Exception as e:\n","          # print('error in ep_idx_list :', e)        \n","          ep_idx_list = [initial_i]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None\n","        h_i, h_j = None, None\n","        \n","        trade_done = False\n","        \n","        for j in range(i + 1, len(res_df)):\n","        # for j in range(i, len(res_df)):\n","          \n","          if static_tp:\n","            tp_j = initial_i\n","          else:\n","            tp_j = j\n","\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['high'].iloc[j - 1] <= res_df['sar2'].iloc[j - 1] and res_df['high'].iloc[j] > res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep < ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","          \n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['high'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST3_Up'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","\n","          # -------------- ultimate limit tp -------------- #\n","          if not non_tp:\n","\n","            #               1. by price line             #\n","            if exit_type != 'market':\n","\n","              for s_i, short_tp_ in enumerate(short_tps):\n","\n","                if res_df['low'].iloc[j] <= short_tp_.iloc[tp_j] and partial_tp_cnt == s_i: # we use static tp now\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j]:\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j] <= res_df['high'].iloc[j]: --> 이건 잘못되었음\n","\n","                  if s_i == len(short_tps) - 1:\n","                    trade_done = True\n","                  \n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if short_tp_.iloc[j] != short_tp_.iloc[j - 1] and not static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_open\")\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_tp\")\n","\n","                  #         static tp         #\n","                  else:\n","                    \n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #              \n","\n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[tp_j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp\")\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp\")   \n","\n","                  tp_list.append(tp)     \n","                  tp_idx_list.append(j)\n","\n","            #           2. by signal        #\n","            else:\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","              #       inversion     #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              # -------------- sar pb tp -------------- #\n","              if res_df['low'].iloc[j] <= short_tp.iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:       \n","\n","              # -------------- fisher tp -------------- #            \n","              # if entry[j] == 1:\n","\n","              # -------------- timestamp tp -------------- #            \n","              # if intmin(res_df.index[j]) in [29, 59]:\n","                \n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = True\n","\n","                if trade_done:\n","                  tp_state_list.append(\"short close tp\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","\n","                  \n","          # -------------- out -------------- #\n","          # if not trade_done:\n","          #   cut = False\n","\n","          #   # -------------- macd -------------- #\n","          #   # if res_df['macd_hist3'].iloc[j] > 0:  #  macd cut\n","          #   # if res_df['macd_hist3'].iloc[i] < 0 and res_df['macd_hist3'].iloc[j] > 0:\n","\n","          #   # -------------- st -------------- #\n","          #   # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:    \n","          #   # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j]:\n","          #   # if res_df['close'].iloc[j] > upper_middle.iloc[j]:\n","          #   # if res_df['close'].iloc[j] > res_df['minor_ST1_Up'].iloc[j]:\n","          #   if res_df['close'].iloc[j] > short_out.iloc[j]:\n","          #     cut = True\n","\n","          #   # -------------- sma -------------- #\n","          #   # if res_df['close'].iloc[j] > res_df[sma].iloc[j]:\n","\n","          #   # -------------- sar -------------- #\n","          #   # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j] \\\n","          #   #   or res_df['sar2'].iloc[j] <= res_df['high'].iloc[j]:\n","          #   # if res_df['close'].iloc[j] > short_out.iloc[initial_i]: # or \\\n","          #   #   cut = True\n","          #     # res_df['sar2_uptrend'].iloc[j] == 1: # or \\\n","\n","          #   # if res_df['sar2_uptrend'].iloc[j] == 1:\n","\n","          #   #   if prev_sar is None:\n","          #   #     prev_sar = res_df['sar2'].iloc[j - 1]\n","              \n","          #   #   if res_df['close'].iloc[j] > prev_sar:\n","          #   #     cut = True\n","\n","          #   # else:\n","          #   #   if res_df['close'].iloc[j] > res_df['sar2'].iloc[j]:\n","          #   #     cut = True\n","              \n","          #   # -------------- hl -------------- #\n","          #   # if res_df['close'].iloc[j] > short_out.iloc[tp_j]:\n","            \n","          #   # -------------- stoch -------------- #\n","          #   # if res_df['stoch'].iloc[j - 2] >= res_df['stoch'].iloc[j - 1] and \\\n","          #   #   res_df['stoch'].iloc[j - 1] < res_df['stoch'].iloc[j] and \\\n","          #   #   res_df['stoch'].iloc[j - 1] <= stoch_lower:\n","          #   #   cut = True\n","\n","          #   if cut:\n","\n","          #     if price_protect:\n","          #       tp = short_out.iloc[j]\n","          #     else:\n","          #       tp = res_df['close'].iloc[j]\n","\n","          #     # tp = res_df['open'].iloc[j]\n","          #     trade_done = True\n","          #     tp_state_list.append(\"short close_out\")\n","            \n","\n","          #     tp_list.append(tp) \n","          #     tp_idx_list.append(j)\n","\n","\n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = True\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","          \n","\n","\n","          # -------------- append trade data -------------- #\n","          if trade_done:\n","\n","            # if entry[initial_i] == -1:\n","            #   # ep = res_df['close'].iloc[initial_i]\n","            #   # ep = short_ep.iloc[initial_i]\n","            #   # ep_list[0] = short_ep.iloc[initial_i]\n","            #   pass\n","            # else:\n","            #   # ep = res_df['open'].iloc[initial_i]\n","            #   ep_list[0] = res_df['open'].iloc[initial_i]\n","\n","              # ep = short_ep.iloc[initial_i]\n","              # ep = res_df['close'].iloc[initial_i - 1]     \n","\n","            # -------------------- partial tp -------------------- #\n","            #        1. len(tp_list) 에 대응하는 qty_list 를 만들어야함    #\n","            #        2. temp_pr_list 를 만들어 총합 + 1 을 pr_list 에 저장      #\n","            #        2-1. temp_pr = sum((ep / tp_list[i] - fee - 1) * qty_list[i])   #\n","            #        3. temp_pr_list 의 첫 tp 에는 r_qty 를 할당함        #\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / p_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty * lvrg\n","              # temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","              qty_list.append(temp_qty)\n","\n","            # if len(temp_pr_list) == 1:\n","            #   print(\"qty_list :\", qty_list)\n","            #   print(\"temp_pr_list :\", temp_pr_list)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (sub_ep_ / tp - fee - 1) * lvrg\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_tp / h_ep - fee - 1) * lvrg  # hedge long\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","            \n","            hh = max(res_df['high'].iloc[i:j + 1])\n","            short_liq = (ep_list[0] / hh - fee - 1) * lvrg + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              # ep_tp_list.append((ep, tp_list))  \n","              ep_tp_list.append((ep_list, tp_list))  \n","              # trade_list.append([initial_i, i, j])\n","              trade_list.append((ep_idx_list, tp_idx_list))\n","\n","              liqd_list.append(short_liq)\n","              short_liqd_list.append(short_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))        \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              short_list.append(temp_pr)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_short_list.append(hedge_pr)\n","\n","              i = j\n","              break\n","\n","            else:\n","          \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(short_liq)\n","              nontp_short_liqd_list.append(short_liq)\n","              nontp_short_indexs.append(i)\n","              nontp_short_ep_list.append(ep_list[0])\n","\n","              nontp_short_pr = (ep_list[0] / tp - fee - 1) * lvrg + 1\n","              nontp_pr_list.append(nontp_short_pr)\n","              nontp_short_pr_list.append(nontp_short_pr)\n","\n","\n","\n","      #                  long  phase                #\n","      elif entry[i] in long_entry: # inversion\n","      \n","\n","        initial_i = i\n","\n","        # -------------- ep scheduling -------------- #\n","        # # if res_df['close'].iloc[i] >= upper_middle.iloc[i]:\n","        # if abs(res_df['close'].iloc[i] - long_ep.iloc[i]) < ep_protect_gap * res_df['st_gap'].iloc[i]:\n","        # if res_df['close'].iloc[i] < long_ep.iloc[i]:\n","        # # if abs((res_df['close'].iloc[i] - lower_middle.iloc[i]) / lower_middle.iloc[i]) < ep_protect_gap:\n","        # # if abs((res_df['close'].iloc[i] - res_df['middle_line'].iloc[i]) / res_df['middle_line'].iloc[i]) < ep_protect_gap:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- distance protection -------------- #\n","        # tp_dist = (long_tp.iloc[i] - res_df['close'].iloc[i])\n","        # cut_dist = (res_df['close'].iloc[i] - res_df['middle_line'].iloc[i])\n","        # if tp_dist / cut_dist >= tp_cut_ratio:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","          \n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- htf data const. -------------- #\n","        # i_min = intmin(res_df.index[i]) # 2020-09-05 00:00:59.999000        \n","        # if i_min >= 30:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"59:59.999000\"\n","        # else:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"29:59.999000\"\n","          \n","        #   # -------------- ema -------------- #\n","        # if fifth_df['close'].shift(1).loc[htf_ts] > fifth_df['ema'].shift(1).loc[htf_ts]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue    \n","        \n","        # -------------- fisher const. -------------- #\n","        # # if res_df['fisher30'].shift(1).iloc[i] > 0:\n","        # # if res_df['fisher60'].shift(1).iloc[i] > 0:\n","        # if res_df['fisher120'].shift(1).iloc[i] > 0:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- ma const. -------------- #\n","        # ------- ema const. ------- #\n","        # if res_df['close'].shift(0).iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] > res_df['ema5'].shift(1).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if long_ep.iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","\n","        # ------- sma const. ------- #\n","        # if res_df['close'].iloc[i] > res_df[sma].iloc[i]: # and \\\n","        if res_df['close'].shift(1).iloc[i] > res_df['sma1'].shift(1).iloc[i]: # and \\\n","        #   long_ep.iloc[i] >= res_df['sma1'].shift(sma_shift_size).iloc[i]:\n","        # # upper_sma = long_ep >= res_df['sma'].shift(sma_shift_size)\n","        # # if np.sum(upper_sma.iloc[i + 1 - sma_lookback:i + 1]) == sma_lookback:\n","          pass\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        # -------------- 1d sma const. -------------- #\n","        # if res_df[sma].iloc[i] <= res_df['close'].iloc[i]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- cloud const. -------------- #     \n","        if i < cloud_lookback:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","        \n","        # if np.sum(under_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(under_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        if np.sum(over_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(over_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","         pass\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue  \n","\n","\n","        # -------------- cloud color const. -------------- #\n","        #               1. senkou_a1 >= senkou_b1            #\n","        #               1-1. mutli clouds color 충분히 고려               #\n","        # if i < cloud_lookback:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # if np.sum(res_df[senkou_a].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[senkou_b].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   np.sum(res_df[\"senkou_a2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback: # and \\\n","        #   # np.sum(res_df[\"senkou_a3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","\n","        # -------------- st color const. -------------- #\n","        # if np.sum(res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) >= 1:\n","        # if np.sum(res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) >= 3:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- htf st color const. -------------- #\n","        # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) >= 1:\n","        # # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) >= 3:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- 3rd st const. : st should have 2, 3 or more -------------- #\n","        # if np.sum(res_df[['minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) >= 2:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- sar const. -------------- #\n","        # # if res_df['sar2'].iloc[i] < res_df['low'].iloc[i] and res_df['sar3'].iloc[i] < res_df['low'].iloc[i]:\n","        # if res_df['sar1'].iloc[i] < res_df['low'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] < res_df['low'].iloc[i]: # and \\\n","        # # if  res_df['sar3'].iloc[i] < res_df['low'].iloc[i]:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # -------------- limit waiting const. -------------- #\n","        # entry_done = False\n","        # prev_sar = None\n","        # # for e_j in range(i, len(res_df)):\n","        # for e_j in range(i + 1, len(res_df)):\n","\n","        #   #             Todo            #\n","        #   #             1. ep 설정\n","          \n","        #   # -------------- np.inf ep -------------- #\n","        #   # if long_ep.iloc[initial_i] == np.inf:\n","        #   #   break\n","\n","        #   #             1-1. close 가 sar_change 이전 sar 을 cross 한 경우만 진입\n","        #   if res_df['low'].iloc[e_j] <= long_ep.iloc[initial_i]:\n","        #     entry_done = True\n","        #     # print(\"e_j :\", e_j)\n","            \n","        #     #     이미, e_j open 이 ep 보다 낮은 경우, entry[initial_i] => -2 로 변경   #\n","        #     if res_df['open'].iloc[e_j] <= long_ep.iloc[initial_i]:\n","        #       entry[initial_i] = -2\n","\n","        #     break\n","\n","        #   #             2. limit 대기 시간 설정\n","        #   #             2-1. tp 하거나, cut 조건이 성립되는 경우 limit 취소\n","        #   #             2-1-1. timestamp = 29 or 59\n","        #   # -------------- st tp -------------- #\n","        #   if res_df['high'].iloc[e_j] >= long_tp.iloc[initial_i]:\n","        #     break\n","\n","        #   # -------------- period fishing -------------- #\n","        #   # if intmin(res_df.index[e_j]) in [29, 59]:\n","        #   #   break\n","          \n","        #   # -------------- sar pbline -------------- #\n","        #   # if res_df['high'].iloc[e_j] >= long_tp.iloc[initial_i]:\n","        #     # break\n","\n","        #   #             2-2. out 조건이 성립되는 경우 limit 취소\n","        #   # -------------- st out -------------- #\n","        #   if res_df['close'].iloc[e_j] < long_out.iloc[e_j]:\n","        #     break\n","              \n","        #   # -------------- stoch -------------- #\n","        #   # if res_df['stoch'].iloc[e_j - 2] <= res_df['stoch'].iloc[e_j - 1] and \\\n","        #   #   res_df['stoch'].iloc[e_j - 1] > res_df['stoch'].iloc[e_j] and \\\n","        #   #   res_df['stoch'].iloc[e_j - 1] >= stoch_upper:\n","        #   #   break\n","\n","        #   # -------------- sar cut -------------- #\n","        #   # if res_df['close'].iloc[e_j] < long_out.iloc[initial_i]: # or \\\n","        #   #   break\n","          \n","        #   # -------------- sar prevsar cut -------------- #\n","\n","        #   # if res_df['sar2_uptrend'].iloc[e_j] == 0:\n","\n","        #   #     if prev_sar is None:\n","        #   #       prev_sar = res_df['sar2'].iloc[e_j - 1]\n","              \n","        #   #     if res_df['close'].iloc[j] < prev_sar:\n","        #   #       break\n","\n","        #   # else:\n","        #   #   if res_df['close'].iloc[e_j] < res_df['sar2'].iloc[e_j]:\n","        #   #     break\n","\n","        # i = e_j\n","        # # print(\"i = e_j :\", i)\n","\n","        # if entry_done:\n","        #   pass\n","        # else:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # ---------------- end wait ---------------- #\n","\n","        open_list.append(initial_i)\n","\n","        if entry_type is 'market':\n","          try:\n","            ep_list = [res_df['close'].iloc[e_j]]\n","          except Exception as e:\n","            # print('error in ep_list (initial) :', e)\n","            ep_list = [res_df['close'].iloc[initial_i]]\n","        else:\n","          if entry[initial_i] == 1:\n","            ep_list = [long_ep.iloc[initial_i]]\n","          else:\n","            try:\n","              ep_list = [res_df['open'].iloc[e_j]]\n","            except Exception as e:\n","              ep_list = [res_df['open'].iloc[initial_i]]\n","\n","        if not static_lvrg:\n","          # lvrg = target_pct / (res_df['close'].iloc[initial_i] / res_df['low'].rolling(hl_lookback).min().iloc[initial_i] - 1)\n","          lvrg = target_pct / (long_ep.iloc[initial_i] / long_out.iloc[initial_i] - 1 - fee)\n","          lvrg = int(min(50, lvrg))\n","          lvrg = max(1, lvrg)\n","          lvrg_list.append(lvrg)\n","          \n","        try:\n","          ep_idx_list = [e_j]\n","        except Exception as e:\n","          # print('error in ep_idx_list :', e)\n","          ep_idx_list = [initial_i]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None        \n","        h_i, h_j = None, None      \n","\n","        trade_done = False\n","\n","        for j in range(i + 1, len(res_df)):     \n","        # for j in range(i, len(res_df)):     \n","          \n","          if static_tp:\n","            tp_j = initial_i\n","          else:\n","            tp_j = j   \n","\n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['low'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST3_Down'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['low'].iloc[j - 1] >= res_df['sar2'].iloc[j - 1] and res_df['low'].iloc[j] < res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep > ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","\n","          # -------------- ultimate tp -------------- #\n","          if not non_tp:\n","            #            1. by price line            #\n","            if exit_type != 'market':\n","\n","              for l_i, long_tp_ in enumerate(long_tps):\n","\n","                if res_df['high'].iloc[j] >= long_tp_.iloc[tp_j] and partial_tp_cnt == l_i:\n","                # if res_df['high'].iloc[j] >= long_tp.iloc[j]:\n","\n","                  if l_i == len(long_tps) - 1:\n","                    trade_done = True\n","\n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if long_tp_.iloc[j] != long_tp_.iloc[j - 1] and not static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[j]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_open\")\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","                      \n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_tp\")\n","\n","                  #         static tp         #\n","                  else:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #\n","\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[tp_j]:\n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp\")\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp\")         \n","                  \n","                  tp_list.append(tp)\n","                  tp_idx_list.append(j)\n","\n","            #           2. by signal        #\n","            else:\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              #       inversion     #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","              # -------------- sar pb tp -------------- #\n","              if res_df['high'].iloc[j] >= long_tp.iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","\n","              # -------------- fisher tp -------------- #\n","              # if entry[j] == -1:\n","\n","              # -------------- timestamp tp -------------- #\n","              # if intmin(res_df.index[j]) in [29, 59]:\n","                \n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = True\n","\n","                if trade_done:\n","                  tp_state_list.append(\"long close tp\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","\n","\n","\n","          # -------------- out -------------- #\n","          # if not trade_done:              \n","\n","          #   out = False            \n","\n","          #   # -------------- macd -------------- #\n","          #   # if res_df['macd_hist3'].iloc[j] < 0:\n","          #   # # if res_df['macd_hist3'].iloc[i] > 0 and res_df['macd_hist3'].iloc[j] < 0:\n","\n","          #   # -------------- st -------------- #\n","          #   # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","          #   # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j]:\n","          #   # if res_df['close'].iloc[j] < lower_middle.iloc[j]:\n","          #   # if res_df['close'].iloc[j] < res_df['minor_ST1_Down'].iloc[j]:\n","          #   if res_df['close'].iloc[j] < long_out.iloc[j]:\n","          #     out = True\n","\n","          #   # -------------- sma -------------- #\n","          #   # if res_df['close'].iloc[j] < res_df[sma].iloc[j]:\n","\n","          #   # -------------- sar -------------- #\n","          #   # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j] \\\n","          #   #   or res_df['sar2'].iloc[j] >= res_df['low'].iloc[j]:\n","          #   # if res_df['close'].iloc[j] < long_out.iloc[initial_i]: # or \\\n","          #   #   #  res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","          #   #   #  res_df['sar2_uptrend'].iloc[j] == 0 or \\\n","          #   #   out = True\n","            \n","          #   # if res_df['sar2_uptrend'].iloc[j] == 0:\n","\n","          #   #     if prev_sar is None:\n","          #   #       prev_sar = res_df['sar2'].iloc[j - 1]\n","                \n","          #   #     if res_df['close'].iloc[j] < prev_sar:\n","          #   #       out = True\n","\n","          #   # else:\n","          #   #   if res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","          #   #     out = True\n","\n","          #   # -------------- hl -------------- #\n","          #   # if res_df['close'].iloc[j] < long_out.iloc[tp_j]:\n","\n","          #   # -------------- stoch -------------- #\n","          #   # if res_df['stoch'].iloc[j - 2] <= res_df['stoch'].iloc[j - 1] and \\\n","          #   #   res_df['stoch'].iloc[j - 1] > res_df['stoch'].iloc[j] and \\\n","          #   #   res_df['stoch'].iloc[j - 1] >= stoch_upper:\n","          #   #   out = True\n","\n","            \n","          #   if out:\n","\n","          #     if price_protect:\n","          #       tp = long_out.iloc[j]\n","          #     else:\n","          #       tp = res_df['close'].iloc[j]\n","\n","          #     # tp = res_df['open'].iloc[j]\n","          #     tp_state_list.append(\"long close_out\")\n","          #     trade_done = True\n","\n","          #     tp_list.append(tp)\n","          #     tp_idx_list.append(j)\n","\n","          \n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = True\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","\n","\n","          if trade_done:\n","\n","            # if entry[initial_i] == 1:\n","            #   # ep = res_df['close'].iloc[initial_i]\n","            #   # ep_list[0] = long_ep.iloc[initial_i]\n","            #   pass\n","            # else:\n","            #   # ep = long_ep.iloc[i]\n","            #   ep_list[0] = res_df['open'].iloc[initial_i]\n","            #   # ep = res_df['close'].iloc[initial_i - 1]\n","\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / p_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              # temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty\n","              temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty * lvrg\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (tp / sub_ep_ - fee - 1) * lvrg\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_ep / h_tp - fee - 1) * lvrg  # hedge short\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","\n","            ll = min(res_df['low'].iloc[i:j + 1])\n","            long_liq = (ll / ep_list[0] - fee - 1) * lvrg + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              ep_tp_list.append((ep_list, tp_list))\n","              trade_list.append((ep_idx_list, tp_idx_list))\n","\n","              liqd_list.append(long_liq)\n","              long_liqd_list.append(long_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))        \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              long_list.append(temp_pr)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_long_list.append(hedge_pr)                    \n","\n","              i = j\n","              break\n","            \n","            else:\n","          \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(long_liq)\n","              nontp_long_liqd_list.append(long_liq)\n","              nontp_long_indexs.append(i)\n","              nontp_long_ep_list.append(ep_list[0])\n","              \n","              nontp_long_pr = (tp / ep_list[0] - fee - 1) * lvrg + 1\n","              nontp_pr_list.append(nontp_long_pr)\n","              nontp_long_pr_list.append(nontp_long_pr)\n","\n","\n","      i += 1\n","      if i >= len(res_df):\n","        break\n","\n","\n","\n","    # -------------------- result analysis -------------------- #\n","    try:\n","      plt.figure(figsize=(16, 12))\n","      plt.suptitle(key)\n","\n","      np_pr = np.array(pr_list)\n","      # np_pr = (np.array(pr_list) - 1) * lvrg + 1\n","\n","      total_pr = np.cumprod(np_pr)\n","      wr = len(np_pr[np_pr > 1]) / len(np_pr[np_pr != 1])\n","\n","      # plt.subplot(121)\n","      plt.subplot(231)\n","      plt.plot(total_pr)\n","      if len(nontp_liqd_list) != 0:\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_liqd_cnt : %s\\nnontp_liqd : %.2f\\nontp_liqd_pr : %.2f\" \n","                  % (wr, np.min(np_pr), total_pr[-1], lvrg, min(liqd_list), len(nontp_liqd_list), min(nontp_liqd_list), min(nontp_pr_list)))\n","      else:\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_liqd_cnt : %s\" \n","                  % (wr, np.min(np_pr), total_pr[-1], lvrg, min(liqd_list), len(nontp_liqd_list)))\n","      # plt.show()\n","\n","      #         short only      #\n","      np_short_pr = np.array(short_list)\n","\n","      total_short_pr = np.cumprod(np_short_pr)\n","      short_wr = len(np_short_pr[np_short_pr > 1]) / len(np_short_pr[np_short_pr != 1])\n","      \n","      plt.subplot(232)\n","      plt.plot(total_short_pr)\n","      if len(nontp_short_liqd_list) != 0:   \n","\n","        max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","        \n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_short_liqd_cnt : %s\\nnontp_short_liqd : %.2f\\nontp_short_liqd_pr : %.2f\\nmax_nontp_short_term : %s\"  \n","                  % (short_wr, np.min(np_short_pr), total_short_pr[-1], lvrg, min(short_liqd_list), \n","                     len(nontp_short_liqd_list), min(nontp_short_liqd_list), min(nontp_short_pr_list), max_nontp_short_term))\n","      else:\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_short_liqd_cnt : %s\"  \n","                  % (short_wr, np.min(np_short_pr), total_short_pr[-1], lvrg, min(short_liqd_list), len(nontp_short_liqd_list)))\n","\n","      #         long only      #\n","      np_long_pr = np.array(long_list)\n","      # np_long_pr = (np.array(long_list) - 1) * lvrg + 1\n","\n","      total_long_pr = np.cumprod(np_long_pr)\n","      long_wr = len(np_long_pr[np_long_pr > 1]) / len(np_long_pr[np_long_pr != 1])\n","      \n","      plt.subplot(233)\n","      plt.plot(total_long_pr)\n","      if len(nontp_long_liqd_list) != 0:\n","\n","        max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_long_liqd_cnt : %s\\nnontp_long_liqd : %.2f\\nontp_long_liqd_pr : %.2f\\nmax_nontp_long_term : %s\"   \n","                  % (long_wr, np.min(np_long_pr), total_long_pr[-1], lvrg, min(long_liqd_list), \n","                     len(nontp_long_liqd_list), min(nontp_long_liqd_list), min(nontp_long_pr_list), max_nontp_long_term))\n","      else:\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\\nliqd : %.2f\\nnontp_long_liqd_cnt : %s\"   \n","                  % (long_wr, np.min(np_long_pr), total_long_pr[-1], lvrg, min(long_liqd_list), len(nontp_long_liqd_list)))\n","\n","\n","      #     reversion adjustment      #\n","      # rev_np_pr = 1 / (np.array(pr_list) + fee) - fee\n","      rev_np_pr = (1 / ((np.array(pr_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","      # rev_np_pr = (1 / (np.array(pr_list) + fee) - fee - 1) * lvrg + 1\n","          \n","      rev_total_pr = np.cumprod(rev_np_pr)\n","      rev_wr = len(rev_np_pr[rev_np_pr > 1]) / len(rev_np_pr[rev_np_pr != 1])\n","\n","      # plt.subplot(122)\n","      plt.subplot(234)\n","      plt.plot(rev_total_pr)\n","      plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (rev_wr, np.min(rev_np_pr), rev_total_pr[-1], lvrg))\n","\n","      #         short       #\n","      # rev_np_short_pr = 1 / (np.array(short_list) + fee) - fee\n","      rev_np_short_pr = (1 / ((np.array(short_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","      # rev_np_short_pr = (1 / (np.array(short_list) + fee) - fee - 1) * lvrg + 1\n","          \n","      rev_total_short_pr = np.cumprod(rev_np_short_pr)\n","      rev_short_wr = len(rev_np_short_pr[rev_np_short_pr > 1]) / len(rev_np_short_pr[rev_np_short_pr != 1])\n","\n","      # plt.subplot(122)\n","      plt.subplot(235)\n","      plt.plot(rev_total_short_pr)\n","      plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (rev_short_wr, np.min(rev_np_short_pr), rev_total_short_pr[-1], lvrg))\n","\n","      #         long       #\n","      # rev_np_long_pr = 1 / (np.array(long_list) + fee) - fee\n","      rev_np_long_pr = (1 / ((np.array(long_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","          \n","      rev_total_long_pr = np.cumprod(rev_np_long_pr)\n","      rev_long_wr = len(rev_np_long_pr[rev_np_long_pr > 1]) / len(rev_np_long_pr[rev_np_long_pr != 1])\n","\n","      # plt.subplot(122)\n","      plt.subplot(236)\n","      plt.plot(rev_total_long_pr)\n","      plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (rev_long_wr, np.min(rev_np_long_pr), rev_total_long_pr[-1], lvrg))\n","      \n","      plt.show()\n","\n","      h_np_pr = np.array(h_pr_list)\n","      # h_rev_np_pr = 1 / (np.array(h_pr_list) + fee) - fee    # define, for plot_check below cell\n","      h_rev_np_pr = (1 / ((np.array(h_pr_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","\n","      # --------------------- h pr plot --------------------- #\n","      if len(h_np_pr[h_np_pr != 1]) != 0:\n","\n","        plt.figure(figsize=(16, 12))\n","        plt.suptitle(key + \" hedge\")\n","\n","        h_total_pr = np.cumprod(h_np_pr)\n","        h_wr = len(h_np_pr[h_np_pr > 1]) / len(h_np_pr[h_np_pr != 1])\n","\n","        # plt.subplot(121)\n","        plt.subplot(231)\n","        plt.plot(h_total_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_wr, np.min(h_np_pr), h_total_pr[-1], lvrg))\n","        # plt.show()\n","\n","        #         short only      #\n","        h_np_short_pr = np.array(h_short_list)\n","\n","        h_total_short_pr = np.cumprod(h_np_short_pr)\n","        h_short_wr = len(h_np_short_pr[h_np_short_pr > 1]) / len(h_np_short_pr[h_np_short_pr != 1])\n","        \n","        plt.subplot(232)\n","        plt.plot(h_total_short_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_short_wr, np.min(h_np_short_pr), h_total_short_pr[-1], lvrg))\n","\n","        #         long only      #\n","        h_np_long_pr = np.array(h_long_list)\n","\n","        h_total_long_pr = np.cumprod(h_np_long_pr)\n","        h_long_wr = len(h_np_long_pr[h_np_long_pr > 1]) / len(h_np_long_pr[h_np_long_pr != 1])\n","        \n","        plt.subplot(233)\n","        plt.plot(h_total_long_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_long_wr, np.min(h_np_long_pr), h_total_long_pr[-1], lvrg))\n","\n","\n","        #     reversion adjustment      #\n","            \n","        h_rev_total_pr = np.cumprod(h_rev_np_pr)\n","        h_rev_wr = len(h_rev_np_pr[h_rev_np_pr > 1]) / len(h_rev_np_pr[h_rev_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(234)\n","        plt.plot(h_rev_total_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_rev_wr, np.min(h_rev_np_pr), h_rev_total_pr[-1], lvrg))\n","\n","        #         short       #\n","        # h_rev_np_short_pr = 1 / (np.array(h_short_list) + fee) - fee\n","        h_rev_np_short_pr =  (1 / ((np.array(h_short_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","           \n","        h_rev_total_short_pr = np.cumprod(h_rev_np_short_pr)\n","        h_rev_short_wr = len(h_rev_np_short_pr[h_rev_np_short_pr > 1]) / len(h_rev_np_short_pr[h_rev_np_short_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(235)\n","        plt.plot(h_rev_total_short_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_rev_short_wr, np.min(h_rev_np_short_pr), h_rev_total_short_pr[-1], lvrg))\n","\n","        #         long       #\n","        # h_rev_np_long_pr = 1 / (np.array(h_long_list) + fee) - fee\n","        h_rev_np_long_pr =  (1 / ((np.array(h_long_list) - 1) / lvrg + fee + 1) - fee - 1) * lvrg + 1\n","            \n","        h_rev_total_long_pr = np.cumprod(h_rev_np_long_pr)\n","        h_rev_long_wr = len(h_rev_np_long_pr[h_rev_np_long_pr > 1]) / len(h_rev_np_long_pr[h_rev_np_long_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(236)\n","        plt.plot(h_rev_total_long_pr)\n","        plt.title(\"wr : %.2f\\nmin_pr : %.2f\\nacc_pr : %.2f\\n lvrg %s\" % (h_rev_long_wr, np.min(h_rev_np_long_pr), h_rev_total_long_pr[-1], lvrg))\n","        \n","        plt.show()\n","          \n","    except Exception as e:\n","      print('error in pr plot :', e)   \n","    \n","\n","    print()\n","\n","    break # indi. loop\n","  break # pair loop"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRe3-Cm6WTX8"},"source":["##### temp test bed"]},{"cell_type":"code","metadata":{"id":"sH8QDdwROp1S"},"source":["# short_col_values = res_df[comp_target_lines].values - oc_max.values.reshape(-1, 1) # target_lines cols 중, 양수 중 최소 index 찾기\n","print(short_col_values.shape)\n","# short_candi_cols = np.argwhere(short_col_values > 0) # -> 여기서 얻고 싶은 건 조건에 해당되는 axis=1 의 col idx\n","# 1. 음수 value 를 모두 해당 axis=1 내의 최대값으로 변경하고, \n","# 2. 변경된 value 내에서 최소값을 찾는다\n","# 3. broad cast issue 로, col 내에서 for loop 로 수정해야할 것\n","\n","# short_col_max = np.max(short_col_values, axis=1)\n","# short_candi_cols = np.where(short_col_values < 0, short_col_max, short_col_values)\n","\n","# for col_idx in range(short_col_values.shape[1]):\n","#   print(\"short_col_values[:, [col_idx]].shape :\", short_col_values[:, [col_idx]].shape)\n","#   short_col_values[:, [col_idx]] = np.where(short_col_values[:, [col_idx]] < 0, short_col_max, short_col_values[:, [col_idx]])\n","\n","short_col_values = res_df[comp_target_lines].values - oc_max.values.reshape(-1, 1) # target_lines cols 중, 양수 중 최소 index 찾기\n","short_ep = oc_max.copy()\n","\n","copy_short_col_values = short_col_values.copy()\n","show_log = 1\n","for row_i in tqdm(range(len(short_col_values))):\n","\n","  if show_log:\n","    print(\"short_col_values[row_i] :\", short_col_values[row_i])\n","  copy_short_col_values[row_i] = np.where(short_col_values[row_i] < 0, np.inf, short_col_values[row_i])\n","  \n","  min_idx = np.argmin(copy_short_col_values[row_i])\n","  min_value = copy_short_col_values[row_i][min_idx]\n","  if show_log:\n","    print(\"copy_short_col_values[row_i] :\", copy_short_col_values[row_i])\n","    print(\"min_value :\", min_value)\n","    print()\n","\n","  print(\"short_ep.iloc[row_i] :\", short_ep.iloc[row_i])\n","  short_ep.iloc[row_i] = short_ep.iloc[row_i] + min_value\n","  print(\"short_ep.iloc[row_i] :\", short_ep.iloc[row_i])\n","  print()\n","\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvJrwx9acP7U"},"source":["long_col_values = oc_min.values.reshape(-1, 1) - res_df[comp_target_lines].values # target_lines cols 중, 양수 중 최소 index 찾기\n","long_ep = oc_min.copy()\n","\n","copy_long_col_values = long_col_values.copy()\n","for row_i in tqdm(range(len(long_col_values))):\n","\n","  if show_log:\n","    print(\"long_col_values[row_i] :\", long_col_values[row_i])\n","  copy_long_col_values[row_i] = np.where(long_col_values[row_i] < 0, np.inf, long_col_values[row_i])\n","  \n","  min_idx = np.argmin(copy_long_col_values[row_i])\n","  min_value = copy_long_col_values[row_i][min_idx]\n","  if show_log:\n","    print(\"copy_long_col_values[row_i] :\", copy_long_col_values[row_i])\n","    print(\"min_value :\", min_value)\n","    print()\n","  \n","  print(\"long_ep.iloc[row_i] :\", long_ep.iloc[row_i])\n","  long_ep.iloc[row_i] = long_ep.iloc[row_i] - min_value\n","  print(\"long_ep.iloc[row_i] :\", long_ep.iloc[row_i])\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-IbP_Z3Dlwk4"},"source":["### nontp survey"]},{"cell_type":"markdown","metadata":{"id":"FxJ1y8v2fkCR"},"source":["##### term & liqd"]},{"cell_type":"code","metadata":{"id":"-qIWa48pl1GO"},"source":["# print(nontp_long_indexs)\n","\n","plot_size = 100\n","\n","for s_i in range(plot_size, len(trade_list), plot_size):\n","\n","  slice_trade_list = trade_list[s_i - plot_size:s_i]\n","  slice_liqd_list = liqd_list[s_i - plot_size:s_i]\n","\n","  # print(len(slice_trade_list))\n","  np_trade = np.array(slice_trade_list)\n","  trade_term = np_trade[:, [2]] - np_trade[:, [1]]\n","\n","  plt.figure(figsize=(5, 10))\n","  plt.subplot(211)\n","  plt.bar(np.arange(len(trade_term)), trade_term.reshape(-1,), width=1, color='b')\n","\n","  # plt.plot(trade_term.reshape(-1,))\n","  plt.ylim(0, 1000)\n","  # plt.show()\n","  # print()\n","\n","  plt.subplot(212)\n","  # print(len(liqd_list))\n","  # plt.bar(np.arange(len(liqd_list)), liqd_list)\n","  plt.bar(np.arange(len(slice_liqd_list)), np.array(slice_liqd_list), width=1, color='r')\n","  # plt.plot(slice_liqd_list)\n","  plt.show()\n","\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBwVaUkvfnOd"},"source":["##### check nontp index"]},{"cell_type":"code","metadata":{"id":"mRCMBOU4frNY"},"source":["# np_nontp_short_indexs = np.array(nontp_short_indexs)\n","# np_nontp_long_indexs = np.array(nontp_long_indexs)\n","\n","# short_til_term = len(res_df) - np_nontp_short_indexs\n","# long_til_term = len(res_df) - np_nontp_long_indexs\n","\n","max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","print(max_nontp_long_term)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNQxkb06ZdTe"},"source":["# traded section plot"]},{"cell_type":"markdown","metadata":{"id":"UmH_Pb5BZUtm"},"source":["## plot with off-color st with dash"]},{"cell_type":"markdown","metadata":{"id":"59nW2aKYzkN8"},"source":["### plot all indicator (stepline ver.)"]},{"cell_type":"code","metadata":{"id":"JDH4rXgNzno6"},"source":["save_plot = False\n","\n","\n","if save_plot:\n","  plot_check_dir = current_path + \"plot_check/\" +  key.replace(\".xlsx\", \"\")\n","  try:\n","    os.mkdir(plot_check_dir)\n","  except:\n","\n","    #     remove existing dir   #\n","    shutil.rmtree(plot_check_dir)\n","    print(plot_check_dir, 'removed !')\n","    os.mkdir(plot_check_dir)\n","    # pass\n","    \n","prev_plotsize = 120\n","post_plotsize = 20\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    try:\n","      h_plot_pr_list = h_np_pr\n","    except Exception as e:\n","      print(\"error in h_plot_pr :\", e)\n","      h_plot_pr_list = np_pr\n","\n","\n","#         select plot columns       #\n","major_st_list = ['major_ST1_Up', 'major_ST1_Down', 'major_ST2_Up', 'major_ST2_Down', 'major_ST3_Up', 'major_ST3_Down',\n","                 'major_middle_line', 'major_upper_middle', 'major_lower_middle']\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower'] # + major_st_list\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1',  'senkou_a2']\n","senkoub_list = ['senkou_b1',  'senkou_b2']\n","\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1']\n","\n","# ma_list = ['sma1', 'sma4']\n","ma_list = ['ema5']\n","\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","# macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3']\n","# trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","trix_list = ['trix1', 'trix2', 'trix3']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","emaroc_list = ['ema_roc']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + ma_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + ma_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","input_colname = basic_list + major_st_list + senkoua_list + senkoub_list + sar_list + stoch_list + fisher_list + emaroc_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list # currently just used for ymin, ymax\n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","\n","# for t_i, (initial_i, i, j) in enumerate(trade_list):\n","for t_i, (ep_idx_list_, tp_idx_list_) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # if 100 < i < 1860:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > short_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  if plot_pr_list[t_i] < 1.0:\n","    continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + post_plotsize, input_cols]\n","  plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  # st_trend_plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize, [7, 10, 13]]\n","  # st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend', 'major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  # htf_st_trend_plot_df = res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","\n","  if np.isnan(y_max) or np.isnan(y_min):\n","    continue\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","  \n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, plot_df['minor_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, plot_df['minor_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, plot_df['minor_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, plot_df['minor_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, plot_df['minor_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, plot_df['minor_ST3_Down'], np.nan)\n","\n","  plot_df[\"off_color_upper_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, plot_df['major_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, plot_df['major_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, plot_df['major_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, plot_df['major_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, plot_df['major_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, plot_df['major_ST3_Down'], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df['minor_ST1_Up'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, np.nan, plot_df['minor_ST1_Up'])\n","  plot_df['minor_ST2_Up'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, np.nan, plot_df['minor_ST2_Up'])\n","  plot_df['minor_ST3_Up'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, np.nan, plot_df['minor_ST3_Up'])\n","  plot_df['minor_ST1_Down'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, np.nan, plot_df['minor_ST1_Down'])\n","  plot_df['minor_ST2_Down'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, np.nan, plot_df['minor_ST2_Down'])\n","  plot_df['minor_ST3_Down'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, np.nan, plot_df['minor_ST3_Down'])\n","\n","  plot_df['major_ST1_Up'] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, np.nan, plot_df['major_ST1_Up'])\n","  plot_df['major_ST2_Up'] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, np.nan, plot_df['major_ST2_Up'])\n","  plot_df['major_ST3_Up'] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, np.nan, plot_df['major_ST3_Up'])\n","  plot_df['major_ST1_Down'] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, np.nan, plot_df['major_ST1_Down'])\n","  plot_df['major_ST2_Down'] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, np.nan, plot_df['major_ST2_Down'])\n","  plot_df['major_ST3_Down'] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, np.nan, plot_df['major_ST3_Down'])\n","\n","\n","  plot_short_ep = short_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_ep = long_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_tp = long_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]  \n","\n","\n","  # fig = trendln.plot_support_resistance(plot_df['close'], accuracy=8, fromwindows=False, numbest=1,  window=30) # requires matplotlib - pip install matplotlib\n","\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  plt.step(plot_df[['minor_ST1_Up', 'minor_ST2_Up', 'minor_ST3_Up']].values, 'r', alpha=1)  # upper on color\n","  plt.step(plot_df[['minor_ST1_Down', 'minor_ST2_Down', 'minor_ST3_Down']].values, 'b', alpha=1)  # lower on color\n","  \n","  plt.step(plot_df[['major_ST1_Up', 'major_ST2_Up', 'major_ST3_Up']].values, 'r', alpha=1, linewidth=3)  # major upper on color\n","  plt.step(plot_df[['major_ST1_Down', 'major_ST2_Down', 'major_ST3_Down']].values, 'b', alpha=1, linewidth=3)  # major lower on color\n","\n","  plt.step(plot_df[['middle_line']].values, 'fuchsia', alpha=1)  # middle \n","  plt.step(plot_df[['major_middle_line']].values, 'fuchsia', alpha=1, linewidth=3)  # major_middle \n","  \n","  plt.step(plot_df[['off_color_upper_st1', 'off_color_upper_st2', 'off_color_upper_st3']].values, 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df[['off_color_lower_st1', 'off_color_lower_st2', 'off_color_lower_st3']].values, 'b', alpha=1, linestyle=':')  # lower off color\n","  \n","  plt.step(plot_df[['off_color_upper_hst1', 'off_color_upper_hst2', 'off_color_upper_hst3']].values, 'r', alpha=1, linestyle=':', linewidth=3)  # major upper off color\n","  plt.step(plot_df[['off_color_lower_hst1', 'off_color_lower_hst2', 'off_color_lower_hst3']].values, 'b', alpha=1, linestyle=':', linewidth=3)  # major lower off color\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_long_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  plt.step(plot_df[['major_upper_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  plt.step(plot_df[['major_lower_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  \n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- on price indicator part ---------------------- #\n","\n","  # ---------------------- sma ---------------------- #\n","  # alpha = 1\n","  # for sm_i, sma in enumerate(ma_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='black', linewidth=lw)\n","  #   alpha -= 0.2\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  # if i != initial_i:\n","  # if len(ep_idx_list_) > 1:\n","  \n","  # ------------- initial order ------------- #\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  for ep_i in range(len(ep_idx_list_)):\n","    plt.axvline(prev_plotsize - (ep_idx_list_[ep_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","  # plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","    plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline  \n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","\n","  #         hedge ep & tp         #\n","  h_i = h_trade_list[t_i][1]\n","  if h_i is not None:\n","    plt.axvline(prev_plotsize + (h_i - ep_idx_list_[0]), linestyle='--')\n","    plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","    plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  if not static_lvrg:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\nlvrg : %s\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i], lvrg_list[t_i]))\n","  else:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i]))\n","\n","  print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee - 1) * lvrg + 1)\n","  print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee - 1) * lvrg + 1)\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # ---------------------- outer price indi. ---------------------- #\n","  #           macd          #\n","  # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","    \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for stoch in stoch_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(stoch_upper, linestyle='--')\n","  # plt.axhline(stoch_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- cctbbo ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for cctbbo in cctbbo_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(cctbbo_upper, linestyle='--')\n","  # plt.axhline(cctbbo_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- ema_roc ---------- #  \n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for emaroc in emaroc_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  plt.axhline(0, linestyle='--')\n","\n","\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  if not save_plot:\n","    plt.show()\n","  \n","  else:\n","    # ---------- save mode ---------- #\n","    fig_name = plot_check_dir +  \"/%s.png\" % t_i\n","    plt.savefig(fig_name)\n","    print(fig_name, \"saved !\")\n","\n","  \n","  plt.close()\n","  print()\n","\n","  # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGuJu2j4Aby9"},"source":["# print()\n","for item in os.listdir(current_path + \"plot_check/\"):\n","  if item.endswith('png'):\n","    os.remove(current_path + \"plot_check/\" + item)\n","    print(current_path + \"plot_check/\" + item, \"removed !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj9X6S1jJjER"},"source":["### plot nontp case"]},{"cell_type":"code","metadata":{"id":"Gb1jGrS4Jl8A"},"source":["prev_plotsize = 50\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","short_ver = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    h_plot_pr_list = h_np_pr\n","\n","\n","\n","#         select plot columns       #\n","# basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","# sar_cols = [15, 18] # 15 ~ 19\n","# ichimoku_cols = [20, 21]  # 20 ~ 29\n","# # ichimoku_cols = [22, 23]  # 20 ~ 29\n","# ichimoku_cols2 = [22, 23]  # 20 ~ 29\n","# macd_cols = [30]  # 30 ~ 34\n","\n","# print(res_df.columns[basic_cols])\n","# break\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher']\n","cctbbo_list = ['cctbbo']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","if short_ver:\n","  nontp_indexs = nontp_short_indexs\n","  nontp_liqd_list = nontp_short_liqd_list\n","  nontp_pr_list = nontp_short_pr_list\n","  nontp_ep = nontp_short_ep_list\n","else:\n","  nontp_indexs = nontp_long_indexs\n","  nontp_liqd_list = nontp_long_liqd_list\n","  nontp_pr_list = nontp_long_pr_list\n","  nontp_ep = nontp_long_ep_list\n","\n","\n","for t_i, i in enumerate(nontp_indexs):\n","\n","  j = len(res_df) - 1\n","\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # # if 1800 < i < 1860:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > upper_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + 1, input_cols]\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","\n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, plot_df.iloc[:, [4]], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, plot_df.iloc[:, [6]], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, plot_df.iloc[:, [8]], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, plot_df.iloc[:, [5]], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, plot_df.iloc[:, [7]], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, plot_df.iloc[:, [9]], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[i - prev_plotsize:j + 1]\n","  plot_long_tp = long_tp.iloc[i - prev_plotsize:j + 1]  \n","\n","\n","\n","  # fig = plt.figure(figsize=(12, 16))\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.step(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  # plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  plt.step(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower on color\n","  plt.step(plot_df.values[:, [10]], 'fuchsia', alpha=1)  # middle\n","  \n","  plt.step(plot_df.values[:, -6:-3], 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df.values[:, -3:], 'b', alpha=1, linestyle=':')  # lower off color\n","\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_upper_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_lower_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- indicator part ---------------------- #\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  if i != initial_i:\n","    plt.axvline(prev_plotsize - (i - initial_i), alpha=0.5, linestyle='--')\n","  plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(nontp_ep[t_i], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  # for sub_i in range(len(ep_tp_list[t_i][1])):\n","  #   plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline    \n","\n","  #         hedge ep & tp         #\n","  # h_i = h_trade_list[t_i][1]\n","  # if h_i is not None:\n","  #   plt.axvline(prev_plotsize + (h_i - i), linestyle='--')\n","  #   plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","  #   plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  plt.title(\"%s ~ %s -> liqd : %.2f\\npr : %.2f\" % (i, j, nontp_liqd_list[t_i], nontp_pr_list[t_i]))\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # #           macd          #\n","  # # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # plt.subplot(313)\n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for stoch in stoch_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(50, linestyle='--')\n","  plt.axhline(stoch_upper, linestyle='--')\n","  plt.axhline(stoch_lower, linestyle='--')\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  plt.show()\n","  # plt.draw()\n","  plt.close()\n","  print()\n","\n","  # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXqR5bwGzqDW"},"source":["### specific plot v1"]},{"cell_type":"code","metadata":{"id":"UiCTTXJpZX1i"},"source":["prev_plotsize = 50\n","\n","# inversion = True\n","inversion = False\n","\n","if inversion:\n","  plot_pr_list = rev_np_pr\n","else:\n","  plot_pr_list = np_pr\n","\n","\n","\n","#         select plot columns       #\n","basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","sar_cols = [15, 18] # 15 ~ 19\n","ichimoku_cols = [20, 21]  # 20 ~ 29\n","# ichimoku_cols = [22, 23]  # 20 ~ 29\n","ichimoku_cols2 = [22, 23]  # 20 ~ 29\n","macd_cols = [30]  # 30 ~ 34\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","\n","input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","\n","for t_i, (i, j) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i != 257:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","\n","  if plot_pr_list[t_i] > 1.0:\n","  # if plot_pr_list[t_i] < 1.0:\n","    continue\n","\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1, input_cols]\n","\n","\n","  #       keep off-color st with another variable         #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","\n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, plot_df.iloc[:, [4]], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, plot_df.iloc[:, [6]], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, plot_df.iloc[:, [8]], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, plot_df.iloc[:, [5]], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, plot_df.iloc[:, [7]], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, plot_df.iloc[:, [9]], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[i - prev_plotsize:j + 1]\n","  plot_long_tp = long_tp.iloc[i - prev_plotsize:j + 1]  \n","\n","\n","\n","  fig = plt.figure(figsize=(12, 16))\n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  ax = fig.add_subplot(211)\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower on color\n","  plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","  \n","  plt.plot(plot_df.values[:, -6:-3], 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.plot(plot_df.values[:, -3:], 'b', alpha=1, linestyle=':')  # lower off color\n","\n","  plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","  # plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  plt.plot(plot_upper_ep.values, alpha=1, linestyle='--')  # ep\n","  plt.plot(plot_lower_ep.values, alpha=1, linestyle='--')  # ep\n","\n","  plt.plot(plot_upper_middle.values, alpha=1, linestyle='--')  # middle\n","  plt.plot(plot_lower_middle.values, alpha=1, linestyle='--')  # middle\n","\n","  plt.plot(plot_short_tp.values, alpha=1, linestyle=':')  # tp\n","  plt.plot(plot_long_tp.values, alpha=1, linestyle=':')  # tp\n","\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14], # ichimoku\n","                    where=plot_df.values[:, 13] >= plot_df.values[:, 14], facecolor='g', alpha=0.5) # ichimoku\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14],\n","                    where=plot_df.values[:, 13] <= plot_df.values[:, 14], facecolor='r', alpha=0.5)  \n","  \n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 16], plot_df.values[:, 17], # ichimoku\n","                    where=plot_df.values[:, 16] >= plot_df.values[:, 17], facecolor='g', alpha=0.3) # ichimoku\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 16], plot_df.values[:, 17],\n","                    where=plot_df.values[:, 16] <= plot_df.values[:, 17], facecolor='r', alpha=0.3)\n","\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(ep_tp_list[t_i][1], linestyle='-')  # tp line axhline\n","  plt.title(\"%s ~ %s -> %.5f\\n %s\" % (i, j, plot_pr_list[t_i], tp_state_list[t_i]))\n","\n","\n","  plt.subplot(212)\n","  plt.plot(plot_df.values[:, [15]], 'g', alpha=1)  # middle\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(0, linestyle='--')\n","\n","  plt.show()\n","  # plt.draw()\n","  plt.close()\n","  print()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-g7YY5BvMcLS"},"source":["### show detail values"]},{"cell_type":"code","metadata":{"id":"5TxQ3rDnKMa7"},"source":["i, j = 27267, 27268\n","print(\"upper_ep.iloc[i] :\", upper_ep.iloc[i])\n","print(\"short_tp.iloc[j] :\", short_tp.iloc[j])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AIl6EBuZNOL"},"source":["## none plot off-color st"]},{"cell_type":"code","metadata":{"id":"yaVxrNGzZgrF"},"source":["prev_plotsize = 50\n","\n","for t_i, (i, j) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if pr_list[t_i] >= 1:\n","  #   continue\n","\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1, [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 16]]\n","\n","  #       replace st values with np.nan, using st trend     #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  fig = plt.figure(figsize=(8, 6))\n","  ax = fig.add_subplot(111)\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper\n","  plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower\n","  plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","\n","  plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","  plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  plt.plot(plot_upper_ep.values, alpha=1, linestyle='--')  # ep\n","  plt.plot(plot_lower_ep.values, alpha=1, linestyle='--')  # ep\n","\n","  plt.axvline(prev_plotsize, linestyle='--')\n","\n","  plt.title(\"%s ~ %s -> %.5f\" % (i, j, pr_list[t_i]))\n","  plt.show()\n","  # plt.draw()\n","  plt.close()"],"execution_count":null,"outputs":[]}]}