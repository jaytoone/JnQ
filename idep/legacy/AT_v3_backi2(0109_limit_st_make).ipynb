{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6rmQpzEGXfCw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, sys\n","\n","current_path = '/content/drive/My Drive/Colab Notebooks/JnQ/'\n","\n","os.chdir(current_path)\n","\n","nb_path = '/content/notebooks'\n","try:\n","  sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/JnQ')\n","  sys.path.insert(0, '/content/drive/My Drive/Colab Notebooks/JnQ/funcs')\n","  os.symlink('/content/drive/My Drive/Colab Notebooks/JnQ/mpl_finance', nb_path)\n","  sys.path.insert(0, nb_path)\n","except:\n","  pass"]},{"cell_type":"markdown","metadata":{"id":"8uqYv5StTazo"},"source":["# requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qGt60DKTZmf"},"outputs":[],"source":["# !pip install findiff\n","\n","# import nvstrings, nvcategory, cudf\n","# import cuml\n","# import cudf\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import gridspec\n","from tqdm.notebook import tqdm\n","from funcs.funcs_indicator import *\n","from funcs.funcs_for_trade import *\n","import logging\n","\n","from utils import utils_v3_1216 as utils1\n","from utils import utils_v5_2_1216 as utils2\n","# from utils import utils_v7_3_1231_v7_3 as utils3\n","from utils import utils_public_0106_v7_3_candle2_1 as utils_public\n","\n","import mpl_finance as mf\n","import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","\n","import numpy as np\n","# import jax.numpy as np\n","import pandas as pd\n","import seaborn as sns\n","# import tensorflow as tf\n","\n","import pickle\n","import shutil\n","import json\n","from easydict import EasyDict\n","\n","# from trendln import trendln\n","\n","from datetime import datetime\n","import random\n","import time\n","\n","# mpl.rcParams['figure.figsize'] = (8, 6)\n","# mpl.rcParams['axes.grid'] = False\n","\n","np.seterr(invalid=\"ignore\")\n","\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)"]},{"cell_type":"markdown","metadata":{"id":"M8-EChy0VsDr"},"source":["## cudf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b09qAb1sVtRP"},"outputs":[],"source":["# !conda install -c rapidsai-nightly -c nvidia -c numba -c conda-forge \\\n","#     cudf python=3.7 cudatoolkit=11.1 -t=$nb_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jnz6i7ZqRnb0"},"outputs":[],"source":["# !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/env-check.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sKA_9Dbg4s2"},"outputs":[],"source":["# This will update the Colab environment and restart the kernel.  Don't run the next cell until you see the session crash.\n","!bash rapidsai-csp-utils/colab/update_gcc.sh\n","import os\n","os._exit(00)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1C4pNiBhYHX"},"outputs":[],"source":["# This will install CondaColab.  This will restart your kernel one last time.  Run this cell by itself and only run the next cell once you see the session crash.\n","import condacolab\n","condacolab.install()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGx3ACTvZqck"},"outputs":[],"source":["# you can now run the rest of the cells as normal\n","import condacolab\n","condacolab.check()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oR8s7U8c7C28"},"outputs":[],"source":["# Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n","# The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n","# The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL, \n","!python rapidsai-csp-utils/colab/install_rapids.py stable\n","import os\n","os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n","os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n","os.environ['CONDA_PREFIX'] = '/usr/local'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWsxi4ZpKtGt"},"outputs":[],"source":["import shutil\n","import sys\n","\n","colab_env = \"/usr/lib\"\n","\n","rapids_path = os.path.join(current_path, \"rapidsai-csp-utils/lib\")\n","rapids_libs = os.listdir(rapids_path)\n","print(rapids_libs)\n","# break\n","\n","for lib_ in rapids_libs:\n","  try:\n","    shutil.copy(os.path.join(rapids_path, lib_), os.path.join(colab_env, lib_))\n","    sys.path.append(os.path.join(colab_env, lib_))\n","    print(\"copied to\" + os.path.join(colab_env, lib_))\n","  except Exception as e:\n","    print(e)"]},{"cell_type":"markdown","metadata":{"id":"Iy76iO7gztne"},"source":["## move legacy files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMRht32Czwry"},"outputs":[],"source":["# print()\n","cur_dir_list = os.listdir('.')\n","for f in cur_dir_list:\n","  if 'legacy' in f :\n","    # print(f)\n","    if os.path.isdir(current_path + f,):\n","      continue\n","\n","    shutil.move(current_path + f, current_path + 'legacy/' + f)\n","    print(\"moved to\" + current_path + 'legacy/' +  f)"]},{"cell_type":"markdown","metadata":{"id":"Ic1mfmwWCIBu"},"source":["# makeset"]},{"cell_type":"markdown","metadata":{"id":"Ci_jUnNTZbm9"},"source":["## load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bXyS2yrZYC6"},"outputs":[],"source":["interval = '1m'\n","date_path = './candlestick_concated/%s/quant_v2/' % interval\n","file_list = os.listdir(date_path)\n","print((file_list))\n","\n","interval2 = '3m'\n","date_path2 = './candlestick_concated/%s/quant_v2/' % interval2\n","file_list2 = os.listdir(date_path2)\n","print((file_list2))\n","\n","interval3 = '5m'\n","date_path3 = './candlestick_concated/%s/quant_v2/' % interval3\n","file_list3 = os.listdir(date_path3)\n","print((file_list3))\n","\n","interval4 = '15m'\n","date_path4 = './candlestick_concated/%s/quant_v2/' % interval4\n","file_list4 = os.listdir(date_path4)\n","print((file_list4))\n","\n","interval5 = '30m'\n","date_path5 = './candlestick_concated/%s/quant_v2/' % interval5\n","file_list5 = os.listdir(date_path5)\n","print((file_list5))\n","\n","interval6 = '1h'\n","date_path6 = './candlestick_concated/%s/quant_v2/' % interval6\n","file_list6 = os.listdir(date_path6)\n","print((file_list6))\n","\n","interval7 = '4h'\n","date_path7 = './candlestick_concated/%s/quant_v2/' % interval7\n","file_list7 = os.listdir(date_path7)\n","print((file_list7))\n","\n","interval8 = '1d'\n","date_path8 = './candlestick_concated/%s/quant_v2/' % interval8\n","file_list8 = os.listdir(date_path8)\n","print((file_list8))"]},{"cell_type":"markdown","metadata":{"id":"AUSBU7T8Suzi"},"source":["## basic_func"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmhLikYlSuzi"},"outputs":[],"source":["def sync_check(df, second_df=None, third_df=None, fourth_df=None, fifth_df=None,\n","               sixth_df=None, seventh_df=None, eighth_df=None):\n","\n","    #           supertrend          #\n","    # df = st_price_line(df, second_df, '3m')\n","    # # print(df.head(100))\n","    # # return\n","\n","    # df = st_price_line(df, third_df, '5m')\n","    df = st_price_line(df, fourth_df, '15m')\n","    # df = st_price_line(df, fifth_df, '30m')\n","    # df = st_price_line(df, sixth_df, '1h')\n","    # df = st_price_line(df, seventh_df, '4h')\n","\n","    print(\"supertrend phase done\")\n","\n","    # --------------- rsi --------------- #  \n","    # df['rsi_1m'] = rsi(df, 14)    \n","    # third_df['rsi_5m'] = rsi(third_df, 14)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['rsi_5m']))\n","    \n","    # print(\"rsi phase done\")\n","\n","\n","    # --------------- cci --------------- #  \n","    # df['cci_1m'] = cci(df, 20)\n","\n","    # print(\"cci phase done\")\n","\n","\n","    # --------------- ema --------------- #      \n","    # third_df['ema_5m'] = ema(third_df['close'], 200)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['ema_5m']))\n","    \n","    # print(\"ema phase done\")\n","\n","\n","    # # --------------- dc --------------- #  \n","    # df = dc_line(df, None, '1m', dc_period=20)\n","    # df = dc_line(df, second_df, '3m', dc_period=20)\n","    # df = dc_line(df, third_df, '5m', dc_period=20)\n","    # df = dc_line(df, fourth_df, '15m', dc_period=20)\n","    # df = dc_line(df, fifth_df, '30m', dc_period=20)\n","    # df = dc_line(df, sixth_df, '1h', dc_period=20)\n","    # df = dc_line(df, seventh_df, '4h', dc_period=20)\n","\n","    # print(\"dc phase done\")\n","    \n","    # # --------------- bband --------------- #  \n","    # df = bb_line(df, None, '1m')\n","    # df = bb_line(df, second_df, '3m')\n","    # df = bb_line(df, third_df, '5m')\n","    # df = bb_line(df, fourth_df, '15m')\n","    # df = bb_line(df, fifth_df, '30m')\n","    # df = bb_line(df, sixth_df, '1h')\n","    # df = bb_line(df, seventh_df, '4h')\n","\n","    # print(\"bband phase done\")\n","\n","    # --------------- cbline --------------- #    \n","    # second_df['cloud_bline_3m'] = cloud_bline(second_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['cloud_bline_3m']))\n","    # third_df['cloud_bline_5m'] = cloud_bline(third_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['cloud_bline_5m']))\n","    # fourth_df['cloud_bline_15m'] = cloud_bline(fourth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['cloud_bline_15m']))\n","    # fifth_df['cloud_bline_30m'] = cloud_bline(fifth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['cloud_bline_30m']))\n","    # sixth_df['cloud_bline_1h'] = cloud_bline(sixth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['cloud_bline_1h']))\n","    # seventh_df['cloud_bline_4h'] = cloud_bline(seventh_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['cloud_bline_4h']))\n","\n","    # print(\"cbline phase done\")\n","    \n","\n","    #           lucid sar              #\n","    # df['sar_1m'], df['sar_uptrend_1m'] = lucid_sar(df, return_uptrend=True)\n","\n","    # second_df['sar_3m'], second_df['sar_uptrend_3m'] = lucid_sar(second_df, af_initial=0.01, return_uptrend=True)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-2, -1], backing_i=-2), columns=['sar_3m', 'sar_uptrend_3m']))\n","\n","    # third_df['sar_5m'], third_df['sar_uptrend_5m'] = lucid_sar(third_df, af_initial=0.01, return_uptrend=True)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-2, -1], backing_i=-2), columns=['sar_5m', 'sar_uptrend_5m']))\n","\n","    # fourth_df['sar_15m'], fourth_df['sar_uptrend_15m'] = lucid_sar(fourth_df, af_initial=0.01, return_uptrend=True)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-2, -1], backing_i=-2), columns=['sar_15m', 'sar_uptrend_15m']))\n","\n","    # seventh_df['sar_4h'], seventh_df['sar_uptrend_4h'] = lucid_sar(seventh_df, return_uptrend=True)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-2, -1], backing_i=-2), columns=['sar_4h', 'sar_uptrend_4h']))\n","    \n","    # print(\"sar phase done\")\n","\n","    \n","    #           stochastic              #\n","    # df['stoch_1m'] = stoch(df, 13, 3, 3)\n","\n","    # third_df['stoch'] = stoch(third_df, 13, 3, 3)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1], backing_i=-1), columns=['stoch_5m']))\n","\n","    # print(\"stoch phase done\")\n","\n","\n","    return df\n"]},{"cell_type":"markdown","metadata":{"id":"mEKyVbHWSuzi"},"source":["## make & save res_df (concat 생각하면, timeindex sync 맞춰야함)"]},{"cell_type":"markdown","metadata":{"id":"VdukVo5-Suzj"},"source":["### old (xlsx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khKb9nhlSuzj"},"outputs":[],"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","exist_list = os.listdir(save_path)\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  # if '2021-04-30'.upper() not in file_list[i]:\n","  if '2021-07-01'.upper() not in file_list[i]:\n","  # if '2021-10-10'.upper() not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","\n","    excel_name = key.replace(\".xlsx\", \"_st1h_backi2.xlsx\")\n","    excel_path = save_path + excel_name\n","\n","    if excel_name in exist_list:\n","      print(excel_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    \n","    df = pd.read_excel(date_path + key, index_col=0)\n","    second_df = pd.read_excel(date_path2 + key, index_col=0)\n","    third_df = pd.read_excel(date_path3 + key, index_col=0)\n","    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n","    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n","    \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n","      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","\n","    except Exception as e:\n","      print(e)\n","\n","    latest_open_index = sorted(open_indexes)[-1]\n","    \n","    open_ts = datetime.timestamp(latest_open_index)\n","    latest_open_index_1m = datetime.fromtimestamp(open_ts + a_day)\n","\n","    #   str 로 만들어 접근하면 불가함  #\n","    end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 08:59:59.999000\")\n","    # break\n","\n","    sliced_df = df.loc[latest_open_index_1m:end_index] # to_lower_tf 의 기준 ltf\n","    sliced_second_df = second_df.loc[latest_open_index:end_index]\n","    sliced_third_df = third_df.loc[latest_open_index:end_index]\n","    sliced_fourth_df = fourth_df.loc[latest_open_index:end_index]\n","    sliced_fifth_df = fifth_df.loc[latest_open_index:end_index]\n","\n","    print(\"sliced index\")\n","    print(sliced_df.index[[0, -1]])\n","    print(sliced_second_df.index[[0, -1]])\n","    print(sliced_third_df.index[[0, -1]])\n","    print(sliced_fourth_df.index[[0, -1]])\n","    print(sliced_fifth_df.index[[0, -1]])\n","\n","    try:\n","      sliced_sixth_df = sixth_df.loc[latest_open_index:end_index]\n","      sliced_seventh_df = seventh_df.loc[latest_open_index:end_index]\n","\n","      print(sliced_sixth_df.index[[0, -1]])\n","      print(sliced_seventh_df.index[[0, -1]])\n","\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df, sliced_sixth_df, sliced_seventh_df)\n","    \n","    except:\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df)\n","\n","\n","\n","    res_df.to_excel(excel_path)\n","    print(excel_name, \"saved succesfully !\")"]},{"cell_type":"markdown","metadata":{"id":"Bw5JibDKSuzj"},"source":["### xlsx to feather"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VA-_gcA7Suzj"},"outputs":[],"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","exist_list = os.listdir(save_path)\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  # if '2021-04-30'.upper() not in file_list[i]:\n","  # if '2021-07-01'.upper() not in file_list[i]:\n","  if '2021-10-10'.upper() not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","\n","    feather_name = key.replace(\".xlsx\", \".ftr\")\n","    # feather_path = save_path + feather_name\n","\n","    if feather_name in exist_list:\n","      print(feather_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    \n","    df = pd.read_excel(date_path + key, index_col=0)\n","    second_df = pd.read_excel(date_path2 + key, index_col=0)\n","    third_df = pd.read_excel(date_path3 + key, index_col=0)\n","    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n","    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n","    \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n","      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","\n","    except Exception as e:\n","      print(e)\n","\n","\n","    df.reset_index().to_feather(date_path + feather_name, compression='lz4')\n","    second_df.reset_index().to_feather(date_path2 + feather_name, compression='lz4')\n","    third_df.reset_index().to_feather(date_path3 + feather_name, compression='lz4')\n","    fourth_df.reset_index().to_feather(date_path4 + feather_name, compression='lz4')\n","    fifth_df.reset_index().to_feather(date_path5 + feather_name, compression='lz4')\n","    sixth_df.reset_index().to_feather(date_path6 + feather_name, compression='lz4')\n","    seventh_df.reset_index().to_feather(date_path7 + feather_name, compression='lz4')\n","\n","    print(\"xlsx converted to feather !\")\n","    "]},{"cell_type":"markdown","metadata":{"id":"Pe0QpnORSuzk"},"source":["### add itv_name to ftr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-gl30KxSuzk"},"outputs":[],"source":["save_path = './candlestick_concated/res_df/'\n","\n","# dir_path = \"bbdc3m_backi2\"\n","# date = '2021-10-10'\n","date = '2021-07-01'\n","\n","db_path = './candlestick_concated/database_bn/non_cum/%s/' % date\n","os.makedirs(os.path.join(db_path), exist_ok=True)\n","\n","# exist_list = os.listdir(os.path.join(save_path, dir_path))\n","# break\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  if date not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","    # print(key)\n","    \n","    if \".ftr\" not in key:\n","      continue\n","        \n","    df = shutil.copy(date_path + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval))\n","    second_df = shutil.copy(date_path2 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval2))\n","    third_df = shutil.copy(date_path3 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval3))\n","    fourth_df = shutil.copy(date_path4 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval4))\n","    fifth_df = shutil.copy(date_path5 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval5))\n","    sixth_df = shutil.copy(date_path6 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval6))\n","    seventh_df = shutil.copy(date_path7 + key, db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval7))\n","\n","    print(\"copied to\" + db_path + key.replace(\".ftr\", \"_%s.ftr\" % interval))\n"]},{"cell_type":"markdown","metadata":{"id":"4oZ1ohTtSuzk"},"source":["### feather ver."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgVHpnUsSuzk"},"outputs":[],"source":["# db_path = './candlestick_concated/database_ub/' # upbit\n","db_path = './candlestick_concated/database_bn/'   # binance\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","save_dir_path = \"st15m_backi2\"\n","\n","date = '2021-11-17'\n","\n","data_path = os.path.join(db_path, \"cum\", date) \n","save_path = os.path.join(save_path, save_dir_path, 'noncat/cum', date)\n","os.makedirs(save_path, exist_ok=True)\n","\n","file_list = os.listdir(data_path)\n","exist_list = os.listdir(save_path)\n","# break\n","\n","interval = '1m'\n","interval2 = '3m'\n","interval3 = '5m'\n","interval4 = '15m'\n","interval5 = '30m'\n","interval6 = '1h'\n","interval7 = '4h'\n","interval8 = '1d'\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  if date not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","    # print(key)\n","    \n","    if \".ftr\" not in key:\n","      continue\n","\n","    if \"_1m\" not in key:\n","      continue\n","\n","    # feather_name = key.replace(\".ftr\", \"_%.ftr\" % save_dir_path)\n","    feather_name = key.replace(\"_1m\", \"\")\n","    feather_path = os.path.join(save_path, feather_name)\n","\n","    if feather_name in exist_list:\n","      print(feather_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    end_indexes = []\n","    \n","    df = pd.read_feather(os.path.join(data_path, key), columns=None, use_threads=True).set_index(\"index\")\n","    second_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval2)), columns=None, use_threads=True).set_index(\"index\")\n","    third_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval3)), columns=None, use_threads=True).set_index(\"index\")\n","    fourth_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval4)), columns=None, use_threads=True).set_index(\"index\")\n","    fifth_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval5)), columns=None, use_threads=True).set_index(\"index\")\n","        \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    end_indexes.append(df.index[-1])\n","    end_indexes.append(second_df.index[-1])\n","    end_indexes.append(third_df.index[-1])\n","    end_indexes.append(fourth_df.index[-1])\n","    end_indexes.append(fifth_df.index[-1])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval6)), columns=None, use_threads=True).set_index(\"index\")\n","      seventh_df = pd.read_feather(os.path.join(data_path, key.replace(interval, interval7)), columns=None, use_threads=True).set_index(\"index\")\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","      end_indexes.append(sixth_df.index[-1])\n","      end_indexes.append(seventh_df.index[-1])\n","\n","    except Exception as e:\n","      print(e)\n","\n","    latest_open_index = sorted(open_indexes)[-1]\n","    recent_end_index = sorted(end_indexes)[0]\n","    \n","    open_ts = datetime.timestamp(latest_open_index)\n","    latest_open_index_1m = datetime.fromtimestamp(open_ts + a_day)\n","\n","    end_ts = datetime.timestamp(recent_end_index)\n","    recent_end_index_1m = datetime.fromtimestamp(end_ts - a_day)\n","\n","    #   str 로 만들어 접근하면 불가함  #\n","    #   latest_open_index_1m 은 latest_open_index 보다 크기만 하면 됨   # (9:00:00 교체 필요없이)\n","    if \"999000\" in str(df.index[-1]):\n","      # end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 08:59:59.999000\")\n","      end_index = pd.to_datetime(str(recent_end_index_1m).split(\" \")[0] + \" 08:59:59.999000\")\n","    else:\n","      # end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 09:00:00\")\n","      end_index = pd.to_datetime(str(recent_end_index_1m).split(\" \")[0] + \" 09:00:00\")\n","      # end_index = pd.to_datetime(\"2021-11-15\" + \" 09:00:00\")\n","\n","    #   ***** 1m open_idx 는 htf 보다 커야함 --> to_lower_tf 를 사용하기 위함임   #\n","    sliced_df = df.loc[latest_open_index_1m:end_index] # to_lower_tf 의 기준 ltf\n","\n","    sliced_second_df = second_df.loc[latest_open_index:end_index]\n","    sliced_third_df = third_df.loc[latest_open_index:end_index]\n","    sliced_fourth_df = fourth_df.loc[latest_open_index:end_index]\n","    sliced_fifth_df = fifth_df.loc[latest_open_index:end_index]\n","\n","    print(\"sliced index\")\n","    print(sliced_df.index[[0, -1]])\n","    print(sliced_second_df.index[[0, -1]])\n","    print(sliced_third_df.index[[0, -1]])\n","    print(sliced_fourth_df.index[[0, -1]])\n","    print(sliced_fifth_df.index[[0, -1]])\n","\n","    try:\n","      sliced_sixth_df = sixth_df.loc[latest_open_index:end_index]\n","      sliced_seventh_df = seventh_df.loc[latest_open_index:end_index]\n","\n","      print(sliced_sixth_df.index[[0, -1]])\n","      print(sliced_seventh_df.index[[0, -1]])\n","\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df, sliced_sixth_df, sliced_seventh_df)\n","    \n","    except:\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df)\n","\n","\n","\n","    # res_df.to_feather(feather_path)\n","    res_df.reset_index().to_feather(feather_path, compression='lz4')\n","    print(feather_path, \"saved succesfully !\")"]},{"cell_type":"markdown","metadata":{"id":"jTN3M842Suzl"},"source":["## concat & save new res_df"]},{"cell_type":"markdown","metadata":{"id":"MlFkpO1MSuzl"},"source":["### old (xlsx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-3QkfbFSuzl"},"outputs":[],"source":["save_path = './candlestick_concated/res_df/'\n","\n","dict_name = \"2021-07-01 ETHUSDT_bb15m_backi2_res_dfs.pkl\"\n","\n","#     load with pickle    #\n","with open(save_path + dict_name, 'rb') as f:\n","  saved_res_df_dict = pickle.load(f)\n","\n","print(dict_name, \"loaded !\")\n","res_df_files = os.listdir(save_path)\n","res_df_files.reverse()\n","\n","print(res_df_files)\n","\n","res_df_dict = {}\n","\n","base_postfix = '_bb15m_backi2.xlsx'\n","new_postfix = '_st1h_backi2.xlsx'\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for k_i, key in enumerate(res_df_files):\n","\n","  if '2021-07-01'.upper() not in key:\n","  # if '2021-10-10'.upper() not in key:\n","    continue\n","\n","  # if \"link\".upper() not in key:\n","  # if \"btc\".upper() not in key:\n","  #   continue\n","\n","  if new_postfix not in key:\n","    continue\n","\n","  # if key in \n","\n","  if sample_cnt == max_cnt:\n","    dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n","    print(\"dict_name :\", dict_name)\n","\n","  base_df = saved_res_df_dict[key.replace(new_postfix, base_postfix)]\n","  # base_df = pd.read_excel(save_path + key.replace(new_postfix, base_postfix), index_col=0)  \n","  res_df = pd.read_excel(save_path + key, index_col=0)  \n","\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n","  # new_res_df.head()\n","\n","  droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  droped_new_res_df.head()\n","  # break\n","\n","  # res_df_dict[key] = res_df\n","  res_df_dict[key] = droped_new_res_df\n","  print(key, \"saved to dict !\")\n","\n","  #     save with pickle    #\n","  with open(save_path + dict_name, 'wb') as f:\n","    pickle.dump(res_df_dict, f)\n","\n","  sample_cnt -= 1\n","\n","  if sample_cnt <= 0:\n","    break\n"]},{"cell_type":"markdown","metadata":{"id":"t1E_eAyPSuzm"},"source":["### new col to latest feather (1m_indi. only)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyI5NrM7Suzm"},"outputs":[],"source":["save_path = './candlestick_concated/res_df/'\n","\n","cum_dir = \"cum\"\n","\n","new_dir_path = \"rsi_backi2\"\n","base_dir_path = \"bbdc3m_backi2\"\n","\n","new_date = '2021-11-17'\n","\n","\n","\n","#     load ftr list    #\n","base_save_path = os.path.join(save_path, base_dir_path, \"concat/cum\", new_date)\n","new_save_path = base_save_path.replace(base_dir_path, new_dir_path)\n","\n","#     save to (new) cum dir    #\n","#      1. if dir. not exists, makedir\n","os.makedirs(new_save_path, exist_ok=True)\n","\n","ftr_list = [s for s in os.listdir(base_save_path) if \"ftr\" in s]\n","print(ftr_list)\n","# break\n","\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for key in ftr_list:\n","\n","  if new_date not in key:\n","    continue\n","\n","\n","  #       read from base postfix's directory    #\n","  base_df = pd.read_feather(os.path.join(base_save_path, key), columns=None, use_threads=True).set_index(\"index\")\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  droped_new_res_df = sync_check(base_df)\n","\n","  # new_res_df = pd.concat([base_df, res_df], axis=0) # df_tot.drop_duplicates()\n","  # # new_res_df.head()\n","\n","  # intersection_cols = res_df.columns.intersection(base_df.columns)\n","\n","  # droped_new_res_df = new_res_df.loc[~new_res_df.index.duplicated(keep='last'),intersection_cols]\n","  # droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  # droped_new_res_df = new_res_df.loc[:,~new_res_df.index.duplicated(keep='last')]\n","  # droped_new_res_df.head()\n","  # break\n","\n","  droped_new_res_df.reset_index().to_feather(os.path.join(new_save_path, key), compression='lz4')\n","\n","  print(os.path.join(new_save_path, key), \"saved !\")\n","\n","  # sample_cnt -= 1\n","\n","  # if sample_cnt <= 0:\n","  #   break\n"]},{"cell_type":"markdown","metadata":{"id":"nUs4fjVHSuzl"},"source":["### feather ver. (col concat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cu-Y82iSuzl"},"outputs":[],"source":["new_dir_path = \"st15m_backi2\"\n","base_dir_path = \"sar2_backi2\"\n","\n","# new_date = \"2021-07-01\"\n","new_date = \"2021-11-17\"\n","\n","#     save to (new) concat dir    #\n","#      1. if dir. not exists, makedir\n","save_path = './candlestick_concated/res_df/'\n","save_path = os.path.join(save_path, new_dir_path, \"concat/cum\", new_date)\n","os.makedirs(save_path, exist_ok=True)\n","\n","\n","#     load ftr list    #\n","# ftr_list = [s for s in os.listdir(os.path.join(save_path, new_dir_path)) if \"ftr\" in s]\n","\n","noncat_path = save_path.replace(\"concat/\", \"noncat/\")\n","ftr_list = [s for s in os.listdir(noncat_path) if \"ftr\" in s]\n","print(ftr_list)\n","# break\n","\n","\n","for key in ftr_list:\n","\n","  if new_date not in key:\n","    continue\n","\n","  #       read from base postfix's directory    #\n","  base_df = pd.read_feather(os.path.join(save_path.replace(new_dir_path, base_dir_path), key), columns=None, use_threads=True).set_index(\"index\")\n","  res_df = pd.read_feather(os.path.join(noncat_path, key), columns=None, use_threads=True).set_index(\"index\")\n","\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n","  # new_res_df.head()\n","\n","  droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  # droped_new_res_df.head()\n","  # break\n","\n","  droped_new_res_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n","\n","  # res_df_dict[key] = res_df\n","  # res_df_dict[key] = droped_new_res_df\n","  print(os.path.join(save_path, key), \"saved !\")\n","  \n","\n","  # sample_cnt -= 1\n","\n","  # if sample_cnt <= 0:\n","  #   break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GiF2NJPSuzm"},"outputs":[],"source":["droped_new_res_df.columns"]},{"cell_type":"markdown","metadata":{"id":"WVAKq3i8Suzm"},"source":["### feather ver. (row concat) , database cum 도 호환가능"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XG2p9OhhSuzm"},"outputs":[],"source":["save_path = './candlestick_concated/res_df/'\n","save_path = './candlestick_concated/database_bn/'\n","\n","new_date = '2021-11-17'\n","# base_date = '2021-10-10'\n","base_date = '2021-07-01'\n","\n","#     load ftr list    #\n","if \"database\" in save_path:\n","  dir_path = \"\"\n","  concat_dir = \"\"\n","else:\n","  dir_path = \"bbdc3m_backi2\"\n","  concat_dir = \"concat\"\n","\n","# base_date_path = os.path.join(save_path, dir_path, concat_dir, \"cum\", base_date)    # --> base 도 non_cum 가능함\n","base_date_path = os.path.join(save_path, dir_path, concat_dir, \"non_cum\", base_date)    # --> base 도 non_cum 가능함\n","# new_date_path = os.path.join(save_path, dir_path, concat_dir, \"non_cum\", new_date)\n","new_date_path = os.path.join(save_path, dir_path, concat_dir, \"cum\", new_date)    # --> cum 가능함\n","  \n","\n","\n","#     save to (new) concat dir    #\n","#      1. if dir. not exists, makedir\n","save_path = new_date_path.replace(\"non_cum\", \"cum\")\n","os.makedirs(save_path, exist_ok=True)   # noncat / concat 두가지 경우 존재가능할 것\n","# os.makedirs(os.path.join(save_path, dir_path, \"noncat/cum\", new_date), exist_ok=True)\n","\n","\n","ftr_list = [s for s in os.listdir(new_date_path) if \"ftr\" in s]\n","exist_list = os.listdir(save_path)\n","print(ftr_list)\n","# break\n","\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for key in ftr_list:\n","\n","  if new_date not in key:\n","    continue\n","\n","  # if key in exist_list:\n","  #   print(key, \"already exist !\")\n","  #   continue\n","\n","  #       read from base postfix's directory    #\n","  base_df = pd.read_feather(os.path.join(base_date_path, key.replace(new_date, base_date)), columns=None, use_threads=True).set_index(\"index\")\n","  res_df = pd.read_feather(os.path.join(new_date_path, key), columns=None, use_threads=True).set_index(\"index\")\n","\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  new_res_df = pd.concat([base_df, res_df], axis=0) # df_tot.drop_duplicates()\n","  # new_res_df.head()\n","\n","  intersection_cols = res_df.columns.intersection(base_df.columns)\n","\n","  droped_new_res_df = new_res_df.loc[~new_res_df.index.duplicated(keep='last'),intersection_cols]\n","  # droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  # droped_new_res_df = new_res_df.loc[:,~new_res_df.index.duplicated(keep='last')]\n","  # droped_new_res_df.head()\n","  # break\n","  \n","  interval = key.split(\".\")[0].split(\"_\")[-1] \n","  itv_num = to_itvnum(interval)\n","\n","  # verified_df = consecutive_df(droped_new_res_df, to_itvnum(interval))\n","\n","  # verified_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n","\n","  # res_df_dict[key] = res_df\n","  # res_df_dict[key] = droped_new_res_df\n","  \n","  print(droped_new_res_df.iloc[[0, -1]])\n","\n","  np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), droped_new_res_df.index)))\n","  ideal_ts_gap = 60 * itv_num\n","\n","  for ts_i in range(len(np_idx_ts)):\n","    \n","    if ts_i != 0:\n","      ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n","\n","      if ts_gap > ideal_ts_gap or ts_gap < ideal_ts_gap:\n","      # if ts_gap == ideal_ts_gap:\n","        print(droped_new_res_df.index[ts_i - 1])\n","        print(droped_new_res_df.index[ts_i])\n","        # print(ts_gap)\n","        print(\"-------------------- unideal ts_gap --------------------\")\n","\n","  droped_new_res_df.reset_index().to_feather(os.path.join(save_path, key), compression='lz4')\n","\n","  print(os.path.join(save_path, key), \"saved !\")\n","  \n","\n","  # sample_cnt -= 1\n","\n","  # if sample_cnt <= 0:\n","  #   break\n"]},{"cell_type":"markdown","metadata":{"id":"L7l5CTJfSuzn"},"source":["### check continuity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGzMGyC3Suzn"},"outputs":[],"source":["# print(droped_new_res_df.columns)\n","\n","print(droped_new_res_df.iloc[[0, -1]])\n","\n","np_idx_ts = np.array(list(map(lambda x: datetime.timestamp(x), droped_new_res_df.index)))\n","\n","print(np_idx_ts[:10])\n","for ts_i in range(len(np_idx_ts)):\n","  \n","  if ts_i != 0:\n","    ts_gap = np_idx_ts[ts_i] - np_idx_ts[ts_i - 1]\n","\n","    if ts_gap > 60 or ts_gap < 60:\n","    # if ts_gap == 60:\n","      print(droped_new_res_df.index[ts_i - 1])\n","      print(droped_new_res_df.index[ts_i])\n","      # print(ts_gap)\n","      print()\n"]},{"cell_type":"markdown","metadata":{"id":"qNGeuYuGDXfv"},"source":["# pr check with strategy"]},{"cell_type":"markdown","metadata":{"id":"6HOjnZjSgzk1"},"source":["## load ftr_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FPBG5Qqg2jB"},"outputs":[],"source":["save_path = './candlestick_concated/res_df/'\n","\n","dir_path = \"sar2_backi2\"\n","\n","date = \"2021-11-17\"\n","\n","ftr_path = os.path.join(save_path, dir_path, \"concat/cum\", date)\n","\n","#     load ftr list    #\n","ftr_list = [s for s in os.listdir(ftr_path) if \"ftr\" in s if date in s]\n","# ftr_list = [s for s in os.listdir(os.path.join(save_path, dir_path)) if \"ftr\" in s if date in s]\n","print(ftr_list)"]},{"cell_type":"markdown","metadata":{"id":"5duWn8t4BRyv"},"source":["## hvp platform"]},{"cell_type":"markdown","metadata":{"id":"wmnyUTS-yjF1"},"source":["##### config"]},{"cell_type":"markdown","metadata":{"id":"JjKHyqftzhD7"},"source":["###### set config (override available)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_4E-zH02WJy"},"outputs":[],"source":["#     caution : MARKET / LIMIT spelling   #\n","#      json doesn't support single quotes     #\n","\n","param_dict = \\\n","{\n","  \"strat_version\": \"v3\",\n","  \"trader_set\": {\n","    \"run\": 1,\n","    \"df_log\": 0,\n","    \"last_index\": -2,\n","    \"limit_fee\": 0.0002,\n","    \"market_fee\": 0.0004,\n","    \"initial_asset\": 3000,\n","    \"asset_changed\": 0,\n","    \"symbol\": \"ETHUSDT\",\n","    \"symbol_changed\": 0,\n","    \"interval_list\": [\n","      \"1m\",\n","      \"5m\",\n","      \"15m\"\n","    ],\n","    \"row_list\": [\n","      200,\n","      100,\n","      100\n","    ],\n","    \"bar_close_second\": 59,\n","    \"realtime_term\": 0.01,\n","    \"api_retry_term\": 3,\n","    \"check_entry_sec\": 10,\n","    \"entry_execution_wait\": 60,\n","    \"breakout_qty_ratio\": 0.97,\n","    \"qty_check_term\": 30,\n","    \"exit_execution_wait\": 60,\n","    \"close_complete_term\": 5,\n","    \"save_stacked_df\": 0,\n","    \"stacked_df_exist\": 1\n","  },\n","  \"pos_set\": {\n","    \"short_inversion\": 0,\n","    \"long_inversion\": 0,\n","    \"short_ban\": 1,\n","    \"long_ban\": 0\n","  },\n","  \"loc_set\": {\n","    \"zone\": {\n","      \"short_spread\": 0.915,\n","      \"long_spread\": 0.953,\n","      \"tr_thresh\": \"None\",\n","      \"dtk_dc_itv\": \"None\",\n","      \"dtk_itv\": \"5m\",\n","      \"dt_k\": 0.22,\n","      \"dc_period\": 135,\n","      \"ei_k\": 0.135,\n","      \"use_dtk_line\": 0,\n","      \"zone_rejection\": 0,\n","      \"gap_mply\": 1,\n","      \"c_itv_ticks\": 60,\n","      \"ad_idx\": 19,\n","      \"bbz_itv\": \"None\",\n","      \"zone_dt_k\": 0.4,\n","      \"zone_dc_period\": 135,\n","      \"dr_error\": 0.1,\n","      \"bbwp_thresh\": 0.5,\n","      \"entry_incycle\": 5,\n","      \"max_eplim_pct\": 0.05,\n","      \"min_eplim_pct\": 0.013\n","    },\n","    \"point\": {\n","      \"exp_itv\": \"5m\",\n","      \"tpg_itv1\": \"5m\",\n","      \"tpg_itv0\": \"5m\",\n","      \"outg_itv1\": \"5m\",\n","      \"outg_itv0\": \"5m\",\n","      \"outg_dc_period\": \"None\",\n","      \"tf_entry\": 1,\n","      \"htf_entry\": 15,\n","      \"candle_ratio\": 40,\n","      \"body_ratio\": \"None\",\n","      \"candle_ratio2\": \"None\",\n","      \"body_ratio2\": \"None\",\n","      \"osc_band\": 20\n","    }\n","  },\n","  \"tr_set\": {\n","    \"ep_gap\": 0.083,\n","    \"tp_gap\": 0.36,\n","    \"decay_gap\": \"None\",\n","    \"out_gap\": -0.5,\n","    \"c_ep_gap\": 0.232,\n","    \"t_out_gap\": -0.5\n","  },\n","  \"ep_set\": {\n","    \"short_entry_score\": -2,\n","    \"entry_type\": \"LIMIT\",\n","    \"static_ep\": 1,\n","    \"tpout_onexec\": 0\n","  },\n","  \"tp_set\": {\n","    \"non_tp\": 0,\n","    \"tp_type\": \"LIMIT\",\n","    \"static_tp\": 1,\n","    \"decay_term\": 60,\n","    \"time_tp\": 0,\n","    \"partial_num\": 1,\n","    \"partial_qty_divider\": 1.5\n","  },\n","  \"out_set\": {\n","    \"out_type\": \"MARKET\",\n","    \"use_out\": 1,\n","    \"static_out\": 1,\n","    \"hl_out\": 1,\n","    \"price_restoration\": 0,\n","    \"retouch\": 0,\n","    \"retouch_out_period\": 500,\n","    \"second_out\": 0,\n","    \"approval_st_gap\": 1.5,\n","    \"second_out_gap\": 0.5\n","  },\n","  \"lvrg_set\": {\n","    \"leverage\": 2,\n","    \"static_lvrg\": 0,\n","    \"allow_float\": 0,\n","    \"target_pct\": 0.12,\n","    \"lvrg_rejection\": 0\n","  }\n","}\n","\n","config1 = EasyDict(param_dict)\n","# param_json = json.dumps(param_dict, indent=2)"]},{"cell_type":"markdown","metadata":{"id":"dzla8i9_ysmP"},"source":["###### save config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlNGKvW_w2za"},"outputs":[],"source":["config_name = \"config_v5_2.1220_candlejson\"\n","# config_name = \"config_v3.json\"\n","cfg_full_path = os.path.join(current_path, \"config\", config_name)\n","\n","\n","with open(cfg_full_path, 'w') as cfg:\n","    json.dump(config1, cfg, indent=2)\n","    print(\"{} dumped !\".format(cfg_full_path))"]},{"cell_type":"markdown","metadata":{"id":"vOVr2jLczFQJ"},"source":["###### load config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPpMThtZzGtZ"},"outputs":[],"source":["config1_name = \"config_v3_1231_v7_3.json\"\n","config2_name = \"config_v5_2_1231_v7_3.json\"\n","config3_name = \"config_v7_3_1231_v7_3.json\"\n","cfg_full_path1 = os.path.join(current_path, \"config\", config1_name)\n","cfg_full_path2 = os.path.join(current_path, \"config\", config2_name)\n","cfg_full_path3 = os.path.join(current_path, \"config\", config3_name)\n","\n","with open(cfg_full_path1, 'r') as cfg:\n","    config1 = EasyDict(json.load(cfg))\n","with open(cfg_full_path2, 'r') as cfg:\n","    config2 = EasyDict(json.load(cfg))\n","with open(cfg_full_path3, 'r') as cfg:\n","    config3 = EasyDict(json.load(cfg))\n","  \n","print(config1.strat_version)\n","print(config2.strat_version)\n","print(config3.strat_version)"]},{"cell_type":"markdown","metadata":{"id":"rrIGjmUzqU-D"},"source":["##### utils override"]},{"cell_type":"markdown","metadata":{"id":"leSQlImg4_9L"},"source":["###### utils_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CB2yZdQ95Cdg"},"outputs":[],"source":["\n","def enlist_rtc(res_df, config):\n","\n","    strat_version = config.strat_version\n","\n","    res_df['short_rtc_1_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.point.outg_itv1]\n","    res_df['short_rtc_0_{}'.format(strat_version)] = res_df['bb_upper_%s' % config.loc_set.point.outg_itv0]\n","\n","    res_df['long_rtc_1_{}'.format(strat_version)] = res_df['bb_upper_%s' % config.loc_set.point.outg_itv1]\n","    res_df['long_rtc_0_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.point.outg_itv0]\n","    \n","    #      entry reversion    #\n","    if config.ep_set.short_entry_score > 0:      \n","      short_rtc_1_copy = res_df['short_rtc_1_{}'.format(strat_version)].copy()\n","      res_df['short_rtc_1_{}'.format(strat_version)] = res_df['long_rtc_1_{}'.format(strat_version)]\n","      res_df['long_rtc_1_{}'.format(strat_version)] = short_rtc_1_copy\n","\n","      short_rtc_0_copy = res_df['short_rtc_0_{}'.format(strat_version)].copy()\n","      res_df['short_rtc_0_{}'.format(strat_version)] = res_df['long_rtc_0_{}'.format(strat_version)]\n","      res_df['long_rtc_0_{}'.format(strat_version)] = short_rtc_0_copy\n","\n","    res_df['short_rtc_gap_{}'.format(strat_version)] = abs(res_df['short_rtc_0_{}'.format(strat_version)] - res_df['short_rtc_1_{}'.format(strat_version)])\n","    res_df['long_rtc_gap_{}'.format(strat_version)] = abs(res_df['long_rtc_1_{}'.format(strat_version)] - res_df['long_rtc_0_{}'.format(strat_version)])\n","\n","    res_df['h_short_rtc_1_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.point.tpg_itv1]\n","    # res_df['h_short_rtc_1_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.point.tpg_itv]\n","    res_df['h_short_rtc_0_{}'.format(strat_version)] = res_df['bb_upper_%s' % config.loc_set.point.tpg_itv0]\n","\n","    res_df['h_long_rtc_1_{}'.format(strat_version)] = res_df['bb_upper_%s' % config.loc_set.point.tpg_itv1]\n","    # res_df['h_long_rtc_1_{}'.format(strat_version)] = res_df['dc_upper_%s' % config.loc_set.point.tpg_itv]\n","    res_df['h_long_rtc_0_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.point.tpg_itv0]\n","\n","    #      entry reversion    #\n","    if config.ep_set.short_entry_score > 0:      \n","      h_short_rtc_1_copy = res_df['h_short_rtc_1_{}'.format(strat_version)].copy()\n","      res_df['h_short_rtc_1_{}'.format(strat_version)] = res_df['h_long_rtc_1_{}'.format(strat_version)]\n","      res_df['h_long_rtc_1_{}'.format(strat_version)] = h_short_rtc_1_copy\n","\n","      h_short_rtc_0_copy = res_df['h_short_rtc_0_{}'.format(strat_version)].copy()\n","      res_df['h_short_rtc_0_{}'.format(strat_version)] = res_df['h_long_rtc_0_{}'.format(strat_version)]\n","      res_df['h_long_rtc_0_{}'.format(strat_version)] = h_short_rtc_0_copy\n","\n","    res_df['h_short_rtc_gap_{}'.format(strat_version)] = abs(res_df['h_short_rtc_0_{}'.format(strat_version)] - res_df['h_short_rtc_1_{}'.format(strat_version)])\n","    res_df['h_long_rtc_gap_{}'.format(strat_version)] = abs(res_df['h_long_rtc_1_{}'.format(strat_version)] - res_df['h_long_rtc_0_{}'.format(strat_version)])   \n","\n","    res_df['short_dtk_1_{}'.format(strat_version)] = res_df['bb_lower_%s' % config.loc_set.zone.dtk_itv]\n","    res_df['short_dtk_0_{}'.format(strat_version)] = res_df['dc_upper_%s' % config.loc_set.zone.dtk_itv]\n","\n","    res_df['long_dtk_1_{}'.format(strat_version)] = res_df['bb_upper_%s' % config.loc_set.zone.dtk_itv]\n","    res_df['long_dtk_0_{}'.format(strat_version)] = res_df['dc_lower_%s' % config.loc_set.zone.dtk_itv]\n","\n","    res_df['short_dtk_gap_{}'.format(strat_version)] = abs(res_df['short_dtk_0_{}'.format(strat_version)] - res_df['short_dtk_1_{}'.format(strat_version)])\n","    res_df['long_dtk_gap_{}'.format(strat_version)] = abs(res_df['long_dtk_1_{}'.format(strat_version)] - res_df['long_dtk_0_{}'.format(strat_version)])\n","\n","    return res_df\n","\n","\n","def enlist_tr(res_df, config, np_timeidx):\n","\n","    strat_version = config.strat_version\n","\n","    res_df['entry_{}'.format(strat_version)] = np.zeros(len(res_df))\n","    res_df['h_entry_{}'.format(strat_version)] = np.zeros(len(res_df))\n","\n","    # -------- set ep level -------- #\n","\n","    #       limit ver.     #\n","    res_df['short_ep_{}'.format(strat_version)] = res_df['short_rtc_1_{}'.format(strat_version)] + res_df['short_rtc_gap_{}'.format(strat_version)] * config.tr_set.ep_gap\n","    res_df['long_ep_{}'.format(strat_version)] = res_df['long_rtc_1_{}'.format(strat_version)] - res_df['long_rtc_gap_{}'.format(strat_version)] * config.tr_set.ep_gap\n","\n","    # res_df['short_ep_{}'.format(strat_version)] = res_df['close'] + res_df['h_short_rtc_gap_{}'.format(strat_version)] * config.tr_set.ep_gap\n","    # res_df['long_ep_{}'.format(strat_version)] = res_df['close'] - res_df['h_long_rtc_gap_{}'.format(strat_version)] * config.tr_set.ep_gap\n","\n","\n","    if config.tr_set.c_ep_gap != \"None\":\n","        res_df['short_ep_org_{}'.format(strat_version)] = res_df['short_ep_{}'.format(strat_version)].copy()\n","        res_df['long_ep_org_{}'.format(strat_version)] = res_df['long_ep_{}'.format(strat_version)].copy()\n","\n","        res_df['short_ep2_{}'.format(strat_version)] = res_df['h_short_rtc_1_{}'.format(strat_version)] + res_df['h_short_rtc_gap_{}'.format(strat_version)] * config.tr_set.c_ep_gap\n","        res_df['long_ep2_{}'.format(strat_version)] = res_df['h_long_rtc_1_{}'.format(strat_version)] - res_df['h_long_rtc_gap_{}'.format(strat_version)] * config.tr_set.c_ep_gap\n","\n","    res_df['short_spread_ep_{}'.format(strat_version)] = res_df['bb_lower_5m'] #+ res_df['h_short_rtc_gap_{}'.format(strat_version)] * config.loc_set.zone.spread_ep_gap\n","    res_df['long_spread_ep_{}'.format(strat_version)] = res_df['bb_upper_5m']  #- res_df'h_long_rtc_gap_{}'.format(strat_version)] * config.loc_set.zone.spread_ep_gap\n","\n","    #       market ver.     #\n","    if config.ep_set.entry_type == \"MARKET\":\n","        res_df['short_ep_{}'.format(strat_version)] = res_df['close']\n","        res_df['long_ep_{}'.format(strat_version)] = res_df['close']\n","\n","    # ---------------------------------------- short = -1 ---------------------------------------- #\n","    # ---------------- ep_time  ---------------- #\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['bb_lower_%s' % config.loc_set.point.exp_itv]) &\n","    res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] >= res_df['bb_lower_%s' % config.loc_set.point.exp_itv]) &\n","                              # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['bb_lower_%s' % config.loc_set.point.exp_itv]) &\n","                              (res_df['close'] < res_df['bb_lower_%s' % config.loc_set.point.exp_itv])\n","                              , res_df['entry_{}'.format(strat_version)] - 1, res_df['entry_{}'.format(strat_version)])\n","\n","    res_df['entry_{}'.format(strat_version)] = np.where((res_df['entry_{}'.format(strat_version)] < 0) &\n","                              (np_timeidx % config.loc_set.point.tf_entry == (config.loc_set.point.tf_entry - 1))\n","                              , res_df['entry_{}'.format(strat_version)] - 1, res_df['entry_{}'.format(strat_version)])\n","    \n","    res_df['h_entry_{}'.format(strat_version)] = np.where(  # (res_df['open'] >= res_df['bb_lower_%s' % config.loc_set.zone.dtk_itv]) &\n","        (res_df['close'].shift(config.loc_set.point.htf_entry * 1) >= res_df['bb_lower_%s' % config.loc_set.zone.dtk_itv]) &\n","        (res_df['close'] < res_df['bb_lower_%s' % config.loc_set.zone.dtk_itv]) &\n","        (np_timeidx % config.loc_set.point.htf_entry == (config.loc_set.point.htf_entry - 1))\n","        , res_df['h_entry_{}'.format(strat_version)] - 1, res_df['h_entry_{}'.format(strat_version)])\n","\n","    # ---------------------------------------- long = 1 ---------------------------------------- #\n","    # ---------------------- ep_time ---------------------- #\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['bb_upper_%s' % config.loc_set.point.exp_itv]) &\n","    res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] <= res_df['bb_upper_%s' % config.loc_set.point.exp_itv]) &\n","                              # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['bb_upper_%s' % config.loc_set.point.exp_itv]) &\n","                              (res_df['close'] > res_df['bb_upper_%s' % config.loc_set.point.exp_itv])\n","                              , res_df['entry_{}'.format(strat_version)] + 1, res_df['entry_{}'.format(strat_version)])\n","\n","    res_df['entry_{}'.format(strat_version)] = np.where((res_df['entry_{}'.format(strat_version)] > 0) &\n","                              (np_timeidx % config.loc_set.point.tf_entry == (config.loc_set.point.tf_entry - 1))\n","                              , res_df['entry_{}'.format(strat_version)] + 1, res_df['entry_{}'.format(strat_version)])\n","    \n","    res_df['h_entry_{}'.format(strat_version)] = np.where(  # (res_df['open'] <= res_df['bb_upper_%s' % config.loc_set.zone.dtk_itv]) &\n","        (res_df['close'].shift(config.loc_set.point.htf_entry * 1) <= res_df['bb_upper_%s' % config.loc_set.zone.dtk_itv]) &\n","        (res_df['close'] > res_df['bb_upper_%s' % config.loc_set.zone.dtk_itv]) &\n","        (np_timeidx % config.loc_set.point.htf_entry == (config.loc_set.point.htf_entry - 1))\n","        , res_df['h_entry_{}'.format(strat_version)] + 1, res_df['h_entry_{}'.format(strat_version)])\n","\n","    # ------------------------------ rtc tp & out ------------------------------ #\n","    # --------------- bb rtc out --------------- #\n","\n","    if config.loc_set.point.outg_dc_period != \"None\":\n","        res_df['short_rtc_0_{}'.format(strat_version)] = res_df['high'].rolling(config.loc_set.point.outg_dc_period).max()\n","        res_df['long_rtc_0_{}'.format(strat_version)] = res_df['low'].rolling(config.loc_set.point.outg_dc_period).min()\n","\n","    res_df['short_out_{}'.format(strat_version)] = res_df['short_rtc_0_{}'.format(strat_version)] + res_df['short_rtc_gap_{}'.format(strat_version)] * config.tr_set.out_gap\n","    res_df['long_out_{}'.format(strat_version)] = res_df['long_rtc_0_{}'.format(strat_version)] - res_df['long_rtc_gap_{}'.format(strat_version)] * config.tr_set.out_gap\n","\n","    if config.tr_set.t_out_gap != \"None\":\n","        res_df['short_out_org_{}'.format(strat_version)] = res_df['short_out_{}'.format(strat_version)].copy()\n","        res_df['long_out_org_{}'.format(strat_version)] = res_df['long_out_{}'.format(strat_version)].copy()\n","\n","        res_df['short_out2_{}'.format(strat_version)] = res_df['short_rtc_0_{}'.format(strat_version)] + res_df['short_rtc_gap_{}'.format(strat_version)] * config.tr_set.t_out_gap\n","        res_df['long_out2_{}'.format(strat_version)] = res_df['long_rtc_0_{}'.format(strat_version)] - res_df['long_rtc_gap_{}'.format(strat_version)] * config.tr_set.t_out_gap\n","\n","    # ------------------------------ tp ------------------------------ #\n","    # --------------- bb rtc tp --------------- #\n","    res_df['short_tp_{}'.format(strat_version)] = res_df['h_short_rtc_1_{}'.format(strat_version)] - res_df['h_short_rtc_gap_{}'.format(strat_version)] * config.tr_set.tp_gap\n","    res_df['long_tp_{}'.format(strat_version)] = res_df['h_long_rtc_1_{}'.format(strat_version)] + res_df['h_long_rtc_gap_{}'.format(strat_version)] * config.tr_set.tp_gap\n","\n","    # --------------- set tp_line / dtk_line --------------- #\n","    # res_df['short_tp_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['short_rtc_1_{}'.format(strat_version)], np.nan)\n","    # res_df['short_tp_1_{}'.format(strat_version)] = ffill(res_df['short_tp_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","    # res_df['short_tp_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['h_short_rtc_gap_{}'.format(strat_version)], np.nan)  # ltf_gap 은 out 을 위한 gap 임\n","    # res_df['short_tp_gap_{}'.format(strat_version)] = ffill(res_df['short_tp_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","\n","    # res_df['long_tp_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['long_rtc_1_{}'.format(strat_version)], np.nan)\n","    # res_df['long_tp_1_{}'.format(strat_version)] = ffill(res_df['long_tp_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","    # res_df['long_tp_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['h_long_rtc_gap_{}'.format(strat_version)], np.nan)\n","    # res_df['long_tp_gap_{}'.format(strat_version)] = ffill(res_df['long_tp_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","\n","    # res_df['h_short_tp_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['h_short_rtc_1_{}'.format(strat_version)], np.nan)\n","    # res_df['h_short_tp_1_{}'.format(strat_version)] = ffill(res_df['h_short_tp_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","    # res_df['h_short_tp_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['h_short_rtc_gap_{}'.format(strat_version)], np.nan)\n","    # res_df['h_short_tp_gap_{}'.format(strat_version)] = ffill(res_df['h_short_tp_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","\n","    # res_df['h_long_tp_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['h_long_rtc_1_{}'.format(strat_version)], np.nan)\n","    # res_df['h_long_tp_1_{}'.format(strat_version)] = ffill(res_df['h_long_tp_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","    # res_df['h_long_tp_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['h_long_rtc_gap_{}'.format(strat_version)], np.nan)\n","    # res_df['h_long_tp_gap_{}'.format(strat_version)] = ffill(res_df['h_long_tp_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","   \n","\n","    if config.loc_set.zone.use_dtk_line:\n","      res_df['short_dtk_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['short_dtk_1_{}'.format(strat_version)], np.nan)\n","      res_df['short_dtk_1_{}'.format(strat_version)] = ffill(res_df['short_dtk_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","      res_df['short_dtk_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == -1, res_df['short_dtk_gap_{}'.format(strat_version)], np.nan)\n","      res_df['short_dtk_gap_{}'.format(strat_version)] = ffill(res_df['short_dtk_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","\n","      res_df['long_dtk_1_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['long_dtk_1_{}'.format(strat_version)], np.nan)\n","      res_df['long_dtk_1_{}'.format(strat_version)] = ffill(res_df['long_dtk_1_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","      res_df['long_dtk_gap_{}'.format(strat_version)] = np.where(res_df['h_entry_{}'.format(strat_version)] == 1, res_df['long_dtk_gap_{}'.format(strat_version)], np.nan)\n","      res_df['long_dtk_gap_{}'.format(strat_version)] = ffill(res_df['long_dtk_gap_{}'.format(strat_version)].values.reshape(1, -1)).reshape(-1, 1)\n","\n","    res_df['dc_upper_v2_{}'.format(strat_version)] = res_df['high'].rolling(config.loc_set.zone.dc_period).max()\n","    res_df['dc_lower_v2_{}'.format(strat_version)] = res_df['low'].rolling(config.loc_set.zone.dc_period).min()\n","    \n","    res_df['zone_dc_upper_v2_{}'.format(strat_version)] = res_df['high'].rolling(config.loc_set.zone.zone_dc_period).max()\n","    res_df['zone_dc_lower_v2_{}'.format(strat_version)] = res_df['low'].rolling(config.loc_set.zone.zone_dc_period).min()\n","\n","    return res_df\n"]},{"cell_type":"markdown","metadata":{"id":"o5psPOVOCA1c"},"source":["###### utils_ override"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5q1V5vTjQszK"},"outputs":[],"source":["enlist_rtc = utils2.enlist_rtc\n","# enlist_rtc = enlist_rtc\n","enlist_tr = utils2.enlist_tr"]},{"cell_type":"markdown","metadata":{"id":"HKdUKKl-483N"},"source":["###### utils_public"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzOYWA2kqZ0d"},"outputs":[],"source":["sys_log3 = logging.getLogger()\n","\n","\n","class OrderSide:\n","    BUY = \"BUY\"\n","    SELL = \"SELL\"\n","    INVALID = None\n","\n","\n","def lvrg_set(res_df, config, open_side, ep_, out_, fee, limit_leverage=50):\n","\n","    strat_version = config.strat_version\n","\n","    if open_side == OrderSide.SELL:\n","\n","        if strat_version in [\"v3\"]:\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / (out_ / ep_ - 1 - (fee + config.trader_set.market_fee))\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / (\n","                        out_ / ep_ - 1 - (fee + config.trader_set.market_fee))\n","\n","            #     zone 에 따른 c_ep_gap 를 고려 (loss 완화 방향) / 윗 줄은 수익 극대화 방향\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / (out_ / res_df['short_ep_org'].iloc[ep_j] - 1 - (fee + config.trader_set.market_fee))\n","\n","        elif strat_version in [\"v5_2\", \"v7_3\"]:\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(ep_ / out_ - 1 - (fee + config.trader_set.market_fee))\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(\n","                ep_ / out_ - 1 - (fee + config.trader_set.market_fee))\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(res_df['short_ep_org'].iloc[ep_j] / out_ - 1 - (fee + config.trader_set.market_fee))\n","\n","    else:\n","        #   윗 phase 는 min_pr 의 오차가 커짐\n","        if strat_version in [\"v3\"]:\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / (ep_ / out_ - 1 - (fee + config.trader_set.market_fee))\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / (\n","                        ep_ / out_ - 1 - (fee + config.trader_set.market_fee))\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['long_ep_org'].iloc[ep_j] / out_ - 1 - (fee + config.trader_set.market_fee))\n","\n","        elif strat_version in [\"v5_2\", \"v7_3\"]:\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(out_ / ep_ - 1 - (fee + config.trader_set.market_fee))\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(\n","                out_ / ep_ - 1 - (fee + config.trader_set.market_fee))\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(out_ / res_df['long_ep_org'].iloc[ep_j] - 1 - (fee + config.trader_set.market_fee))\n","\n","    if not config.lvrg_set.allow_float:\n","        config.lvrg_set.leverage = int(config.lvrg_set.leverage)\n","\n","    # -------------- leverage rejection -------------- #\n","    if config.lvrg_set.leverage < 1 and config.lvrg_set.lvrg_rejection:\n","        return None\n","\n","    config.lvrg_set.leverage = max(config.lvrg_set.leverage, 1)\n","\n","    config.lvrg_set.leverage = min(limit_leverage, config.lvrg_set.leverage)\n","\n","    return config.lvrg_set.leverage\n","\n","\n","def sync_check(res_df_list, order_side=\"OPEN\"):\n","\n","    df, third_df, fourth_df = res_df_list\n","\n","    #       add indi. only      #\n","\n","    #       Todo : manual        #\n","    #        1. 필요한 indi. 는 enlist_epouttp & mr_check 보면서 삽입\n","    #        2. htf use_rows 는 1m use_rows 의 길이를 만족시킬 수 있는 정도\n","    #         a. 1m use_rows / htf_interval 하면 대략 나옴\n","    #         b. 또한, htf indi. 를 생성하기 위해 필요한 최소 row 이상\n","    df = dc_line(df, None, '1m', dc_period=20)\n","    df = bb_line(df, None, '1m')\n","    df = bb_line(df, third_df, '5m')\n","    df = dc_line(df, third_df, '5m')\n","    df = bb_line(df, fourth_df, '15m')\n","    df = dc_line(df, fourth_df, '15m')\n","\n","    df['rsi_1m'] = rsi(df, 14)\n","\n","    if order_side in [\"OPEN\"]:\n","\n","        third_df['ema_5m'] = ema(third_df['close'], 200)\n","        df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['ema_5m']))\n","\n","    return df\n","\n","\n","def public_indi(res_df, order_side=\"OPEN\"):\n","\n","    res_df = bb_level(res_df, '5m', 1)\n","    res_df = dc_level(res_df, '5m', 1)\n","    res_df = bb_level(res_df, '15m', 1)\n","    res_df = dc_level(res_df, '15m', 1)\n","    # res_df = bb_level(res_df, '30m', 1)\n","    # res_df = dc_level(res_df, '30m', 1)\n","\n","    if order_side in [\"OPEN\"]:\n","\n","        res_df[\"candle_ratio\"], res_df['body_ratio'] = candle_ratio(res_df)\n","\n","        start_0 = time.time()\n","\n","        h_c_intv1 = 15\n","        h_c_intv2 = 60\n","        res_df = h_candle(res_df, h_c_intv1)\n","        res_df = h_candle(res_df, h_c_intv2)\n","        h_candle_col = ['hopen_{}'.format(h_c_intv2), 'hhigh_{}'.format(h_c_intv2), 'hlow_{}'.format(h_c_intv2), 'hclose_{}'.format(h_c_intv2)]\n","\n","        res_df['h_candle_ratio'], res_df['h_body_ratio'] = candle_ratio(res_df, ohlc_col=h_candle_col, unsigned=0)\n","\n","        # sys_log3.warning(\"~ h_candle_ratio elapsed time : {}\".format(time.time() - start_0))\n","\n","    #     temp indi.    #\n","    # res_df[\"ma30_1m\"] = res_df['close'].rolling(30).mean()\n","    # res_df[\"ma60_1m\"] = res_df['close'].rolling(60).mean()\n","    res_df = dtk_plot(res_df, dtk_itv2='15m', hhtf_entry=15, use_dtk_line=config.loc_set.zone.use_dtk_line)\n","\n","    return res_df\n","\n","\n","def short_ep_loc(res_df, config, i, np_timeidx, show_detail=True):\n","\n","    strat_version = config.strat_version\n","\n","    # ------- param init ------- #\n","    open_side = None\n","\n","    mr_const_cnt = 0\n","    mr_score = 0\n","    zone = 'n'\n","\n","    if config.ep_set.entry_type == 'MARKET':\n","        if config.tp_set.tp_type != 'MARKET':\n","            tp_fee = config.trader_set.market_fee + config.trader_set.limit_fee\n","        else:\n","            tp_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","        out_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","    else:\n","        if config.tp_set.tp_type != 'MARKET':\n","            tp_fee = config.trader_set.limit_fee + config.trader_set.limit_fee\n","        else:\n","            tp_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","        out_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","\n","\n","    # -------------- candle_ratio -------------- #\n","    # if config.loc_set.zone.c_itv_ticks != \"None\":\n","    if config.loc_set.point.candle_ratio != \"None\":\n","\n","      # -------------- candle_ratio_v0 (1m initial tick 기준임)  -------------- #\n","      if strat_version in ['v5_2']:\n","        mr_const_cnt += 1\n","        candle_ratio_ = res_df['candle_ratio'].iloc[i]\n","        # body_ratio_ = res_df['body_ratio'].iloc[i]\n","        if candle_ratio_ >= config.loc_set.point.candle_ratio:\n","          mr_score += 1\n","\n","        if show_detail:\n","          sys_log3.warning(\"candle_ratio_ : {}\".format(candle_ratio_))\n","\n","      # -------------- candle_ratio_v1 (previous)  -------------- #\n","      if strat_version in ['v7_3', '2_2', 'v3']:\n","\n","        prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","\n","        if prev_hclose_idx >= 0:\n","          \n","          h_candle_ratio_ = res_df['h_candle_ratio'].iloc[prev_hclose_idx]\n","          h_body_ratio_ = res_df['h_body_ratio'].iloc[prev_hclose_idx]\n","\n","          if strat_version in ['v7_3']:\n","            mr_const_cnt += 1\n","            if h_candle_ratio_ + h_body_ratio_/100 <= -config.loc_set.point.candle_ratio:\n","                mr_score += 1\n","\n","            if show_detail:\n","                sys_log3.warning(\"h_candle_ratio_ : {}\".format(h_candle_ratio_))\n","          \n","          elif strat_version in ['2_2', 'v3']:\n","            mr_const_cnt += 1\n","            if h_candle_ratio_ <= -config.loc_set.point.candle_ratio:\n","                mr_score += 1\n","\n","            if show_detail:\n","                sys_log3.warning(\"h_candle_ratio_ : {}\".format(h_candle_ratio_))\n","\n","            if config.loc_set.point.body_ratio != \"None\":\n","              mr_const_cnt += 1\n","              if h_body_ratio_ >= config.loc_set.point.body_ratio:\n","                  mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"h_body_ratio_ : {}\".format(h_body_ratio_))\n","\n","    if config.loc_set.point.candle_ratio2 != \"None\":\n","\n","        #     candle_ratio_v2 (current)     #\n","      prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","\n","      if prev_hclose_idx >= -1:\n","        hc_res_df = res_df.iloc[prev_hclose_idx + 1:i + 1].copy()\n","        ho = hc_res_df['open'].iloc[0]\n","        hh = hc_res_df['high'].max()\n","        hl = hc_res_df['low'].min()\n","        hc = hc_res_df['close'].iloc[-1]\n","\n","\n","        if strat_version in ['1_3']:\n","          score, body_score = candle_score(ho, hh, hl, hc, updown=None, unsigned=False)\n","        else:\n","          score, body_score = candle_score(ho, hh, hl, ho, updown=None, unsigned=False)\n","\n","        mr_const_cnt += 1\n","        if score <= -config.loc_set.point.candle_ratio2:\n","          mr_score += 1\n","\n","        if show_detail:\n","          sys_log3.warning(\"candle_ratio2 : {}\".format(score))\n","\n","        if config.loc_set.point.body_ratio2 != \"None\":\n","          mr_const_cnt += 1\n","          if ho > hc and body_score >= config.loc_set.point.body_ratio2:\n","            mr_score += 1\n","\n","          if show_detail:\n","            sys_log3.warning(\"body_ratio2 : {}\".format(body_score))\n","    \n","    # # -------------- tr scheduling -------------- #\n","    # if config.loc_set.zone.tr_thresh != \"None\":\n","\n","    #   mr_const_cnt += 1\n","    #   tr = ((done_tp - ep_list[0] - tp_fee * ep_list[0]) / (ep_list[0] - done_out + out_fee * ep_list[0]))\n","\n","    # -------------- spread scheduling -------------- #\n","    if config.loc_set.zone.short_spread != \"None\":\n","\n","        mr_const_cnt += 1\n","\n","        spread = (res_df['bb_base_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] - tp_fee * res_df['bb_base_5m'].iloc[\n","            # spread = (res_df['bb_base_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] - out_fee * res_df['bb_base_5m'].iloc[\n","            # i]) / (res_df['bb_base_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] + tp_fee *\n","            i]) / (res_df['bb_base_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] + out_fee *\n","                  res_df['bb_base_5m'].iloc[i])\n","        # spread = (res_df['bb_base_15m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] - tp_fee * res_df['bb_base_15m'].iloc[\n","        #     i]) / (res_df['bb_base_15m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] + out_fee *\n","        #             res_df['bb_base_15m'].iloc[i])\n","\n","        # spread = (res_df['dc_upper_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] - tp_fee * res_df['bb_lower_5m'].iloc[\n","        #     i]) / (res_df['dc_upper_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] + out_fee *\n","        #             res_df['bb_lower_5m'].iloc[i])\n","        # spread = (res_df['short_rtc_gap'].iloc[i] * (0.443) - tp_fee * res_df['short_ep'].iloc[\n","        #     i]) / (res_df['short_rtc_gap'].iloc[i] * (0.417) + out_fee * res_df['short_ep'].iloc[i])\n","\n","        # spread = (res_df['dc_upper_15m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] - tp_fee * res_df['dc_lower_5m'].iloc[\n","        #     i]) / (res_df['dc_upper_15m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] + out_fee *\n","        #             res_df['dc_lower_5m'].iloc[i])\n","        # spread = ((res_df['dc_upper_15m'].iloc[i] - res_df['dc_lower_5m'].iloc[i])/2 - tp_fee * res_df['dc_lower_5m'].iloc[\n","        #     i]) / ((res_df['dc_upper_15m'].iloc[i] - res_df['dc_lower_5m'].iloc[i])/2 + out_fee *\n","        #             res_df['dc_lower_5m'].iloc[i])\n","\n","        if spread >= config.loc_set.zone.short_spread:\n","            mr_score += 1\n","\n","        if show_detail:\n","            sys_log3.warning(\"spread : {}\".format(spread))\n","\n","    # -------------- dtk -------------- #\n","    if config.loc_set.zone.dt_k != \"None\":\n","\n","        mr_const_cnt += 1\n","        # if res_df['dc_lower_%s' % config.loc_set.zone.dtk_dc_itv].iloc[i] >= res_df['short_rtc_1'].iloc[i] - res_df['h_short_rtc_gap'].iloc[i] * config.loc_set.zone.dt_k:\n","        #     dtk_v1 & v2 platform     #\n","        if config.loc_set.zone.dtk_dc_itv != \"None\":\n","            dc = res_df['dc_lower_%s' % config.loc_set.zone.dtk_dc_itv].iloc[i]\n","            dt_k = res_df['short_dtk_1_{}'.format(strat_version)].iloc[i] - \\\n","                  res_df['short_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k\n","            if dc >= dt_k:\n","                mr_score += 1\n","\n","                #     dc_v2   #\n","        else:\n","            dc = res_df['dc_lower_v2_{}'.format(strat_version)].iloc[i]\n","            dt_k = res_df['short_dtk_1_{}'.format(strat_version)].iloc[i] - \\\n","                  res_df['short_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k\n","            if dc >= dt_k:\n","                # if res_df['dc_lower_v2_{}'.format(strat_version)].iloc[i] >= res_df['short_dtk_1_{}'.format(strat_version)].iloc[i] - res_df['short_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k and \\\n","                # res_df['dc_upper_v2_{}'.format(strat_version)].iloc[i] <= res_df['long_dtk_1_{}'.format(strat_version)].iloc[i] + res_df['long_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k:\n","                mr_score += 1\n","\n","        if show_detail:\n","            sys_log3.warning(\"dc : {}\".format(dc))\n","            sys_log3.warning(\"dt_k : {}\".format(dt_k))\n","            \n","      # -------------- candle_dt_k -------------- #\n","    # mr_const_cnt += 1\n","    # # if res_df['dc_lower_1m'].iloc[i] >= res_df['hclose_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    # if res_df['dc_lower_1m'].iloc[i] >= res_df['hlow_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    #   mr_score += 1        \n","\n","    # mr_const_cnt += 1\n","    # if res_df['dc_upper_1m'].iloc[i] <= res_df['hhigh_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    # # if res_df['dc_upper_1m'].iloc[i] <= res_df['hopen_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    #   mr_score += 1  \n","\n","\n","    # -------------- zone rejection  -------------- #\n","    if config.loc_set.zone.zone_rejection:\n","\n","        #       config 로 통제할 수 없는 rejection 은 strat_version 으로 조건문을 나눔 (lvrg_set 과 동일)\n","\n","        # --------- by bb --------- # \n","\n","          #     bb & close   #\n","        if strat_version in [\"v5_2\"]:\n","          mr_const_cnt += 1\n","          # if res_df['close'].iloc[i] < res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:   # org\n","          # if res_df['close'].iloc[i] > res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:  # inv\n","          # if res_df['close'].iloc[i] > res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          if res_df['close'].iloc[i] > res_df['bb_upper2_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          # if res_df['close'].iloc[i] > res_df['bb_upper3_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"bb & close passed\")\n","\n","          #     bb & bb   #           \n","        if strat_version in [\"v7_3\"]:\n","\n","          mr_const_cnt += 1\n","          if res_df['bb_upper_5m'].iloc[i] < res_df['bb_base_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          # if res_df['bb_upper_1m'].iloc[i] < res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","            mr_score += 1\n","\n","            if show_detail:\n","                sys_log3.warning(\"bb & bb passed\")\n","\n","            #     bb & ep   #\n","          mr_const_cnt += 1\n","          # if res_df['short_ep_{}'.format(strat_version)].iloc[i] < res_df['bb_base_15m'].iloc[i]:\n","          # if res_df['short_ep_{}'.format(strat_version)].iloc[i] < res_df['bb_base_15m'].iloc[i] + res_df['bb_gap_15m'].iloc[i]:\n","          # if res_df['short_ep_{}'.format(strat_version)].iloc[i] < res_df['bb_base_5m'].iloc[i]:\n","          if res_df['short_ep_{}'.format(strat_version)].iloc[i] < res_df['bb_upper_5m'].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"bb & ep passed\")\n","\n","            #     bb & dc   #\n","          mr_const_cnt += 1\n","          # if res_df['bb_base_%s' % config.loc_set.zone.bbz_itv].iloc[i] <= res_df['dc_upper_1m'].iloc[i] <= res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          \n","          prev_hopen_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1 + config.loc_set.zone.c_itv_ticks) + config.loc_set.zone.ad_idx\n","\n","          if prev_hopen_idx >= 0:\n","            # if res_df['dc_upper_5m'].iloc[prev_hopen_idx] < res_df['bb_upper_15m'].iloc[i]:\n","            if res_df['dc_upper_5m'].iloc[prev_hopen_idx] < res_df['bb_upper_15m'].iloc[prev_hopen_idx]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"bb & dc passed\")\n","\n","          # --------- by ema --------- # \n","\n","          #    bb & ema   #\n","        if strat_version in [\"v7_3\"]:\n","          mr_const_cnt += 1\n","          # if res_df['bb_upper_15m'].iloc[i] < res_df['ema_5m'].iloc[i]:\n","          if res_df['dc_upper_5m'].iloc[i] < res_df['ema_5m'].iloc[i]:\n","            mr_score += 1\n","\n","            if show_detail:\n","                sys_log3.warning(\"bb & ema passed\")\n","\n","          #    close & ema   #\n","        if strat_version in [\"v5_2\", \"v3\"]:\n","          mr_const_cnt += 1\n","          # if res_df['short_ep'].iloc[i] < res_df['ema_5m'].iloc[i]:\n","          if res_df['close'].iloc[i] < res_df['ema_5m'].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"close & ema passed\")\n","\n","\n","        # --------- by dc --------- # \n","        \n","          #     descending dc    #\n","        # mr_const_cnt += 1\n","        # if res_df['dc_lower_5m'].iloc[i] <= res_df['dc_lower_5m'].iloc[i - 50 : i].min():\n","        #   mr_score += 1\n","\n","        # --------- by candle --------- #\n","        if strat_version in ['2_2']:\n","\n","          prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","          if prev_hclose_idx >= 0:\n","            mr_const_cnt += 1\n","            # if res_df['short_ep_{}'.format(strat_version)].iloc[i] <= res_df['hclose_60'].iloc[prev_hclose_idx)]:\n","            if res_df['close'].iloc[i] <= res_df['hclose_60'].iloc[prev_hclose_idx]:\n","                mr_score += 1\n","\n","        # --------- by macd --------- #\n","        # mr_const_cnt += 1\n","        # if res_df['ma30_1m'].iloc[i] < res_df['ma60_1m'].iloc[i]:\n","        #     mr_score += 1\n","\n","\n","        # --------- by zone_dtk --------- #\n","        # mr_const_cnt += 1\n","        # if res_df['zone_dc_upper_v2_{}'.format(strat_version)].iloc[i] < res_df['long_dtk_plot_1'].iloc[i] + res_df['long_dtk_plot_gap'].iloc[\n","        #     i] * config.loc_set.zone.zone_dt_k:\n","        #   mr_score += 1\n","\n","    # -------------- zoned tr_set - post_Work -------------- #\n","    if config.tr_set.c_ep_gap != \"None\":\n","\n","        #       by bb       # \n","        # if res_df['close'].iloc[i] > res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","\n","        #       by zone_dtk       #\n","\n","        #         c_zone        #\n","        if res_df['zone_dc_upper_v2_{}'.format(strat_version)].iloc[i] > res_df['long_dtk_plot_1'].iloc[i] + \\\n","                res_df['long_dtk_plot_gap'].iloc[\n","                    i] * config.loc_set.zone.zone_dt_k:\n","\n","            if config.ep_set.static_ep:\n","                res_df['short_ep_{}'.format(strat_version)].iloc[i] = res_df['short_ep2_{}'.format(strat_version)].iloc[\n","                    i]\n","            else:\n","                res_df['short_ep_{}'.format(strat_version)] = res_df['short_ep2_{}'.format(strat_version)]\n","\n","            if config.out_set.static_out:\n","                res_df['short_out_{}'.format(strat_version)].iloc[i] = \\\n","                res_df['short_out_org_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['short_out_{}'.format(strat_version)] = res_df['short_out_org_{}'.format(strat_version)]\n","\n","            zone = 'c'\n","\n","        #         t_zone        #\n","        else:\n","\n","            # mr_const_cnt += 1   # zone_rejection - temporary\n","\n","            if config.ep_set.static_ep:\n","                res_df['short_ep_{}'.format(strat_version)].iloc[i] = \\\n","                res_df['short_ep_org_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['short_ep_{}'.format(strat_version)] = res_df['short_ep_org_{}'.format(strat_version)]\n","\n","            if config.out_set.static_out:\n","                res_df['short_out_{}'.format(strat_version)].iloc[i] = \\\n","                res_df['short_out2_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['short_out_{}'.format(strat_version)] = res_df['short_out2_{}'.format(strat_version)]\n","\n","            zone = 't'\n","\n","    if mr_const_cnt == mr_score:\n","        open_side = OrderSide.SELL\n","\n","    return res_df, open_side, zone\n","\n","\n","def long_ep_loc(res_df, config, i, np_timeidx, show_detail=True):\n","\n","    strat_version = config.strat_version\n","\n","    # ------- param init ------- #\n","    open_side = None\n","\n","    mr_const_cnt = 0\n","    mr_score = 0\n","    zone = 'n'\n","\n","    if config.ep_set.entry_type == 'MARKET':\n","        if config.tp_set.tp_type != 'MARKET':\n","            tp_fee = config.trader_set.market_fee + config.trader_set.limit_fee\n","        else:\n","            tp_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","        out_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","    else:\n","        if config.tp_set.tp_type != 'MARKET':\n","            tp_fee = config.trader_set.limit_fee + config.trader_set.limit_fee\n","        else:\n","            tp_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","        out_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","\n","\n","    # -------------- candle_ratio -------------- #\n","    # if config.loc_set.zone.c_itv_ticks != \"None\":\n","    if config.loc_set.point.candle_ratio != \"None\":\n","\n","      # -------------- candle_ratio_v0 (1m initial tick 기준임)  -------------- #\n","      if strat_version in ['v5_2']:\n","        mr_const_cnt += 1\n","        candle_ratio_ = res_df['candle_ratio'].iloc[i]\n","        # body_ratio_ = res_df['body_ratio'].iloc[i]\n","        if candle_ratio_ >= config.loc_set.point.candle_ratio:\n","          mr_score += 1\n","\n","        if show_detail:\n","            sys_log3.warning(\"candle_ratio_ : {}\".format(candle_ratio_))\n","\n","      # -------------- candle_ratio_v1 (previous)  -------------- #\n","      if strat_version in ['v7_3', '2_2', 'v3']:\n","\n","        prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","        \n","        if prev_hclose_idx >= 0:\n","\n","          h_candle_ratio_ = res_df['h_candle_ratio'].iloc[prev_hclose_idx]\n","          h_body_ratio_ = res_df['h_body_ratio'].iloc[prev_hclose_idx]\n","\n","          if strat_version in ['v7_3']:\n","            mr_const_cnt += 1\n","            if h_candle_ratio_ + h_body_ratio_/100 >= config.loc_set.point.candle_ratio:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"h_candle_ratio_ : {}\".format(h_candle_ratio_))\n","\n","          elif strat_version in ['2_2', 'v3']:\n","            mr_const_cnt += 1\n","            if h_candle_ratio_ >= config.loc_set.point.candle_ratio:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"h_candle_ratio_ : {}\".format(h_candle_ratio_))        \n","\n","            if config.loc_set.point.body_ratio != \"None\":\n","              mr_const_cnt += 1\n","              if h_body_ratio_ >= config.loc_set.point.body_ratio:\n","                  mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"h_body_ratio_ : {}\".format(h_body_ratio_))\n","\n","    if config.loc_set.point.candle_ratio2 != \"None\":\n","\n","      #     candle_ratio_v2 (current)     #\n","      prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","\n","      if prev_hclose_idx >= -1:\n","\n","        hc_res_df = res_df.iloc[prev_hclose_idx + 1:i + 1].copy()\n","        ho = hc_res_df['open'].iloc[0]\n","        hc = hc_res_df['close'].iloc[-1]\n","        hh = hc_res_df['high'].max()\n","        hl = hc_res_df['low'].min()\n","\n","        if strat_version in ['1_3']:\n","          score, body_score = candle_score(ho, hh, hl, hc, updown=None, unsigned=False)\n","        else:\n","          score, body_score = candle_score(ho, hh, hl, ho, updown=None, unsigned=False)\n","        \n","        mr_const_cnt += 1\n","        if score >= config.loc_set.point.candle_ratio2:\n","          mr_score += 1\n","\n","          if show_detail:\n","            sys_log3.warning(\"candle_ratio_v2 : {}\".format(score))\n","\n","        # print(\"candle_ratio2 passed !\")\n","\n","        if config.loc_set.point.body_ratio2 != \"None\":\n","          mr_const_cnt += 1\n","          if ho < hc and body_score >= config.loc_set.point.body_ratio2:\n","            mr_score += 1\n","\n","          if show_detail:\n","            sys_log3.warning(\"body_ratio2 : {}\".format(body_score))\n","\n","    # -------------- spread scheduling -------------- #\n","    if config.loc_set.zone.long_spread != \"None\":\n","\n","        mr_const_cnt += 1\n","\n","        # spread = (res_df['bb_upper_5m'].iloc[i] - res_df['bb_base_5m'].iloc[i] - tp_fee * res_df['bb_base_5m'].iloc[\n","        #     i]) / (res_df['bb_base_5m'].iloc[i] - res_df['bb_lower_5m'].iloc[i] + out_fee *\n","        #             res_df['bb_base_5m'].iloc[i])\n","        # spread = (res_df['bb_upper_5m'].iloc[i] - res_df['bb_base_15m'].iloc[i] - tp_fee * res_df['bb_base_15m'].iloc[\n","        #     i]) / (res_df['bb_upper_5m'].iloc[i] - res_df['bb_base_15m'].iloc[i] + out_fee *\n","        #             res_df['bb_base_15m'].iloc[i])\n","\n","        spread = (res_df['bb_upper_5m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] - tp_fee * res_df['bb_upper_5m'].iloc[\n","            # spread = (res_df['bb_upper_5m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] - out_fee * res_df['bb_upper_5m'].iloc[\n","            # i]) / (res_df['bb_upper_5m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] + tp_fee *\n","            i]) / (res_df['bb_upper_5m'].iloc[i] - res_df['dc_lower_5m'].iloc[i] + out_fee *\n","                  res_df['bb_upper_5m'].iloc[i])\n","        # spread = (res_df['long_rtc_gap'].iloc[i] * (0.443) - tp_fee * res_df['long_ep'].iloc[\n","        #     i]) / (res_df['long_rtc_gap'].iloc[i] * (0.417) + out_fee * res_df['long_ep'].iloc[i])\n","\n","        # spread = (res_df['dc_upper_5m'].iloc[i] - res_df['dc_lower_15m'].iloc[i] - tp_fee * res_df['dc_upper_5m'].iloc[\n","        #     i]) / (res_df['dc_upper_5m'].iloc[i] - res_df['dc_lower_15m'].iloc[i] + out_fee *\n","        #             res_df['dc_upper_5m'].iloc[i])\n","        # spread = ((res_df['dc_upper_5m'].iloc[i] - res_df['dc_lower_15m'].iloc[i])/2 - tp_fee * res_df['dc_upper_5m'].iloc[\n","        #     i]) / ((res_df['dc_upper_5m'].iloc[i] - res_df['dc_lower_15m'].iloc[i])/2 + out_fee *\n","        #             res_df['dc_upper_5m'].iloc[i])\n","\n","        if spread >= config.loc_set.zone.long_spread:\n","            mr_score += 1\n","\n","        if show_detail:\n","            sys_log3.warning(\"spread : {}\".format(spread))\n","\n","    # -------------- dtk -------------- #\n","    if config.loc_set.zone.dt_k != \"None\":\n","\n","        mr_const_cnt += 1\n","        # if res_df['dc_upper_%s' % config.loc_set.zone.dtk_dc_itv].iloc[i] <= res_df['long_rtc_1'].iloc[i] + res_df['long_rtc_gap'].iloc[i] * config.loc_set.zone.dt_k:\n","        #     dtk_v1 & v2 platform    #\n","        if config.loc_set.zone.dtk_dc_itv != \"None\":\n","            dc = res_df['dc_upper_%s' % config.loc_set.zone.dtk_dc_itv].iloc[i]\n","            dt_k = res_df['long_dtk_1_{}'.format(strat_version)].iloc[i] + \\\n","                  res_df['long_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k\n","            if dc <= dt_k:\n","                mr_score += 1\n","\n","        else:\n","            #     dc_v2     #\n","            dc = res_df['dc_upper_v2_{}'.format(strat_version)].iloc[i]\n","            dt_k = res_df['long_dtk_1_{}'.format(strat_version)].iloc[i] + \\\n","                  res_df['long_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k\n","            if dc <= dt_k:\n","                # if res_df['dc_upper_v2_{}'.format(strat_version)].iloc[i] >= res_df['long_dtk_1_{}'.format(strat_version)].iloc[i] + res_df['long_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k:\n","\n","                # if res_df['dc_upper_v2_{}'.format(strat_version)].iloc[i] <= res_df['long_dtk_1_{}'.format(strat_version)].iloc[i] + res_df['long_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k and \\\n","                #   res_df['dc_lower_v2_{}'.format(strat_version)].iloc[i] >= res_df['short_dtk_1_{}'.format(strat_version)].iloc[i] - res_df['short_dtk_gap_{}'.format(strat_version)].iloc[i] * config.loc_set.zone.dt_k:\n","\n","                mr_score += 1\n","\n","        if show_detail:\n","            sys_log3.warning(\"dc : {}\".format(dc))\n","            sys_log3.warning(\"dt_k : {}\".format(dt_k))\n","\n","      # -------------- candle_dt_k -------------- #\n","    # mr_const_cnt += 1\n","    # # if res_df['dc_upper_1m'].iloc[i] <= res_df['hclose_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    # if res_df['dc_upper_1m'].iloc[i] <= res_df['hhigh_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    #   mr_score += 1  \n","\n","    # mr_const_cnt += 1\n","    # if res_df['dc_lower_1m'].iloc[i] >= res_df['hlow_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    # # if res_df['dc_lower_1m'].iloc[i] >= res_df['hopen_60'].iloc[i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)]:\n","    #   mr_score += 1  \n","\n","    # -------------- zone rejection  -------------- #\n","    if config.loc_set.zone.zone_rejection:\n","\n","        # --------- by bb --------- #    \n","        \n","          #     bb & close   #\n","        if strat_version in [\"v5_2\"]:\n","\n","          mr_const_cnt += 1\n","          # if res_df['close'].iloc[i] > res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:    # org\n","          # if res_df['close'].iloc[i] < res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:  # inv\n","          # if res_df['close'].iloc[i] < res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          if res_df['close'].iloc[i] < res_df['bb_lower2_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          # if res_df['close'].iloc[i] < res_df['bb_lower3_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"bb & close passed\")\n","\n","          #     bb & bb   #\n","        if strat_version in [\"v7_3\"]:\n","\n","          mr_const_cnt += 1\n","          if  res_df['bb_lower_5m'].iloc[i] > res_df['bb_base_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","          # if res_df['bb_lower_1m'].iloc[i] > res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:            \n","              mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"bb & bb passed\")\n","\n","            #     bb & ep   #\n","          mr_const_cnt += 1\n","          # if res_df['long_ep_{}'.format(strat_version)].iloc[i] > res_df['bb_base_15m'].iloc[i]:\n","          # if res_df['long_ep_{}'.format(strat_version)].iloc[i] > res_df['bb_base_15m'].iloc[i] + res_df['bb_gap_15m'].iloc[i]:\n","          # if res_df['long_ep_{}'.format(strat_version)].iloc[i] > res_df['bb_base_5m'].iloc[i]:\n","          if res_df['long_ep_{}'.format(strat_version)].iloc[i] > res_df['bb_lower_5m'].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"bb & ep passed\")\n","          \n","            #     bb & dc   #\n","          mr_const_cnt += 1\n","          # if res_df['bb_base_%s' % config.loc_set.zone.bbz_itv].iloc[i] >= res_df['dc_lower_1m'].iloc[i] >= res_df['bb_lower_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","\n","          prev_hopen_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1 + config.loc_set.zone.c_itv_ticks) + config.loc_set.zone.ad_idx\n","          \n","          if prev_hopen_idx >= 0:            \n","            # if res_df['dc_lower_5m'].iloc[prev_hopen_idx] > res_df['bb_lower_15m'].iloc[i]:\n","            if res_df['dc_lower_5m'].iloc[prev_hopen_idx] > res_df['bb_lower_15m'].iloc[prev_hopen_idx]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                  sys_log3.warning(\"bb & dc passed\")\n","\n","        # --------- by ema --------- # \n","\n","          #     bb & ema   #\n","        if strat_version in [\"v7_3\"]:\n","\n","          mr_const_cnt += 1\n","          # if res_df['bb_lower_15m'].iloc[i] > res_df['ema_5m'].iloc[i]:\n","          if res_df['dc_lower_5m'].iloc[i] > res_df['ema_5m'].iloc[i]:\n","            mr_score += 1\n","\n","            if show_detail:\n","              sys_log3.warning(\"bb & ema passed\")\n","\n","          #     close & ema     #\n","        if strat_version in [\"v5_2\", \"v3\"]:\n","\n","          mr_const_cnt += 1\n","          # if  res_df['long_ep'].iloc[i] > res_df['ema_5m'].iloc[i]:\n","          if res_df['close'].iloc[i] > res_df['ema_5m'].iloc[i]:\n","              mr_score += 1\n","\n","              if show_detail:\n","                sys_log3.warning(\"close & ema passed\")\n","\n","        # if strat_version in [\"2_2\"]:\n","\n","        #   mr_const_cnt += 1\n","        #   # if  res_df['long_ep'].iloc[i] > res_df['ema_5m'].iloc[i]:\n","        #   if res_df['close'].iloc[i] < res_df['ema_5m'].iloc[i]:\n","        #       mr_score += 1\n","\n","        #       if show_detail:\n","        #         sys_log3.warning(\"close & ema passed\")\n","          \n","        # --------- by dc --------- # \n","\n","          #     ascending dc    #\n","        # mr_const_cnt += 1\n","        # if res_df['dc_upper_5m'].iloc[i] >= res_df['dc_upper_5m'].iloc[i - 50 : i].max():\n","        #   mr_score += 1          \n","\n","        # --------- by candle --------- #\n","        if strat_version in ['2_2']:\n","\n","          prev_hclose_idx = i - (np_timeidx[i] % config.loc_set.zone.c_itv_ticks + 1)\n","          if prev_hclose_idx >= 0:\n","            mr_const_cnt += 1\n","            if res_df['close'].iloc[i] >= res_df['hclose_60'].iloc[prev_hclose_idx]:\n","                mr_score += 1\n","        \n","        # --------- by macd --------- #\n","        # mr_const_cnt += 1\n","        # if res_df['ma30_1m'].iloc[i] > res_df['ma60_1m'].iloc[i]:\n","        #     mr_score += 1\n","\n","        # --------- by zone_dtk --------- #\n","        # mr_const_cnt += 1\n","        # if res_df['zone_dc_lower_v2_{}'.format(strat_version)].iloc[i] > res_df['short_dtk_plot_1'].iloc[i] - res_df['short_dtk_plot_gap'].iloc[i] * config.loc_set.zone.zone_dt_k:\n","        #   mr_score += 1\n","\n","    # -------------- zoned tr_set - post_work -------------- #\n","    if config.tr_set.c_ep_gap != \"None\":\n","        #       by bb       # \n","        # if res_df['close'].iloc[i] < res_df['bb_upper_%s' % config.loc_set.zone.bbz_itv].iloc[i]:\n","\n","        #       by zone_dtk       #\n","\n","        #         c_zone        #\n","        if res_df['zone_dc_lower_v2_{}'.format(strat_version)].iloc[i] < res_df['short_dtk_plot_1'].iloc[i] - \\\n","                res_df['short_dtk_plot_gap'].iloc[i] * config.loc_set.zone.zone_dt_k:\n","\n","            if config.ep_set.static_ep:\n","                res_df['long_ep_{}'.format(strat_version)].iloc[i] = res_df['long_ep2_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['long_ep_{}'.format(strat_version)] = res_df['long_ep2_{}'.format(strat_version)]\n","\n","            if config.out_set.static_out:\n","                res_df['long_out_{}'.format(strat_version)].iloc[i] = \\\n","                res_df['long_out_org_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['long_out_{}'.format(strat_version)] = res_df['long_out_org_{}'.format(strat_version)]\n","\n","            zone = 'c'\n","\n","            # mr_const_cnt += 1\n","            # dc_lb_period = 100\n","            # if np.sum((res_df['dc_upper_15m'] > res_df['dc_upper_15m'].shift(15)).iloc[i - dc_lb_period:i]) == 0:\n","            #   mr_score += 1\n","\n","            #         t_zone        #\n","        else:\n","\n","            # mr_const_cnt += 1   # zone_rejection - temporary\n","\n","            if config.ep_set.static_ep:\n","                res_df['long_ep_{}'.format(strat_version)].iloc[i] = \\\n","                res_df['long_ep_org_{}'.format(strat_version)].iloc[i]\n","            else:\n","                res_df['long_ep_{}'.format(strat_version)] = res_df['long_ep_org_{}'.format(strat_version)]\n","\n","            if config.out_set.static_out:\n","                res_df['long_out_{}'.format(strat_version)].iloc[i] = res_df['long_out2_{}'.format(strat_version)].iloc[\n","                    i]\n","            else:\n","                res_df['long_out_{}'.format(strat_version)] = res_df['long_out2_{}'.format(strat_version)]\n","\n","            zone = 't'\n","\n","    if mr_const_cnt == mr_score:\n","        open_side = OrderSide.BUY\n","\n","    return res_df, open_side, zone\n"]},{"cell_type":"markdown","metadata":{"id":"rLI8unIyroiC"},"source":["##### run"]},{"cell_type":"code","source":["res_df.columns"],"metadata":{"id":"1bvtIidEv15B"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdAn2bHHBWMF"},"outputs":[],"source":["config = config1  # custom base config, if use override -> set to config1\n","\n","multi_mode = 0\n","strat_switch = 0\n","override = 1\n","\n","if strat_switch:    # override 하지않는 경우에 config1 만을 사용하니, config1 에 어떤 version 을 배치할지 선택\n","  utils1 = utils2\n","  config1 = config3\n","\n","# ------- tp / out fee calc ------- #\n","if config.ep_set.entry_type == 'MARKET':\n","  if config.tp_set.tp_type != 'MARKET':   # Todo : 실제로, tp_fee 가 아닌 spread const. 를 위한 spread_fee1 임 (추후 수정 권고)\n","    tp_fee = config.trader_set.market_fee + config.trader_set.limit_fee\n","  else:\n","    tp_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","  out_fee = config.trader_set.market_fee + config.trader_set.market_fee\n","else:\n","  if config.tp_set.tp_type != 'MARKET':\n","    tp_fee = config.trader_set.limit_fee + config.trader_set.limit_fee\n","  else:\n","    tp_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","  out_fee = config.trader_set.limit_fee + config.trader_set.market_fee\n","  \n","\n","# ------- inversion set ------- #\n","inversion = 0\n","fdist_thresh = 1\n","\n","title_position = (0.30, 1)\n","show_plot = 1\n","show_detail = 0\n","\n","for key in ftr_list:\n","\n","  if config.trader_set.symbol in key:\n","    pass\n","  else:\n","    continue\n","\n","  start_0 = time.time()\n","\n","  res_df = pd.read_feather(os.path.join(ftr_path, key), columns=None, use_threads=True).set_index(\"index\") #.loc[pd.to_datetime(\"2021-07-10 04:59:59.999000\"):]\n","  print(key, \"loaded !\")\n","  # break\n","\n","  print(\"~ load res_df elapsed time :\", time.time() - start_0)\n","  \n","  # print(\"res_df.columns :\", res_df.columns)  \n","  # print(res_df.tail(100))\n","  # print(\"res_df.index[0] :\", res_df.index[0])\n","  # # print(\"intmin(res_df.index[0]) :\", intmin(res_df.index[0]))\n","  # break\n","\n","  # -------------------- additional indi. -------------------- #    \n","  start_0 = time.time()\n","\n","  np_timeidx = np.array(list(map(lambda x : intmin(x), res_df.index)))  # 이곳에 latency 조금 있음\n","\n","  if override:\n","    res_df = public_indi(res_df)\n","  else:\n","    res_df = utils_public.public_indi(res_df)\n","  \n","\n","  # -------------------- entlist rtc & tr 은 중복되는 여부에 따라 user 가 flexible coding 해야할 것 -------------------- #    \n","  if override:\n","    res_df = enlist_rtc(res_df, config1)\n","  else:\n","    res_df = utils1.enlist_rtc(res_df, config1)\n","    if multi_mode:\n","      res_df = utils2.enlist_rtc(res_df, config2)\n","      res_df = utils2.enlist_rtc(res_df, config3)   # form 같은 경우, 같은 utils 사용 - config 만 변경\n","\n","  print(\"load_df ~ enlist_rtc elapsed time :\", time.time() - start_0)\n","\n","  #   temp param    #\n","  allow_osc_touch = 0\n","  rsi_gap = 5\n","\n","  early_out_tpg = 0.36\n","\n","  itv_num_list = [1, 3, 5, 15]\n","\n","  itv_list = ['15m', '30m', '1h', '4h']\n","  # itv_list = ['3m', '5m', '15m', '30m', '1h', '4h']\n","\n","  x_val_list = np.arange(0.3, 1., 0.1)     # prcn 1\n","  x_val_list = np.arange(0.095, 0.3, 0.02)     # prcn 2\n","  # x_val_list = np.arange(-0.64, -0.7, -0.001)    # prcn 3\n","  # x_val_list = np.arange(0.944, 0.945, 0.0001)    # prcn 4\n","  # x_val_list = np.arange(20, 15, -1)   # prcn -1\n","  x_val_list = np.arange(10, 110, 10)   # prcn -2\n","\n","  y_val_cols = [\"wr\", \"sr\", \"frq\", \"dpf\", \"acc_pr\", \"sum_pr\", \"acc_mdd\", \"sum_mdd\", \"liqd\", \"min_pr\", \"tr\", \"dr\"]\n","  y_rev_val_cols = [\"wr\", \"sr\", \"acc_pr\", \"sum_pr\", \"acc_mdd\", \"sum_mdd\", \"min_pr\"]\n","\n","  survey_df = pd.DataFrame(index=x_val_list, columns=y_val_cols)\n","  short_survey_df = pd.DataFrame(index=x_val_list, columns=y_val_cols)\n","  long_survey_df = pd.DataFrame(index=x_val_list, columns=y_val_cols)\n","  rev_survey_df = pd.DataFrame(index=x_val_list, columns=y_rev_val_cols)\n","  rev_short_survey_df = pd.DataFrame(index=x_val_list, columns=y_rev_val_cols)\n","  rev_long_survey_df = pd.DataFrame(index=x_val_list, columns=y_rev_val_cols)\n","\n","  # for survey_i, just_loop in enumerate(range(1)):\n","  # for survey_i, config.loc_set.zone.tr_thresh in enumerate(x_val_list): \n","  # for survey_i, config.loc_set.zone.short_spread in enumerate(x_val_list): \n","  # for survey_i, config.loc_set.zone.long_spread in enumerate(x_val_list): \n","  # for survey_i, config.loc_set.zone.dt_k in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.zone.dc_period in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.zone.ei_k in enumerate(x_val_list):   \n","  # for survey_i, config.loc_set.zone.dr_error in enumerate(x_val_list): \n","  # for survey_i, config.loc_set.zone.bbz_itv in enumerate(itv_list):\n","  # for survey_i, config.loc_set.zone.gap_mply in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.zone.ad_idx in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.point.tf_entry in enumerate(x_val_list):\n","  for survey_i, config.loc_set.point.candle_ratio in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.point.body_ratio in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.point.candle_ratio2 in enumerate(x_val_list):\n","  # for survey_i, config.loc_set.point.osc_band in enumerate(x_val_list):\n","  # for survey_i, config.tr_set.ep_gap in enumerate(x_val_list): \n","  # for survey_i, config.tr_set.out_gap in enumerate(x_val_list): \n","  # for survey_i, config.tr_set.tp_gap in enumerate(x_val_list): \n","  # for survey_i, config.lvrg_set.leverage in enumerate(x_val_list):\n","  # for survey_i, config.lvrg_set.target_pct in enumerate(x_val_list):   \n","  # for survey_i, config.lvrg_set.target_pct in enumerate(x_val_list):   \n","  # for survey_i, config.tp_set.decay_term in enumerate(x_val_list):   \n","  # for survey_i, outg_dc_itv_num in enumerate(x_val_list): \n","  # for survey_i, exp_itv in enumerate(itv_list): \n","  # for survey_i, zone_dt_k in enumerate(x_val_list): \n","  # for survey_i, t_out_gap in enumerate(x_val_list): \n","  # for survey_i, zone_dc_period in enumerate(x_val_list): \n","  # for survey_i, early_out_tpg in enumerate(x_val_list): \n","  \n","    start_0 = time.time()\n","\n","    print(\"config.loc_set.point.exp_itv :\", config.loc_set.point.exp_itv)\n","    print(\"config.loc_set.point.tpg_itv1 :\", config.loc_set.point.tpg_itv1)\n","    print(\"config.loc_set.point.tpg_itv0 :\", config.loc_set.point.tpg_itv0)\n","    print(\"config.loc_set.point.outg_itv1 :\", config.loc_set.point.outg_itv1)\n","    print(\"config.loc_set.point.outg_itv0 :\", config.loc_set.point.outg_itv0)\n","    print(\"config.loc_set.point.outg_dc_period :\", config.loc_set.point.outg_dc_period)\n","    print(\"-----------------------------------\")    \n","    # print(\"dtk_dc_itv :\", dtk_dc_itv)    \n","    # print(\"config.loc_set.dtk_dc_itv_num :\", config.loc_set.dtk_dc_itv_num :\",)\n","    print(\"config.loc_set.zone.short_spread :\", config.loc_set.zone.short_spread)\n","    print(\"config.loc_set.zone.long_spread :\", config.loc_set.zone.long_spread)\n","    print(\"config.loc_set.zone.tr_thresh :\", config.loc_set.zone.tr_thresh)\n","    print(\"config.loc_set.zone.dtk_itv :\", config.loc_set.zone.dtk_itv)\n","    print(\"config.loc_set.zone.dt_k :\", config.loc_set.zone.dt_k)\n","    print(\"config.loc_set.zone.ei_k :\", config.loc_set.zone.ei_k)\n","    print(\"config.loc_set.zone.dc_period :\", config.loc_set.zone.dc_period)\n","    print(\"config.loc_set.zone.use_dtk_line :\", config.loc_set.zone.use_dtk_line)\n","\n","    print(\"config.loc_set.zone.zone_rejection :\", config.loc_set.zone.zone_rejection)\n","    print(\"config.loc_set.zone.bbz_itv :\", config.loc_set.zone.bbz_itv)\n","    print(\"config.loc_set.zone.gap_mply :\", config.loc_set.zone.gap_mply)\n","    print(\"config.loc_set.zone.ad_idx :\", config.loc_set.zone.ad_idx)\n","    print(\"config.loc_set.zone.zone_dt_k :\", config.loc_set.zone.zone_dt_k)\n","    print(\"config.loc_set.zone.zone_dc_period :\", config.loc_set.zone.zone_dc_period)\n","    # print(\"config.loc_set.open_shift :\", config.loc_set.open_shift)\n","    print(\"-----------------------------------\")\n","    # print(\"config.ep_set.dr_error :\", config.ep_set.dr_error)\n","    print(\"config.loc_set.point.tf_entry :\", config.loc_set.point.tf_entry)\n","    print(\"config.loc_set.point.htf_entry :\", config.loc_set.point.htf_entry)\n","    print(\"config.loc_set.point.candle_ratio :\", config.loc_set.point.candle_ratio)\n","    print(\"config.loc_set.point.body_ratio :\", config.loc_set.point.body_ratio)\n","    print(\"config.loc_set.point.candle_ratio2 :\", config.loc_set.point.candle_ratio2)\n","    print(\"config.loc_set.point.body_ratio2 :\", config.loc_set.point.body_ratio2)\n","    print(\"config.loc_set.point.osc_band :\", config.loc_set.point.osc_band)\n","    print(\"config.tr_set.ep_gap :\", config.tr_set.ep_gap)\n","    print(\"config.tr_set.tp_gap :\", config.tr_set.tp_gap)  \n","    print(\"config.tr_set.decay_gap :\", config.tr_set.decay_gap)  \n","    print(\"config.tr_set.out_gap :\", config.tr_set.out_gap)\n","    print(\"config.tr_set.c_ep_gap :\", config.tr_set.c_ep_gap)\n","    print(\"config.tr_set.t_out_gap :\", config.tr_set.t_out_gap)\n","    print(\"-----------------------------------\")\n","    print(\"config.lvrg_set.leverage :\", config.lvrg_set.leverage)\n","    print(\"config.lvrg_set.static_lvrg :\", config.lvrg_set.static_lvrg)\n","    print(\"config.lvrg_set.target_pct :\", config.lvrg_set.target_pct)\n","    print(\"-----------------------------------\")\n","    print(\"config.ep_set.entry_type :\", config.ep_set.entry_type)\n","    print(\"config.tp_set.tp_type :\", config.tp_set.tp_type)\n","    print(\"config.tp_set.static_tp :\", config.tp_set.static_tp)\n","    print(\"config.tp_set.decay_term :\", config.tp_set.decay_term)\n","    print(\"config.out_set.use_out :\", config.out_set.use_out)    \n","    print(\"config.out_set.out_type :\", config.out_set.out_type)\n","    \n","    # print(\"early_out_tpg :\", early_out_tpg)\n","\n","    # res_df = bb_level(res_df, '15m', config.loc_set.zone.gap_mply)\n","    \n","    # rsi_upper = 50 + config.loc_set.point.osc_band\n","    # rsi_lower = 50 - config.loc_set.point.osc_band\n","\n","    if override:\n","      res_df = enlist_tr(res_df, config1, np_timeidx)\n","    else:\n","      res_df = utils1.enlist_tr(res_df, config1, np_timeidx)\n","      if multi_mode:\n","        res_df = utils2.enlist_tr(res_df, config2, np_timeidx)\n","        res_df = utils2.enlist_tr(res_df, config3, np_timeidx)\n","\n","\n","    #       trading : 여기도 체결 결과에 대해 묘사함       #\n","    trade_list = []\n","    h_trade_list = []\n","    leverage_list = []\n","    fee_list = []\n","    short_fee_list = []\n","    long_fee_list = []\n","    open_list = []\n","    zone_list = []\n","    side_list = []\n","    strat_ver_list = []\n","\n","    tp_ratio_list = []\n","    short_tp_ratio_list = []\n","    long_tp_ratio_list = []\n","\n","    dr_list = []\n","    short_dr_list = []\n","    long_dr_list = []\n","\n","    liqd_list = []\n","    short_liqd_list = []\n","    long_liqd_list = []\n","\n","    nontp_liqd_list = []\n","    nontp_short_liqd_list = []\n","    nontp_long_liqd_list = []\n","\n","    nontp_pr_list = []\n","    nontp_short_pr_list = []\n","    nontp_long_pr_list = []\n","\n","    nontp_short_indexs = []\n","    nontp_long_indexs = []\n","\n","    nontp_short_ep_list = []\n","    nontp_long_ep_list = []\n","\n","    pr_list = []\n","    long_list = []\n","    short_list = []\n","\n","    h_pr_list = []\n","    h_long_list = []\n","    h_short_list = []\n","\n","    ep_tp_list = []\n","    h_ep_tp_list = []\n","    tp_state_list = []\n","\n","    i = 0\n","    while 1:\n","    # for i in range(len(res_df)):  \n","\n","      run = 0\n","      # if res_df['entry_{}'.format(config.strat_version)][i] == config.ep_set.short_entry_score: \n","      if multi_mode:\n","        if res_df['entry_{}'.format(config1.strat_version)][i] == config1.ep_set.short_entry_score or \\\n","            res_df['entry_{}'.format(config2.strat_version)][i] == config2.ep_set.short_entry_score: \n","          run = -1\n","        elif res_df['entry_{}'.format(config1.strat_version)][i] == -config1.ep_set.short_entry_score or \\\n","          res_df['entry_{}'.format(config2.strat_version)][i] == -config2.ep_set.short_entry_score: \n","          run = 1 \n","      else:\n","        if res_df['entry_{}'.format(config1.strat_version)][i] == config1.ep_set.short_entry_score:\n","          run = -1\n","        elif res_df['entry_{}'.format(config1.strat_version)][i] == -config1.ep_set.short_entry_score:\n","          run = 1\n","\n","      if run == -1:\n","        # print(\"i in short :\", i)\n","\n","        #     이곳에서 사용될 config 가 정해짐    #\n","        if res_df['entry_{}'.format(config1.strat_version)][i] == config1.ep_set.short_entry_score:\n","          config = config1\n","        else:\n","          config = config2  # 기본 setting 은 lower version strat. 으로 설정함\n","\n","        # strat_version = config.strat_version\n","    \n","\n","        initial_i = i\n","\n","\n","        if override:\n","          res_df, open_side, zone = short_ep_loc(res_df, config, i, np_timeidx, show_detail)          \n","        else:\n","          #       config 는 ep_loc 을 통해 재정의 될 수 있음      #\n","          res_df, open_side, zone = utils_public.short_ep_loc(res_df, config, i, np_timeidx, show_detail)\n","          if multi_mode:\n","            if config.strat_version == 'v5_2' and open_side is None:\n","              res_df, open_side, zone = utils_public.short_ep_loc(res_df, config3, i, np_timeidx, show_detail)\n","\n","              if open_side is not None:  # 이 형태를 유지하는 이유는, 아래의 summation form 을 깨뜨리지 않기 위함\n","                config = config3 \n","\n","\n","        # -------------- mr_score summation -------------- #\n","        if open_side is not None:     \n","          pass\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        # --------------------- config 가 확정된 이후의 setting --------------------- #\n","        strat_version = config.strat_version\n","        \n","        # p_i 의 용도 모르겠음\n","        if config.out_set.static_out:\n","          p_i = initial_i  \n","        else:\n","          p_i = i\n","\n","        # ------- fee init ------- #\n","        if config.ep_set.entry_type == 'LIMIT':\n","          fee = config.trader_set.limit_fee\n","        else:\n","          fee = config.trader_set.market_fee\n","        \n","        # --------------- set partial tp --------------- #\n","        short_tps = [res_df['short_tp_{}'.format(strat_version)]]\n","        long_tps = [res_df['long_tp_{}'.format(strat_version)]]\n","\n","        # short_tps = [short_tp2, short_tp] # org\n","        # long_tps = [long_tp2, long_tp]\n","        \n","        # short_tps = [short_tp, short_tp2]\n","        # long_tps = [long_tp, long_tp2]\n","\n","\n","        ep_j = initial_i\n","        out_j = initial_i\n","\n","        # -------------- limit waiting : limit_out -------------- #\n","\n","        if config.ep_set.entry_type == \"LIMIT\":\n","\n","          allow_ep_in = 0 if strat_version in [\"v5_2\"] else 1\n","          # allow_ep_in = 1\n","          entry_done = 0\n","          entry_open = 0\n","          prev_sar = None\n","\n","          # for e_j in range(i, len(res_df)): # entry_signal 이 open 기준 (해당 bar 에서 체결 가능함)\n","          if i + 1 >= len(res_df):  # i should be checked if e_j starts from i+1\n","            break\n","          for e_j in range(i + 1, len(res_df)): # entry signal이 close 기준 일 경우\n","        \n","            if not config.ep_set.static_ep:\n","              ep_j = e_j\n","              out_j = e_j\n","\n","            if config.tp_set.static_tp:\n","              # if config.ep_set.tpout_onexec:\n","              #   tp_j = e_j\n","              # else:\n","                tp_j = initial_i\n","            else:\n","              tp_j = e_j  \n","\n","            #             1. ep 설정 \n","            # -------------- np.inf ep -------------- #\n","            # if short_ep.iloc[initial_i] == np.inf:\n","            #   break\n","\n","\n","            #     1. check ep_out     #\n","            if config.loc_set.zone.ei_k != \"None\":\n","\n","              # if strat_version == \"v3\":\n","              if res_df['low'].iloc[e_j] <= res_df['h_short_rtc_1_{}'.format(strat_version)].iloc[tp_j] - \\\n","                res_df['h_short_rtc_gap_{}'.format(strat_version)].iloc[tp_j] * config.loc_set.zone.ei_k:\n","                break\n","\n","              # elif strat_version == \"v5_2\":\n","              # if res_df['low'].iloc[e_j] <= res_df['short_tp_{}'.format(strat_version)].iloc[tp_j]: # ep_out : tp_done\n","              # # if np_timeidx[e_j] % config.loc_set.point.tf_entry == config.loc_set.point.tf_entry - 1:\n","              #   break\n","\n","              # elif (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[e_j - 1] >= 50 - config.loc_set.point.osc_band) & \\\n","              #                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[e_j] < 50 - config.loc_set.point.osc_band):\n","              #   break\n","\n","            # if config.loc_set.zone.c_itv_ticks != \"None\":\n","\n","            #   if np_timeidx[e_j] % config.loc_set.zone.c_itv_ticks == config.loc_set.zone.c_itv_ticks - 1:\n","            #     break\n","\n","            #     2. ep_loc.point2\n","            if strat_version == \"v5_2\" and allow_ep_in == 0:\n","              if (res_df['dc_upper_1m'].iloc[e_j - 1] <= res_df['dc_upper_15m'].iloc[e_j]) & \\\n","                  (res_df['dc_upper_15m'].iloc[e_j - 1] != res_df['dc_upper_15m'].iloc[e_j]): # & \\\n","              # if (res_df['dc_upper_1m'].iloc[e_j - 1] <= res_df['dc_upper_5m'].iloc[e_j]) & \\\n","              #     (res_df['dc_upper_5m'].iloc[e_j - 1] != res_df['dc_upper_5m'].iloc[e_j]): # & \\\n","                  # (res_df['dc_upper_15m'].iloc[e_j] <= res_df['ema_5m'].iloc[e_j]):\n","                allow_ep_in = 1\n","                out_j = e_j\n","                # ep_j = e_j\n","                # continue  # limit entry 의 경우 ep_loc.point2 완료 시점 이후로 진입이 가능한 점\n","\n","              #     2-1. ep_out (ep_loc2) by ep_loc.point\n","              # if allow_ep_in and config.loc_set.zone.tr_thresh != \"None\":\n","              #   ep_ = res_df['close'].iloc[ep_j - 1]\n","              #   tr = ((res_df['short_tp_{}'.format(strat_version)].iloc[tp_j] - ep_ - tp_fee * ep_) / (ep_ - res_df['short_out_{}'.format(strat_version)].iloc[out_j] + out_fee * ep_))\n","              #   if tr < config.loc_set.zone.tr_thresh:\n","              #     break\n","\n","            #     3. check ep_in       #\n","            if allow_ep_in and res_df['high'].iloc[e_j] >= res_df['short_ep_{}'.format(strat_version)].iloc[ep_j]:\n","              entry_done = 1\n","              # print(\"res_df['high'].iloc[e_j] :\", res_df['high'].iloc[e_j])\n","              # print(\"e_j :\", e_j)\n","\n","              #     이미, e_j open 이 ep 보다 높은 경우, entry[ep_j] => -2 로 변경   #\n","              if res_df['open'].iloc[e_j] >= res_df['short_ep_{}'.format(strat_version)].iloc[ep_j]:\n","                entry_open = 1\n","              break\n","\n","\n","          i = e_j\n","          # print(\"i = e_j :\", i)\n","\n","          if entry_done:      \n","            pass\n","\n","          else:\n","            i += 1\n","            if i >= len(res_df):\n","              break\n","            continue\n","\n","        # ----------------- end wait ----------------- #\n","\n","        # if e_j - initial_i >= 200:\n","        #   print(\"e_j, initial_i :\", e_j, initial_i)\n","        # print(\"e_j - initial_i :\", e_j - initial_i)\n","        # print()\n","\n","        open_list.append(initial_i)\n","        zone_list.append(zone)\n","        side_list.append('s')\n","        strat_ver_list.append(strat_version)\n","        \n","        #     e_j 라는 변수는 MARKET 에 있어서 정의되서는 안되는 변수임   #\n","        if config.ep_set.entry_type == 'MARKET':\n","          # try:\n","          #   ep_list = [res_df['close'].iloc[e_j]]\n","          # except Exception as e:\n","          #   # print('error in ep_list (initial) :', e)\n","          ep_list = [res_df['close'].iloc[ep_j]]\n","\n","        else:          \n","          if not entry_open:\n","            ep_list = [res_df['short_ep_{}'.format(strat_version)].iloc[ep_j]]\n","          \n","          else:\n","            #   ep_j 는 항상 있음, LIMIT 인 경우 e_j 도 항상 존재함 --> dynamic_ep 여부에 따라 ep_j = e_j 가 되는 경우만 존재할 뿐임 \n","            #   따라서, ep_j 로 통일 가능함 (dynamic_ep 인 경우, ep_j = e_j 되어있음)\n","            fee = config.trader_set.market_fee\n","            ep_list = [res_df['open'].iloc[e_j]]  # --> 체결이 되는 e_j idx 기준으로 하는게 맞음\n","\n","        if not config.lvrg_set.static_lvrg:\n","\n","          ep_ = ep_list[0]\n","          out_ = res_df['short_out_{}'.format(strat_version)].iloc[out_j]\n","          if override:\n","            config.lvrg_set.leverage = lvrg_set(res_df, config, \"SELL\", ep_, out_, fee)\n","          else:\n","            config.lvrg_set.leverage = utils_public.lvrg_set(res_df, config, \"SELL\", ep_, out_, fee)\n","\n","          # -------------- leverage rejection -------------- #\n","          if config.lvrg_set.leverage == None:\n","            open_list.pop()\n","            zone_list.pop()\n","            side_list.pop()\n","            strat_ver_list.pop()\n","\n","            i += 1\n","            if i >= len(res_df):\n","              break\n","            continue          \n","        \n","        leverage_list.append(config.lvrg_set.leverage)\n","\n","        # try:\n","        if config.ep_set.entry_type == \"MARKET\":\n","          ep_idx_list = [ep_j]  # ep_j 는 ep_type 유관하게 존재하는 변수니까 try 에 걸어두는게 맞음 <-- # market 인데, e_j 변수가 할당된 경우 고려해야함\n","        else:\n","          ep_idx_list = [e_j]\n","\n","        out_idx_list = [out_j]\n","\n","        # except Exception as e:\n","        #   # print('error in ep_idx_list :', e)        \n","        #   ep_idx_list = [e_j]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None\n","        h_i, h_j = None, None\n","        \n","        trade_done = 0\n","        cross_on = 0\n","        out = 0\n","        # config.out_set.retouch\n","\n","        #     Todo    #\n","        #      1. future_work : 상단의 retouch 와 겹침 \n","        config.out_set.retouch = 0\n","        \n","\n","        if i == len(res_df) - 1: # if j start from i + 1 \n","          open_list.pop()       \n","          zone_list.pop()       \n","          side_list.pop()       \n","        for j in range(i + 1, len(res_df)):\n","\n","        # for j in range(i, len(res_df)):\n","\n","          if config.tp_set.static_tp:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              tp_j = ep_j  # tpout_onexec = using dynamic_ep --> using ep_j 에 대한 이유\n","            else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = j\n","\n","          if config.out_set.static_out:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              out_j = ep_j\n","            # else:           \n","            #   out_j = initial_i   # --> referenced upper phase as initail_j / e_j (start of limit wait)\n","          else:\n","            out_j = j\n","\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['high'].iloc[j - 1] <= res_df['sar2'].iloc[j - 1] and res_df['high'].iloc[j] > res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep < ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","          \n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['high'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST3_Up'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","\n","          # -------------- ultimate limit tp -------------- #\n","          if not config.tp_set.non_tp:\n","\n","            #               1. by price line             #\n","            if config.tp_set.tp_type == 'LIMIT' or config.tp_set.tp_type == \"BOTH\":\n","\n","              for s_i, short_tp_ in enumerate(short_tps):\n","\n","                #     decay adjustment    #\n","                #     tp_j includes dynamic_j   #\n","                if config.tr_set.decay_gap != \"None\":\n","                  decay_share = (j - initial_i) // config.tp_set.decay_term\n","                  decay_remain = (j - initial_i) % config.tp_set.decay_term\n","                  if j != initial_i and decay_remain == 0:\n","                    short_tp_.iloc[tp_j] += res_df['h_short_rtc_gap_{}'.format(strat_version)].iloc[initial_i] * config.tr_set.decay_gap * decay_share\n","\n","                if res_df['low'].iloc[j] <= short_tp_.iloc[tp_j] and partial_tp_cnt == s_i: # we use static tp now\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j]:\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j] <= res_df['high'].iloc[j]: --> 이건 잘못되었음\n","\n","                  if s_i == len(short_tps) - 1:\n","                    trade_done = 1\n","                  \n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if short_tp_.iloc[j] != short_tp_.iloc[j - 1] and not config.tp_set.static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_open {}\".format(strat_version))\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_tp {}\".format(strat_version))\n","\n","                  #         static tp         #\n","                  else:\n","                    \n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #              \n","\n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[tp_j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","\n","                      if config.tr_set.decay_gap != \"None\" and decay_remain == 0:\n","                        tp = res_df['open'].iloc[j]  # tp_j -> initial_i 를 가리키기 때문에 decay 는 한번만 진행되는게 맞음\n","                      else:\n","                        tp = short_tp_.iloc[tp_j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp {}\".format(strat_version))\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp {}\".format(strat_version))   \n","\n","                  tp_list.append(tp)     \n","                  tp_idx_list.append(j)\n","                  fee += config.trader_set.limit_fee\n","\n","\n","            #           2. by signal        #\n","            if config.tp_set.tp_type == 'MARKET' or (config.tp_set.tp_type == \"BOTH\" and not trade_done):\n","\n","              market_tp = 0\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","              #       inversion     #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              # ----------- st short ----------- #\n","              # if res_df['close'].iloc[j] <= res_df['short_tp'].iloc[tp_j]:\n","              \n","              # -------------- sar pb tp -------------- #\n","              # if res_df['low'].iloc[j] <= res_df['short_tp'].iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:       \n","\n","              # -------------- fisher tp -------------- #            \n","              # if entry[j] == 1:\n","              \n","              # -------------- timestamp -------------- #\n","              if config.tp_set.time_tp:\n","                if np_timeidx[j] % config.loc_set.zone.c_itv_ticks == config.loc_set.zone.c_itv_ticks - 1 and \\\n","                  j - initial_i >= config.loc_set.zone.c_itv_ticks:\n","                  market_tp = 1     \n","\n","              # -------------- rsi -------------- #\n","              # if strat_version in ['v7_3', 'v5_2']:\n","              if strat_version in ['v7_3']:\n","                if (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j - 1] >= 50 - config.loc_set.point.osc_band) & \\\n","                                (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] < 50 - config.loc_set.point.osc_band):   \n","                # if (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j - 1] <= 50 - config.loc_set.point.osc_band) & \\\n","                #                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] > 50 - config.loc_set.point.osc_band):                            \n","                  market_tp = 1\n","\n","                # -------------- cci -------------- #\n","                # if (res_df['cci_%s' % config.loc_set.point.exp_itv].iloc[j - 1] >= -config.loc_set.point.osc_band) & \\\n","                #                  (res_df['cci_%s' % config.loc_set.point.exp_itv].iloc[j] < -config.loc_set.point.osc_band):                            \n","                #   market_tp = 1 \n","\n","              # ---------------------------- early out ---------------------------- #\n","\n","              # #         rsi slight touch        #\n","              if allow_osc_touch:\n","                if (np.min(res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[initial_i:j]) < 50 - config.loc_set.point.osc_band + rsi_gap) & \\\n","                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] >= 50):\n","                  market_tp = 1              \n","                           \n","              #           tp early out          #\n","              # # if (np.min(res_df['low'].iloc[e_j:j]) < res_df['short_tp'].iloc[tp_j]) & \\\n","              # if (np.min(res_df['low'].iloc[e_j:j]) < res_df['h_short_rtc_1'].iloc[tp_j] - res_df['h_short_rtc_gap'].iloc[tp_j] * early_out_tpg) & \\\n","              #   (res_df['close'].iloc[j] >= res_df['short_ep'].iloc[ep_j]):\n","              #   market_tp = 1 \n","\n","              # if strat_version == \"v7\":\n","              #   if res_df['dc_upper_1m'].iloc[j] > res_df['dc_upper_5m'].iloc[j]:\n","              #     market_tp = 1\n","\n","              #         bb_upper early out        #\n","              if strat_version in [\"v5_2\"]:\n","                if res_df['close'].iloc[j] < res_df['bb_lower_5m'].iloc[j] < res_df['close'].iloc[j - 1]:\n","                  cross_on = 1\n","\n","                if cross_on == 1 and res_df['close'].iloc[j] > res_df['bb_upper_5m'].iloc[j] > res_df['close'].iloc[j - 1]:\n","                  market_tp = 1\n","\n","              if market_tp:\n","                \n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = 1\n","\n","                if trade_done:\n","                  tp_state_list.append(\"short close tp\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","                fee += config.trader_set.market_fee\n","\n","\n","                  \n","          # -------------- out -------------- #\n","          if not trade_done and config.out_set.use_out and j != len(res_df) - 1:\n","\n","            # -------------- macd -------------- #\n","            # if res_df['macd_hist3'].iloc[j] > 0:  #  macd out\n","            # if res_df['macd_hist3'].iloc[i] < 0 and res_df['macd_hist3'].iloc[j] > 0:\n","\n","            # -------------- st config.out_set.retouch -------------- #\n","            # out = 1 상태면 동일 tick 에서 config.out_set.retouch 를 조사할 거기 때문에, 먼저 검사함\n","            # 그리고, out 기준이 close 라 이게 맞음 \n","            # close 가 short_out 보다 올라가있는 상태일테니 low 를 조사하는게 맞음           \n","            # if out and res_df['low'].iloc[j] <= short_out.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","            \n","             # ------- 일정시간 이상, dynamic_out 적용 ------ #\n","            try:\n","              if j - out_idx >= config.out_set.retouch_out_period:\n","                static_short_out = res_df['short_out_{}'.format(strat_version)].iloc[j]\n","            \n","            except Exception as e:\n","              pass\n","\n","              # ------- static out ------ #\n","            try:\n","              if out and res_df['low'].iloc[j] <= static_short_out:\n","                config.out_set.retouch = 1\n","            except Exception as e:\n","              pass\n","\n","            \n","              # ------- config.out_set.retouch out ------ #\n","            # if out and res_df['low'].iloc[j] <= short_out2.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","\n","            # -------------- st -------------- #\n","            # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:    \n","            # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j]:\n","            # if res_df['close'].iloc[j] > upper_middle.iloc[j]:\n","            # if res_df['close'].iloc[j] > res_df['minor_ST1_Up'].iloc[j]:\n","            if out == 0:              \n","              if config.out_set.hl_out:\n","                if res_df['high'].iloc[j] >= res_df['short_out_{}'.format(strat_version)].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              else:\n","                if res_df['close'].iloc[j] >= res_df['short_out_{}'.format(strat_version)].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              # out_idx = j\n","              # static_short_out = short_out.iloc[out_j]\n","              # if config.out_set.second_out:              \n","                # static_short_out = short_out.iloc[out_j] + res_df['st_gap'].iloc[out_j] * config.out_set.second_out_gap\n","            \n","            # if out == 0 and res_df['high'].iloc[j] >= short_out.iloc[out_j]: # check out only once\n","            #   out = 1\n","             \n","\n","            # -------------- sma -------------- #\n","            # if res_df['close'].iloc[j] > res_df[sma].iloc[j]:\n","\n","            # -------------- sar -------------- #\n","            # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j] \\\n","            #   or res_df['sar2'].iloc[j] <= res_df['high'].iloc[j]:\n","            # if res_df['close'].iloc[j] > short_out.iloc[initial_i]: # or \\\n","            #   out = 1\n","              # res_df['sar2_uptrend'].iloc[j] == 1: # or \\\n","\n","            # if res_df['sar2_uptrend'].iloc[j] == 1:\n","\n","            #   if prev_sar is None:\n","            #     prev_sar = res_df['sar2'].iloc[j - 1]\n","              \n","            #   if res_df['close'].iloc[j] > prev_sar:\n","            #     out = 1\n","\n","            # else:\n","            #   if res_df['close'].iloc[j] > res_df['sar2'].iloc[j]:\n","            #     out = 1\n","              \n","            # -------------- hl -------------- #\n","            # if res_df['close'].iloc[j] > short_out.iloc[tp_j]:\n","            \n","            # -------------- stoch -------------- #\n","            # if res_df['stoch'].iloc[j - 2] >= res_df['stoch'].iloc[j - 1] and \\\n","            #   res_df['stoch'].iloc[j - 1] < res_df['stoch'].iloc[j] and \\\n","            #   res_df['stoch'].iloc[j - 1] <= stoch_lower:\n","            #   out = 1\n","\n","            # config.out_set.retouch 1 경우, config.out_set.retouch 조건도 있어야함\n","            if out:\n","              if config.out_set.retouch:\n","                if config.out_set.retouch:\n","                  pass\n","                else:\n","                    continue\n","\n","              else:\n","                pass\n","\n","              if config.out_set.price_restoration:\n","                tp = res_df['short_out_{}'.format(strat_version)].iloc[out_j]\n","                if config.out_set.second_out:\n","                  tp = res_df['short_out2_{}'.format(strat_version)].iloc[out_j]\n","                \n","                # if res_df['close'].iloc[j] > tp: # 이 경우를 protect 하는건 insane 임\n","                #   tp = res_df['close'].iloc[j]\n","\n","              else:\n","                \n","                if res_df['open'].iloc[j] >= res_df['short_out_{}'.format(strat_version)].iloc[out_j]:\n","                  tp = res_df['open'].iloc[j]\n","                else:\n","                  if config.out_set.hl_out:\n","                    tp = res_df['short_out_{}'.format(strat_version)].iloc[out_j]\n","                  else:\n","                    tp = res_df['close'].iloc[j]\n","                \n","                # if not config.out_set.static_out:\n","                #   if res_df['open'].iloc[j] >= res_df['short_out_{}'.format(strat_version)].iloc[out_j]: # close 기준이라 이런 조건을 못씀, 차라리 j 를 i 부터 시작\n","                #     tp = res_df['open'].iloc[j]\n","                #   else:\n","                #     tp = res_df['close'].iloc[j]\n","\n","                # else:\n","                #   tp = res_df['close'].iloc[j]\n","\n","              \n","              if config.out_set.retouch: # out 과 open 비교\n","                if config.out_set.second_out:\n","                  if res_df['open'].iloc[j] <= res_df['short_out2_{}'.format(strat_version)].iloc[out_j]:\n","                    tp = res_df['open'].iloc[j]\n","                else:\n","                  if res_df['open'].iloc[j] <= res_df['short_out_{}'.format(strat_version)].iloc[out_j]:\n","                    tp = res_df['open'].iloc[j]\n","\n","                try: # static_short_out 인 경우, open 도 고려한 tp set\n","                  if res_df['open'].iloc[j] <= static_short_out:\n","                    tp = res_df['open'].iloc[j]\n","                  else:\n","                    tp = static_short_out\n","                except Exception as e:\n","                  pass\n","\n","              trade_done = 1\n","              tp_state_list.append(\"short close_out {}\".format(strat_version))\n","            \n","\n","              tp_list.append(tp) \n","              tp_idx_list.append(j)\n","              fee += config.trader_set.market_fee\n","\n","\n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = 1\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","            fee += config.trader_set.market_fee\n","          \n","\n","\n","          # -------------- append trade data -------------- #\n","          if trade_done:\n","\n","            # --------------- tp_ratio info --------------- #\n","            #         Todo        #\n","            #          short_out 에 대한 정보는 존재함,\n","            #          short_tp 에 대한 정보는 존재함,\n","            #       => initial_i 기준으로 ,dynamic | static set 을 tp 와 out 에 각각 적용\n","            #          config.lvrg_set.leverage 는 initial_i 기준으로 적용되니까\n","            #          적용된 tp & out 으로 abs((tp - ep) / (ep - out)) 계산\n","            try:\n","              if config.out_set.use_out:\n","                done_tp = res_df['short_tp_{}'.format(strat_version)].iloc[tp_j]\n","                done_out = res_df['short_out_{}'.format(strat_version)].iloc[out_j]\n","\n","                if done_out <= ep_list[0]: # loss > 1\n","                  dr = np.nan\n","                  tp_ratio = np.nan\n","                else:                \n","                  dr = ((ep_list[0] - done_tp) / (done_out - ep_list[0]))\n","                  tp_ratio = ((ep_list[0] - done_tp - tp_fee * ep_list[0]) / (done_out - ep_list[0] + out_fee * ep_list[0]))\n","                \n","              else:\n","                dr = np.nan\n","                tp_ratio = np.nan  \n","\n","\n","            except Exception as e:\n","              dr = np.nan \n","              tp_ratio = np.nan  \n","            \n","            tp_ratio_list.append(tp_ratio)\n","            short_tp_ratio_list.append(tp_ratio)     \n","            dr_list.append(dr)\n","            short_dr_list.append(dr)   \n","\n","\n","            # -------------------- partial tp -------------------- #\n","            #        1. len(tp_list) 에 대응하는 qty_list 를 만들어야함    #\n","            #        2. temp_pr_list 를 만들어 총합 + 1 을 pr_list 에 저장      #\n","            #        2-1. temp_pr = sum((ep / tp_list[i] - fee - 1) * qty_list[i])   #\n","            #        3. temp_pr_list 의 첫 tp 에는 r_qty 를 할당함        #\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / config.tp_set.partial_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty * config.lvrg_set.leverage\n","              # temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","              qty_list.append(temp_qty)\n","\n","            # if len(temp_pr_list) == 1:\n","            #   print(\"qty_list :\", qty_list)\n","            #   print(\"temp_pr_list :\", temp_pr_list)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (sub_ep_ / tp - fee - 1) * config.lvrg_set.leverage\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_tp / h_ep - fee - 1) * config.lvrg_set.leverage  # hedge long\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","            \n","            # hh = max(res_df['high'].iloc[i:j + 1])\n","            hh = max(res_df['high'].iloc[i:j])    # pos. 정리하기 바로 직전까지\n","            short_liq = (ep_list[0] / hh - fee - 1) * config.lvrg_set.leverage + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              # ep_tp_list.append((ep, tp_list))  \n","              ep_tp_list.append((ep_list, tp_list))  \n","              # trade_list.append([initial_i, i, j])\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              trade_list.append((ep_idx_list, out_idx_list, tp_idx_list))\n","\n","              liqd_list.append(short_liq)\n","              short_liqd_list.append(short_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))      # hedge 도 ep_tp_list 처럼 변경해주어야하는데 아직 안건드림, 딱히 사용할 일이 없어보여   \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              fee_list.append(fee)\n","              short_list.append(temp_pr)\n","              short_fee_list.append(fee)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_short_list.append(hedge_pr)\n","\n","              i = j\n","              break\n","\n","            else:\n","\n","              # ep_tp_list.append((ep_list, tp_list))\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              # plot_check 때문에, pr_list 까지 하게되면 acc_pr eval 이 꼬이게댐\n","          \n","              # pr_list 를 넣지 않을거니까, open_list 에서 해당 idx 는 pop\n","              open_list.pop()\n","              zone_list.pop()\n","              side_list.pop()\n","              strat_ver_list.pop()\n","              \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(short_liq)\n","              nontp_short_liqd_list.append(short_liq)\n","              nontp_short_indexs.append(i)\n","              nontp_short_ep_list.append(ep_list[0])\n","\n","              nontp_short_pr = (ep_list[0] / tp - fee - 1) * config.lvrg_set.leverage + 1\n","              nontp_pr_list.append(nontp_short_pr)\n","              nontp_short_pr_list.append(nontp_short_pr)\n","\n","\n","      #                  long  phase                #\n","      # elif res_df['entry'][i] == -config.ep_set.short_entry_score:       \n","      # elif res_df['entry_{}'.format(config1.strat_version)][i] == -config1.ep_set.short_entry_score or \\\n","      #     res_df['entry_{}'.format(config2.strat_version)][i] == -config2.ep_set.short_entry_score: \n","      elif run == 1:\n","      \n","        #     이곳에서 사용될 config 가 정해짐    #\n","        if res_df['entry_{}'.format(config1.strat_version)][i] == -config1.ep_set.short_entry_score:\n","          config = config1\n","        else:\n","          config = config2\n","\n","        # print(\"entry check passed !\")\n","\n","        initial_i = i\n","\n","\n","        if override:\n","          res_df, open_side, zone = long_ep_loc(res_df, config, i, np_timeidx, show_detail)\n","        else:          \n","          res_df, open_side, zone = utils_public.long_ep_loc(res_df, config, i, np_timeidx, show_detail)\n","          if multi_mode:\n","            if config.strat_version == 'v5_2' and open_side is None:\n","              res_df, open_side, zone = utils_public.long_ep_loc(res_df, config3, i, np_timeidx, show_detail)\n","\n","              if open_side is not None: \n","                config = config3\n","\n","\n","        # -------------- mr_score summation -------------- #\n","        if open_side is not None:        \n","          pass\n","        \n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        # print(\"long_ep_loc passed !\")\n","\n","        strat_version = config.strat_version\n","\n","        # ------- fee init ------- #\n","        if config.ep_set.entry_type == 'LIMIT':\n","          fee = config.trader_set.limit_fee\n","        else:\n","          fee = config.trader_set.market_fee\n","        \n","        # --------------- set partial tp --------------- #\n","        short_tps = [res_df['short_tp_{}'.format(strat_version)]]\n","        long_tps = [res_df['long_tp_{}'.format(strat_version)]]\n","\n","        # short_tps = [short_tp2, short_tp] # org\n","        # long_tps = [long_tp2, long_tp]\n","        \n","        # short_tps = [short_tp, short_tp2]\n","        # long_tps = [long_tp, long_tp2]\n","        # print(\"i after long_ep_loc :\", i)\n","\n","        if config.out_set.static_out:\n","          p_i = initial_i\n","        else:\n","          p_i = i\n","\n","        ep_j = initial_i\n","        out_j = initial_i\n","      \n","        # -------------- limit waiting const. -------------- #      \n","        if config.ep_set.entry_type == \"LIMIT\":\n","\n","          allow_ep_in = 0 if strat_version in [\"v5_2\"] else 1\n","          # allow_ep_in = 1\n","          entry_done = 0\n","          entry_open = 0\n","          prev_sar = None\n","\n","          # for e_j in range(i, len(res_df)):   \n","\n","          if i + 1 >= len(res_df):  # i should be checked if e_j starts from i+1\n","            break\n","          for e_j in range(i + 1, len(res_df)):  # entry 가 close 기준일 경우 사용 (open 기준일 경우 i 부터 시작해도 무방함)\n","            \n","            if not config.ep_set.static_ep:\n","              ep_j = e_j  \n","              out_j = e_j\n","            \n","            if config.tp_set.static_tp:\n","              # if config.ep_set.tpout_onexec:\n","              #   tp_j = e_j\n","              # else:\n","                tp_j = initial_i\n","            else:\n","              tp_j = e_j  \n","\n","            \n","            #          np.inf ep         #\n","            # if long_ep.iloc[initial_i] == np.inf:\n","            #   break\n","            \n","            #     1. check ep_out     #\n","            if config.loc_set.zone.ei_k != \"None\":\n","\n","              if res_df['high'].iloc[e_j] >= res_df['h_long_rtc_1_{}'.format(strat_version)].iloc[tp_j] + \\\n","                res_df['h_long_rtc_gap_{}'.format(strat_version)].iloc[tp_j] * config.loc_set.zone.ei_k:\n","              # if res_df['high'].iloc[e_j] >= res_df['long_tp_{}'.format(strat_version)].iloc[tp_j]:                \n","              # if np_timeidx[e_j] % config.loc_set.point.tf_entry == config.loc_set.point.tf_entry - 1:\n","                break\n","\n","              # elif (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[e_j - 1] <= 50 + config.loc_set.point.osc_band) & \\\n","              #                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[e_j] > 50 + config.loc_set.point.osc_band):\n","              #   break            \n","\n","            # if config.loc_set.zone.c_itv_ticks != \"None\":\n","\n","            #   if np_timeidx[e_j] % config.loc_set.zone.c_itv_ticks == config.loc_set.zone.c_itv_ticks - 1:\n","            #     break\n","\n","            #     2. ep_loc.point2\n","            if strat_version == \"v5_2\" and allow_ep_in == 0:\n","              if (res_df['dc_lower_1m'].iloc[e_j - 1] >= res_df['dc_lower_15m'].iloc[e_j]) & \\\n","                  (res_df['dc_lower_15m'].iloc[e_j - 1] != res_df['dc_lower_15m'].iloc[e_j]): # & \\\n","              # if (res_df['dc_lower_1m'].iloc[e_j - 1] >= res_df['dc_lower_5m'].iloc[e_j]) & \\\n","              #     (res_df['dc_lower_5m'].iloc[e_j - 1] != res_df['dc_lower_5m'].iloc[e_j]): # & \\\n","                  # (res_df['dc_lower_15m'].iloc[e_j] >= res_df['ema_5m'].iloc[e_j]):\n","                allow_ep_in = 1\n","                out_j = e_j\n","                # ep_j = e_j\n","                # continue  # limit entry 의 경우 ep_loc.point2 완료 시점 이후로 진입이 가능한 점\n","                #     htf indi. 가 backi2 기준이라 continue 하지 않아도 됨\n","              \n","              #     2-1. ep_out (ep_loc2) by ep_loc.point\n","              # if allow_ep_in and config.loc_set.zone.tr_thresh != \"None\":\n","              #   ep_ = res_df['close'].iloc[ep_j - 1]\n","              #   tr = ((res_df['long_tp_{}'.format(strat_version)].iloc[tp_j] - ep_ - tp_fee * ep_) / (ep_ - res_df['long_out_{}'.format(strat_version)].iloc[out_j] + out_fee * ep_))\n","              #   # print(\"tr in long :\", tr)\n","              #   if tr < config.loc_set.zone.tr_thresh:\n","              #     break\n","\n","            #     3. check ep_in      #\n","            if allow_ep_in and res_df['low'].iloc[e_j] <= res_df['long_ep_{}'.format(strat_version)].iloc[ep_j]:\n","              entry_done = 1\n","              # print(\"e_j :\", e_j)\n","              \n","              #     이미, e_j open 이 ep 보다 낮은 경우, entry[initial_i] => -2 로 변경   #\n","              if res_df['open'].iloc[e_j] <= res_df['long_ep_{}'.format(strat_version)].iloc[ep_j]:\n","                entry_open = 1\n","\n","              break\n","\n","\n","          i = e_j\n","          # print(\"i = e_j :\", i)\n","\n","          if entry_done:      \n","            pass\n","            # print(\"i, entry_done :\", i, entry_done)\n","\n","          else:\n","            i += 1\n","            if i >= len(res_df):\n","              # print(\"i :\", i)\n","              break\n","\n","            # print(\"i in continue :\", i)          \n","            continue\n","\n","\n","        # ---------------- end wait ---------------- #\n","        # if e_j - initial_i >= 200:\n","        #   print(\"e_j, initial_i :\", e_j, initial_i)\n","        \n","        # print(i)\n","\n","        open_list.append(initial_i)\n","        zone_list.append(zone)\n","        side_list.append('l')\n","        strat_ver_list.append(strat_version)\n","\n","        if config.ep_set.entry_type == 'MARKET':\n","          ep_list = [res_df['close'].iloc[ep_j]]\n","        else:\n","          if not entry_open:\n","            ep_list = [res_df['long_ep_{}'.format(strat_version)].iloc[ep_j]]    # dynamic_ep 인 경우에도 e_j 가 ep_j 로 대응되기 때문에 ep_j 만 사용해도 무관\n","          else:\n","            # try:\n","            #   ep_list = [res_df['open'].iloc[e_j]]\n","            # except Exception as e:\n","            fee = config.trader_set.market_fee\n","            ep_list = [res_df['open'].iloc[e_j]]  # --> 체결이 되는 e_j idx 기준으로 하는게 맞음\n","\n","        if not config.lvrg_set.static_lvrg:\n","\n","          ep_ = ep_list[0]\n","          out_ = res_df['long_out_{}'.format(strat_version)].iloc[out_j]\n","          if override:\n","            config.lvrg_set.leverage = lvrg_set(res_df, config, \"BUY\", ep_, out_, fee)\n","          else:\n","            config.lvrg_set.leverage = utils_public.lvrg_set(res_df, config, \"BUY\", ep_, out_, fee)\n","\n","          # -------------- leverage rejection -------------- #\n","          if config.lvrg_set.leverage == None:\n","            open_list.pop()\n","            zone_list.pop()\n","            side_list.pop()\n","            strat_ver_list.pop()\n","\n","            i += 1\n","            if i >= len(res_df):\n","              break\n","            continue   \n","\n","        leverage_list.append(config.lvrg_set.leverage)\n","          \n","        if config.ep_set.entry_type == \"MARKET\":\n","          ep_idx_list = [ep_j]\n","        else:\n","          ep_idx_list = [e_j]\n","\n","        out_idx_list = [out_j]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None        \n","        h_i, h_j = None, None      \n","\n","        trade_done = 0\n","        cross_on = 0\n","        out = 0          \n","        config.out_set.retouch = 0\n","\n","\n","        if i == len(res_df) - 1: # if j start from i + 1 \n","          open_list.pop()\n","          zone_list.pop()\n","          side_list.pop()\n","          strat_ver_list.pop()\n","\n","        for j in range(i + 1, len(res_df)):\n","\n","        # for j in range(i, len(res_df)):  \n","          \n","          if config.tp_set.static_tp:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              tp_j = ep_j\n","            else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = j\n","\n","          if config.out_set.static_out:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              out_j = ep_j\n","            # else:           \n","            #   out_j = initial_i\n","          else:\n","            out_j = j   \n","\n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['low'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST3_Down'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['low'].iloc[j - 1] >= res_df['sar2'].iloc[j - 1] and res_df['low'].iloc[j] < res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep > ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","\n","          # -------------- ultimate tp -------------- #\n","          if not config.tp_set.non_tp:\n","            #            1. by level          #\n","            if config.tp_set.tp_type == \"LIMIT\" or config.tp_set.tp_type == \"BOTH\":\n","              \n","\n","              for l_i, long_tp_ in enumerate(long_tps):\n","              \n","                #     decay adjustment    #\n","                #     tp_j includes dynamic_j   #\n","                if config.tr_set.decay_gap != \"None\":\n","                  decay_share = (j - initial_i) // config.tp_set.decay_term\n","                  decay_remain = (j - initial_i) % config.tp_set.decay_term\n","                  if j != initial_i and decay_remain == 0:\n","                    long_tp_.iloc[tp_j] -= res_df['h_long_rtc_gap_{}'.format(strat_version)].iloc[initial_i] * config.tr_set.decay_gap * decay_share\n","\n","\n","                if res_df['high'].iloc[j] >= long_tp_.iloc[tp_j] and partial_tp_cnt == l_i:\n","                # if res_df['high'].iloc[j] >= long_tp.iloc[j]:\n","\n","                  if l_i == len(long_tps) - 1:\n","                    trade_done = 1\n","\n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if long_tp_.iloc[j] != long_tp_.iloc[j - 1] and not config.tp_set.static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[j]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_open {}\".format(strat_version))\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","                      \n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_tp {}\".format(strat_version))\n","\n","                  #         static tp         #\n","                  else:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #\n","\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[tp_j]:\n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","\n","                      if config.tr_set.decay_gap != \"None\" and decay_remain == 0:\n","                        tp = res_df['open'].iloc[j]\n","                      else:\n","                        tp = long_tp_.iloc[tp_j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp {}\".format(strat_version))\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp {}\".format(strat_version))         \n","                  \n","                  tp_list.append(tp)\n","                  tp_idx_list.append(j)\n","                  fee += config.trader_set.limit_fee\n","\n","            #           2. by time        #\n","            if config.tp_set.tp_type == 'MARKET' or (config.tp_set.tp_type == \"BOTH\" and not trade_done):\n","\n","              market_tp = 0\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              #       inversion     #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","\n","              # ----------- st long ----------- #\n","              # if res_df['close'].iloc[j] >= res_df['long_tp'].iloc[tp_j]:\n","\n","              # -------------- sar pb tp -------------- #\n","              # if res_df['high'].iloc[j] >= res_df['long_tp'].iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","\n","              # -------------- fisher tp -------------- #\n","              # if entry[j] == -1:\n","              \n","              # -------------- timestamp -------------- #\n","              if config.tp_set.time_tp:\n","                if np_timeidx[j] % config.loc_set.zone.c_itv_ticks == config.loc_set.zone.c_itv_ticks - 1 and \\\n","                  j - initial_i >= config.loc_set.zone.c_itv_ticks:\n","                  market_tp = 1\n","\n","              # -------------- rsi -------------- #\n","              # if strat_version in ['v7_3', 'v5_2']:\n","              # if strat_version in ['v7_3', 'v3']:\n","              if strat_version in ['v7_3']:\n","                if (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j - 1] <= 50 + config.loc_set.point.osc_band) & \\\n","                                (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] > 50 + config.loc_set.point.osc_band):\n","                # if (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j - 1] >= 50 + config.loc_set.point.osc_band) & \\\n","                #                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] < 50 + config.loc_set.point.osc_band):\n","                  market_tp = 1\n","\n","                # -------------- cci -------------- #\n","                # if (res_df['cci_%s' % config.loc_set.point.exp_itv].iloc[j - 1] <= config.loc_set.point.osc_band) & \\\n","                #                  (res_df['cci_%s' % config.loc_set.point.exp_itv].iloc[j] > config.loc_set.point.osc_band):\n","                #   market_tp = 1\n","\n","              # ---------------------------- early out phase ---------------------------- #\n","\n","              #        osc slight touch     #\n","              if allow_osc_touch:\n","                if (np.max(res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[initial_i:j]) > 50 + config.loc_set.point.osc_band - rsi_gap) & \\\n","                  (res_df['rsi_%s' % config.loc_set.point.exp_itv].iloc[j] <= 50):\n","                  market_tp = 1\n","\n","              #         tp early out        #\n","              # # if (np.max(res_df['high'].iloc[e_j:j]) > res_df['long_tp'].iloc[tp_j]) & \\\n","              # if (np.max(res_df['high'].iloc[e_j:j]) > res_df['h_long_rtc_1'].iloc[tp_j] + res_df['h_long_rtc_gap'].iloc[tp_j] * early_out_tpg) & \\\n","              #   (res_df['close'].iloc[j] <= res_df['long_ep'].iloc[ep_j]):\n","              #   market_tp = 1 \n","\n","              # if strat_version == \"v7\":\n","              #   if res_df['dc_lower_1m'].iloc[j] < res_df['dc_lower_5m'].iloc[j]:\n","              #     market_tp = 1\n","\n","\n","              #         bb_upper early out        #\n","              if strat_version in ['v5_2']:\n","                if res_df['close'].iloc[j] > res_df['bb_upper_5m'].iloc[j] > res_df['close'].iloc[j - 1]:\n","                  cross_on = 1\n","\n","                if cross_on == 1 and res_df['close'].iloc[j] < res_df['bb_lower_5m'].iloc[j] < res_df['close'].iloc[j - 1]:\n","                  market_tp = 1\n","                              \n","              if market_tp:\n","\n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = 1\n","\n","                if trade_done:\n","                  tp_state_list.append(\"long close tp {}\".format(strat_version))\n","                  # print(\"early_out passed !\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","                fee += config.trader_set.market_fee\n","\n","\n","\n","          # -------------- out -------------- #\n","          if not trade_done and config.out_set.use_out and j != len(res_df) - 1:              \n","\n","            # -------------- macd -------------- #\n","            # if res_df['macd_hist3'].iloc[j] < 0:\n","            # # if res_df['macd_hist3'].iloc[i] > 0 and res_df['macd_hist3'].iloc[j] < 0:\n","\n","            # -------------- st config.out_set.retouch -------------- #\n","            # out = 1 상태면 동일 tick 에서 config.out_set.retouch 를 조사할 거기 때문에, 먼저 검사함\n","            # 그리고, out 기준이 close 라 이게 맞음 \n","            # close 가 long_out 보다 내려가있는 상태일테니 high 를 조사하는게 맞음           \n","            # if out and res_df['high'].iloc[j] >= long_out.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","            \n","            # ------- 일정시간 이상, dynamic_out 적용 ------ #\n","            try:\n","              if j - out_idx >= config.out_set.retouch_out_period:\n","                static_long_out = res_df['long_out_{}'.format(strat_version)].iloc[j]\n","            \n","            except Exception as e:\n","              pass\n","\n","              # ------- static out ------ #\n","            try:\n","              if out and res_df['high'].iloc[j] >= static_long_out:\n","                config.out_set.retouch = 1\n","            except Exception as e:\n","              pass\n","\n","              # ------- config.out_set.retouch out ------ #\n","            # if out and res_df['high'].iloc[j] >= long_out2.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","\n","\n","            # -------------- st -------------- #\n","            # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","            # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j]:\n","            # if res_df['close'].iloc[j] < lower_middle.iloc[j]:\n","            # if res_df['close'].iloc[j] < res_df['minor_ST1_Down'].iloc[j]:\n","            if out == 0:\n","              if config.out_set.hl_out:\n","                if res_df['low'].iloc[j] <= res_df['long_out_{}'.format(strat_version)].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              else:\n","                if res_df['close'].iloc[j] <= res_df['long_out_{}'.format(strat_version)].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              # out_idx = j\n","              # static_long_out = long_out.iloc[out_j]\n","              # if config.out_set.second_out:\n","              # static_long_out = long_out.iloc[out_j] - res_df['st_gap'].iloc[out_j] * config.out_set.second_out_gap\n","\n","            # if out == 0 and res_df['low'].iloc[j] <= long_out.iloc[out_j]: # check out only once\n","            #   out = 1            \n","            \n","\n","\n","            # -------------- sma -------------- #\n","            # if res_df['close'].iloc[j] < res_df[sma].iloc[j]:\n","\n","            # -------------- sar -------------- #\n","            # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j] \\\n","            #   or res_df['sar2'].iloc[j] >= res_df['low'].iloc[j]:\n","            # if res_df['close'].iloc[j] < long_out.iloc[initial_i]: # or \\\n","            #   #  res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","            #   #  res_df['sar2_uptrend'].iloc[j] == 0 or \\\n","            #   out = 1\n","            \n","            # if res_df['sar2_uptrend'].iloc[j] == 0:\n","\n","            #     if prev_sar is None:\n","            #       prev_sar = res_df['sar2'].iloc[j - 1]\n","                \n","            #     if res_df['close'].iloc[j] < prev_sar:\n","            #       out = 1\n","\n","            # else:\n","            #   if res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","            #     out = 1\n","\n","            # -------------- hl -------------- #\n","            # if res_df['close'].iloc[j] < long_out.iloc[tp_j]:\n","\n","            # -------------- stoch -------------- #\n","            # if res_df['stoch'].iloc[j - 2] <= res_df['stoch'].iloc[j - 1] and \\\n","            #   res_df['stoch'].iloc[j - 1] > res_df['stoch'].iloc[j] and \\\n","            #   res_df['stoch'].iloc[j - 1] >= stoch_upper:\n","            #   out = 1\n","\n","            # config.out_set.retouch 1 경우, config.out_set.retouch 조건도 있어야함\n","            if out:\n","              if config.out_set.retouch:\n","                if config.out_set.retouch:\n","                  pass\n","                else:\n","                    continue\n","\n","              else:\n","                pass\n","\n","              if config.out_set.price_restoration:\n","                tp = res_df['long_out_{}'.format(strat_version)].iloc[out_j]\n","                if config.out_set.second_out:\n","                  tp = res_df['long_out2_{}'.format(strat_version)].iloc[out_j]\n","\n","                # if res_df['close'].iloc[j] < tp: # 이 경우를 protect 하는건 insane 임\n","                # # if res_df['high'].iloc[j] < tp: # --> config.out_set.hl_out 사용시 이 조건은 valid 함\n","                #   tp = res_df['close'].iloc[j]\n","\n","              else:\n","\n","                if res_df['open'].iloc[j] <= res_df['long_out_{}'.format(strat_version)].iloc[out_j]:\n","                  tp = res_df['open'].iloc[j]\n","                else:\n","                  if config.out_set.hl_out:\n","                    tp = res_df['long_out_{}'.format(strat_version)].iloc[out_j]\n","                  else:\n","                    tp = res_df['close'].iloc[j]\n","\n","                # if not config.out_set.static_out:\n","                #   if res_df['open'].iloc[j] <= res_df['long_out'].iloc[out_j]: # dynamic close out 의 open 고려\n","                #     tp = res_df['open'].iloc[j]\n","                #   else:\n","                #     tp = res_df['close'].iloc[j]\n","\n","                # else:\n","                #   tp = res_df['close'].iloc[j]\n","\n","              if config.out_set.retouch: # out 과 open 비교\n","                if config.out_set.second_out:  # long_out = sell\n","                # config.out_set.second_out 은 기본적으로 limit 이라 이 구조가 가능함\n","                  if res_df['open'].iloc[j] >= res_df['long_out2_{}'.format(strat_version)].iloc[out_j]: # dynamic_out 일 경우 고려해야함\n","                    tp = res_df['open'].iloc[j]\n","                else:\n","                  if res_df['open'].iloc[j] >= res_df['long_out_{}'.format(strat_version)].iloc[out_j]: # dynamic_out 일 경우 고려해야함\n","                    tp = res_df['open'].iloc[j]\n","\n","                try:\n","                  if res_df['open'].iloc[j] >= static_long_out:\n","                    tp = res_df['open'].iloc[j]\n","                  else:\n","                    tp = static_long_out\n","                except Exception as e:\n","                  pass\n","\n","              # tp = res_df['open'].iloc[j]\n","              tp_state_list.append(\"long close_out {}\".format(strat_version))\n","              trade_done = 1\n","\n","              tp_list.append(tp)\n","              tp_idx_list.append(j)\n","              fee += config.trader_set.market_fee\n","\n","          \n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = 1\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","            fee += config.trader_set.market_fee\n","\n","\n","          if trade_done:\n","\n","            # --------------- tp_ratio info --------------- #\n","            try:\n","              if config.out_set.use_out:\n","                done_tp = res_df['long_tp_{}'.format(strat_version)].iloc[tp_j]\n","                done_out = res_df['long_out_{}'.format(strat_version)].iloc[out_j]\n","\n","                if done_out >= ep_list[0]: # loss >= 1\n","                  tp_ratio = np.nan\n","                  dr = np.nan\n","                  # print(\"loss >= 1\")\n","                else:\n","                  tp_ratio = ((done_tp - ep_list[0] - tp_fee * ep_list[0]) / (ep_list[0] - done_out + out_fee * ep_list[0]))                \n","                  dr = ((done_tp - ep_list[0]) / (ep_list[0] - done_out))          \n","\n","              else:      \n","                dr = np.nan\n","                tp_ratio = np.nan\n","\n","            except Exception as e:\n","              print(\"error in tr phase :\", e)\n","              dr = np.nan              \n","              tp_ratio = np.nan\n","            \n","            tp_ratio_list.append(tp_ratio)\n","            long_tp_ratio_list.append(tp_ratio)\n","            dr_list.append(dr)\n","            long_dr_list.append(dr)\n","\n","\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / config.tp_set.partial_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              # temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty\n","              temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty * config.lvrg_set.leverage\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (tp / sub_ep_ - fee - 1) * config.lvrg_set.leverage\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_ep / h_tp - fee - 1) * config.lvrg_set.leverage  # hedge short\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","\n","            # ll = min(res_df['low'].iloc[i:j + 1])\n","            ll = min(res_df['low'].iloc[i:j])   # pos. 정리하기 바로 직전까지\n","            long_liq = (ll / ep_list[0] - fee - 1) * config.lvrg_set.leverage + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              ep_tp_list.append((ep_list, tp_list))\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              trade_list.append((ep_idx_list, out_idx_list, tp_idx_list))\n","\n","              liqd_list.append(long_liq)\n","              long_liqd_list.append(long_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))        \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              fee_list.append(fee)\n","              long_list.append(temp_pr)\n","              long_fee_list.append(fee)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_long_list.append(hedge_pr)                    \n","\n","              i = j\n","              break\n","            \n","            else:\n","\n","              # ep_tp_list.append((ep_list, tp_list))\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              \n","              # pr_list 를 넣지 않을거니까, open_list 에서 해당 idx 는 pop\n","              open_list.pop()\n","              zone_list.pop()\n","              side_list.pop()\n","              strat_ver_list.pop()\n","          \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(long_liq)\n","              nontp_long_liqd_list.append(long_liq)\n","              nontp_long_indexs.append(i)\n","              nontp_long_ep_list.append(ep_list[0])\n","              \n","              nontp_long_pr = (tp / ep_list[0] - fee - 1) * config.lvrg_set.leverage + 1\n","              nontp_pr_list.append(nontp_long_pr)\n","              nontp_long_pr_list.append(nontp_long_pr)\n","\n","            if len(open_list) > len(trade_list):\n","              print('debug from index :', i)\n","              print(len(open_list), len(trade_list))\n","              print(\"len(res_df) :\", len(res_df))\n","              assert len(open_list) == len(trade_list), 'stopped'\n","      \n","      i += 1  # if entry starts with prev trade's close, do not use it ! \n","      # print(\"i in end :\", i)\n","      if i >= len(res_df):\n","        break\n","\n","\n","\n","    # -------------------- result analysis -------------------- #\n","    # try:\n","    print(\"elapsed_time :\", time.time() - start_0)\n","\n","    plt.style.use('default')\n","    # mpl.rcParams.update(mpl.rcParamsDefault)\n","\n","    plt.figure(figsize=(16, 12))\n","    # plt.figure(figsize=(12, 8))\n","    # plt.figure(figsize=(10, 6))\n","    plt.suptitle(key)\n","\n","    try:\n","      np_pr = np.array(pr_list)\n","\n","      sr = sharpe_ratio(np_pr)\n","\n","      dpf = (len(res_df) / 1440) / len(np_pr)\n","\n","      np_zone_list = np.array(zone_list)\n","      # np_pr_list = np.array(pr_list)\n","      np_side_list = np.array(side_list)\n","\n","      t_w = np.sum(np.where((np_zone_list == 't') & (np_pr > 1), 1, 0))\n","      c_w = np.sum(np.where((np_zone_list == 'c') & (np_pr > 1), 1, 0))\n","      t_ls = np.sum(np.where((np_zone_list == 't') & (np_pr < 1), 1, 0))\n","      c_ls = np.sum(np.where((np_zone_list == 'c') & (np_pr < 1), 1, 0))\n","\n","      # np_pr = (np.array(pr_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      # ----- fake_pr ----- #\n","      # np_pr = np.where(np_pr > 1, 1 + (np_pr - 1) * 3, np_pr)\n","\n","      total_pr = np.cumprod(np_pr)\n","\n","      for_sum_pr = np_pr - 1\n","      for_sum_pr[0] = 1\n","      sum_pr = np.cumsum(for_sum_pr)\n","      sum_pr = np.where(sum_pr < 0, 0, sum_pr)\n","\n","      wr = len(np_pr[np_pr > 1]) / len(np_pr[np_pr != 1])\n","      \n","      total_rollmax_pr = np.maximum.accumulate(total_pr)\n","      total_acc_mdd = np.max((total_rollmax_pr - total_pr) / total_rollmax_pr)\n","      total_rollmax_sumpr = np.maximum.accumulate(sum_pr)\n","      total_sum_mdd = np.max((total_rollmax_sumpr - sum_pr) / total_rollmax_sumpr)\n","\n","      np_tp_ratio_list = np.array(tp_ratio_list) # 초기에 tr 을 정하는거라 mean 사용하는게 맞음\n","      mean_tr = np.mean(np_tp_ratio_list[np.isnan(np_tp_ratio_list) == 0])\n","\n","      np_dr_list = np.array(dr_list) # 초기에 tr 을 정하는거라 mean 사용하는게 맞음\n","      mean_dr = np.mean(np_dr_list[np.isnan(np_dr_list) == 0])\n","\n","      # pr_gap = (np_pr - 1) / config.lvrg_set.leverage + fee\n","      # tp_gap_ = pr_gap[pr_gap > 0]\n","      # # mean_config.tr_set.tp_gap = np.mean(pr_gap[pr_gap > 0])\n","      # mean_ls_gap = np.mean(pr_gap[pr_gap < 0])\n","\n","      # ---- profit fee ratio ---- #\n","      # mean_pgfr = np.mean((tp_gap_ - fee) / abs(tp_gap_ + fee))\n","\n","      # plt.subplot(121)\n","      plt.subplot(231)\n","      plt.plot(total_pr)\n","      plt.plot(sum_pr, color='gold')\n","      if len(nontp_liqd_list) != 0:\n","        plt.title(\"wr : %.3f\\n len(td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\"\n","                  % (wr, len(np_pr[np_pr != 1]), dpf, np.min(np_pr), total_pr[-1], sum_pr[-1], sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (total_acc_mdd, total_sum_mdd, config.lvrg_set.leverage, min(liqd_list), mean_tr, mean_dr)  + \\\n","                  \"\\n nontp_liqd_cnt : %s\\nnontp_liqd : %.3f\\nontp_liqd_pr : %.3f\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_liqd_list), min(nontp_liqd_list), min(nontp_pr_list), t_w, c_w, t_ls, c_ls) ,\n","                  position=title_position)\n","      else:\n","        plt.title(\"wr : %.3f\\n len(td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\" \n","                  % (wr, len(np_pr[np_pr != 1]), dpf, np.min(np_pr), total_pr[-1], sum_pr[-1], sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (total_acc_mdd, total_sum_mdd, config.lvrg_set.leverage, min(liqd_list), mean_tr, mean_dr)  + \\\n","                  \"\\n nontp_liqd_cnt : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_liqd_list), t_w, c_w, t_ls, c_ls) ,\n","                  position=title_position)\n","                  # \"\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\\n nontp_liqd_cnt : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  # % (config.lvrg_set.leverage, min(liqd_list), mean_tr, mean_dr, len(nontp_liqd_list), t_w, c_w, t_ls, c_ls), \n","                  # position=title_position)\n","      # plt.show()\n","\n","      survey_df.iloc[survey_i] = wr, sr, len(np_pr[np_pr != 1]), dpf, \\\n","        total_pr[-1], sum_pr[-1], total_acc_mdd, total_sum_mdd, min(liqd_list), np.min(np_pr), mean_tr, mean_dr\n","\n","      print('supblot231 passed')\n","\n","    except Exception as e:\n","      print(\"error in 231 :\", e)\n","\n","\n","    try:\n","      #         short only      #\n","      short_np_pr = np.array(short_list)\n","\n","      short_sr = sharpe_ratio(short_np_pr)\n","\n","      short_dpf = (len(res_df) / 1440) / len(short_np_pr)\n","\n","      short_total_pr = np.cumprod(short_np_pr)\n","      \n","      short_for_sum_pr = short_np_pr - 1\n","      short_for_sum_pr[0] = 1\n","      short_sum_pr = np.cumsum(short_for_sum_pr)\n","      short_sum_pr = np.where(short_sum_pr < 0, 0, short_sum_pr)\n","\n","      short_wr = len(short_np_pr[short_np_pr > 1]) / len(short_np_pr[short_np_pr != 1])\n","      \n","      t_w_s = np.sum(np.where((np_zone_list == 't') & (np_pr > 1) & (np_side_list == 's'), 1, 0))\n","      c_w_s = np.sum(np.where((np_zone_list == 'c') & (np_pr > 1) & (np_side_list == 's'), 1, 0))\n","      t_ls_s = np.sum(np.where((np_zone_list == 't') & (np_pr < 1) & (np_side_list == 's'), 1, 0))\n","      c_ls_s = np.sum(np.where((np_zone_list == 'c') & (np_pr < 1) & (np_side_list == 's'), 1, 0))\n","\n","      short_rollmax_pr = np.maximum.accumulate(short_total_pr)\n","      short_acc_mdd = np.max((short_rollmax_pr - short_total_pr) / short_rollmax_pr)\n","      short_rollmax_sumpr = np.maximum.accumulate(short_sum_pr)\n","      short_sum_mdd = np.max((short_rollmax_sumpr - short_sum_pr) / short_rollmax_sumpr)\n","\n","      np_short_tp_ratio_list = np.array(short_tp_ratio_list)\n","      mean_short_tr = np.mean(np_short_tp_ratio_list[np.isnan(np_short_tp_ratio_list) == 0])\n","      \n","      np_short_dr_list = np.array(short_dr_list)\n","      mean_short_dr = np.mean(np_short_dr_list[np.isnan(np_short_dr_list) == 0])\n","      \n","      # short_pr_gap = (short_np_pr - 1) / config.lvrg_set.leverage + fee\n","      # short_tp_gap = short_pr_gap[short_pr_gap > 0]\n","      # # mean_short_tp_gap = np.mean(short_pr_gap[short_pr_gap > 0])\n","      # # mean_short_ls_gap = np.mean(short_pr_gap[short_pr_gap < 0])\n","\n","      # mean_short_pgfr = np.mean((short_tp_gap - fee) / abs(short_tp_gap + fee))\n","      \n","      plt.subplot(232)\n","      plt.plot(short_total_pr)\n","      plt.plot(short_sum_pr, color='gold')\n","      if len(nontp_short_liqd_list) != 0:   \n","\n","        max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","        \n","        plt.title(\"wr : %.3f\\nlen(short_td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\"\n","                  % (short_wr, len(short_np_pr[short_np_pr != 1]), short_dpf, np.min(short_np_pr), short_total_pr[-1], short_sum_pr[-1], short_sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (short_acc_mdd, short_sum_mdd, config.lvrg_set.leverage, min(short_liqd_list), mean_short_tr, mean_short_dr) + \\\n","                  \"\\n nontp_liqd_cnt : %s\\n nontp_liqd : %.3f\\n nontp_liqd_pr : %.3f\\n max_nontp_term : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_short_liqd_list), min(nontp_short_liqd_list), min(nontp_short_pr_list), max_nontp_short_term, t_w_s, c_w_s, t_ls_s, c_ls_s) ,\n","                  position=title_position)\n","                  # \"\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_short_liqd_cnt : %s\\nnontp_short_liqd : %.3f\\nontp_short_liqd_pr : %.3f\\nmax_nontp_short_term : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  # % (config.lvrg_set.leverage, min(short_liqd_list), mean_short_tr, mean_short_dr, \n","                  #    len(nontp_short_liqd_list), min(nontp_short_liqd_list), min(nontp_short_pr_list), max_nontp_short_term, t_w_s, c_w_s, t_ls_s, c_ls_s),\n","                  # position=title_position)\n","      else:\n","        plt.title(\"wr : %.3f\\nlen(short_td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\"\n","                  % (short_wr, len(short_np_pr[short_np_pr != 1]), short_dpf, np.min(short_np_pr), short_total_pr[-1], short_sum_pr[-1], short_sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (short_acc_mdd, short_sum_mdd, config.lvrg_set.leverage, min(short_liqd_list), mean_short_tr, mean_short_dr) + \\\n","                  \"\\n nontp_liqd_cnt : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_short_liqd_list), t_w_s, c_w_s, t_ls_s, c_ls_s),\n","                  position=title_position)\n","   \n","      short_survey_df.iloc[survey_i] = short_wr, short_sr, len(short_np_pr[short_np_pr != 1]), short_dpf, \\\n","        short_total_pr[-1], short_sum_pr[-1], short_acc_mdd, short_sum_mdd, min(short_liqd_list), np.min(short_np_pr), mean_short_tr, mean_short_dr\n","        \n","      print('supblot232 passed')\n","    \n","    except Exception as e:\n","      print(\"error in 232 :\", e)\n","\n","    try:\n","      #         long only      #\n","      long_np_pr = np.array(long_list)\n","      # long_np_pr = (np.array(long_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      long_sr = sharpe_ratio(long_np_pr)\n","\n","      long_dpf = (len(res_df) / 1440) / len(long_np_pr)\n","\n","      long_total_pr = np.cumprod(long_np_pr)\n","      \n","      long_for_sum_pr = long_np_pr - 1\n","      long_for_sum_pr[0] = 1\n","      long_sum_pr = np.cumsum(long_for_sum_pr)\n","      long_sum_pr = np.where(long_sum_pr < 0, 0, long_sum_pr)\n","\n","      long_wr = len(long_np_pr[long_np_pr > 1]) / len(long_np_pr[long_np_pr != 1])\n","\n","      t_w_l = np.sum(np.where((np_zone_list == 't') & (np_pr > 1) & (np_side_list == 'l'), 1, 0))\n","      c_w_l = np.sum(np.where((np_zone_list == 'c') & (np_pr > 1) & (np_side_list == 'l'), 1, 0))\n","      t_ls_l = np.sum(np.where((np_zone_list == 't') & (np_pr < 1) & (np_side_list == 'l'), 1, 0))\n","      c_ls_l = np.sum(np.where((np_zone_list == 'c') & (np_pr < 1) & (np_side_list == 'l'), 1, 0))\n","\n","      long_rollmax_pr = np.maximum.accumulate(long_total_pr)\n","      long_acc_mdd = np.max((long_rollmax_pr - long_total_pr) / long_rollmax_pr)\n","      long_rollmax_sumpr = np.maximum.accumulate(long_sum_pr)\n","      long_sum_mdd = np.max((long_rollmax_sumpr - long_sum_pr) / long_rollmax_sumpr)\n","\n","      np_long_tp_ratio_list = np.array(long_tp_ratio_list)\n","      mean_long_tr = np.mean(np_long_tp_ratio_list[np.isnan(np_long_tp_ratio_list) == 0])\n","      \n","      np_long_dr_list = np.array(long_dr_list)\n","      mean_long_dr = np.mean(np_long_dr_list[np.isnan(np_long_dr_list) == 0])\n","\n","      # long_pr_gap = (long_np_pr - 1) / config.lvrg_set.leverage + fee\n","      # long_tp_gap = long_pr_gap[long_pr_gap > 0]\n","      # # mean_long_tp_gap = np.mean(long_pr_gap[long_pr_gap > 0])\n","      # # mean_long_ls_gap = np.mean(long_pr_gap[long_pr_gap < 0])\n","\n","      # mean_long_pgfr = np.mean((long_tp_gap - fee) / abs(long_tp_gap + fee))\n","\n","      plt.subplot(233)\n","      plt.plot(long_total_pr)\n","      plt.plot(long_sum_pr, color='gold')\n","      if len(nontp_long_liqd_list) != 0:\n","\n","        max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","        plt.title(\"wr : %.3f\\nlen(long_td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\"\n","                  % (long_wr, len(long_np_pr[long_np_pr != 1]), long_dpf, np.min(long_np_pr), long_total_pr[-1], long_sum_pr[-1], long_sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (long_acc_mdd, long_sum_mdd, config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr)  + \\\n","                  \"\\n nontp_liqd_cnt : %s\\n nontp_liqd : %.3f\\n nontp_liqd_pr : %.3f\\n max_nontp_term : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_long_liqd_list), min(nontp_long_liqd_list), min(nontp_long_pr_list), max_nontp_long_term, t_w_l, c_w_l, t_ls_l, c_ls_l) ,\n","                  position=title_position)\n","                  # \"\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_long_liqd_cnt : %s\\nnontp_long_liqd : %.3f\\nontp_long_liqd_pr : %.3f\\nmax_nontp_long_term : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  # % (config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr, \n","                  #    len(nontp_long_liqd_list), min(nontp_long_liqd_list), min(nontp_long_pr_list), max_nontp_long_term, t_w_l, c_w_l, t_ls_l, c_ls_l),\n","                  # position=title_position)\n","      else:\n","        plt.title(\"wr : %.3f\\nlen(long_td) : %s\\n dpf : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n sr : %.3f\"\n","                  % (long_wr, len(long_np_pr[long_np_pr != 1]), long_dpf, np.min(long_np_pr), long_total_pr[-1], long_sum_pr[-1], long_sr) + \\\n","                  \"\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n leverage %s\\n liqd : %.3f\\n mean_tr : %.3f\\n mean_dr : %.3f\"\n","                  % (long_acc_mdd, long_sum_mdd, config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr) + \\\n","                  \"\\n nontp_liqd_cnt : %s\\n tw cw tls cls : %s %s %s %s\"\n","                  % (len(nontp_long_liqd_list), t_w_l, c_w_l, t_ls_l, c_ls_l),\n","                  position=title_position)\n","                  # \"\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_long_liqd_cnt : %s\\n tw cw tls cls : %s %s %s %s\" \n","                  # % (config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr, len(nontp_long_liqd_list), t_w_l, c_w_l, t_ls_l, c_ls_l),\n","                  # position=title_position)\n","\n","      long_survey_df.iloc[survey_i] = long_wr, long_sr, len(long_np_pr[long_np_pr != 1]), long_dpf, \\\n","        long_total_pr[-1], long_sum_pr[-1], long_acc_mdd, long_sum_mdd, min(long_liqd_list), np.min(long_np_pr), mean_long_tr, mean_long_dr\n","\n","      print('supblot233 passed')\n","\n","    except Exception as e:\n","      print(\"error in 233 :\", e)\n","\n","\n","    try:\n","      #     reversion adjustment      #\n","      # rev_np_pr = 1 / (np.array(pr_list) + fee) - fee\n","      rev_fee = tp_fee + out_fee - np.array(fee_list)\n","      rev_np_pr = (1 / ((np.array(pr_list) - 1) / config.lvrg_set.leverage + np.array(fee_list) + 1) - rev_fee - 1) * config.lvrg_set.leverage + 1\n","      # rev_np_pr = (1 / (np.array(pr_list) + fee) - fee - 1) * config.lvrg_set.leverage + 1\n","          \n","      rev_sr = sharpe_ratio(rev_np_pr)\n","\n","      rev_total_pr = np.cumprod(rev_np_pr)\n","      rev_wr = len(rev_np_pr[rev_np_pr > 1]) / len(rev_np_pr[rev_np_pr != 1])\n","\n","      rev_total_for_sum_pr = rev_np_pr - 1\n","      rev_total_for_sum_pr[0] = 1\n","      rev_total_sum_pr = np.cumsum(rev_total_for_sum_pr)\n","      rev_total_sum_pr = np.where(rev_total_sum_pr < 0, 0, rev_total_sum_pr)\n","\n","      rev_rollmax_pr = np.maximum.accumulate(rev_total_pr)\n","      rev_acc_mdd = np.max((rev_rollmax_pr - rev_total_pr) / rev_rollmax_pr)\n","      rev_rollmax_sumpr = np.maximum.accumulate(rev_total_sum_pr)\n","      rev_sum_mdd = np.max((rev_rollmax_sumpr - rev_total_sum_pr) / rev_rollmax_sumpr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(234)\n","      plt.plot(rev_total_pr)\n","      plt.plot(rev_total_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\n sr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n min_pr : %.3f\" \n","                % (rev_wr, rev_sr, rev_total_pr[-1], rev_total_sum_pr[-1], rev_acc_mdd, rev_sum_mdd, np.min(rev_np_pr)))\n","      \n","      rev_survey_df.iloc[survey_i] = rev_wr, rev_sr, rev_total_pr[-1], rev_total_sum_pr[-1], rev_acc_mdd, rev_sum_mdd, np.min(rev_np_pr)\n","\n","    except Exception as e:\n","      print(\"error in 234 :\", e)\n","\n","    try:\n","      #         short       #\n","      # rev_short_np_pr = 1 / (np.array(short_list) + fee) - fee\n","      rev_short_fee = tp_fee + out_fee - np.array(short_fee_list)\n","      rev_short_np_pr = (1 / ((np.array(short_list) - 1) / config.lvrg_set.leverage + np.array(short_fee_list) + 1) - rev_short_fee - 1) * config.lvrg_set.leverage + 1\n","      # rev_short_np_pr = (1 / (np.array(short_list) + fee) - fee - 1) * config.lvrg_set.leverage + 1\n","      \n","      rev_short_sr = sharpe_ratio(rev_short_np_pr)\n","          \n","      short_rev_total_pr = np.cumprod(rev_short_np_pr)\n","      rev_short_wr = len(rev_short_np_pr[rev_short_np_pr > 1]) / len(rev_short_np_pr[rev_short_np_pr != 1])\n","\n","      rev_short_for_sum_pr = rev_short_np_pr - 1\n","      rev_short_for_sum_pr[0] = 1\n","      short_rev_sum_pr = np.cumsum(rev_short_for_sum_pr)\n","      short_rev_sum_pr = np.where(short_rev_sum_pr < 0, 0, short_rev_sum_pr)\n","\n","      short_rev_rollmax_pr = np.maximum.accumulate(short_rev_total_pr)\n","      short_rev_acc_mdd = np.max((short_rev_rollmax_pr - short_rev_total_pr) / short_rev_rollmax_pr)\n","      short_rev_rollmax_sumpr = np.maximum.accumulate(short_rev_sum_pr)\n","      short_rev_sum_mdd = np.max((short_rev_rollmax_sumpr - short_rev_sum_pr) / short_rev_rollmax_sumpr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(235)\n","      plt.plot(short_rev_total_pr)\n","      plt.plot(short_rev_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\n sr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n min_pr : %.3f\" \n","                % (rev_short_wr, rev_short_sr, short_rev_total_pr[-1], short_rev_sum_pr[-1], short_rev_acc_mdd, short_rev_sum_mdd, np.min(rev_short_np_pr)))\n","      \n","      rev_short_survey_df.iloc[survey_i] = rev_short_wr, rev_short_sr, short_rev_total_pr[-1], short_rev_sum_pr[-1], short_rev_acc_mdd, short_rev_sum_mdd, np.min(rev_short_np_pr)\n","\n","    except Exception as e:\n","      print(\"error in 235 :\", e)\n","\n","    try:\n","      #         long       #\n","      # rev_long_np_pr = 1 / (np.array(long_list) + fee) - fee\n","      rev_long_fee = tp_fee + out_fee - np.array(long_fee_list)\n","      rev_long_np_pr = (1 / ((np.array(long_list) - 1) / config.lvrg_set.leverage + np.array(long_fee_list) + 1) - rev_long_fee - 1) * config.lvrg_set.leverage + 1\n","          \n","      rev_long_sr = sharpe_ratio(rev_long_np_pr)\n","\n","      long_rev_total_pr = np.cumprod(rev_long_np_pr)\n","      rev_long_wr = len(rev_long_np_pr[rev_long_np_pr > 1]) / len(rev_long_np_pr[rev_long_np_pr != 1])\n","\n","      rev_long_for_sum_pr = rev_long_np_pr - 1\n","      rev_long_for_sum_pr[0] = 1\n","      long_rev_sum_pr = np.cumsum(rev_long_for_sum_pr)\n","      long_rev_sum_pr = np.where(long_rev_sum_pr < 0, 0, long_rev_sum_pr)\n","\n","      long_rev_rollmax_pr = np.maximum.accumulate(long_rev_total_pr)\n","      long_rev_acc_mdd = np.max((long_rev_rollmax_pr - long_rev_total_pr) / long_rev_rollmax_pr)\n","      long_rev_rollmax_sumpr = np.maximum.accumulate(long_rev_sum_pr)\n","      long_rev_sum_mdd = np.max((long_rev_rollmax_sumpr - long_rev_sum_pr) / long_rev_rollmax_sumpr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(236)\n","      plt.plot(long_rev_total_pr)\n","      plt.plot(long_rev_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\n sr : %.3f\\n acc_pr : %.3f\\n sum_pr : %.3f\\n acc_mdd : -%.3f\\n sum_mdd : -%.3f\\n min_pr : %.3f\" \n","                % (rev_long_wr, rev_long_sr, long_rev_total_pr[-1], long_rev_sum_pr[-1], long_rev_acc_mdd, long_rev_sum_mdd, np.min(rev_long_np_pr)))\n","      \n","      rev_long_survey_df.iloc[survey_i] = rev_long_wr, rev_long_sr, long_rev_total_pr[-1], long_rev_sum_pr[-1], long_rev_acc_mdd, long_rev_sum_mdd, np.min(rev_long_np_pr)\n","      \n","    except Exception as e:\n","      print(\"error in 236 :\", e)\n","\n","    if show_plot:\n","      plt.show()\n","    \n","\n","    try:\n","\n","      h_np_pr = np.array(h_pr_list)\n","      # h_rev_np_pr = 1 / (np.array(h_pr_list) + fee) - fee    # define, for plot_check below cell\n","      h_rev_np_pr = (1 / ((np.array(h_pr_list) - 1) / config.lvrg_set.leverage + np.array(fee_list) + 1) - np.array(fee_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      # --------------------- h pr plot --------------------- #\n","      if len(h_np_pr[h_np_pr != 1]) != 0:\n","\n","        plt.figure(figsize=(16, 12))\n","        plt.suptitle(key + \" hedge\")\n","\n","        h_total_pr = np.cumprod(h_np_pr)\n","        h_wr = len(h_np_pr[h_np_pr > 1]) / len(h_np_pr[h_np_pr != 1])\n","\n","        # plt.subplot(121)\n","        plt.subplot(231)\n","        plt.plot(h_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_wr, np.min(h_np_pr), h_total_pr[-1], config.lvrg_set.leverage))\n","        # plt.show()\n","\n","        #         short only      #\n","        h_short_np_pr = np.array(h_short_list)\n","\n","        short_h_total_pr = np.cumprod(h_short_np_pr)\n","        h_short_wr = len(h_short_np_pr[h_short_np_pr > 1]) / len(h_short_np_pr[h_short_np_pr != 1])\n","        \n","        plt.subplot(232)\n","        plt.plot(short_h_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_short_wr, np.min(h_short_np_pr), short_h_total_pr[-1], config.lvrg_set.leverage))\n","\n","        #         long only      #\n","        h_long_np_pr = np.array(h_long_list)\n","\n","        long_h_total_pr = np.cumprod(h_long_np_pr)\n","        h_long_wr = len(h_long_np_pr[h_long_np_pr > 1]) / len(h_long_np_pr[h_long_np_pr != 1])\n","        \n","        plt.subplot(233)\n","        plt.plot(long_h_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_long_wr, np.min(h_long_np_pr), long_h_total_pr[-1], config.lvrg_set.leverage))\n","\n","\n","        #     reversion adjustment      #\n","            \n","        h_rev_total_pr = np.cumprod(h_rev_np_pr)\n","        h_rev_wr = len(h_rev_np_pr[h_rev_np_pr > 1]) / len(h_rev_np_pr[h_rev_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(234)\n","        plt.plot(h_rev_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_rev_wr, np.min(h_rev_np_pr), h_rev_total_pr[-1], config.lvrg_set.leverage))\n","\n","        #         short       #\n","        # h_rev_short_np_pr = 1 / (np.array(h_short_list) + fee) - fee\n","        h_rev_short_np_pr =  (1 / ((np.array(h_short_list) - 1) / config.lvrg_set.leverage + np.array(short_fee_list) + 1) - np.array(short_fee_list) - 1) * config.lvrg_set.leverage + 1\n","           \n","        short_h_rev_total_pr = np.cumprod(h_rev_short_np_pr)\n","        h_rev_short_wr = len(h_rev_short_np_pr[h_rev_short_np_pr > 1]) / len(h_rev_short_np_pr[h_rev_short_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(235)\n","        plt.plot(short_h_rev_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_rev_short_wr, np.min(h_rev_short_np_pr), short_h_rev_total_pr[-1], config.lvrg_set.leverage))\n","\n","        #         long       #\n","        # h_rev_long_np_pr = 1 / (np.array(h_long_list) + fee) - fee\n","        h_rev_long_np_pr =  (1 / ((np.array(h_long_list) - 1) / config.lvrg_set.leverage + np.array(long_fee_list) + 1) - np.array(long_fee_list) - 1) * config.lvrg_set.leverage + 1\n","            \n","        long_h_rev_total_pr = np.cumprod(h_rev_long_np_pr)\n","        h_rev_long_wr = len(h_rev_long_np_pr[h_rev_long_np_pr > 1]) / len(h_rev_long_np_pr[h_rev_long_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(236)\n","        plt.plot(long_h_rev_total_pr)\n","        plt.title(\"wr : %.3f\\n min_pr : %.3f\\n acc_pr : %.3f\\n leverage %s\" % (h_rev_long_wr, np.min(h_rev_long_np_pr), long_h_rev_total_pr[-1], config.lvrg_set.leverage))\n","        \n","        if show_plot:\n","          plt.show()\n","          \n","    except Exception as e:\n","      print('error in h_pr plot :', e)   \n","    \n","    print()\n","\n","\n","  # break # pair loop"]},{"cell_type":"markdown","metadata":{"id":"MteLY9PS2ZeK"},"source":["##### check statistical significance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzbWuwSw2jaj"},"outputs":[],"source":["# print(survey_df)\n","\n","plt.style.use('dark_background')\n","\n","title_name_list = [[\"total\", \"short\", \"long\"], [\"rev_total\", \"rev_short\", \"rev_long\"]]\n","survey_dfs_list = [[survey_df, short_survey_df, long_survey_df], [rev_survey_df, rev_short_survey_df, rev_long_survey_df]]\n","# title_name = \n","# survey_df_list = \n","\n","space_ = \" \" * 140\n","\n","for d_idx, (title_name, survey_dfs) in enumerate(zip(title_name_list, survey_dfs_list)):\n","\n","  fig = plt.figure(figsize=(30, 10))\n","\n","  gs = gridspec.GridSpec(nrows=1, # row 몇 개 \n","                          ncols=3, # col 몇 개 \n","                          # height_ratios=[1, 1, 1]\n","                        )\n","\n","  # gs = fig.add_gridspec(1, 3, wspace=0, hspace=0)\n","\n","  # nrows, ncols, h_r = 3, 3, [1, 1, 1]\n","  nrows, ncols, h_r = 3, 4, [1, 1, 1]\n","  # nrows, ncols, h_r = 4, 3, [1, 1, 1, 1]\n","\n","  # if d_idx == 0:\n","  # else:\n","    # nrows, ncols, h_r = 2, 2, [1, 1]\n","\n","  for gs_idx, (title, s_df) in enumerate(zip(title_name, survey_dfs)):  \n","\n","\n","    inner_gs = gs[gs_idx].subgridspec(nrows=nrows, # row 몇 개 \n","                          ncols=ncols, # col 몇 개 \n","                          height_ratios=h_r\n","                        )\n","\n","    for col_idx, s_cols in enumerate(s_df.columns):\n","      plt.subplot(inner_gs[col_idx])\n","      plt.plot(s_df[s_cols])\n","      plt.title(s_cols)\n","\n","  # plt.suptitle(\"total\" + \" \" * 140 + \"short\" + \" \" * 140 + \"long\")\n","  plt.suptitle(space_.join(title_name))\n","  plt.show()\n","  print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"GZ0y_x9ugOUD"},"source":["##### check dent_detph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETgm1avml0fE"},"outputs":[],"source":["target_pr = long_total_pr\n","\n","plt.figure(figsize=(4, 8))\n","gs = gridspec.GridSpec(nrows=2,\n","                        ncols=1,\n","                        height_ratios=[1, 1]\n","                      )\n","\n","plt.subplot(gs[0])\n","plt.plot(target_pr)\n","h_roll = pd.Series(target_pr).rolling(10).max()\n","plt.plot(h_roll)\n","# plt.show()\n","# print()\n","\n","plt.subplot(gs[1])\n","dent_depth = target_pr / h_roll\n","plt.plot(dent_depth)\n","plt.show()\n","\n","rolling_max = np.maximum.accumulate(long_total_pr)\n","max_dd = np.max((rolling_max - long_total_pr)/rolling_max)\n","print(\"max_dd :\", max_dd)"]},{"cell_type":"markdown","metadata":{"id":"v2Gjv019AEz8"},"source":["##### check frequency "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"atdBjod9-e21"},"outputs":[],"source":["total_len = np.zeros(len(res_df))\n","print(total_len)\n","np_trade_list = np.array(trade_list)\n","# print(np_trade_list.shape)\n","print(np_trade_list[:, [0], [0]].shape)\n","total_len[np_trade_list[:, [0], [0]]] = 1\n","\n","plt.plot(total_len)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zItdCdJXhQtu"},"source":["##### candle study (난수 생성을 통해 candle strength ratio 를 serialize 할 수 있어야함)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTM-5HpehcSB"},"outputs":[],"source":["# wick_score -> 정수자리, body_score -> 소수점 자리\n","# def candle_strn_ratio(ohlc_data):\n","\n","#   # o, h, l, c = ohlc_data\n","#   if type(ohlc_data) != np.array:\n","#     ohlc_data = np.array(ohlc_data)\n","\n","#   o, h, l, c = np.split(ohlc_data, 4, axis=1)\n","#   #   check up / downward\n","#   # up = 1 if c >= o else 0\n","#   up = np.where(c >= o, 1, 0)\n","\n","#   total_len = h - l\n","#   upper_wick = (h - np.maximum(c, o)) / total_len\n","#   lower_wick = (np.minimum(c, o) - l) / total_len\n","#   body = abs(c - o) / total_len\n","\n","#   # if up:\n","    \n","#   # else:\n","    \n","#   up_score = (1 - upper_wick) * 100 + body\n","#   dn_score = (1 - lower_wick) * 100 + body\n","#   score = np.where(up, up_score, dn_score)  \n","\n","#   return score\n","\n","\n","def candle_strn_ratio(res_df, plot_check=0):\n","  \n","  ohlc_col = [\"open\", \"high\", \"low\", \"close\"]\n","  ohlcs = res_df[ohlc_col]\n","  o, h, l, c = np.split(ohlcs.values, 4, axis=1)\n","\n","  # if type(ohlc_data) != np.array:\n","  #   ohlc_data = np.array(ohlc_data)\n","\n","  #   check up / downward\n","  up = np.where(c >= o, 1, 0)\n","\n","  total_len = h - l\n","  upper_wick = (h - np.maximum(c, o)) / total_len\n","  lower_wick = (np.minimum(c, o) - l) / total_len\n","  body = abs(c - o) / total_len\n","    \n","  up_score = (1 - upper_wick) * 100 + body\n","  dn_score = (1 - lower_wick) * 100 + body\n","  score = np.where(up, up_score, dn_score)  \n","\n","  if plot_check:\n","    fig = plt.figure(figsize=(14, 18))\n","      \n","    gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                          ncols=1, # col 몇 개 \n","                          height_ratios=[3, 1, 1]\n","                        )\n","\n","    ax = fig.add_subplot(gs[0])\n","\n","    # fig.show()\n","    # fig.canvas.draw()\n","\n","    temp_ohlc = ohlcs.values\n","    index = np.arange(len(temp_ohlc))\n","    candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","    mf.candlestick_ohlc(ax, candle, width=0.5, colorup='#26a69a', colordown='#ef5350', alpha=0.5)\n","\n","    plt.show()\n","\n","  return score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGJbx4BgKHKd"},"outputs":[],"source":["#   plot_check    #\n","print(candle_strn_ratio(res_df.iloc[:20], 1))\n","# break\n","# ohlc_data\n","\n","# fig = plt.figure(figsize=(14, 18))\n","  \n","# gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","#                       ncols=1, # col 몇 개 \n","#                       height_ratios=[3, 1, 1]\n","#                     )\n","\n","# ax = fig.add_subplot(gs[0])\n","\n","# # fig.show()\n","# # fig.canvas.draw()\n","\n","# temp_ohlc = ohlc_data.values\n","# index = np.arange(len(temp_ohlc))\n","# candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","# mf.candlestick_ohlc(ax, candle, width=0.5, colorup='#26a69a', colordown='#ef5350', alpha=0.5)\n","\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"o-XjNS1L31YB"},"source":["##### ep_loc.point & zone legacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"taB2j7kT33iN"},"outputs":[],"source":["\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] >= res_df['cloud_bline_%s' % cb_itv]) &\n","    #                 # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['cloud_bline_%s' % cb_itv]) &\n","    #                 (res_df['close'] < res_df['cloud_bline_%s' % cb_itv])\n","    #                 , res_df['entry_{}'.format(strat_version)] - 1, res_df['entry_{}'.format(strat_version)])\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] >= res_df['bb_lower_1m']) &\n","    #                 # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) <= res_df['bb_lower_1m']) &\n","    #                 (res_df['close'] < res_df['bb_lower_1m'])\n","    #                 , res_df['entry_{}'.format(strat_version)] - 1, res_df['entry_{}'.format(strat_version)])\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] <= res_df['cloud_bline_%s' % cb_itv]) &\n","    #                   # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['cloud_bline_%s' % cb_itv]) &\n","    #                   (res_df['close'] > res_df['cloud_bline_%s' % cb_itv])\n","    #                 , res_df['entry_{}'.format(strat_version)] + 1, res_df['entry_{}'.format(strat_version)])\n","\n","    # res_df['entry_{}'.format(strat_version)] = np.where((res_df['open'] <= res_df['bb_upper_1m']) &\n","    #                   # (res_df['close'].shift(config.loc_set.point.tf_entry * 1) >= res_df['bb_upper_1m']) &\n","    #                   (res_df['close'] > res_df['bb_upper_1m'])\n","    #                 , res_df['entry_{}'.format(strat_version)] + 1, res_df['entry_{}'.format(strat_version)])\n","\n","\n","    \n","   # --------------- ema --------------- #   \n","  # res_df['ema5_1m'] = ema(res_df['close'], 5).shift(1)\n","\n","  #   # --------------- cloud bline --------------- #   \n","  # res_df['cloud_bline_1m'] = cloud_bline(res_df, 26).shift(1)\n","  \n","    #       stochastic      #\n","  # res_df['stoch'] = stoch(res_df, 5, 3, 3)\n","\n","    #       fisher      #\n","  # res_df['fisher30'] = fisher(res_df, 30)\n","  # res_df['fisher60'] = fisher(res_df, 60)\n","  # res_df['fisher120'] = fisher(res_df, 120)\n","\n","    #       cctbbo      #\n","  # res_df['cctbbo'], _ = cct_bbo(res_df, 21, 13)\n","\n","    #       ema_roc      #\n","  # res_df['ema_roc'] = ema_roc(res_df['close'], 13, 9)\n","\n","\n","   # ------------------------------ htf data ------------------------------ #    \n","\n","  #             Todo              #\n","  # htf_df = pd.read_excel(date_path2 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # htf_df = pd.read_excel(date_path3 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # htf_df = pd.read_excel(date_path4 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # # htf_df = pd.read_excel(date_path5 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # # # # # htf_df = pd.read_excel(date_path6 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","\n","  # # ---- htf index slicing ---- #\n","  # htf_df = htf_df.loc[:res_df.index[-1]]\n","  \n","  # print(\"res_df.index[-1] :\", res_df.index[-1])\n","  # print(\"htf_df.index[-1] :\", htf_df.index[-1])\n","\n","  # res_df = dc_line(res_df, htf_df, '5m')\n","  # res_df = dc_level(res_df, '5m', 1)\n","\n","\n","  # # # if \"sma4\" in res_df.columns:\n","  # # #   res_df.drop(\"sma4\", axis=1, inplace=1)\n","\n","  # # htf_df['sma'] = htf_df['close'].rolling(60).mean()\n","  # # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, htf_df, [-1]), columns=['sma_30m']))\n","  \n","  # htf_df['stoch'] = stoch(htf_df, 13, 3, 3)\n","  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, htf_df, [-1], backing_i=-1), columns=['stoch_5m']))\n","\n","   \n","  # fifth_df['ema'] = ema(fifth_df['close'], 5)\n","  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, fifth_df, [-1]), columns=['ema5']))\n","\n","        # ------------------------------------ short ------------------------------------ # \n","\n","        # --------- by sar --------- # \n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_3m'].iloc[i] == 0:\n","        #   mr_score += 1\n","\n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_5m'].iloc[i] == 0:\n","        #   mr_score += 1          \n","\n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_15m'].iloc[i] == 0:\n","        #   mr_score += 1\n","\n","          #      dc & sar      # \n","        # mr_const_cnt += 1\n","        # # if res_df['dc_upper_1m'].iloc[i] <= res_df['sar_15m'].iloc[i]:\n","        # if res_df['dc_upper_3m'].iloc[i] <= res_df['sar_5m'].iloc[i]:\n","        # # if res_df['dc_upper_5m'].iloc[i] <= res_df['sar_15m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # -------------- dr scheduling -------------- #\n","        # if config.ep_set.entry_type == 'MARKET':\n","        #   mr_const_cnt += 1\n","        #   if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error):  \n","        #     mr_score += 1\n","\n","           \n","        # ------- entry once ------- #   \n","        # prev_entry_cnt = 0\n","        # for back_i in range(i - 1, 0, -1):\n","        #   if res_df['entry'][back_i] == 1:\n","        #     break\n","\n","        #   elif res_df['entry'][back_i] == -1:\n","        #     prev_entry_cnt += 1          \n","        # # # print(\"prev_entry_cnt :\", prev_entry_cnt)\n","\n","        # mr_const_cnt += 1\n","        # # if prev_entry_cnt <= config.ep_set.entry_incycle:\n","        # # if prev_entry_cnt == config.ep_set.entry_incycle:\n","        # if prev_entry_cnt >= config.ep_set.entry_incycle:\n","        #   mr_score += 1\n","\n","        # ------- htf zoning ------- #   \n","        # mr_const_cnt += 1\n","        #   #       bb zone     #\n","        # if res_df['close'].iloc[i] < res_df['bb_lower_%s' % bbz_interval].iloc[i]:\n","        # # if res_df['close'].iloc[i] < res_df['bb_lower2_1h'].iloc[i]:\n","        # # if res_df['close'].iloc[i] < res_df['bb_base_1h'].iloc[i]:\n","\n","        #   #       cbline zone     #\n","        # # if res_df['close'].iloc[i] < res_df['cloud_bline_%s' % cb_interval].iloc[i]:\n","\n","        #   mr_score += 1\n","\n","  \n","        # ------- ben ep_in's tp done ------- #   \n","        # mr_const_cnt += 1\n","        # if res_df['low'].iloc[i] > res_df['short_tp'].iloc[i]:\n","        #   mr_score += 1\n","\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","          # mr_score += 1\n","\n","\n","\n","        # ------------------------------------ long ------------------------------------ # \n","          \n","\n","        # --------- by sar --------- # \n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_3m'].iloc[i] == 1:\n","        #   mr_score += 1   \n","\n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_5m'].iloc[i] == 1:\n","        #   mr_score += 1     \n","\n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_15m'].iloc[i] == 1:\n","          # mr_score += 1\n","\n","          #      dc & sar      # \n","        # mr_const_cnt += 1\n","        # # if res_df['dc_lower_1m'].iloc[i] >= res_df['sar_15m'].iloc[i]:\n","        # if res_df['dc_lower_3m'].iloc[i] >= res_df['sar_5m'].iloc[i]:\n","        # # if res_df['dc_lower_5m'].iloc[i] >= res_df['sar_15m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # -------------- dr scheduling -------------- #\n","        # if config.ep_set.entry_type == \"MARKET\":\n","          # mr_const_cnt += 1        \n","          # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error): # 일반적으로 dr 상에서 tp 비율이 더 커짐 (tr 보다)\n","          #   mr_score += 1\n","\n","        # -------------- ep limit -------------- #    \n","        # mr_const_cnt += 1\n","        # # if (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        # if config.ep_set.min_eplim_pct < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        # # if 0 < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        #   # if res_df['st_gap_15m'].iloc[i] / res_df['open'].iloc[i] < 0:\n","        #   #   print(\"i, res_df['st_gap_15m'].iloc[i] :\", i, res_df['st_gap_15m'].iloc[i])\n","        #   mr_score += 1\n","\n","\n","        # -------------- entry once -------------- #    \n","        # prev_entry_cnt = 0\n","        # for back_i in range(i - 1, 0, -1):\n","        #   if res_df['entry'][back_i] == -1:\n","        #     break\n","\n","        #   elif res_df['entry'][back_i] == 1:\n","        #     prev_entry_cnt += 1\n","          \n","        # mr_const_cnt += 1\n","        # # if prev_entry_cnt <= config.ep_set.entry_incycle:\n","        # # if prev_entry_cnt == config.ep_set.entry_incycle:\n","        # if prev_entry_cnt >= config.ep_set.entry_incycle:\n","        #   mr_score += 1\n","\n","\n","        # ------- htf zoning ------- #   \n","        # mr_const_cnt += 1\n","          \n","        #   #       bb zone     #\n","        # if res_df['close'].iloc[i] > res_df['bb_upper_%s' % bbz_interval].iloc[i]:\n","        # # if res_df['close'].iloc[i] > res_df['bb_upper2_1h'].iloc[i]:\n","        # # if res_df['close'].iloc[i] > res_df['bb_base_1h'].iloc[i]:\n","        \n","        #   #       cbline zone     #\n","        # # if res_df['close'].iloc[i] > res_df['cloud_bline_%s' % cb_interval].iloc[i]:\n","\n","        #   mr_score += 1\n","\n","\n","        # ------- ben ep_in's tp done ------- #   \n","        # mr_const_cnt += 1\n","        # if res_df['high'].iloc[i] < res_df['long_tp'].iloc[i]:\n","        #   mr_score += 1\n","\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","          \n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","          # mr_score += 1"]},{"cell_type":"markdown","metadata":{"id":"-IbP_Z3Dlwk4"},"source":["### nontp survey"]},{"cell_type":"markdown","metadata":{"id":"FxJ1y8v2fkCR"},"source":["##### term & liqd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qIWa48pl1GO"},"outputs":[],"source":["# print(nontp_long_indexs)\n","\n","plot_size = 100\n","\n","for s_i in range(plot_size, len(trade_list), plot_size):\n","\n","  slice_trade_list = trade_list[s_i - plot_size:s_i]\n","  slice_liqd_list = liqd_list[s_i - plot_size:s_i]\n","\n","  # print(len(slice_trade_list))\n","  np_trade = np.array(slice_trade_list)\n","  trade_term = np_trade[:, [2]] - np_trade[:, [1]]\n","\n","  plt.figure(figsize=(5, 10))\n","  plt.subplot(211)\n","  plt.bar(np.arange(len(trade_term)), trade_term.reshape(-1,), width=1, color='b')\n","\n","  # plt.plot(trade_term.reshape(-1,))\n","  plt.ylim(0, 1000)\n","  # plt.show()\n","  # print()\n","\n","  plt.subplot(212)\n","  # print(len(liqd_list))\n","  # plt.bar(np.arange(len(liqd_list)), liqd_list)\n","  plt.bar(np.arange(len(slice_liqd_list)), np.array(slice_liqd_list), width=1, color='r')\n","  # plt.plot(slice_liqd_list)\n","  plt.show()\n","\n","print()"]},{"cell_type":"markdown","metadata":{"id":"VBwVaUkvfnOd"},"source":["##### check nontp index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRCMBOU4frNY"},"outputs":[],"source":["# np_nontp_short_indexs = np.array(nontp_short_indexs)\n","# np_nontp_long_indexs = np.array(nontp_long_indexs)\n","\n","# short_til_term = len(res_df) - np_nontp_short_indexs\n","# long_til_term = len(res_df) - np_nontp_long_indexs\n","\n","max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","print(max_nontp_long_term)"]},{"cell_type":"markdown","metadata":{"id":"tApzvz_gK9lR"},"source":["## basic strategy"]},{"cell_type":"markdown","metadata":{"id":"FaRGwR4NEop2"},"source":["### shifting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8aYsjEgQnGF"},"outputs":[],"source":["org_res_df = res_df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RF3RM2G2RCb1"},"outputs":[],"source":["#         refresh res_df      #\n","res_df = org_res_df.copy()\n","print(org_res_df.tail(5))\n","\n","# break\n","\n","\n","shift_size = -4\n","# shift_size = -1\n","# shift_size = -7\n","# shift_size = +3\n","\n","res_df['min_upper'] = res_df['min_upper'].shift(shift_size)\n","res_df['max_lower'] = res_df['max_lower'].shift(shift_size)\n","res_df['minor_ST1_Trend'] = res_df['minor_ST1_Trend'].shift(shift_size)\n","res_df['minor_ST2_Trend'] = res_df['minor_ST2_Trend'].shift(shift_size)\n","res_df['minor_ST3_Trend'] = res_df['minor_ST3_Trend'].shift(shift_size)\n","res_df['middle_line'] = res_df['middle_line'].shift(shift_size)\n","\n","print(res_df.tail(5))"]},{"cell_type":"markdown","metadata":{"id":"2gxvme1PC6ha"},"source":["### load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtYdAuSsC72_"},"outputs":[],"source":["# model_name = 'inner_tick_cnnreg_lscalemm_prefee_gpu_%s_%s_%s_%s_%s.h5'\n","\n","# model = tf.keras.models.load_model(ckpt_path + model_name)\n","\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","model = ResNet50(weights='imagenet', include_top=False)\n","# model.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"5la6usMOFzkX"},"source":["#### gen selected vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQk3-jbKF8FB"},"outputs":[],"source":["def min_max_scale(npy_x):\n","\n","  return (npy_x - np.min(npy_x)) / (np.max(npy_x) - np.min(npy_x))\n","\n","def expand_dims(npy_x):\n","\n","  row, col = npy_x.shape\n","  npy_x2 = np.array(npy_x).reshape(-1, row, col, 1).astype(np.float32)\n","  # input_x = np.array(data_x).reshape(-1, row, col).astype(np.float32)\n","\n","  #     1c to 3c    #\n","  npy_x3 = npy_x2 * np.ones(3, dtype=np.float32)[None, None, None, :]\n","\n","  return npy_x3\n","\n","\n","def vector_dist(f1, f2):\n","  return np.linalg.norm(f1-f2)\n","\n","\n","\n","# ------------------------ params ------------------------  #\n","selected_i = 500\n","input_size = 100\n","\n","\n","\n","#   1. 선택된 인덱스를 입력받았을 때, input generating 형태만 만들어놓고,     #\n","#   1-1. input cols 필요함    #\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","sma_list = ['sma']\n","\n","#     -------------- outer price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","\n","selected_price_colname = basic_list + senkoua_list + senkoub_list + sar_list\n","selected_outprice_colname = [macd_list]\n","\n","\n","#         global scaling for outer price data       #\n","#         1. nan 처리       #\n","\n","# # print((np.isnan(df.values)))\n","# print(\"np.sum(np.isnan(df.values), axis=0) :\", np.sum(np.isnan(df.values), axis=0))\n","\n","# max_nan = np.max(np.sum(np.isnan(df.values), axis=0))\n","# # print(max_nan)\n","\n","# df = df.iloc[max_nan:-max_nan]\n","\n","# total_gdata = []\n","# for g_col in selected_outprice_colname:\n","\n","#   temp_data = min_max_scale(res_df[g_col])\n","#   total_gdata.append(temp_data)\n","\n","\n","\n","#   1-2. cols 에 따른, scaling method 구분함    #\n","onprice_input_x = min_max_scale(res_df[selected_price_colname].iloc[selected_i - input_size:selected_i].values)\n","print(onprice_input_x.shape)\n","\n","\n","#   2. plot_check 에서 본인이 원하는 shape 의 인덱스를 선택   #\n","#   3. vertorize, \n","#   3-1. input generator 를 이용해 entry signal 발생할 때마다 dist 비교 진행    #\n","re_onprice_input_x = expand_dims(onprice_input_x)\n","print(re_onprice_input_x.shape)\n","      \n","# break\n","\n","selected_vector = model.predict(re_onprice_input_x, verbose=1)\n","print(selected_vector.shape)"]},{"cell_type":"markdown","metadata":{"id":"OJqkmkpsLCYC"},"source":["### tr_tresh calc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcpo4MGd9Wm4"},"outputs":[],"source":["res_wr = 0.6\n","# tr_thresh = 1\n","# tr_thresh = ((1 - res_wr) / res_wr) ** 0.5\n","tr_thresh = ((1 - res_wr) / res_wr) + 0.01\n","# tr_thresh = 2.6\n","print(\"res_wr :\", res_wr)\n","print(\"tr_thresh :\", tr_thresh)\n","\n","\n","#   단리    #\n","trade_num = 1000\n","asset = 1 # thousand USDT\n","test_loss_gap = 0.95  # fee adjusted\n","test_pr_gap = 1 + (1 - test_loss_gap) * tr_thresh\n","\n","test_loss_cnt = trade_num * (1 - res_wr)\n","test_pr_cnt = trade_num * res_wr\n","\n","test_trade_list = [test_pr_gap] * int(test_pr_cnt) + [test_loss_gap] * int(test_loss_cnt)\n","random.shuffle(test_trade_list)\n","# print(\"len(test_trade_list) :\", len(test_trade_list))\n","print(test_trade_list[:10])\n","print()\n","\n","# print(\"%.5f\" % np.cumprod(test_trade_list)[-1])\n","for tr_thresh_ in np.arange(1, 3, 0.2):\n","  if (1 + (1 - test_loss_gap) * tr_thresh_) ** test_pr_cnt * test_loss_gap ** test_loss_cnt > 1:\n","    break\n","print(\"복리를 위한 tr_thresh_ :\", tr_thresh_)\n","# print(\"tr_thresh :\", tr_thresh)\n","print(\"np.cumprod(test_trade_list)[-1] :\", np.cumprod(test_trade_list)[-1])\n","print(\"total_pr : \", np.cumprod(test_trade_list)[-1])\n","print()\n","#   복리 tr_thresh  #\n","#   1. trade_num 에 영향 받지 않음\n","#   2. loss_gap 에 비례함\n","\n","for tr_thresh_ in np.arange(1, 3, 0.01):\n","  if ((1 - test_loss_gap) * tr_thresh_) * test_pr_cnt + (test_loss_gap - 1) * test_loss_cnt > 0:\n","    break\n","np_test_trade = np.array(test_trade_list) - 1\n","print(np_test_trade[:10])\n","# print(\"%.3f\" % )\n","print(\"단리를 위한 tr_thresh_ :\", tr_thresh_)\n","# print(\"tr_thresh :\", tr_thresh)\n","print(\"np.cumsum(np_test_trade)[-1] :\", np.cumsum(np_test_trade)[-1])\n","print(\"total_pr : \", 1 + np.cumsum(np_test_trade)[-1])\n"]},{"cell_type":"markdown","metadata":{"id":"JNQxkb06ZdTe"},"source":["# traded section plot"]},{"cell_type":"markdown","metadata":{"id":"UmH_Pb5BZUtm"},"source":["## plot with off-color st with dash"]},{"cell_type":"markdown","metadata":{"id":"5z4L3MMYmUI0"},"source":["### sorted plot_check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qv1MM2MemZnF"},"outputs":[],"source":["assert len(open_list) == len(trade_list), \"len(open_list) != len(trade_list)\"\n","assert len(tp_state_list) == len(fee_list), \"len(tp_state_list) != len(fee_list)\"\n","\n","if multi_mode:\n","  strat_version = \"v3\"\n","\n","save_plot = 0\n","tf_plot = 1\n","pr_sort = 1     # 이상한 체결 확인하기 좋음\n","pr_descend = 1  # 1 -> 내림차순\n","# wl_case = 1     # 1 / -1 / 0 (win loss study)\n","position = 1    # -1 / 1 / 0 (short / long / both)\n","\n","x_max = 500\n","\n","inversion = 0\n","hedge = 0\n","\n","\n","if save_plot:\n","  plot_check_dir = current_path + \"plot_check/\" +  key.replace(\".ftr\", \"\")\n","  try:\n","    os.mkdir(plot_check_dir)\n","  except:\n","\n","    #     remove existing dir   #\n","    shutil.rmtree(plot_check_dir)\n","    print(plot_check_dir, 'removed !')\n","    os.mkdir(plot_check_dir)\n","    # pass\n","    \n","\n","prev_plotsize = 130\n","post_plotsize = 120\n","\n","\n","if position == -1:\n","  position = config.ep_set.short_entry_score\n","elif position == 1:\n","  position = -config.ep_set.short_entry_score\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    try:\n","      h_plot_pr_list = h_np_pr\n","    except Exception as e:\n","      print(\"error in h_plot_pr :\", e)\n","      h_plot_pr_list = np_pr\n","\n","\n","h_candle_intv1 = 15\n","h_candle_intv2 = 60\n","if 'hopen_{}'.format(h_candle_intv2) not in res_df.columns:\n","  res_df = h_candle(res_df, h_candle_intv1)\n","  res_df = h_candle(res_df, h_candle_intv2)\n","\n","res_df[\"ma30_1m\"] = res_df['close'].rolling(30).mean()\n","res_df[\"ma60_1m\"] = res_df['close'].rolling(60).mean()\n","\n","res_df = dtk_plot(res_df, dtk_itv2='15m', hhtf_entry=15, use_dtk_line=config.loc_set.zone.use_dtk_line)\n","# res_df = dtk_plot(res_df, dtk_itv2='15m', hhtf_entry=1, use_dtk_line=1)\n","# break\n","\n","rtc_list = [\"short_tp_1_{}\".format(strat_version), \"short_tp_gap_{}\".format(strat_version), \"long_tp_1_{}\".format(strat_version), \"long_tp_gap_{}\".format(strat_version)]\n","# h_rtc_list = [\"h_short_tp_1\", \"h_short_tp_gap\", \"h_long_tp_1\", \"h_long_tp_gap\"]\n","dtk_list = [\"short_dtk_1_{}\".format(strat_version), \"short_dtk_gap_{}\".format(strat_version), \"long_dtk_1_{}\".format(strat_version), \"long_dtk_gap_{}\".format(strat_version),\n","            # \"short_dtk_1_line\", \"short_dtk_gap_line\", \"long_dtk_1_line\", \"long_dtk_gap_line\",\n","            \"short_dtk_plot_1\", \"short_dtk_plot_gap\", \"long_dtk_plot_1\", \"long_dtk_plot_gap\"]\n","dc_v2_list = ['dc_upper_v2_{}'.format(strat_version), 'dc_lower_v2_{}'.format(strat_version)]\n","\n","\n","ohlc_list = ['open', 'high', 'low', 'close'] # + basic_st_list\n","hcandle_list = ['hopen_%s' % h_candle_intv1, 'hclose_%s' % h_candle_intv1, 'hopen_%s' % h_candle_intv2, 'hclose_%s' % h_candle_intv2]\n","# hcandle_list = ['hopen_%s' % h_candle_intv1, 'hclose_%s' % h_candle_intv1, 'hhigh_%s' % h_candle_intv2, 'hlow_%s' % h_candle_intv2]\n","\n","# --------------------- dc & bb level --------------------- #\n","dc_interval = '1m'\n","hdc_interval = '5m'\n","hhdc_interval = '15m'\n","\n","dc_list = ['dc_upper_%s' % dc_interval, 'dc_lower_%s' % dc_interval]\n","hdc_list = ['dc_upper_%s' % hdc_interval, 'dc_lower_%s' % hdc_interval]\n","hhdc_list = ['dc_upper_%s' % hhdc_interval, 'dc_lower_%s' % hhdc_interval]\n","\n","bb_interval = dc_interval\n","hbb_interval = hdc_interval\n","hhbb_interval = hhdc_interval\n","\n","bb_list = ['bb_upper_%s' % bb_interval, 'bb_lower_%s' % bb_interval]\n","hbb_list = ['bb_upper_%s' % hbb_interval, 'bb_lower_%s' % hbb_interval]\n","hhbb_list = ['bb_upper_%s' % hhbb_interval, 'bb_lower_%s' % hhbb_interval]\n","\n","bbwp_list = ['bbwp', 'bbwp_ma']\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1']\n","senkoub_list = ['senkou_b1']\n","\n","sar_list = ['sar_3m', 'sar_5m', 'sar_15m']\n","\n","ma_list = ['ma30_1m', 'ma60_1m']\n","sma_list = ['sma_1m']\n","\n","ema_list = ['ema_5m']\n","# cb_list = ['cloud_bline_1m']\n","cb_list = ['cloud_bline_30m']\n","# cb_list = ['cloud_bline_5m']\n","\n","\n","\n","# -------------- under price phase -------------- #\n","# macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3']\n","# trix_list = ['trix1', 'trix2', 'trix3']\n","# stoch_list = ['stoch_5m']\n","# fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","# cctbbo_list = ['cctbbo']\n","# emaroc_list = ['ema_roc']\n","rsi_list = ['rsi_%s' % config.loc_set.point.exp_itv] \n","cci_list = ['cci_%s' % config.loc_set.point.exp_itv] \n","\n","\n","# -------------- summation -------------- #\n","# input_colname = ohlc_list + basic_st_list + pline_list + bb_list + hbb_list + sma_list + cb_list + stoch_list + sar_list + dc_list\n","input_colname = ohlc_list + hcandle_list + bb_list + hbb_list + hhbb_list + dc_list + hdc_list + hhdc_list + dtk_list + dc_v2_list + rsi_list + ema_list + ma_list# + cci_list\n","\n","# yrange_colname = ohlc_list + basic_st_list + pline_list # currently just used for ymin, ymax\n","yrange_colname = ohlc_list + hcandle_list + bb_list + hbb_list + hhbb_list + dc_list + hdc_list + hhdc_list + dc_v2_list + ema_list # currently just used for ymin, ymax\n","yrange_colname = ohlc_list + hcandle_list + bb_list + hbb_list + hhbb_list + dc_list + hdc_list + dc_v2_list + ema_list # currently just used for ymin, ymax\n","\n","\n","# aggr_obj = dict(zip(plot_pr_list, open_list, enumerate(trade_list)))\n","aggr_obj = dict(zip(plot_pr_list, zip(open_list, enumerate(trade_list))))\n","sorted_obj = sorted(aggr_obj.items(), key=(lambda x: x[0]), reverse=pr_descend)\n","\n","# print(aggr_obj)\n","# print(sorted_obj)\n","\n","if pr_sort:\n","  iter_obj = sorted_obj\n","else:\n","  iter_obj = aggr_obj.items()\n","\n","odd_cnt = 0\n","obj_i = -1\n","rev_obj_i = 0\n","len_obj = len(sorted_obj)\n","\n","#   지금, continue 발생시 true / false idx 가 같이 상승하는 문제\n","\n","# for temp_pr, (open_idx, (t_i, (ep_idx_list_, tp_idx_list_))) in iter_obj:  # 0.699700153073042, (291402, (3014, ([370012], [370014])))\n","# for obj_i, (temp_pr, (open_idx, (t_i, (ep_idx_list_, out_idx_list_, tp_idx_list_)))) in enumerate(iter_obj):  # 0.699700153073042, (291402, (3014, ([370012], [370014])))\n","# for temp_pr, (open_idx, (t_i, (ep_idx_list_, out_idx_list_, tp_idx_list_))) in iter_obj:  # 0.699700153073042, (291402, (3014, ([370012], [370014])))\n","\n","while 1:\n","\n","  if obj_i >= len_obj or rev_obj_i >= len_obj:\n","    break\n","\n","  if odd_cnt % 2 == 1 and tf_plot: #  loss plot 을 채워야하는 상황\n","    rev_obj_i += 1\n","    temp_pr, (open_idx, (t_i, (ep_idx_list_, out_idx_list_, tp_idx_list_))) = sorted_obj[-rev_obj_i]\n","    if temp_pr > 1.0:\n","      continue  \n","\n","  else:\n","    obj_i += 1\n","    temp_pr, (open_idx, (t_i, (ep_idx_list_, out_idx_list_, tp_idx_list_))) = sorted_obj[obj_i]\n","    if temp_pr < 1.0:\n","      continue  \n","\n","  if not(i >= prev_plotsize):\n","    continue\n","  \n","  #   open size indexing by open_idx    #\n","  open_side_ = res_df['entry_{}'.format(strat_version)].iloc[open_idx]\n","\n","  # ---------- const. zone ---------- #\n","\n","  if position != 0:\n","    if open_side_ != position:\n","      continue\n","\n","  if multi_mode:\n","    if not strat_version in tp_state_list[t_i]:\n","    # if tp_state_list[t_i] != 'long close tp':\n","    # if tp_state_list[t_i] != 's-long_tp':\n","      continue\n","\n","  # if open_idx == 63901:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","\n","  # if tp_ratio_list[t_i] > 0.4:\n","  #   continue\n","\n"," \n","  # print(\"open_idx :\", open_idx)\n","  print(\"open_side_ :\", open_side_)\n","  print(\"np_timeidx[open_idx] :\", np_timeidx[open_idx])\n","  print(\"open_idx, ep_idx_list_[0], tp_idx_list_[-1] :\", open_idx, ep_idx_list_[0], tp_idx_list_[-1])\n","  #   const. 에 합하는 조건 나올때까지 loop 돌리고, const. phase 통과시 odd_cnt += 1,\n","  #   => odd_cnt 로 gs_plot 을 채운다는 느낌 \n","  #   odds = 1 -> wl_case == 1 만 허용, odds = 2 -> wl_case == -1 만 허용\n","  odd_cnt += 1\n","\n","  # break\n","\n","  plot_df = res_df.iloc[open_idx - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  # st_trend_plot_df = res_df[['ST1_Trend%s' % basic_st_interval, 'ST2_Trend%s' % basic_st_interval, 'ST3_Trend%s' % basic_st_interval]].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  # fig = trendln.plot_support_resistance(plot_df['close'], accuracy=8, fromwindows=0, numbest=1,  window=30) # requires matplotlib - pip install matplotlib\n","  \n","  odds = 1 if odd_cnt % 2 == 1 else 2\n","  if odds == 1:\n","\n","    plt.style.use('dark_background')\n","\n","    fig = plt.figure(figsize=(26, 18))\n","    \n","    gs = gridspec.GridSpec(nrows=2, # row 몇 개 \n","                        ncols=2, # col 몇 개 \n","                        height_ratios=[3, 1]\n","                        )\n","    \n","  ax = fig.add_subplot(gs[odds - 1])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='#26a69a', colordown='#ef5350', alpha=0.5)\n","\n","  # ---------- h_candle ---------- #\n","  alpha = 1\n","  lw = 1\n","  for cd_i, candle in enumerate(hcandle_list):\n","\n","    if cd_i == 2:\n","      lw = 2      \n","    plt.step(np.arange(len(plot_df)), plot_df[candle].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","\n","  # alpha = 0.1\n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['hclose_60'].values, plot_df['hopen_60'].values, \n","  #                     where=1, facecolor='#ffffff', alpha=alpha)  \n","  \n","\n","   # --------- ma --------- #\n","  alpha = 1\n","  lw = 2\n","  for ma_i, item in enumerate(ma_list):\n","    plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","\n","   # --------- ema --------- #\n","  alpha = 1\n","  lw = 4\n","  for sm_i, item in enumerate(ema_list):\n","    plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#03ed30', linewidth=lw)\n","    \n","  # ---------------------- dc_v2 ---------------------- #\n","  # alpha = 1\n","  # lw = 2\n","  # for sm_i, item in enumerate(dc_v2_list):\n","  #     plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","\n","  # ---------------------- dc ---------------------- #\n","  alpha = 1\n","  lw = 2\n","  for sm_i, item in enumerate(dc_list):\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","\n","  # ---------------------- hdc ---------------------- #\n","  alpha = 1\n","  lw = 2\n","  for sm_i, item in enumerate(hdc_list):\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#e65100', linewidth=lw)\n","\n","  # ---------------------- hhdc ---------------------- #\n","  alpha = 1\n","  lw = 4\n","  for sm_i, item in enumerate(hhdc_list):\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#c2185b', linewidth=lw)\n","\n","\n","  # ---------------------- bb ---------------------- #\n","  alpha = 1\n","  lw = 1\n","  for sm_i, item in enumerate(bb_list):\n","    plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","\n","  alpha = 0.2\n","  plt.fill_between(np.arange(len(plot_df)), plot_df['bb_upper_%s' % bb_interval].values, plot_df['bb_lower_%s' % bb_interval].values, \n","                      where=plot_df['bb_upper_%s' % bb_interval].values >= plot_df['bb_lower_%s' % bb_interval].values, facecolor='#ffffff', alpha=alpha)   \n","\n","  # ---------------------- hbb ---------------------- #\n","  alpha = 1\n","  lw = 2\n","  for sm_i, item in enumerate(hbb_list):\n","    plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ff00ff', linewidth=lw)\n","  \n","  alpha = 0.2\n","  plt.fill_between(np.arange(len(plot_df)), plot_df['bb_upper_%s' % hbb_interval].values, plot_df['bb_lower_%s' % hbb_interval].values, \n","                      where=plot_df['bb_upper_%s' % hbb_interval].values >= plot_df['bb_lower_%s' % hbb_interval].values, facecolor='#ff00ff', alpha=alpha) \n","  \n","  # ---------------------- hhbb ---------------------- #\n","\n","  alpha = 1\n","  lw = 4\n","  for sm_i, item in enumerate(hhbb_list):\n","    plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#3179f5', linewidth=lw)\n","  \n","  alpha = 0.2\n","  plt.fill_between(np.arange(len(plot_df)), plot_df['bb_upper_%s' % hhbb_interval].values, plot_df['bb_lower_%s' % hhbb_interval].values, \n","                      where=plot_df['bb_upper_%s' % hhbb_interval].values >= plot_df['bb_lower_%s' % hhbb_interval].values, facecolor='#3179f5', alpha=alpha) \n","  \n","  # ------------------- dtk_line (old, tp_line) ------------------- #\n","  \n","  # alpha = 1\n","  # lw = 2\n","  # rtc_ratio_list = [config.loc_set.zone.dt_k]\n","  \n","  # for rtc_k in rtc_ratio_list:    \n","  #   # plt.step(np.arange(len(plot_df)), plot_df['short_dtk_1_line'].values - plot_df['short_dtk_gap_line'].values * rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   # plt.step(np.arange(len(plot_df)), plot_df['long_dtk_1_line'].values + plot_df['long_dtk_gap_line'].values * rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   plt.step(np.arange(len(plot_df)), plot_df['short_dtk_1'].values - plot_df['short_dtk_gap'].values * rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   plt.step(np.arange(len(plot_df)), plot_df['long_dtk_1'].values + plot_df['long_dtk_gap'].values * rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","\n","  # hy_min = np.min(plot_df['short_dtk_1'].values - plot_df['short_dtk_gap'].values * rtc_k)\n","  # hy_max = np.max(plot_df['long_dtk_1'].values + plot_df['long_dtk_gap'].values * rtc_k)  \n","\n","  # alpha = 1\n","  # lw = 4\n","  # # h_rtc_ratio_list = [config.loc_set.zone.dt_k]\n","  # h_rtc_ratio_list = [config.loc_set.zone.zone_dt_k]\n","  # # h_rtc_ratio_list = [0.272, 0.36, 0.4, 0.5]\n","  \n","  # for h_rtc_k in h_rtc_ratio_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df['short_dtk_plot_1'].values - plot_df['short_dtk_plot_gap'].values * h_rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   plt.step(np.arange(len(plot_df)), plot_df['long_dtk_plot_1'].values + plot_df['long_dtk_plot_gap'].values * h_rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   # plt.step(np.arange(len(plot_df)), plot_df['h_short_tp_1'].values - plot_df['h_short_tp_gap'].values * h_rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","  #   # plt.step(np.arange(len(plot_df)), plot_df['h_long_tp_1'].values + plot_df['h_long_tp_gap'].values * h_rtc_k, alpha=alpha, linestyle='--', color='#ffffff', linewidth=lw)\n","\n","  # # hy_min = np.min(plot_df['short_dtk_plot_1'].values - plot_df['short_dtk_plot_gap'].values * h_rtc_k)\n","  # # hy_max = np.max(plot_df['long_dtk_plot_1'].values + plot_df['long_dtk_plot_gap'].values * h_rtc_k)  \n","\n","  # ------------------------------------------------------------- #\n","\n","\n","  # ------------- ep ------------- #\n","  # if i != initial_i:\n","  # if len(ep_idx_list_) > 1:\n","  \n","    #        initial order         #\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='#ffeb3b')\n","  plt.axvline(prev_plotsize, alpha=0.5, linestyle='--', color='#ffeb3b')\n","\n","  for ep_i in range(len(ep_idx_list_)):\n","    # plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0]), alpha=0.7, linestyle='--', color='#ffeb3b')\n","    plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - open_idx), alpha=0.7, linestyle='--', color='#ffeb3b')\n","\n","  # plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","\n","  # ------------- x lim ------------- #\n","  if len(plot_df) > x_max:\n","    plt.xlim(0, x_max)\n","\n","  x0,x1 = plt.gca().get_xlim()\n","\n","  # ep_xmin = (prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0])) / x1\n","  ep_xmin = (prev_plotsize + (ep_idx_list_[ep_i] - open_idx)) / x1\n","  plt.axhline(ep_tp_list[t_i][0], linestyle='--', xmin=ep_xmin, xmax=1, alpha=1, color='lime')  # ep line axhline  \n","  plt.text(x1, ep_tp_list[t_i][0][0], ' ep :\\n %s' % ep_tp_list[t_i][0][0], ha='left', va='center', fontweight='bold') # ep line label\n","\n","  \n","  # ------------- tp ------------- #\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","\n","    # tp_xmin = (prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0])) / x1\n","    tp_xmin = (prev_plotsize + (tp_idx_list_[sub_i] - open_idx)) / x1\n","    plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='--', xmin=tp_xmin , xmax=1, alpha=1, color='lime')  # tp line axhline\n","    plt.text(x1, ep_tp_list[t_i][1][sub_i], ' tp :\\n %s' % ep_tp_list[t_i][1][sub_i], ha='left', va='center', fontweight='bold') # tp line label\n","     \n","    # plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0]), alpha=1., linestyle='--', color='#ffeb3b', zorder=2)\n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - open_idx), alpha=1., linestyle='--', color='#ffeb3b', zorder=2)\n","\n","\n","  # ------------- rtc horizontal range ------------- # --> open_idx 로 할지는 추후 수정 권고 (ep_loc.point2 에 의해 진입 기준 point 가 변경될 수 있음)\n","  # rtc_ratio_list = [0.272, 0.36, 0.4, 0.5]\n","  rtc_ratio_list = [0.]\n","  if open_side_ == config.ep_set.short_entry_score:\n","    # plt.axhline(res_df['short_rtc_1'].iloc[open_idx], linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","    # plt.axhline(res_df['short_rtc_0'].iloc[open_idx], linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","    out_line = res_df['short_out_{}'.format(strat_version)].iloc[out_idx_list_[0]]\n","    plt.axhline(out_line, linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","    plt.text(x0, out_line, ' %s' % config.tr_set.out_gap, ha='left', va='center', fontweight='bold')\n","\n","    for rtc_k in rtc_ratio_list:\n","      plt.axhline(res_df['h_short_rtc_1_{}'.format(strat_version)].iloc[open_idx] - res_df['h_short_rtc_gap_{}'.format(strat_version)].iloc[open_idx] * rtc_k, linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","      plt.text(x0, res_df['h_short_rtc_1_{}'.format(strat_version)].iloc[open_idx] - res_df['h_short_rtc_gap_{}'.format(strat_version)].iloc[open_idx] * rtc_k, ' %s' % rtc_k, ha='left', va='center', fontweight='bold')\n","      \n","    y_max = out_line\n","    y_min = res_df['h_short_rtc_1_{}'.format(strat_version)].iloc[tp_idx_list_[-1]] - res_df['h_short_rtc_gap_{}'.format(strat_version)].iloc[tp_idx_list_[-1]] * rtc_k\n","\n","    print(\"short_tp :\", res_df['short_tp_{}'.format(strat_version)].iloc[tp_idx_list_[-1]])\n","    print(\"short_out :\", out_line)\n","\n","  else:\n","    # plt.axhline(res_df['long_rtc_1'].iloc[open_idx], linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","    # plt.axhline(res_df['long_rtc_0'].iloc[open_idx], linewidth=.5, linestyle='-', alpha=1, color='#ffffff') \n","    out_line = res_df['long_out_{}'.format(strat_version)].iloc[out_idx_list_[0]]\n","    plt.axhline(out_line, linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","    plt.text(x0, out_line, ' %s' % config.tr_set.out_gap, ha='left', va='center', fontweight='bold')\n","\n","    for rtc_k in rtc_ratio_list:\n","      plt.axhline(res_df['h_long_rtc_1_{}'.format(strat_version)].iloc[open_idx] + res_df['h_long_rtc_gap_{}'.format(strat_version)].iloc[open_idx] * rtc_k, linewidth=.5, linestyle='-', alpha=1, color='#ffffff')\n","      plt.text(x0, res_df['h_long_rtc_1_{}'.format(strat_version)].iloc[open_idx] + res_df['h_long_rtc_gap_{}'.format(strat_version)].iloc[open_idx] * rtc_k, ' %s' % rtc_k, ha='left', va='center', fontweight='bold')\n","\n","    y_max = res_df['h_long_rtc_1_{}'.format(strat_version)].iloc[tp_idx_list_[-1]] + res_df['h_long_rtc_gap_{}'.format(strat_version)].iloc[tp_idx_list_[-1]] * rtc_k\n","    y_min = out_line\n","\n","    print(\"long_tp :\", res_df['long_tp_{}'.format(strat_version)].iloc[tp_idx_list_[-1]])\n","    print(\"long_out :\", out_line)\n","  \n","    # t_tr = ((res_df['long_tp'].iloc[open_idx] - res_df['close'].iloc[open_idx] - tp_fee * res_df['close'].iloc[open_idx]) / (res_df['close'].iloc[open_idx] - res_df['long_out'].iloc[open_idx] + out_fee * res_df['close'].iloc[open_idx]))\n","    # t_dr = ((res_df['long_tp'].iloc[open_idx] - res_df['close'].iloc[open_idx]) / (res_df['close'].iloc[open_idx] - res_df['long_out'].iloc[open_idx]))     \n","    # print(\"t_tr :\", t_tr)\n","    # print(\"t_dr :\", t_dr)\n","\n","  #         hedge ep & tp         #\n","  h_i = h_trade_list[t_i][1]\n","  if h_i is not None:\n","    # plt.axvline(prev_plotsize + (h_i - ep_idx_list_[0]), linestyle='--')\n","    plt.axvline(prev_plotsize + (h_i - open_idx), linestyle='--')\n","    plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","    plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  if not config.lvrg_set.static_lvrg:\n","    \n","    #   list length 만 sync 맞으면 t_i 걱정 안해도됨, zip 해서 순서가 바뀌었을 뿐, original serialized order 에서 t_i 로 indexing 하는 것뿐임   #\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\n lvrg : %s\\ntp_ratio : %.3f\\n dr : %.3f\\n fee : %.4f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], \n","                                                                                                h_plot_pr_list[t_i], leverage_list[t_i], tp_ratio_list[t_i], dr_list[t_i], fee_list[t_i]))\n","\n","    print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee_list[t_i] - 1) * leverage_list[t_i] + 1)\n","    print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee_list[t_i] - 1) * leverage_list[t_i] + 1)    \n","\n","  else:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\n tp_ratio : %.3f\\n dr : %.3f\\n fee : %.4f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], \n","                                                                                     h_plot_pr_list[t_i], tp_ratio_list[t_i], dr_list[t_i], fee_list[t_i]))\n","\n","    print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee_list[t_i] - 1) * config.lvrg_set.leverage + 1)\n","    print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee_list[t_i] - 1) * config.lvrg_set.leverage + 1)\n","  \n","  # ------------- y lim ------------- #  \n","  y_max_ = max(np.max(plot_df[yrange_colname]))\n","  y_min_ = min(np.min(plot_df[yrange_colname]))\n","  y_max = max(y_max, y_max_)\n","  y_min = min(y_min, y_min_)\n","  \n","  # hy_min = np.min(plot_df['short_dtk_1'].values - plot_df['short_dtk_gap'].values * 0.36)\n","  # hy_max = np.max(plot_df['long_dtk_1'].values + plot_df['long_dtk_gap'].values * 0.36)  \n","  # y_max = max(y_max, y_max_, hy_max)\n","  # y_min = min(y_min, y_min_, hy_min)\n","\n","  if np.isnan(y_max) or np.isnan(y_min):\n","    print('continued in yminmax')\n","    continue\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  #           rsi          #    \n","  plt.subplot(gs[odds + 1])\n","  alpha = 1\n","  for rsi_ in rsi_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[rsi_].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axhline(50, linestyle='--')\n","  plt.axhline(50 + config.loc_set.point.osc_band, linestyle='--')\n","  plt.axhline(50 - config.loc_set.point.osc_band, linestyle='--')\n","  \n","  plt.axvline(prev_plotsize, linestyle='--')\n","  \n","  #           cci          #    \n","  # plt.subplot(gs[odds + 1])\n","  # alpha = 1\n","  # for cci_ in cci_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cci_].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axhline(config.loc_set.point.osc_band, linestyle='--')\n","  # plt.axhline(-config.loc_set.point.osc_band, linestyle='--')\n","  \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","\n","\n","  #     vline open     #\n","  for ep_i in range(len(ep_idx_list_)):\n","    plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - open_idx), alpha=0.7, linestyle='--', color='#ffeb3b')\n","  \n","  #     vline close     #\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - open_idx), alpha=1., linestyle='--', color='#ffeb3b', zorder=2)\n","\n","  if len(plot_df) > x_max:\n","    plt.xlim(0, x_max)\n","\n","\n","  if not save_plot:\n","    if odds == 2:\n","      plt.show()\n","      plt.close()\n","  \n","  else:\n","    # ---------- save mode ---------- #\n","    fig_name = plot_check_dir +  \"/%s.png\" % t_i\n","    plt.savefig(fig_name)\n","    print(fig_name, \"saved !\")\n","\n","  # plt.close()  \n","  print()\n","\n","  # break\n"]},{"cell_type":"markdown","metadata":{"id":"13a-U32Uy50I"},"source":["### brief np_pr survey"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L9LdjV2uUWnp"},"outputs":[],"source":["# plot_pr_list[:100]\n","\n","plt.plot(np_pr)\n","plt.axhline(1)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TBE0l6dHRYrE"},"source":["### whole pr & chart sync"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-txULkhXRbz5"},"outputs":[],"source":["#     chunky survey 필요함    #\n","chunk_size = 50000\n","\n","sync_pr = np.ones(len(res_df))\n","sync_tr = np.zeros(len(res_df))\n","# sync_tr = np.empty(len(res_df))\n","# sync_tr[:] = np.nan\n","\n","max_tr = np.max(tp_ratio_list)\n","min_tr = np.min(tp_ratio_list)\n","\n","for ck_i in range(0, len(res_df), chunk_size):\n","\n","  chunked_df = res_df.iloc[ck_i:ck_i + chunk_size]\n","  # break\n","\n","  for pr_, eptp_idx, tr_ in zip(pr_list[ck_i:ck_i + chunk_size], trade_list[ck_i:ck_i + chunk_size], tp_ratio_list[ck_i:ck_i + chunk_size]):\n","    # print(pr_, eptp_idx)\n","    sync_pr[eptp_idx[-1][0]] = pr_\n","    sync_tr[eptp_idx[-1][0]] = tr_\n","    # break\n","\n","  chunked_pr = sync_pr[ck_i:ck_i + chunk_size]\n","  chunked_tr = sync_tr[ck_i:ck_i + chunk_size]\n","  chunked_tr = np.where(np.isnan(chunked_tr), pd.Series(chunked_tr).shift(1), chunked_tr)\n","\n","  # plt.figure(figsize=(8, 6))\n","\n","  plt.subplot(311)\n","  plt.plot(np.arange(len(chunked_df)), chunked_df['close'])\n","  # plt.show()\n","\n","  plt.subplot(312)\n","  plt.plot(np.cumprod(chunked_pr))\n","  \n","  plt.subplot(313)\n","  plt.plot(chunked_tr)\n","  plt.ylim(min_tr + 0.5 * (max_tr - min_tr), max_tr)\n","  \n","  plt.show()\n","  print()\n"]},{"cell_type":"markdown","metadata":{"id":"Qys2Bw5Ou3u9"},"source":["### plot indi. legacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi5ntOOVu6JT"},"outputs":[],"source":["\n","  # ---------------------- ma ---------------------- #\n","   # --------- ema --------- #\n","  # alpha = 1\n","  # for sm_i, item in enumerate(ema_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#03ed30', linewidth=lw)\n","  #   alpha -= 0.2\n","\n","  #   # --------- sma --------- #\n","  # alpha = 1\n","  # for sm_i, sma in enumerate(sma_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 4\n","  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='#e91e63', linewidth=lw)\n","  #   alpha -= 0.2\n","\n","  \n","  # ---------------------- cb ---------------------- #\n","  # alpha = 1\n","  # for sm_i, item in enumerate(cb_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#5b9cf6', linewidth=lw)\n","  #   alpha -= 0.2\n","\n","\n","  \n","  # ---------------------- sar ---------------------- #\n","  # alpha = 1\n","  # markersize = 5\n","  # for sar in sar_list:\n","  #   plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","  #   markersize += 1\n","  #   alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  # alpha = 0.7\n","  # for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","  #                     where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","  #                     where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","  #   alpha -= 0.05\n","  \n","\n","\n","  # ---------------------- outer price indi. ---------------------- #\n","  #           macd          #\n","  # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","    \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for stoch_ in stoch_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[stoch_].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(stoch_upper, linestyle='--')\n","  # plt.axhline(stoch_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- cctbbo ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for cctbbo in cctbbo_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(cctbbo_upper, linestyle='--')\n","  # plt.axhline(cctbbo_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- ema_roc ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for emaroc in emaroc_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","  \n","  # ---------- bbw ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for bbwp_ in bbwp_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[bbwp_].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(bbwp_thresh, linestyle='--')\n","\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"59nW2aKYzkN8"},"source":["### plot all indicator (stepline ver.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDH4rXgNzno6"},"outputs":[],"source":["save_plot = False\n","\n","\n","if save_plot:\n","  plot_check_dir = current_path + \"plot_check/\" +  key.replace(\".xlsx\", \"\")\n","  try:\n","    os.mkdir(plot_check_dir)\n","  except:\n","\n","    #     remove existing dir   #\n","    shutil.rmtree(plot_check_dir)\n","    print(plot_check_dir, 'removed !')\n","    os.mkdir(plot_check_dir)\n","    # pass\n","    \n","# prev_plotsize = 120\n","prev_plotsize = 150\n","post_plotsize = 20\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    try:\n","      h_plot_pr_list = h_np_pr\n","    except Exception as e:\n","      print(\"error in h_plot_pr :\", e)\n","      h_plot_pr_list = np_pr\n","\n","\n","#         select plot columns       #\n","major_st_list = ['major_ST1_Up', 'major_ST1_Down', 'major_ST2_Up', 'major_ST2_Down', 'major_ST3_Up', 'major_ST3_Down',\n","                 'major_middle_line', 'major_upper_middle', 'major_lower_middle']\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower'] # + major_st_list\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1',  'senkou_a2']\n","senkoub_list = ['senkou_b1',  'senkou_b2']\n","\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1']\n","\n","# ma_list = ['sma1', 'sma4']\n","ma_list = ['ema5']\n","\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","# macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3']\n","# trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","trix_list = ['trix1', 'trix2', 'trix3']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","emaroc_list = ['ema_roc']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + ma_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + ma_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","input_colname = basic_list + major_st_list + senkoua_list + senkoub_list + sar_list + stoch_list + fisher_list + emaroc_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list # currently just used for ymin, ymax\n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","\n","# for t_i, (initial_i, i, j) in enumerate(trade_list):\n","for t_i, (ep_idx_list_, tp_idx_list_) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # if 100 < i < 1860:\n","  if ep_idx_list_[0] == 370530:\n","    pass\n","  else:\n","    continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > short_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + post_plotsize, input_cols]\n","  plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  # st_trend_plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize, [7, 10, 13]]\n","  # st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend', 'major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  # htf_st_trend_plot_df = res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","\n","  if np.isnan(y_max) or np.isnan(y_min):\n","    continue\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","  \n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, plot_df['minor_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, plot_df['minor_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, plot_df['minor_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, plot_df['minor_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, plot_df['minor_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, plot_df['minor_ST3_Down'], np.nan)\n","\n","  plot_df[\"off_color_upper_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, plot_df['major_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, plot_df['major_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, plot_df['major_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, plot_df['major_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, plot_df['major_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, plot_df['major_ST3_Down'], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df['minor_ST1_Up'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, np.nan, plot_df['minor_ST1_Up'])\n","  plot_df['minor_ST2_Up'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, np.nan, plot_df['minor_ST2_Up'])\n","  plot_df['minor_ST3_Up'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, np.nan, plot_df['minor_ST3_Up'])\n","  plot_df['minor_ST1_Down'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, np.nan, plot_df['minor_ST1_Down'])\n","  plot_df['minor_ST2_Down'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, np.nan, plot_df['minor_ST2_Down'])\n","  plot_df['minor_ST3_Down'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, np.nan, plot_df['minor_ST3_Down'])\n","\n","  plot_df['major_ST1_Up'] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, np.nan, plot_df['major_ST1_Up'])\n","  plot_df['major_ST2_Up'] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, np.nan, plot_df['major_ST2_Up'])\n","  plot_df['major_ST3_Up'] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, np.nan, plot_df['major_ST3_Up'])\n","  plot_df['major_ST1_Down'] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, np.nan, plot_df['major_ST1_Down'])\n","  plot_df['major_ST2_Down'] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, np.nan, plot_df['major_ST2_Down'])\n","  plot_df['major_ST3_Down'] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, np.nan, plot_df['major_ST3_Down'])\n","\n","\n","  plot_short_ep = short_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_ep = long_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_tp = long_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]  \n","\n","\n","  # fig = trendln.plot_support_resistance(plot_df['close'], accuracy=8, fromwindows=False, numbest=1,  window=30) # requires matplotlib - pip install matplotlib\n","\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  plt.step(plot_df[['minor_ST1_Up', 'minor_ST2_Up', 'minor_ST3_Up']].values, 'r', alpha=1)  # upper on color\n","  plt.step(plot_df[['minor_ST1_Down', 'minor_ST2_Down', 'minor_ST3_Down']].values, 'b', alpha=1)  # lower on color\n","  \n","  plt.step(plot_df[['major_ST1_Up', 'major_ST2_Up', 'major_ST3_Up']].values, 'r', alpha=1, linewidth=3)  # major upper on color\n","  plt.step(plot_df[['major_ST1_Down', 'major_ST2_Down', 'major_ST3_Down']].values, 'b', alpha=1, linewidth=3)  # major lower on color\n","\n","  plt.step(plot_df[['middle_line']].values, 'fuchsia', alpha=1)  # middle \n","  plt.step(plot_df[['major_middle_line']].values, 'fuchsia', alpha=1, linewidth=3)  # major_middle \n","  \n","  plt.step(plot_df[['off_color_upper_st1', 'off_color_upper_st2', 'off_color_upper_st3']].values, 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df[['off_color_lower_st1', 'off_color_lower_st2', 'off_color_lower_st3']].values, 'b', alpha=1, linestyle=':')  # lower off color\n","  \n","  plt.step(plot_df[['off_color_upper_hst1', 'off_color_upper_hst2', 'off_color_upper_hst3']].values, 'r', alpha=1, linestyle=':', linewidth=3)  # major upper off color\n","  plt.step(plot_df[['off_color_lower_hst1', 'off_color_lower_hst2', 'off_color_lower_hst3']].values, 'b', alpha=1, linestyle=':', linewidth=3)  # major lower off color\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_long_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  plt.step(plot_df[['major_upper_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  plt.step(plot_df[['major_lower_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  \n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- on price indicator part ---------------------- #\n","\n","  # ---------------------- sma ---------------------- #\n","  # alpha = 1\n","  # for sm_i, sma in enumerate(ma_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='black', linewidth=lw)\n","  #   alpha -= 0.2\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  # if i != initial_i:\n","  # if len(ep_idx_list_) > 1:\n","  \n","  # ------------- initial order ------------- #\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  for ep_i in range(len(ep_idx_list_)):\n","    plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","  # plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","    plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline  \n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","\n","  #         hedge ep & tp         #\n","  h_i = h_trade_list[t_i][1]\n","  if h_i is not None:\n","    plt.axvline(prev_plotsize + (h_i - ep_idx_list_[0]), linestyle='--')\n","    plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","    plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  if not static_lvrg:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\nlvrg : %s\\ntp_ratio : %.2f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i], lvrg_list[t_i], tp_ratio_list[t_i]))\n","  else:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\ntp_ratio : %.2f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i], tp_ratio_list[t_i]))\n","\n","  print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee - 1) * lvrg + 1)\n","  print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee - 1) * lvrg + 1)\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # ---------------------- outer price indi. ---------------------- #\n","  #           macd          #\n","  # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","    \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for stoch in stoch_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(stoch_upper, linestyle='--')\n","  # plt.axhline(stoch_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- cctbbo ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for cctbbo in cctbbo_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(cctbbo_upper, linestyle='--')\n","  # plt.axhline(cctbbo_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- ema_roc ---------- #  \n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for emaroc in emaroc_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  plt.axhline(0, linestyle='--')\n","\n","\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  if not save_plot:\n","    plt.show()\n","  \n","  else:\n","    # ---------- save mode ---------- #\n","    fig_name = plot_check_dir +  \"/%s.png\" % t_i\n","    plt.savefig(fig_name)\n","    print(fig_name, \"saved !\")\n","\n","  \n","  plt.close()\n","  print()\n","\n","  # break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGuJu2j4Aby9"},"outputs":[],"source":["# print()\n","for item in os.listdir(current_path + \"plot_check/\"):\n","  if item.endswith('png'):\n","    os.remove(current_path + \"plot_check/\" + item)\n","    print(current_path + \"plot_check/\" + item, \"removed !\")"]},{"cell_type":"markdown","metadata":{"id":"cj9X6S1jJjER"},"source":["### plot nontp case"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gb1jGrS4Jl8A"},"outputs":[],"source":["prev_plotsize = 50\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","short_ver = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    h_plot_pr_list = h_np_pr\n","\n","\n","\n","#         select plot columns       #\n","# basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","# sar_cols = [15, 18] # 15 ~ 19\n","# ichimoku_cols = [20, 21]  # 20 ~ 29\n","# # ichimoku_cols = [22, 23]  # 20 ~ 29\n","# ichimoku_cols2 = [22, 23]  # 20 ~ 29\n","# macd_cols = [30]  # 30 ~ 34\n","\n","# print(res_df.columns[basic_cols])\n","# break\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher']\n","cctbbo_list = ['cctbbo']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","if short_ver:\n","  nontp_indexs = nontp_short_indexs\n","  nontp_liqd_list = nontp_short_liqd_list\n","  nontp_pr_list = nontp_short_pr_list\n","  nontp_ep = nontp_short_ep_list\n","else:\n","  nontp_indexs = nontp_long_indexs\n","  nontp_liqd_list = nontp_long_liqd_list\n","  nontp_pr_list = nontp_long_pr_list\n","  nontp_ep = nontp_long_ep_list\n","\n","\n","for t_i, i in enumerate(nontp_indexs):\n","\n","  j = len(res_df) - 1\n","\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # # if 1800 < i < 1860:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > upper_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + 1, input_cols]\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","\n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, plot_df.iloc[:, [4]], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, plot_df.iloc[:, [6]], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, plot_df.iloc[:, [8]], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, plot_df.iloc[:, [5]], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, plot_df.iloc[:, [7]], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, plot_df.iloc[:, [9]], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[i - prev_plotsize:j + 1]\n","  plot_long_tp = long_tp.iloc[i - prev_plotsize:j + 1]  \n","\n","\n","\n","  # fig = plt.figure(figsize=(12, 16))\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.step(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  # plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  plt.step(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower on color\n","  plt.step(plot_df.values[:, [10]], 'fuchsia', alpha=1)  # middle\n","  \n","  plt.step(plot_df.values[:, -6:-3], 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df.values[:, -3:], 'b', alpha=1, linestyle=':')  # lower off color\n","\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_upper_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_lower_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- indicator part ---------------------- #\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  if i != initial_i:\n","    plt.axvline(prev_plotsize - (i - initial_i), alpha=0.5, linestyle='--')\n","  plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(nontp_ep[t_i], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  # for sub_i in range(len(ep_tp_list[t_i][1])):\n","  #   plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline    \n","\n","  #         hedge ep & tp         #\n","  # h_i = h_trade_list[t_i][1]\n","  # if h_i is not None:\n","  #   plt.axvline(prev_plotsize + (h_i - i), linestyle='--')\n","  #   plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","  #   plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  plt.title(\"%s ~ %s -> liqd : %.2f\\npr : %.2f\" % (i, j, nontp_liqd_list[t_i], nontp_pr_list[t_i]))\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # #           macd          #\n","  # # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # plt.subplot(313)\n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for stoch in stoch_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(50, linestyle='--')\n","  plt.axhline(stoch_upper, linestyle='--')\n","  plt.axhline(stoch_lower, linestyle='--')\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  plt.show()\n","  # plt.draw()\n","  plt.close()\n","  print()\n","\n","  # break\n"]},{"cell_type":"markdown","metadata":{"id":"-g7YY5BvMcLS"},"source":["### show detail values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TxQ3rDnKMa7"},"outputs":[],"source":["i, j = 27267, 27268\n","print(\"upper_ep.iloc[i] :\", upper_ep.iloc[i])\n","print(\"short_tp.iloc[j] :\", short_tp.iloc[j])"]},{"cell_type":"markdown","metadata":{"id":"7AIl6EBuZNOL"},"source":["## none plot off-color st"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaVxrNGzZgrF"},"outputs":[],"source":["prev_plotsize = 50\n","\n","for t_i, (i, j) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if pr_list[t_i] >= 1:\n","  #   continue\n","\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1, [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 16]]\n","\n","  #       replace st values with np.nan, using st trend     #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  fig = plt.figure(figsize=(8, 6))\n","  ax = fig.add_subplot(111)\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper\n","  plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower\n","  plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","\n","  plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","  plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  plt.plot(plot_upper_ep.values, alpha=1, linestyle='--')  # ep\n","  plt.plot(plot_lower_ep.values, alpha=1, linestyle='--')  # ep\n","\n","  plt.axvline(prev_plotsize, linestyle='--')\n","\n","  plt.title(\"%s ~ %s -> %.5f\" % (i, j, pr_list[t_i]))\n","  plt.show()\n","  # plt.draw()\n","  plt.close()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["M8-EChy0VsDr","Iy76iO7gztne","Ci_jUnNTZbm9","VdukVo5-Suzj","Bw5JibDKSuzj","Pe0QpnORSuzk","t1E_eAyPSuzm","dzla8i9_ysmP","o5psPOVOCA1c","v2Gjv019AEz8","FxJ1y8v2fkCR","VBwVaUkvfnOd"],"name":"AT_v3_backi2(0109_limit_st_make).ipynb","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOPfJ8gGoMGZK7Gap6rJiia"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}