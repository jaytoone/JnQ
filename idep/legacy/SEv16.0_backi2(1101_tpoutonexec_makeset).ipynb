{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SEv16.0_backi2(1101_tpoutonexec_makeset).ipynb","provenance":[{"file_id":"1z4z_KLPzc6RWsxo3X_dHbpByxUAgjoMJ","timestamp":1583754134002}],"collapsed_sections":["Iy76iO7gztne","u6HJnX16i36D","aAzRBq67tBno","9Lbr-ZsJjzIT","qkzeUFAyeJXK","JcKfLZ7QnYcK","FaRGwR4NEop2","2gxvme1PC6ha","OJqkmkpsLCYC","-IbP_Z3Dlwk4","VBwVaUkvfnOd"],"toc_visible":true},"kernelspec":{"display_name":"Python [conda env:tensorflow2_p36]","language":"python","name":"conda-env-tensorflow2_p36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"code","metadata":{"id":"AK9FjWwLOyay"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, sys\n","\n","current_path = '/content/drive/My Drive/Colab Notebooks/JnQ/'\n","\n","os.chdir(current_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uqYv5StTazo"},"source":["# requirements"]},{"cell_type":"code","metadata":{"id":"9qGt60DKTZmf"},"source":["!pip install mpl_finance\n","# !pip install findiff\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import gridspec\n","from tqdm.notebook import tqdm\n","from funcs_indicator import *\n","from funcs_for_trade import *\n","\n","import mpl_finance as mf\n","import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","# import tensorflow as tf\n","\n","import pickle\n","import shutil\n","# import json\n","from easydict import EasyDict\n","\n","# from trendln import trendln\n","\n","from datetime import datetime\n","import random\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iy76iO7gztne"},"source":["## move legacy files"]},{"cell_type":"code","metadata":{"id":"hMRht32Czwry"},"source":["# print()\n","cur_dir_list = os.listdir('.')\n","for f in cur_dir_list:\n","  if 'legacy' in f :\n","    # print(f)\n","    if os.path.isdir(current_path + f,):\n","      continue\n","\n","    shutil.move(current_path + f, current_path + 'legacy/' + f)\n","    print(\"moved to\" + current_path + 'legacy/' +  f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ic1mfmwWCIBu"},"source":["# makeset"]},{"cell_type":"markdown","metadata":{"id":"Ci_jUnNTZbm9"},"source":["## load data"]},{"cell_type":"code","metadata":{"id":"_bXyS2yrZYC6"},"source":["interval = '1m'\n","date_path = './candlestick_concated/%s/quant_v2/' % interval\n","file_list = os.listdir(date_path)\n","print((file_list))\n","\n","interval2 = '3m'\n","date_path2 = './candlestick_concated/%s/quant_v2/' % interval2\n","file_list2 = os.listdir(date_path2)\n","print((file_list2))\n","\n","interval3 = '5m'\n","date_path3 = './candlestick_concated/%s/quant_v2/' % interval3\n","file_list3 = os.listdir(date_path3)\n","print((file_list3))\n","\n","interval4 = '15m'\n","date_path4 = './candlestick_concated/%s/quant_v2/' % interval4\n","file_list4 = os.listdir(date_path4)\n","print((file_list4))\n","\n","interval5 = '30m'\n","date_path5 = './candlestick_concated/%s/quant_v2/' % interval5\n","file_list5 = os.listdir(date_path5)\n","print((file_list5))\n","\n","interval6 = '1h'\n","date_path6 = './candlestick_concated/%s/quant_v2/' % interval6\n","file_list6 = os.listdir(date_path6)\n","print((file_list6))\n","\n","interval7 = '4h'\n","date_path7 = './candlestick_concated/%s/quant_v2/' % interval7\n","file_list7 = os.listdir(date_path7)\n","print((file_list7))\n","\n","interval8 = '1d'\n","date_path8 = './candlestick_concated/%s/quant_v2/' % interval8\n","file_list8 = os.listdir(date_path8)\n","print((file_list8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EiXxraeZCj0c"},"source":["## basic_func"]},{"cell_type":"code","metadata":{"id":"mi8H188MCiaH"},"source":["def sync_check(df, second_df, third_df, fourth_df, fifth_df, sixth_df=None, seventh_df=None, eighth_df=None):\n","\n","    #           supertrend          #\n","    # df = st_price_line(df, second_df, '3m')\n","    # # print(df.head(100))\n","    # # return\n","\n","    # df = st_price_line(df, third_df, '5m')\n","    # df = st_price_line(df, fourth_df, '15m')\n","    # df = st_price_line(df, fifth_df, '30m')\n","    # df = st_price_line(df, sixth_df, '1h')\n","    # df = st_price_line(df, seventh_df, '4h')\n","\n","    # print(\"supertrend phase done\")\n","\n","    # --------------- dc --------------- #  \n","    # df = dc_line(df, None, '1m')\n","    # df = dc_line(df, third_df, '5m')\n","    # df = dc_line(df, fourth_df, '15m')\n","    # df = dc_line(df, fifth_df, '30m')\n","    # df = dc_line(df, sixth_df, '1h')\n","    # df = dc_line(df, seventh_df, '4h')\n","\n","    # print(\"dc phase done\")\n","    \n","    # --------------- bband --------------- #  \n","    # df = bb_line(df, None, '1m')\n","    # df = bb_line(df, third_df, '5m')\n","    # df = bb_line(df, fourth_df, '15m')\n","    # # df = bb_line(df, fifth_df, '30m')\n","    # df = bb_line(df, sixth_df, '1h')\n","    # df = bb_line(df, seventh_df, '4h')\n","\n","    # print(\"bband phase done\")\n","\n","    # --------------- cbline --------------- #    \n","    # second_df['cloud_bline_3m'] = cloud_bline(second_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['cloud_bline_3m']))\n","    # third_df['cloud_bline_5m'] = cloud_bline(third_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['cloud_bline_5m']))\n","    # fourth_df['cloud_bline_15m'] = cloud_bline(fourth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['cloud_bline_15m']))\n","    # fifth_df['cloud_bline_30m'] = cloud_bline(fifth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['cloud_bline_30m']))\n","    # sixth_df['cloud_bline_1h'] = cloud_bline(sixth_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['cloud_bline_1h']))\n","    # seventh_df['cloud_bline_4h'] = cloud_bline(seventh_df, 26)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['cloud_bline_4h']))\n","\n","    # print(\"cbline phase done\")\n","    \n","    # --------------- mmh & norm st --------------- #    \n","    # df['mmh_st1'] = mmh_st(df, 3)\n","    # df['mmh_st2'] = mmh_st(df, 5)\n","    # df['norm_st_up'], df['norm_st_down'], df['norm_st_trend'] = supertrend(df, 5, 6)\n","\n","    # print(\"mmh & norm st phase done\")\n","\n","\n","    #           lucid sar              #\n","    # df['sar_1m'], df['sar_uptrend_1m'] = lucid_sar(df, return_uptrend=True)\n","\n","    # third_df['sar_5m'], third_df['sar_uptrend_5m'] = lucid_sar(third_df, return_uptrend=True)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-2, -1], backing_i=-1), columns=['sar_5m', 'sar_uptrend_5m']))\n","\n","    fourth_df['sar_15m'], fourth_df['sar_uptrend_15m'] = lucid_sar(fourth_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-2, -1], backing_i=-1), columns=['sar_15m', 'sar_uptrend_15m']))\n","\n","    seventh_df['sar_4h'], seventh_df['sar_uptrend_4h'] = lucid_sar(seventh_df, return_uptrend=True)\n","    df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-2, -1], backing_i=-1), columns=['sar_4h', 'sar_uptrend_4h']))\n","    \n","    # print(\"sar phase done\")\n","\n","    \n","    #           stochastic              #\n","    # df['stoch_1m'] = stoch(df, 13, 3, 3)\n","\n","    # third_df['stoch'] = stoch(third_df, 13, 3, 3)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1], backing_i=-1), columns=['stoch_5m']))\n","\n","    # print(\"stoch phase done\")\n","\n","\n","\n","    \n","    # #           ichimoku            #\n","    # df['senkou_a1'], df['senkou_b1'] = ichimoku(df)\n","    \n","    # second_df['senkou_a'], second_df['senkou_b'] = ichimoku(second_df)\n","    # df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-2, -1]), columns=['senkou_a2', 'senkou_b2']))\n","    \n","    # third_df['senkou_a'], third_df['senkou_b'] = ichimoku(third_df)\n","    # df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-2, -1]), columns=['senkou_a3', 'senkou_b3']))\n","    \n","    # fourth_df['senkou_a'], fourth_df['senkou_b'] = ichimoku(fourth_df)\n","    # df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-2, -1]), columns=['senkou_a4', 'senkou_b4']))\n","    \n","    # fifth_df['senkou_a'], fifth_df['senkou_b'] = ichimoku(fifth_df)\n","    # df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-2, -1]), columns=['senkou_a5', 'senkou_b5']))\n","\n","    # if sixth_df is not None:\n","    #   sixth_df['senkou_a'], sixth_df['senkou_b'] = ichimoku(sixth_df)\n","    #   df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-2, -1]), columns=['senkou_a6', 'senkou_b6']))\n","\n","    # if seventh_df is not None:\n","    #   seventh_df['senkou_a'], seventh_df['senkou_b'] = ichimoku(seventh_df)\n","    #   df = df.join( pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-2, -1]), columns=['senkou_a7', 'senkou_b7']))\n","\n","\n","    # #           1-2. displacement           #\n","    # cloud_cnt = 0\n","    # for col_n in df.columns:\n","    #   if 'senkou' in col_n:\n","    #     cloud_cnt += 1\n","    # print(cloud_cnt)\n","\n","    # # df['senkou_a1'] = df['senkou_a1'].shift(26 - 1)\n","    # # df['senkou_b1'] = df['senkou_b1'].shift(26 - 1)\n","    # # # df.iloc[:, -10:] = df.iloc[:, -10:].shift(26 - 1)\n","    # # # df.iloc[:, -14:] = df.iloc[:, -14:].shift(26 - 1)\n","    # df.iloc[:, -cloud_cnt:] = df.iloc[:, -cloud_cnt:].shift(26 - 1)\n","\n","    # print(\"cloud phase done\")\n","\n","    \n","    # #           macd            #\n","    # df['macd_hist1'] = macd(df)\n","    \n","    # second_df['macd_hist'] = macd(second_df)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['macd_hist2']))\n","\n","    # third_df['macd_hist'] = macd(third_df)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['macd_hist3']))\n","\n","    # fourth_df['macd_hist'] = macd(fourth_df)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['macd_hist4']))\n","\n","    # fifth_df['macd_hist'] = macd(fifth_df)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['macd_hist5']))\n","    \n","    # if sixth_df is not None:\n","    #   sixth_df['macd_hist'] = macd(sixth_df)\n","    #   df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['macd_hist6']))\n","    \n","    # if seventh_df is not None:\n","    #   seventh_df['macd_hist'] = macd(seventh_df)\n","    #   df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['macd_hist7']))\n","\n","\n","    # print(\"macd phase done\")\n","\n","\n","    # #         trix        #\n","    # df['trix1'] = trix_hist(df, 14, 1, 5)\n","    \n","    # second_df['trix'] = trix_hist(second_df, 14, 1, 5)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, second_df, [-1]), columns=['trix2']))\n","\n","    # third_df['trix'] = trix_hist(third_df, 14, 1, 5)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, third_df, [-1]), columns=['trix3']))\n","\n","    # fourth_df['trix'] = trix_hist(fourth_df, 14, 1, 5)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fourth_df, [-1]), columns=['trix4']))\n","\n","    # fifth_df['trix'] = trix_hist(fifth_df, 14, 1, 5)\n","    # df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, fifth_df, [-1]), columns=['trix5']))\n","\n","    # if sixth_df is not None:\n","    #   sixth_df['trix'] = trix_hist(sixth_df, 14, 1, 5)\n","    #   df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, sixth_df, [-1]), columns=['trix6']))\n","\n","    # if seventh_df is not None:\n","    #   seventh_df['trix'] = trix_hist(seventh_df, 14, 1, 5)\n","    #   df = df.join(pd.DataFrame(index=df.index, data=to_lower_tf(df, seventh_df, [-1]), columns=['trix7']))\n","  \n","\n","    return df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnrBE3etCpIA"},"source":["## make & save res_df (concat 생각하면, timeindex sync 맞춰야함)"]},{"cell_type":"code","metadata":{"id":"T7EmgJ5OiggE"},"source":["for key, res_df in res_df_dict.items():tail())\n","  \n","  res_df.reset_index().to_feather(save_path + key.replace(\"xlsx\", \"ftr\"), compression='lz4')\n","  print(save_path + key.replace(\"xlsx\", \"ftr\"), \"saved !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6HJnX16i36D"},"source":["### old (xlsx)"]},{"cell_type":"code","metadata":{"id":"X1g9vGP0UnTT"},"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","exist_list = os.listdir(save_path)\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  # if '2021-04-30'.upper() not in file_list[i]:\n","  if '2021-07-01'.upper() not in file_list[i]:\n","  # if '2021-10-10'.upper() not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","\n","    excel_name = key.replace(\".xlsx\", \"_st1h_backi2.xlsx\")\n","    excel_path = save_path + excel_name\n","\n","    if excel_name in exist_list:\n","      print(excel_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    \n","    df = pd.read_excel(date_path + key, index_col=0)\n","    second_df = pd.read_excel(date_path2 + key, index_col=0)\n","    third_df = pd.read_excel(date_path3 + key, index_col=0)\n","    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n","    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n","    \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n","      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","\n","    except Exception as e:\n","      print(e)\n","\n","    latest_open_index = sorted(open_indexes)[-1]\n","    \n","    open_ts = datetime.timestamp(latest_open_index)\n","    latest_open_index_1m = datetime.fromtimestamp(open_ts + a_day)\n","\n","    #   str 로 만들어 접근하면 불가함  #\n","    end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 08:59:59.999000\")\n","    # break\n","\n","    sliced_df = df.loc[latest_open_index_1m:end_index] # to_lower_tf 의 기준 ltf\n","    sliced_second_df = second_df.loc[latest_open_index:end_index]\n","    sliced_third_df = third_df.loc[latest_open_index:end_index]\n","    sliced_fourth_df = fourth_df.loc[latest_open_index:end_index]\n","    sliced_fifth_df = fifth_df.loc[latest_open_index:end_index]\n","\n","    print(\"sliced index\")\n","    print(sliced_df.index[[0, -1]])\n","    print(sliced_second_df.index[[0, -1]])\n","    print(sliced_third_df.index[[0, -1]])\n","    print(sliced_fourth_df.index[[0, -1]])\n","    print(sliced_fifth_df.index[[0, -1]])\n","\n","    try:\n","      sliced_sixth_df = sixth_df.loc[latest_open_index:end_index]\n","      sliced_seventh_df = seventh_df.loc[latest_open_index:end_index]\n","\n","      print(sliced_sixth_df.index[[0, -1]])\n","      print(sliced_seventh_df.index[[0, -1]])\n","\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df, sliced_sixth_df, sliced_seventh_df)\n","    \n","    except:\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df)\n","\n","\n","\n","    res_df.to_excel(excel_path)\n","    print(excel_name, \"saved succesfully !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAzRBq67tBno"},"source":["### xlsx to feather"]},{"cell_type":"code","metadata":{"id":"YJtFAah_tE0S"},"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","exist_list = os.listdir(save_path)\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  # if '2021-04-30'.upper() not in file_list[i]:\n","  if '2021-07-01'.upper() not in file_list[i]:\n","  # if '2021-10-10'.upper() not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","\n","    feather_name = key.replace(\".xlsx\", \".ftr\")\n","    # feather_path = save_path + feather_name\n","\n","    if feather_name in exist_list:\n","      print(feather_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    \n","    df = pd.read_excel(date_path + key, index_col=0)\n","    second_df = pd.read_excel(date_path2 + key, index_col=0)\n","    third_df = pd.read_excel(date_path3 + key, index_col=0)\n","    fourth_df = pd.read_excel(date_path4 + key, index_col=0)\n","    fifth_df = pd.read_excel(date_path5 + key, index_col=0)\n","    \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_excel(date_path6 + key, index_col=0)\n","      seventh_df = pd.read_excel(date_path7 + key, index_col=0)\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","\n","    except Exception as e:\n","      print(e)\n","\n","\n","    df.reset_index().to_feather(date_path + feather_name, compression='lz4')\n","    second_df.reset_index().to_feather(date_path2 + feather_name, compression='lz4')\n","    third_df.reset_index().to_feather(date_path3 + feather_name, compression='lz4')\n","    fourth_df.reset_index().to_feather(date_path4 + feather_name, compression='lz4')\n","    fifth_df.reset_index().to_feather(date_path5 + feather_name, compression='lz4')\n","    sixth_df.reset_index().to_feather(date_path6 + feather_name, compression='lz4')\n","    seventh_df.reset_index().to_feather(date_path7 + feather_name, compression='lz4')\n","\n","    print(\"xlsx converted to feather !\")\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QtiavGJOi8NV"},"source":["### feather ver."]},{"cell_type":"code","metadata":{"id":"0ZoiPvbOxdgO"},"source":["print(date_path + key)\n","df = pd.read_feather(date_path + key, columns=None, use_threads=True).set_index(\"index\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0g2fXaCmi9zN"},"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","dir_path = \"sar15m4h_backi2\"\n","os.makedirs(os.path.join(save_path, dir_path), exist_ok=True)\n","\n","exist_list = os.listdir(os.path.join(save_path, dir_path))\n","\n","\n","a_day = 3600 * 24\n","\n","for i in tqdm(range(len(file_list))):\n","\n","  keys = [file_list[i]]\n","\n","  # if 'neo'.upper() not in file_list[i]:\n","    # continue\n","\n","  if '2021-07-01'.upper() not in file_list[i]:\n","    continue\n","\n","\n","  for key in keys:      \n","\n","    # if 'eth'.upper() not in key:\n","    #   continue\n","    # print(key)\n","    \n","    if \".ftr\" not in key:\n","      continue\n","\n","    # feather_name = key.replace(\".ftr\", \"_%.ftr\" % dir_path)\n","    feather_name = key\n","    feather_path = os.path.join(save_path, dir_path, feather_name)\n","\n","    if feather_name in exist_list:\n","      print(feather_name, \"already exist !\")\n","      continue\n","    \n","    open_indexes = []\n","    \n","    df = pd.read_feather(date_path + key, columns=None, use_threads=True).set_index(\"index\")\n","    second_df = pd.read_feather(date_path2 + key, columns=None, use_threads=True).set_index(\"index\")\n","    third_df = pd.read_feather(date_path3 + key, columns=None, use_threads=True).set_index(\"index\")\n","    fourth_df = pd.read_feather(date_path4 + key, columns=None, use_threads=True).set_index(\"index\")\n","    fifth_df = pd.read_feather(date_path5 + key, columns=None, use_threads=True).set_index(\"index\")\n","        \n","    print(df.index[[0, -1]])\n","    print(second_df.index[[0, -1]])\n","    print(third_df.index[[0, -1]])\n","    print(fourth_df.index[[0, -1]])\n","    print(fifth_df.index[[0, -1]])\n","\n","    open_indexes.append(df.index[0])\n","    open_indexes.append(second_df.index[0])\n","    open_indexes.append(third_df.index[0])\n","    open_indexes.append(fourth_df.index[0])\n","    open_indexes.append(fifth_df.index[0])\n","    \n","    try:\n","      #     Todo    #\n","      #      1. 1m 마지막 timeindex 의 date 기준, 08:59:59.999000 를 last timestamp 로 설정\n","      #      2. 시작 timestamp 는 모든 tf 의 가장 최근 시작 index,\n","      #       a. 1m 의 시작 timeindex 는 최소, htf 의 시작 timeindex 보다 interval 만큼 앞서야함\n","      #         i. 따라서 1m open_index, latest_open_index + 1d 를 하면 댐\n","      #           1. timestamp 으로 변환후 1day 를 더하고 datetime 으로 변환\n","      sixth_df = pd.read_feather(date_path6 + key, columns=None, use_threads=True).set_index(\"index\")\n","      seventh_df = pd.read_feather(date_path7 + key, columns=None, use_threads=True).set_index(\"index\")\n","\n","      print(sixth_df.index[[0, -1]])\n","      print(seventh_df.index[[0, -1]])\n","      print()\n","\n","      open_indexes.append(sixth_df.index[0])\n","      open_indexes.append(seventh_df.index[0])\n","\n","    except Exception as e:\n","      print(e)\n","\n","    latest_open_index = sorted(open_indexes)[-1]\n","    \n","    open_ts = datetime.timestamp(latest_open_index)\n","    latest_open_index_1m = datetime.fromtimestamp(open_ts + a_day)\n","\n","    #   str 로 만들어 접근하면 불가함  #\n","    end_index = pd.to_datetime(str(df.index[-1]).split(\" \")[0] + \" 08:59:59.999000\")\n","    # break\n","\n","    sliced_df = df.loc[latest_open_index_1m:end_index] # to_lower_tf 의 기준 ltf\n","    sliced_second_df = second_df.loc[latest_open_index:end_index]\n","    sliced_third_df = third_df.loc[latest_open_index:end_index]\n","    sliced_fourth_df = fourth_df.loc[latest_open_index:end_index]\n","    sliced_fifth_df = fifth_df.loc[latest_open_index:end_index]\n","\n","    print(\"sliced index\")\n","    print(sliced_df.index[[0, -1]])\n","    print(sliced_second_df.index[[0, -1]])\n","    print(sliced_third_df.index[[0, -1]])\n","    print(sliced_fourth_df.index[[0, -1]])\n","    print(sliced_fifth_df.index[[0, -1]])\n","\n","    try:\n","      sliced_sixth_df = sixth_df.loc[latest_open_index:end_index]\n","      sliced_seventh_df = seventh_df.loc[latest_open_index:end_index]\n","\n","      print(sliced_sixth_df.index[[0, -1]])\n","      print(sliced_seventh_df.index[[0, -1]])\n","\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df, sliced_sixth_df, sliced_seventh_df)\n","    \n","    except:\n","      res_df = sync_check(sliced_df, sliced_second_df, sliced_third_df, sliced_fourth_df, sliced_fifth_df)\n","\n","\n","\n","    # res_df.to_feather(feather_path)\n","    res_df.reset_index().to_feather(feather_path, compression='lz4')\n","    print(feather_name, \"saved succesfully !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYqoJuPowqHq"},"source":["## concat & save new res_df"]},{"cell_type":"markdown","metadata":{"id":"9Lbr-ZsJjzIT"},"source":["### old (xlsx)"]},{"cell_type":"code","metadata":{"id":"TRXKKMr0wwKF"},"source":["save_path = './candlestick_concated/res_df/'\n","\n","dict_name = \"2021-07-01 ETHUSDT_bb15m_backi2_res_dfs.pkl\"\n","\n","#     load with pickle    #\n","with open(save_path + dict_name, 'rb') as f:\n","  saved_res_df_dict = pickle.load(f)\n","\n","print(dict_name, \"loaded !\")\n","res_df_files = os.listdir(save_path)\n","res_df_files.reverse()\n","\n","print(res_df_files)\n","\n","res_df_dict = {}\n","\n","base_postfix = '_bb15m_backi2.xlsx'\n","new_postfix = '_st1h_backi2.xlsx'\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for k_i, key in enumerate(res_df_files):\n","\n","  if '2021-07-01'.upper() not in key:\n","  # if '2021-10-10'.upper() not in key:\n","    continue\n","\n","  # if \"link\".upper() not in key:\n","  # if \"btc\".upper() not in key:\n","  #   continue\n","\n","  if new_postfix not in key:\n","    continue\n","\n","  # if key in \n","\n","  if sample_cnt == max_cnt:\n","    dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n","    print(\"dict_name :\", dict_name)\n","\n","  base_df = saved_res_df_dict[key.replace(new_postfix, base_postfix)]\n","  # base_df = pd.read_excel(save_path + key.replace(new_postfix, base_postfix), index_col=0)  \n","  res_df = pd.read_excel(save_path + key, index_col=0)  \n","\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n","  # new_res_df.head()\n","\n","  droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  droped_new_res_df.head()\n","  # break\n","\n","  # res_df_dict[key] = res_df\n","  res_df_dict[key] = droped_new_res_df\n","  print(key, \"saved to dict !\")\n","\n","  #     save with pickle    #\n","  with open(save_path + dict_name, 'wb') as f:\n","    pickle.dump(res_df_dict, f)\n","\n","  sample_cnt -= 1\n","\n","  if sample_cnt <= 0:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHtKmKvEj2TU"},"source":["### feather ver."]},{"cell_type":"code","metadata":{"id":"TswTadFXj35X"},"source":["save_path = './candlestick_concated/res_df/'\n","\n","concat_dir = \"concat\"\n","\n","dir_path = \"sar15m4h_backi2\"\n","base_dir_path = \"dc_backi2\"\n","\n","\n","#     save to (new) concat dir    #\n","#      1. if dir. not exists, makedir\n","os.makedirs(os.path.join(save_path, dir_path, concat_dir), exist_ok=True)\n","\n","\n","#     load ftr list    #\n","ftr_list = [s for s in os.listdir(os.path.join(save_path, dir_path)) if \"ftr\" in s]\n","print(ftr_list)\n","# break\n","\n","# dict_name = \"2021-07-01 ETHUSDT_bb15m_backi2_res_dfs.pkl\"\n","\n","# #     load with pickle    #\n","# with open(save_path + dict_name, 'rb') as f:\n","#   saved_res_df_dict = pickle.load(f)\n","\n","# print(dict_name, \"loaded !\")\n","# res_df_files = os.listdir(save_path)\n","# res_df_files.reverse()\n","\n","# print(res_df_files)\n","\n","# res_df_dict = {}\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for key in ftr_list:\n","\n","  if '2021-07-01'.upper() not in key:\n","  # if '2021-10-10'.upper() not in key:\n","    continue\n","\n","\n","  # if sample_cnt == max_cnt:\n","  #   dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n","  #   print(\"dict_name :\", dict_name)\n","\n","  # base_df = saved_res_df_dict[key.replace(new_postfix, base_postfix)]\n","  #       read from base postfix's directory    #\n","  base_df = pd.read_feather(os.path.join(save_path, base_dir_path, concat_dir, key.replace(\".ftr\", \"_dc_backi2.ftr\")), columns=None, use_threads=True).set_index(\"index\")\n","  # base_df = pd.read_excel(save_path + key.replace(new_postfix, base_postfix), index_col=0)  \n","  res_df = pd.read_feather(os.path.join(save_path, dir_path, key), columns=None, use_threads=True).set_index(\"index\")\n","\n","  # print(base_df.head())\n","  # print(res_df.head())\n","  # break\n","\n","  new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n","  # new_res_df.head()\n","\n","  droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","  droped_new_res_df.head()\n","  # break\n","\n","  droped_new_res_df.reset_index().to_feather(os.path.join(save_path, dir_path, concat_dir, key), compression='lz4')\n","\n","  # res_df_dict[key] = res_df\n","  # res_df_dict[key] = droped_new_res_df\n","  print(key, \"saved !\")\n","\n","  # #     save with pickle    #\n","  # with open(save_path + dict_name, 'wb') as f:\n","  #   pickle.dump(res_df_dict, f)\n","\n","  sample_cnt -= 1\n","\n","  if sample_cnt <= 0:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNLIzxy8ZED5"},"source":["droped_new_res_df.tail()\n","# new_res_df = pd.concat([base_df, res_df], axis=1) # df_tot.drop_duplicates()\n","#   # new_res_df.head()\n","\n","# droped_new_res_df = new_res_df.loc[:,~new_res_df.columns.duplicated(keep='last')]\n","# droped_new_res_df.head()\n","# break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkzeUFAyeJXK"},"source":["## save sample res_dfs"]},{"cell_type":"code","metadata":{"id":"dIL0k_VEeL6B"},"source":["save_path = './candlestick_concated/res_df/'\n","res_df_files = os.listdir(save_path)\n","res_df_files.reverse()\n","\n","print(res_df_files)\n","\n","res_df_dict = {}\n","\n","max_cnt = 10\n","sample_cnt = max_cnt\n","\n","for k_i, key in enumerate(res_df_files):\n","\n","  # if '2021-07-01'.upper() not in key:\n","  if '2021-10-10'.upper() not in key:\n","    continue\n","\n","  # if \"link\".upper() not in key:\n","  # if \"btc\".upper() not in key:\n","  #   continue\n","\n","  if \"_stline15_backi2.xlsx\" not in key:\n","    continue\n","\n","  if sample_cnt == max_cnt:\n","    dict_name = \"%s_res_dfs.pkl\" % key.split(\".\")[0]\n","    print(\"dict_name :\", dict_name)\n","\n","  res_df = pd.read_excel(save_path + key, index_col=0)  \n","\n","  res_df_dict[key] = res_df\n","  print(key, \"saved to dict !\")\n","\n","  #     save with pickle    #\n","  with open(save_path + dict_name, 'wb') as f:\n","    pickle.dump(res_df_dict, f)\n","\n","  sample_cnt -= 1\n","\n","  if sample_cnt <= 0:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ShvMpmWtC_Uv"},"source":["## modify colname"]},{"cell_type":"markdown","metadata":{"id":"yvrNFdxrnVjt"},"source":["### old (xlsx)"]},{"cell_type":"code","metadata":{"id":"3SvktSAzDDrk"},"source":["pd.set_option('display.max_seq_items', None)\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","dict_name = \"2021-07-01 ETHUSDT_sarstoch_backi2_res_dfs.pkl\"\n","# new_dict_name = \"2021-07-01 ETHUSDT_bbline_backi2_res_dfs_colmod.pkl\"\n","\n","new_colname = ['open', 'high', 'low', 'close', 'volume', 'ST1_Up_3m', 'ST1_Down_3m',\n","       'ST1_Trend_3m', 'ST2_Up_3m', 'ST2_Down_3m', 'ST2_Trend_3m', 'ST3_Up_3m',\n","       'ST3_Down_3m', 'ST3_Trend_3m', 'min_upper_3m', 'max_lower_3m', 'middle_line_3m',\n","       'upper_middle_3m', 'lower_middle_3m', 'st_gap_3m', 'ST1_Up_30m', 'ST1_Down_30m',\n","       'ST1_Trend_30m', 'ST2_Up_30m', 'ST2_Down_30m', 'ST2_Trend_30m', 'ST3_Up_30m',\n","       'ST3_Down_30m', 'ST3_Trend_30m', 'min_upper_30m', 'max_lower_30m', 'middle_line_30m',\n","       'upper_middle_30m', 'lower_middle_30m', 'st_gap_30m', 'ST1_Up_4h', 'ST1_Down_4h',\n","       'ST1_Trend_4h', 'ST2_Up_4h', 'ST2_Down_4h', 'ST2_Trend_4h', 'ST3_Up_4h',\n","       'ST3_Down_4h', 'ST3_Trend_4h', 'min_upper_4h', 'max_lower_4h', 'middle_line_4h',\n","       'upper_middle_4h', 'lower_middle_4h', 'st_gap_4h', 'ST1_Up_1d', 'ST1_Down_1d',\n","       'ST1_Trend_1d', 'ST2_Up_1d', 'ST2_Down_1d', 'ST2_Trend_1d', 'ST3_Up_1d',\n","       'ST3_Down_1d', 'ST3_Trend_1d', 'min_upper_1d', 'max_lower_1d', 'middle_line_1d',\n","       'upper_middle_1d', 'lower_middle_1d', 'st_gap_1d', 'mmh_st1_1m', 'mmh_st2_1m',\n","       'norm_st_up_1m', 'norm_st_down_1m', 'norm_st_trend_1m', 'ST1_Up_5m', 'ST1_Down_5m',\n","       'ST1_Trend_5m', 'ST2_Up_5m', 'ST2_Down_5m', 'ST2_Trend_5m', 'ST3_Up_5m',\n","       'ST3_Down_5m', 'ST3_Trend_5m', 'min_upper_5m', 'max_lower_5m', 'middle_line_5m',\n","       'upper_middle_5m', 'lower_middle_5m', 'st_gap_5m',\n","       'bb_upper_1m', 'bb_lower_1m', 'bb_base_1m', 'bb_upper2_1m',\n","       'bb_upper3_1m', 'bb_lower2_1m', 'bb_lower3_1m', 'bb_upper_30m',\n","       'bb_lower_30m', 'bb_base_30m', 'bb_upper2_30m', 'bb_upper3_30m',\n","       'bb_lower2_30m', 'bb_lower3_30m']\n","\n","#     load with pickle    #\n","with open(save_path + dict_name, 'rb') as f:\n","  saved_res_df_dict = pickle.load(f)\n","\n","for key, res_df in saved_res_df_dict.items():\n","\n","  # if '_stline15_backi2' not in key:\n","  #   continue\n","\n","  # print(res_df.columns)\n","\n","  try:\n","\n","    #     rename whole cols   #\n","    # res_df.columns = new_colname\n","\n","    #     rename specific cols   #\n","    res_df.rename(columns={\"stoch5\" : \"stoch_30m\"}, inplace=True)\n","\n","\n","    #     drop cols   #\n","    # res_df.drop(['bb_upper', 'bb_lower'], axis=1, inplace=True)\n","    # break\n","\n","  except Exception as e:\n","    print(e)\n","\n","  \n","  # res_df_dict[key] = res_df\n","  saved_res_df_dict[key] = res_df\n","  print(key, \"modified & saved to dict !\")\n","\n","  #     save with pickle    #\n","  with open(save_path + dict_name, 'wb') as f:\n","    pickle.dump(saved_res_df_dict, f)\n","\n","# res_df.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-wuP0cHSwvC"},"source":["# print(res_df.tail()) # 35215.568620 35182.644944\n","res_df.tail() # 35215.568620 35182.644944"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcKfLZ7QnYcK"},"source":["### feather ver."]},{"cell_type":"code","metadata":{"id":"qcltRDX8nZ4e"},"source":["pd.set_option('display.max_seq_items', None)\n","\n","save_path = './candlestick_concated/res_df/'\n","\n","dir_path = \"dc_backi2\"\n","concat_dir = \"concat\"\n","\n","#     load ftr list    #\n","ftr_list = [s for s in os.listdir(os.path.join(save_path, dir_path, concat_dir)) if \"ftr\" in s]\n","print(ftr_list)\n","\n","# dict_name = \"2021-07-01 ETHUSDT_sarstoch_backi2_res_dfs.pkl\"\n","\n","new_colname = ['open', 'high', 'low', 'close', 'volume', 'ST1_Up_3m', 'ST1_Down_3m',\n","       'ST1_Trend_3m', 'ST2_Up_3m', 'ST2_Down_3m', 'ST2_Trend_3m', 'ST3_Up_3m',\n","       'ST3_Down_3m', 'ST3_Trend_3m', 'min_upper_3m', 'max_lower_3m', 'middle_line_3m',\n","       'upper_middle_3m', 'lower_middle_3m', 'st_gap_3m', 'ST1_Up_30m', 'ST1_Down_30m',\n","       'ST1_Trend_30m', 'ST2_Up_30m', 'ST2_Down_30m', 'ST2_Trend_30m', 'ST3_Up_30m',\n","       'ST3_Down_30m', 'ST3_Trend_30m', 'min_upper_30m', 'max_lower_30m', 'middle_line_30m',\n","       'upper_middle_30m', 'lower_middle_30m', 'st_gap_30m', 'ST1_Up_4h', 'ST1_Down_4h',\n","       'ST1_Trend_4h', 'ST2_Up_4h', 'ST2_Down_4h', 'ST2_Trend_4h', 'ST3_Up_4h',\n","       'ST3_Down_4h', 'ST3_Trend_4h', 'min_upper_4h', 'max_lower_4h', 'middle_line_4h',\n","       'upper_middle_4h', 'lower_middle_4h', 'st_gap_4h', 'ST1_Up_1d', 'ST1_Down_1d',\n","       'ST1_Trend_1d', 'ST2_Up_1d', 'ST2_Down_1d', 'ST2_Trend_1d', 'ST3_Up_1d',\n","       'ST3_Down_1d', 'ST3_Trend_1d', 'min_upper_1d', 'max_lower_1d', 'middle_line_1d',\n","       'upper_middle_1d', 'lower_middle_1d', 'st_gap_1d', 'mmh_st1_1m', 'mmh_st2_1m',\n","       'norm_st_up_1m', 'norm_st_down_1m', 'norm_st_trend_1m', 'ST1_Up_5m', 'ST1_Down_5m',\n","       'ST1_Trend_5m', 'ST2_Up_5m', 'ST2_Down_5m', 'ST2_Trend_5m', 'ST3_Up_5m',\n","       'ST3_Down_5m', 'ST3_Trend_5m', 'min_upper_5m', 'max_lower_5m', 'middle_line_5m',\n","       'upper_middle_5m', 'lower_middle_5m', 'st_gap_5m',\n","       'bb_upper_1m', 'bb_lower_1m', 'bb_base_1m', 'bb_upper2_1m',\n","       'bb_upper3_1m', 'bb_lower2_1m', 'bb_lower3_1m', 'bb_upper_30m',\n","       'bb_lower_30m', 'bb_base_30m', 'bb_upper2_30m', 'bb_upper3_30m',\n","       'bb_lower2_30m', 'bb_lower3_30m']\n","\n","# #     load with pickle    #\n","# with open(save_path + dict_name, 'rb') as f:\n","#   saved_res_df_dict = pickle.load(f)\n","\n","for key in ftr_list:\n","\n","  res_df = pd.read_feather(os.path.join(save_path, dir_path, concat_dir, key), columns=None, use_threads=True).set_index(\"index\")\n","\n","  try:\n","\n","    #     rename whole cols   #\n","    # res_df.columns = new_colname\n","\n","    #     rename specific cols   #\n","    res_df.rename(columns={\"stoch5\" : \"stoch_30m\"}, inplace=True)\n","\n","\n","    #     drop cols   #\n","    # res_df.drop(['bb_upper', 'bb_lower'], axis=1, inplace=True)\n","    # break\n","\n","  except Exception as e:\n","    print(e)\n","\n","  \n","  res_df.reset_index().to_feather(os.path.join(save_path, dir_path, concat_dir, key), compression='lz4')\n","\n","  # res_df_dict[key] = res_df\n","  # saved_res_df_dict[key] = res_df\n","  print(key, \"modified & saved !\")\n","\n","  # #     save with pickle    #\n","  # with open(save_path + dict_name, 'wb') as f:\n","  #   pickle.dump(saved_res_df_dict, f)\n","\n","# res_df.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNGeuYuGDXfv"},"source":["# pr check with strategy"]},{"cell_type":"markdown","metadata":{"id":"6HOjnZjSgzk1"},"source":["## load ftr_list"]},{"cell_type":"code","metadata":{"id":"7FPBG5Qqg2jB"},"source":["save_path = './candlestick_concated/res_df/'\n","\n","dir_path = \"dc_backi2\"\n","\n","#     load ftr list    #\n","ftr_list = [s for s in os.listdir(os.path.join(save_path, dir_path)) if \"ftr\" in s]\n","print(ftr_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tApzvz_gK9lR"},"source":["## basic strategy"]},{"cell_type":"markdown","metadata":{"id":"FaRGwR4NEop2"},"source":["### shifting"]},{"cell_type":"code","metadata":{"id":"a8aYsjEgQnGF"},"source":["org_res_df = res_df.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RF3RM2G2RCb1"},"source":["#         refresh res_df      #\n","res_df = org_res_df.copy()\n","print(org_res_df.tail(5))\n","\n","# break\n","\n","\n","shift_size = -4\n","# shift_size = -1\n","# shift_size = -7\n","# shift_size = +3\n","\n","res_df['min_upper'] = res_df['min_upper'].shift(shift_size)\n","res_df['max_lower'] = res_df['max_lower'].shift(shift_size)\n","res_df['minor_ST1_Trend'] = res_df['minor_ST1_Trend'].shift(shift_size)\n","res_df['minor_ST2_Trend'] = res_df['minor_ST2_Trend'].shift(shift_size)\n","res_df['minor_ST3_Trend'] = res_df['minor_ST3_Trend'].shift(shift_size)\n","res_df['middle_line'] = res_df['middle_line'].shift(shift_size)\n","\n","print(res_df.tail(5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2gxvme1PC6ha"},"source":["### load model"]},{"cell_type":"code","metadata":{"id":"dtYdAuSsC72_"},"source":["# model_name = 'inner_tick_cnnreg_lscalemm_prefee_gpu_%s_%s_%s_%s_%s.h5'\n","\n","# model = tf.keras.models.load_model(ckpt_path + model_name)\n","\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","model = ResNet50(weights='imagenet', include_top=False)\n","# model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5la6usMOFzkX"},"source":["#### gen selected vector"]},{"cell_type":"code","metadata":{"id":"oQk3-jbKF8FB"},"source":["def min_max_scale(npy_x):\n","\n","  return (npy_x - np.min(npy_x)) / (np.max(npy_x) - np.min(npy_x))\n","\n","def expand_dims(npy_x):\n","\n","  row, col = npy_x.shape\n","  npy_x2 = np.array(npy_x).reshape(-1, row, col, 1).astype(np.float32)\n","  # input_x = np.array(data_x).reshape(-1, row, col).astype(np.float32)\n","\n","  #     1c to 3c    #\n","  npy_x3 = npy_x2 * np.ones(3, dtype=np.float32)[None, None, None, :]\n","\n","  return npy_x3\n","\n","\n","def vector_dist(f1, f2):\n","  return np.linalg.norm(f1-f2)\n","\n","\n","\n","# ------------------------ params ------------------------  #\n","selected_i = 500\n","input_size = 100\n","\n","\n","\n","#   1. 선택된 인덱스를 입력받았을 때, input generating 형태만 만들어놓고,     #\n","#   1-1. input cols 필요함    #\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","sma_list = ['sma']\n","\n","#     -------------- outer price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","\n","selected_price_colname = basic_list + senkoua_list + senkoub_list + sar_list\n","selected_outprice_colname = [macd_list]\n","\n","\n","#         global scaling for outer price data       #\n","#         1. nan 처리       #\n","\n","# # print((np.isnan(df.values)))\n","# print(\"np.sum(np.isnan(df.values), axis=0) :\", np.sum(np.isnan(df.values), axis=0))\n","\n","# max_nan = np.max(np.sum(np.isnan(df.values), axis=0))\n","# # print(max_nan)\n","\n","# df = df.iloc[max_nan:-max_nan]\n","\n","# total_gdata = []\n","# for g_col in selected_outprice_colname:\n","\n","#   temp_data = min_max_scale(res_df[g_col])\n","#   total_gdata.append(temp_data)\n","\n","\n","\n","#   1-2. cols 에 따른, scaling method 구분함    #\n","onprice_input_x = min_max_scale(res_df[selected_price_colname].iloc[selected_i - input_size:selected_i].values)\n","print(onprice_input_x.shape)\n","\n","\n","#   2. plot_check 에서 본인이 원하는 shape 의 인덱스를 선택   #\n","#   3. vertorize, \n","#   3-1. input generator 를 이용해 entry signal 발생할 때마다 dist 비교 진행    #\n","re_onprice_input_x = expand_dims(onprice_input_x)\n","print(re_onprice_input_x.shape)\n","      \n","# break\n","\n","selected_vector = model.predict(re_onprice_input_x, verbose=1)\n","print(selected_vector.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OJqkmkpsLCYC"},"source":["### tr_tresh calc"]},{"cell_type":"code","metadata":{"id":"gcpo4MGd9Wm4"},"source":["res_wr = 0.3\n","# tr_thresh = 1\n","# tr_thresh = ((1 - res_wr) / res_wr) ** 0.5\n","tr_thresh = ((1 - res_wr) / res_wr) + 0.01\n","tr_thresh = 2.6\n","print(\"res_wr :\", res_wr)\n","print(\"tr_thresh :\", tr_thresh)\n","\n","\n","#   단리    #\n","trade_num = 1000\n","asset = 1 # thousand USDT\n","test_loss_gap = 0.95  # fee adjusted\n","test_pr_gap = 1 + (1 - test_loss_gap) * tr_thresh\n","\n","test_loss_cnt = trade_num * (1 - res_wr)\n","test_pr_cnt = trade_num * res_wr\n","\n","test_trade_list = [test_pr_gap] * int(test_pr_cnt) + [test_loss_gap] * int(test_loss_cnt)\n","random.shuffle(test_trade_list)\n","# print(\"len(test_trade_list) :\", len(test_trade_list))\n","print(test_trade_list[:10])\n","print()\n","\n","# print(\"%.5f\" % np.cumprod(test_trade_list)[-1])\n","for tr_thresh_ in np.arange(1, 3, 0.2):\n","  if (1 + (1 - test_loss_gap) * tr_thresh_) ** test_pr_cnt * test_loss_gap ** test_loss_cnt > 1:\n","    break\n","print(\"복리를 위한 tr_thresh_ :\", tr_thresh_)\n","# print(\"tr_thresh :\", tr_thresh)\n","print(\"np.cumprod(test_trade_list)[-1] :\", np.cumprod(test_trade_list)[-1])\n","print(\"total_pr : \", np.cumprod(test_trade_list)[-1])\n","print()\n","#   복리 tr_thresh  #\n","#   1. trade_num 에 영향 받지 않음\n","#   2. loss_gap 에 비례함\n","\n","for tr_thresh_ in np.arange(1, 3, 0.01):\n","  if ((1 - test_loss_gap) * tr_thresh_) * test_pr_cnt + (test_loss_gap - 1) * test_loss_cnt > 0:\n","    break\n","np_test_trade = np.array(test_trade_list) - 1\n","print(np_test_trade[:10])\n","# print(\"%.3f\" % )\n","print(\"단리를 위한 tr_thresh_ :\", tr_thresh_)\n","# print(\"tr_thresh :\", tr_thresh)\n","print(\"np.cumsum(np_test_trade)[-1] :\", np.cumsum(np_test_trade)[-1])\n","print(\"total_pr : \", 1 + np.cumsum(np_test_trade)[-1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5duWn8t4BRyv"},"source":["### lastest platform"]},{"cell_type":"code","metadata":{"id":"lUJTZV7kjX0H"},"source":["# res_df.columns\n","res_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_4E-zH02WJy"},"source":["#     caution : MARKET / LIMIT spelling   #\n","\n","param_dict = \\\n","{\n","  \"init_set\": {\n","    \"run\": 1,\n","    \"df_log\": 0,\n","    \"bar_close_second\": 59,\n","    \"realtime_term\": 0.01,\n","    \"last_index\": -2,\n","    \"limit_fee\": 0.0002,\n","    \"market_fee\": 0.0004,\n","    \"initial_asset\": 5000,\n","    \"asset_changed\" : 1,\n","    \"symbol\": \"ETHUSDT\",\n","    \"symbol_changed\": 0,\n","    \"interval_list\": [\n","      \"1m\",\n","      \"15m\",\n","      \"None\"\n","    ],\n","    \"row_list\": [\n","      200,\n","      100,\n","      100\n","    ],\n","    \"api_retry_term\": 3,\n","    \"save_stacked_df\": 0,\n","    \"stacked_df_exist\": 1\n","  },\n","  \"ep_set\": {\n","    \"short_entry_score\": -1,\n","    \"tr_thresh\": 0.5,\n","    \"dr_error\": 0.1,\n","    \"bbwp_thresh\": 0.5,\n","    \"entry_incycle\": 0,\n","    \"htf_entry\": 5,\n","    \"entry_type\": \"LIMIT\",\n","    \"static_ep\": 1,\n","    \"tpout_onexec\": 1,\n","    \"ep_gap\": 0,\n","    \"max_eplim_pct\": 0.05,\n","    \"min_eplim_pct\": 0.013,\n","    \"short_inversion\": 0,\n","    \"long_inversion\": 0,\n","    \"check_entry_sec\": 10,\n","    \"entry_execution_wait\": 60,\n","    \"breakout_qty_ratio\": 0.97\n","  },\n","  \"out_set\": {\n","    \"out_type\": \"MARKET\",\n","    \"exit_execution_wait\": 60,\n","    \"close_complete_term\": 5,\n","    \"use_out\": 1,\n","    \"static_out\": 1,\n","    \"out_gap\": 0,\n","    \"hl_out\": 1,\n","    \"price_restoration\": 0,\n","    \"retouch\": 0,\n","    \"retouch_out_period\": 500,\n","    \"second_out\": 0,\n","    \"approval_st_gap\": 1.5,\n","    \"second_out_gap\": 0.5\n","  },\n","  \"tp_set\": {\n","    \"non_tp\": 0,\n","    \"tp_type\": \"LIMIT\",\n","    \"static_tp\": 1,\n","    \"tp_gap\": 0,\n","    \"partial_num\": 1,\n","    \"partial_qty_divider\": 1.5\n","  },\n","  \"lvrg_set\": {\n","    \"leverage\": 2,\n","    \"static_lvrg\": 1,\n","    \"allow_float\": 0,\n","    \"target_pct\": 0.05\n","  }\n","}\n","\n","config = EasyDict(param_dict)\n","# param_json = json.dumps(param_dict, indent=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdAn2bHHBWMF"},"source":["# ------- tp / out fee calc ------- #\n","if config.ep_set.entry_type == 'MARKET':\n","  if config.tp_set.tp_type == 'LIMIT':\n","    tp_fee = config.init_set.market_fee + config.init_set.limit_fee\n","  else:\n","    tp_fee = config.init_set.market_fee + config.init_set.market_fee\n","  out_fee = config.init_set.market_fee + config.init_set.market_fee\n","else:\n","  if config.tp_set.tp_type == 'LIMIT':\n","    tp_fee = config.init_set.limit_fee + config.init_set.limit_fee\n","  else:\n","    tp_fee = config.init_set.limit_fee + config.init_set.market_fee\n","  out_fee = config.init_set.limit_fee + config.init_set.market_fee\n","  \n","\n","# ------- inversion set ------- #\n","inversion = 0\n","  \n","fdist_thresh = 1\n","\n","# ----------------- indicator ----------------- #\n","# ------- shift_size ------- #\n","cloud_shift_size = 1\n","sma_shift_size = 1\n","close_shift_size = 1\n","\n","\n","# ------- lb ------- #\n","# cloud_lookback = 30\n","cloud_lookback = 69\n","# cloud_lookback = 150\n","# cloud_lookback = 10\n","\n","sma_lookback = 100\n","# sma_lookback = 100\n","\n","sar_lookback = 5\n","\n","\n","# ------- indi. params ------- #\n","\n","# sma_period = 60\n","\n","fisher_upper = 1.5\n","fisher_lower = -1.5\n","\n","stoch_upper = 67\n","stoch_lower = 33\n","\n","cctbbo_upper = 80\n","cctbbo_lower = 20\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","\n","for key in ftr_list:\n","\n","  if config.init_set.symbol in key:\n","    pass\n","  else:\n","    continue\n","\n","  # break\n","\n","  res_df = pd.read_feather(os.path.join(save_path, dir_path, key.replace(\"xlsx\", \"ftr\")), columns=None, use_threads=True).set_index(\"index\")\n","  print(key, \"loaded !\")\n","  \n","  # print(\"res_df.columns :\", res_df.columns)  \n","  # print(res_df.tail(100))\n","  # print(\"res_df.index[0] :\", res_df.index[0])\n","  # # print(\"intmin(res_df.index[0]) :\", intmin(res_df.index[0]))\n","  # break\n","\n","  # -------------------- additional indi. -------------------- #    \n","  np_timeidx = np.array(list(map(lambda x : intmin(x), res_df.index)))\n","\n","   # --------------- level function --------------- #\n","  # res_df = st_level(res_df, '3m', 1)\n","  res_df = st_level(res_df, '5m', 1)\n","  res_df = st_level(res_df, '15m', 1)\n","  res_df = st_level(res_df, '30m', 1)\n","  res_df = st_level(res_df, '1h', 1)\n","  res_df = st_level(res_df, '4h', 1)\n","\n","  # res_df = bb_level(res_df, '1m', 1)\n","  res_df = bb_level(res_df, '5m', 1)\n","  res_df = bb_level(res_df, '15m', 1)\n","  res_df = bb_level(res_df, '30m', 1)\n","  res_df = bb_level(res_df, '1h', 1)\n","  res_df = bb_level(res_df, '4h', 1)\n","\n","  res_df = dc_level(res_df, '5m', 1)\n","  res_df = dc_level(res_df, '15m', 1)\n","  res_df = dc_level(res_df, '30m', 1)\n","  res_df = dc_level(res_df, '1h', 1)\n","  res_df = dc_level(res_df, '4h', 1)\n","\n","  # res_df['bbwp'], res_df['bbwp_ma'] = bbwp(res_df['bb_gap_1m'], res_df['st_gap_5m'])\n","\n","  # break\n","\n","    # --------------- sma --------------- #    \n","  res_df['sma_1m'] = res_df['close'].rolling(60).mean()  \n","\n","   # --------------- ema --------------- #   \n","  # res_df['ema5_1m'] = ema(res_df['close'], 5).shift(1)\n","\n","  #   # --------------- cloud bline --------------- #   \n","  # res_df['cloud_bline_1m'] = cloud_bline(res_df, 26).shift(1)\n","  \n","    #       stochastic      #\n","  # res_df['stoch'] = stoch(res_df, 5, 3, 3)\n","\n","    #       fisher      #\n","  # res_df['fisher30'] = fisher(res_df, 30)\n","  # res_df['fisher60'] = fisher(res_df, 60)\n","  # res_df['fisher120'] = fisher(res_df, 120)\n","\n","    #       cctbbo      #\n","  # res_df['cctbbo'], _ = cct_bbo(res_df, 21, 13)\n","\n","    #       ema_roc      #\n","  # res_df['ema_roc'] = ema_roc(res_df['close'], 13, 9)\n","\n","\n","   # ------------------------------ htf data ------------------------------ #    \n","\n","  #             Todo              #\n","  # htf_df = pd.read_excel(date_path2 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # htf_df = pd.read_excel(date_path3 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # htf_df = pd.read_excel(date_path4 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # # htf_df = pd.read_excel(date_path5 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","  # # # # # # htf_df = pd.read_excel(date_path6 + key.replace(\"_st1h_backi2\", \"\"), index_col=0)\n","\n","  # # ---- htf index slicing ---- #\n","  # htf_df = htf_df.loc[:res_df.index[-1]]\n","  \n","  # print(\"res_df.index[-1] :\", res_df.index[-1])\n","  # print(\"htf_df.index[-1] :\", htf_df.index[-1])\n","\n","  # res_df = dc_line(res_df, htf_df, '5m')\n","  # res_df = dc_level(res_df, '5m', 1)\n","\n","\n","  # # # if \"sma4\" in res_df.columns:\n","  # # #   res_df.drop(\"sma4\", axis=1, inplace=1)\n","\n","  # # htf_df['sma'] = htf_df['close'].rolling(60).mean()\n","  # # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, htf_df, [-1]), columns=['sma_30m']))\n","  \n","  # htf_df['stoch'] = stoch(htf_df, 13, 3, 3)\n","  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, htf_df, [-1], backing_i=-1), columns=['stoch_5m']))\n","\n","   \n","  # fifth_df['ema'] = ema(fifth_df['close'], 5)\n","  # res_df = res_df.join(pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, fifth_df, [-1]), columns=['ema5']))\n","\n","\n","  for just_loop in range(1):\n","  # for senkou_a, senkou_b in zip(senkoua_list, senkoub_list): \n","  # for config.ep_set.tr_thresh in np.arange(2., 4., 0.3): \n","  # for config.ep_set.dr_error in np.arange(0.05, 0.4, 0.03): \n","  # for config.ep_set.ep_gap in np.arange(1, 10, 1): \n","  # for config.out_set.out_gap in np.arange(0., -1, -0.1): \n","  # for config.tp_set.tp_gap in np.arange(1., 4., 0.2):     \n","  # for config.ep_set.entry_incycle in range(5, 10):\n","  # for config.ep_set.htf_entry in [1, 3, 5, 15, 45, 60]:\n","  # for config.ep_set.bbwp_thresh in np.arange(0.5, 1.1, 0.03): \n","  # for config.lvrg_set.leverage in range(1, 10):\n","  # for config.lvrg_set.target_pct in np.arange(0.05, 0.15, 0.03): \n","  # for config.ep_set.max_eplim_pct in np.arange(0.01, 0.1, 0.01):\n","  # for config.ep_set.min_eplim_pct in np.arange(0.005, 0.02, 0.002):\n","  # for sma_period in range(10, 100, 10):\n","  # for ep_protect_gap in np.arange(0.2, 0.5, 0.05):\n","  # for cloud_lookback in np.arange(5, 100, 3): \n","\n","    # config.out_set.out_gap = config.tp_set.tp_gap / config.ep_set.tr_thresh\n","        \n","    print(\"config.ep_set.tr_thresh :\", config.ep_set.tr_thresh)\n","    print(\"config.ep_set.dr_error :\", config.ep_set.dr_error)\n","    print(\"config.ep_set.htf_entry :\", config.ep_set.htf_entry)\n","    print(\"config.ep_set.ep_gap :\", config.ep_set.ep_gap)\n","    print(\"config.out_set.out_gap :\", config.out_set.out_gap)\n","    print(\"config.tp_set.tp_gap :\", config.tp_set.tp_gap)\n","    print(\"config.ep_set.bbwp_thresh :\", config.ep_set.bbwp_thresh)\n","    print(\"config.ep_set.entry_incycle :\", config.ep_set.entry_incycle)\n","    print(\"config.lvrg_set.leverage :\", config.lvrg_set.leverage)\n","    print(\"config.lvrg_set.target_pct :\", config.lvrg_set.target_pct)\n","    print(\"config.ep_set.max_eplim_pct :\", config.ep_set.max_eplim_pct)\n","    print(\"config.ep_set.min_eplim_pct :\", config.ep_set.min_eplim_pct)\n","\n","    # print(\"sma_period :\", sma_period)\n","    # res_df['sma_1m'] = res_df['close'].rolling(sma_period).mean()  \n","\n","\n","    # print(\"sma4_period :\", sma4_period)\n","    # print(\"cloud_lookback :\", cloud_lookback)\n","\n","    # -------------------- additional indicators by loop -------------------- #    \n","    \n","    #           ichimoku            #\n","    # res_df['senkou_a1'], res_df['senkou_b1'] = ichimoku(res_df)\n","    \n","    # # second_df['senkou_a'], second_df['senkou_b'] = ichimoku(second_df)\n","    # # res_df = res_df.join( pd.DataFrame(index=res_df.index, data=to_lower_tf(res_df, second_df, [-2, -1]), columns=['senkou_a2', 'senkou_b2']))\n","\n","    # # #           cloud displacement           #\n","    # cloud_cnt = 0\n","    # for col_n in res_df.columns:\n","    #   if 'senkou' in col_n:\n","    #     cloud_cnt += 1\n","    # print(\"cloud_cnt :\", cloud_cnt)\n","\n","    # res_df.iloc[:, -cloud_cnt:] = res_df.iloc[:, -cloud_cnt:].shift(26 - 1)\n","\n","    # senkou_a, senkou_b = 'senkou_a1', 'senkou_b1'\n","    \n","    # cloud_top = np.max(res_df[[senkou_a, senkou_b]], axis=1)\n","    # cloud_bottom = np.min(res_df[[senkou_a, senkou_b]], axis=1)\n","\n","    # under_top = res_df['close'].shift(cloud_shift_size) <= cloud_top.shift(cloud_shift_size)\n","    # over_top = res_df['close'].shift(cloud_shift_size) >= cloud_top.shift(cloud_shift_size)\n","\n","    # over_bottom = res_df['close'].shift(cloud_shift_size) >= cloud_bottom.shift(cloud_shift_size)\n","    # under_bottom = res_df['close'].shift(cloud_shift_size) >= cloud_bottom.shift(cloud_shift_size)    \n","\n","    \n","    \n","    # ---------------------------------------- short = -1 ---------------------------------------- #\n","    res_df['entry'] = np.zeros(len(res_df))\n","\n","\n","    # -------- limit zone, limit_in : define ep, if use limit -------- #\n","    \n","    #        st ep         #    \n","    res_df['short_ep'] = res_df['st_base_15m']\n","    res_df['long_ep'] = res_df['st_base_15m']\n","    \n","    # res_df['short_ep'] = res_df['open'] + res_df['st_gap_30m'] * config.ep_set.ep_gap\n","    # res_df['long_ep'] = res_df['open'] - res_df['st_gap_30m'] * config.ep_set.ep_gap\n","    \n","    # --------------- %  ep --------------- #    \n","    # res_df['short_ep'] = res_df['open'] * (1 / (1 + res_df['st_gap_30m'] * config.ep_set.ep_gap / res_df['open']))\n","    # res_df['long_ep'] = res_df['open'] * (1 / (1 + res_df['st_gap_30m'] * config.ep_set.ep_gap / res_df['open']))\n","\n","    # short_ep_out = res_df['st_base_5m']\n","    # long_ep_out = res_df['st_base_5m']\n","\n","    #          timestamp entry         #        \n","    # res_df['entry'] = np.where((np_timeidx % config.ep_set.htf_entry == 0)\n","    #                     , res_df['entry'] - 1, res_df['entry'])\n","\n","    #          st entry          #    \n","    res_df['entry'] = np.where((np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1)) &\n","                               (res_df['close'] < res_df['st_lower_15m'])\n","                        , res_df['entry'] - 1, res_df['entry'])  \n","                        # , res_df['entry'] + 1, res_df['entry'])  \n","    \n","    # entry = np.where((res_df['st_upper3_5m'] - res_df['st_gap_5m'] <= res_df['close'].shift(1)) &\n","    #                  (res_df['close'].shift(1) <= res_df['st_upper3_5m'])\n","    #                 , entry - 1, entry) \n","\n","    # -------- market zone  -------- #\n","\n","    #        stoch entry        #       \n","    # res_df['entry'] = np.where((res_df['stoch_5m'].shift(config.ep_set.htf_entry * 2) < res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1)) &\n","    #                 (res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1) > res_df['stoch_5m']) & \n","    #                 (res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1) > stoch_upper) & \n","    #                 (np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1))\n","    #                 , res_df['entry'] - 1, res_df['entry']) \n","    \n","\n","    #        st level entry      #       \n","    # entry = np.where((res_df['close'].shift(1) >= res_df['st_lower2_15m']) &\n","    #                 (res_df['close'] < res_df['st_lower2_15m'])\n","    #                 , -1, 0)     \n","    # entry = np.where((res_df['close'].shift(1) >= res_df['st_base_5m']) &\n","    #                 (res_df['close'] < res_df['st_base_5m'])\n","    #                 , entry - 1, entry)  \n","\n","      #        st level htf entry      #   \n","    # res_df['entry'] = np.where((res_df['close'].shift(config.ep_set.htf_entry) >= res_df['st_lower_5m']) &\n","    #                 (res_df['close'] < res_df['st_lower_5m']) & \n","    #                 (np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1))\n","    #                 , res_df['entry'] - 1, res_df['entry']) \n","\n","    #        bb level entry      #\n","    # entry = np.where((res_df['close'].shift(1) >= res_df['bb_lower_1m']) & \n","    #                 (res_df['close'] < res_df['bb_lower_1m'])\n","    #                 , entry - 1, entry) \n","    # entry = np.where((res_df['close'].shift(1) >= res_df['bb_lower_1m'].shift(1)) & \n","    #                 (res_df['close'] < res_df['bb_lower_1m'])\n","    #                 , entry - 1, entry)           \n","\n","    # print(\"len(entry[entry==-1]) :\", len(entry[entry==-1]))\n","    # break    \n","\n","\n","\n","    # ---------------------------------------- long = 1 ---------------------------------------- #\n","    \n","    # ----------- limit zone : limit_in ----------- #    \n","\n","    #        timestamp entry        #   \n","    \n","    # res_df['entry'] = np.where((np_timeidx % config.ep_set.htf_entry == 0)\n","    #                     , res_df['entry'] + 1, res_df['entry'])  \n","\n","    res_df['entry'] = np.where((np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1)) &\n","                               (res_df['close'] > res_df['st_upper_15m'])\n","                        , res_df['entry'] + 1, res_df['entry'])     \n","                        # , res_df['entry'] - 1, res_df['entry'])     \n","    \n","    #        st entry        #    \n","    # entry = np.where((res_df['st_lower3_5m'] + res_df['st_gap_5m'] >= res_df['close'].shift(1)) &\n","    #                  (res_df['close'].shift(1) >= res_df['st_lower3_5m'])\n","    #                 , entry + 1, entry) \n","    # entry = np.where((long_ep + res_df['st_gap_5m'] >= res_df['close'].shift(1)) &\n","    #   (res_df['close'].shift(1) >= long_ep)\n","    # , entry + 1, entry) \n","     \n","\n","    # ----------- market zone ----------- #    \n","\n","    #        stoch entry        #               \n","    # res_df['entry'] = np.where((res_df['stoch_5m'].shift(config.ep_set.htf_entry * 2) > res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1)) &\n","    #                 (res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1) < res_df['stoch_5m']) & \n","    #                 (res_df['stoch_5m'].shift(config.ep_set.htf_entry * 1) < stoch_lower) & \n","    #                 (np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1))\n","    #                 , res_df['entry'] + 1, res_df['entry']) \n","    \n","    #      st level entry      #       \n","    # entry = np.where((res_df['close'].shift(1) <= res_df['st_upper2_15m']) &      \n","    #                   (res_df['close'] > res_df['st_upper2_15m'])\n","    #                   , 1, entry) \n","    # entry = np.where((res_df['close'].shift(1) <= res_df['st_base_5m']) &      \n","    #                   (res_df['close'] > res_df['st_base_5m'])\n","    #                   , entry + 1, entry) \n","    \n","      #      st level htf entry      #   \n","    # res_df['entry'] = np.where((res_df['close'].shift(config.ep_set.htf_entry) <= res_df['st_upper_5m']) &      \n","    #                 (res_df['close'] > res_df['st_upper_5m']) & \n","    #                 (np_timeidx % config.ep_set.htf_entry == (config.ep_set.htf_entry - 1))\n","    #                 , res_df['entry'] + 1, res_df['entry']) \n","\n","    #      bb level entry      #\n","    # entry = np.where((res_df['close'].shift(1) <= res_df['bb_upper_1m']) & \n","    #                   (res_df['close'] > res_df['bb_upper_1m']) \n","    #                   , entry + 1, entry)                      \n","    # entry = np.where((res_df['close'].shift(1) <= res_df['bb_upper_1m'].shift(1)) & \n","    #                   (res_df['close'] > res_df['bb_upper_1m']) \n","    #                   , entry + 1, entry)\n","\n","\n","\n","    #       1-2. tp line = middle line 조금 이내         #    \n","\n","    # ------------------------------ out ------------------------------ #\n","    \n","      # --------------- hl out --------------- #    \n","    # short_out = res_df['high'] + res_df['st_gap_15m'] * config.out_set.out_gap\n","    # long_out = res_df['low'] - res_df['st_gap_15m'] * config.out_set.out_gap\n","\n","      # --------------- st level consolidation out --------------- #    \n","    # short_out = res_df['st_lower_15m'] + res_df['st_gap_15m'] * config.out_set.out_gap\n","    # long_out = res_df['st_upper_15m'] - res_df['st_gap_15m'] * config.out_set.out_gap\n","\n","    # short_out = res_df['st_lower_5m'] + res_df['st_gap_5m'] * config.out_set.out_gap\n","    # long_out = res_df['st_upper_5m'] - res_df['st_gap_5m'] * config.out_set.out_gap\n","    \n","    # res_df['short_out'] = res_df['close'] + res_df['st_gap_5m'] * config.out_set.out_gap - res_df['close'] * (tp_fee / config.ep_set.tr_thresh + out_fee)\n","    # res_df['long_out'] = res_df['close'] - res_df['st_gap_5m'] * config.out_set.out_gap + res_df['close'] * (tp_fee / config.ep_set.tr_thresh + out_fee)\n","\n","    res_df['short_out'] = res_df['st_upper_15m'] + res_df['st_gap_15m'] * config.out_set.out_gap\n","    res_df['long_out'] = res_df['st_lower_15m'] - res_df['st_gap_15m'] * config.out_set.out_gap\n","\n","    # short_out = short_ep + res_df['st_gap_5m'] * config.out_set.out_gap\n","    # long_out = long_ep - res_df['st_gap_5m'] * config.out_set.out_gap\n","\n","      # --------------- bb level consolidation out --------------- #   \n","    # short_out = res_df['bb_upper_1m'] + res_df['bb_gap_1m'] * config.out_set.out_gap\n","    # long_out = res_df['bb_lower_1m'] - res_df['bb_gap_1m'] * config.out_set.out_gap\n","\n","\n","      # --------------- cloud_bline rolling out --------------- #    \n","    # short_out = res_df['cloud_bline1']\n","    # long_out = res_df['cloud_bline1']\n","\n","      # --------------- ema rolling out --------------- #    \n","    # short_out = res_df['ema1_5']\n","    # long_out = res_df['ema1_5']\n","    \n","\n","      # --------------- mmh_st rolling out --------------- #    \n","    # short_out = res_df['mmh_st1']\n","    # long_out = res_df['mmh_st1']\n","\n","      # --------------- st rolling out --------------- #     \n","\n","    # short_out = res_df['lower_middle%s' % basic_st_number]\n","    # long_out = res_df['upper_middle%s' % basic_st_number]\n","\n","    # short_out = res_df['upper_middle%s' % basic_st_number]\n","    # long_out = res_df['lower_middle%s' % basic_st_number]\n","\n","    # short_out = short_ep + res_df['st_gap%s' % basic_st_number] * config.out_set.out_gap\n","    # long_out = long_ep - res_df['st_gap%s' % basic_st_number] * config.out_set.out_gap\n","    \n","    # short_out2 = res_df['lower_middle]\n","    # long_out2 = res_df['upper_middle]\n","    \n","    # short_out = short_ep + res_df['st_gap']\n","    # long_out = long_ep - res_df['st_gap']\n","    \n","\n","    # ------------------------------ tp ------------------------------ #\n","\n","    # --------------- st level tp --------------- #    \n","    # short_tp = short_ep - res_df['st_gap_5m'] * config.tp_set.tp_gap\n","    # long_tp = long_ep + res_df['st_gap_5m'] * config.tp_set.tp_gap\n","\n","    # res_df['short_tp'] = res_df['close'] - res_df['st_gap_5m'] * config.tp_set.tp_gap\n","    # res_df['long_tp'] = res_df['close'] + res_df['st_gap_5m'] * config.tp_set.tp_gap\n","    \n","    res_df['short_tp'] = res_df['st_lower2_15m'] - res_df['st_gap_15m'] * config.tp_set.tp_gap\n","    res_df['long_tp'] = res_df['st_upper2_15m'] + res_df['st_gap_15m'] * config.tp_set.tp_gap\n","\n","    # short_tp = res_df['st_lower_30m'] - res_df['st_gap_30m'] * config.tp_set.tp_gap\n","    # long_tp = res_df['st_upper_30m'] + res_df['st_gap_30m'] * config.tp_set.tp_gap\n","\n","    # --------------- bb level tp --------------- #        \n","    # short_tp = res_df['bb_lower3_5m'] - res_df['bb_gap_5m'] * config.tp_set.tp_gap\n","    # long_tp = res_df['bb_upper3_5m'] + res_df['bb_gap_5m'] * config.tp_set.tp_gap\n","\n","    # --------------- mmh_st tp --------------- #    \n","\n","    # short_tp = res_df['close'] - config.tp_set.tp_gap * abs(res_df['mmh_st1'] - res_df['close'])\n","    # long_tp = res_df['close'] + config.tp_set.tp_gap * abs(res_df['mmh_st1'] - res_df['close'])\n","\n","    # short_tp2 = res_df['close'] - config.tp_set.tp_gap / 2 * abs(res_df['mmh_st1'] - res_df['close'])\n","    # long_tp2 = res_df['close'] + config.tp_set.tp_gap / 2 * abs(res_df['mmh_st1'] - res_df['close'])\n","\n","    # --------------- st rolling tp --------------- #    \n","    # short_tp = res_df['min_lower%s' % basic_st_number]\n","    # long_tp = res_df['max_upper%s' % basic_st_number]    \n","\n","    # short_tp = short_ep - res_df['st_gap%s' % basic_st_number] * config.tp_set.tp_gap\n","    # long_tp = long_ep + res_df['st_gap%s' % basic_st_number] * config.tp_set.tp_gap\n","\n","\n","\n","\n","    # --------------- set partial tp --------------- #\n","\n","    short_tps = [res_df['short_tp']]\n","    long_tps = [res_df['long_tp']]\n","\n","    # short_tps = [short_tp2]\n","    # long_tps = [long_tp2]\n","\n","    # short_tps = [short_tp2, short_tp] # org\n","    # long_tps = [long_tp2, long_tp]\n","    \n","    # short_tps = [short_tp, short_tp2]\n","    # long_tps = [long_tp, long_tp2]\n","\n","\n","\n","    #       trading : 여기도 체결 결과에 대해 묘사함       #\n","    trade_list = []\n","    h_trade_list = []\n","    leverage_list = []\n","    fee_list = []\n","    short_fee_list = []\n","    long_fee_list = []\n","    open_list = []\n","\n","    tp_ratio_list = []\n","    short_tp_ratio_list = []\n","    long_tp_ratio_list = []\n","\n","    dr_list = []\n","    short_dr_list = []\n","    long_dr_list = []\n","\n","    liqd_list = []\n","    short_liqd_list = []\n","    long_liqd_list = []\n","\n","    nontp_liqd_list = []\n","    nontp_short_liqd_list = []\n","    nontp_long_liqd_list = []\n","\n","    nontp_pr_list = []\n","    nontp_short_pr_list = []\n","    nontp_long_pr_list = []\n","\n","    nontp_short_indexs = []\n","    nontp_long_indexs = []\n","\n","    nontp_short_ep_list = []\n","    nontp_long_ep_list = []\n","\n","    pr_list = []\n","    long_list = []\n","    short_list = []\n","\n","    h_pr_list = []\n","    h_long_list = []\n","    h_short_list = []\n","\n","    ep_tp_list = []\n","    h_ep_tp_list = []\n","    tp_state_list = []\n","\n","    i = 0\n","    while 1:\n","    # for i in range(len(res_df)):  \n","    \n","      # ------- fee init ------- #\n","      if config.ep_set.entry_type == 'LIMIT':\n","        fee = config.init_set.limit_fee\n","      else:\n","        fee = config.init_set.market_fee\n","\n","\n","      # ------- mr_score init ------- #\n","\n","      mr_const_cnt = 0\n","      mr_score = 0\n","\n","\n","      if res_df['entry'][i] == config.ep_set.short_entry_score: \n","\n","        # print(\"i in short :\", i)\n","\n","        initial_i = i\n","\n","        if config.out_set.static_out:\n","          p_i = initial_i\n","        else:\n","          p_i = i\n","\n","\n","        # -------------- tr scheduling -------------- #\n","        # if config.ep_set.entry_type == 'MARKET':\n","        #   mr_const_cnt += 1\n","        #   # if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i] + out_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","        #   if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i] + tp_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","        #   # if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i] + out_fee * res_df['close'].iloc[i]) == config.ep_set.tr_thresh:\n","        #   # if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i] - out_fee * res_df['close'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i] + out_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","\n","        #     mr_score += 1\n","\n","        # -------------- dr scheduling -------------- #\n","        # mr_const_cnt += 1\n","        # if (res_df['close'].iloc[i] - res_df['short_tp'].iloc[i]) / (res_df['short_out'].iloc[i] - res_df['close'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error):  \n","        #  mr_score += 1\n","        \n","\n","\n","        # ---------------------------- mr ---------------------------- #      \n","          # ------- entry once ------- #   \n","          #          1. find prev out         #\n","          #          2. count entry til prev out         #\n","        # prev_entry_cnt = 0\n","        # for back_i in range(i - 1, 0, -1):\n","        #   if res_df['entry'][back_i] == 1:\n","        #     break\n","\n","        #   elif res_df['entry'][back_i] == -1:\n","        #     prev_entry_cnt += 1\n","          \n","        # # print(\"prev_entry_cnt :\", prev_entry_cnt)\n","        # mr_const_cnt += 1\n","        # if prev_entry_cnt <= config.ep_set.entry_incycle:\n","        # # if prev_entry_cnt >= config.ep_set.entry_incycle:\n","        #   mr_score += 1\n","\n","\n","        \n","        # -------------- bbwp const. -------------- #\n","        # if res_df['bbwp'].iloc[i] <= config.ep_set.bbwp_thresh:\n","        # if res_df['bbwp'].iloc[i] >= config.ep_set.bbwp_thresh:\n","          # mr_score += 1\n","\n","        # -------------- ma const. -------------- #\n","        # ------- ema const. ------- #\n","        # if res_df['close'].shift(0).iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] < res_df['ema5'].shift(1).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if short_ep.iloc[i] < res_df['ema5'].shift(0).iloc[i]: # and \\\n","          # mr_score += 1\n","\n","        # # ------- sma const. ------- #\n","        # mr_const_cnt += 1\n","        # if res_df['close'].iloc[i] <= res_df['sma_1m'].iloc[i]: # and \\\n","        # # if res_df['close'].iloc[i] <= res_df['sma_30m'].iloc[i]: # and \\\n","        #   mr_score += 1\n","\n","        # ------- sar zone const. ------- #\n","        # mr_const_cnt += 1\n","        # if not res_df['sar_uptrend_30m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # ------- st zone const. ------- #\n","        # mr_const_cnt += 1\n","        # # if res_df['close'].iloc[i] <= res_df['st_base_5m'].iloc[i]:\n","        # # if res_df['close'].iloc[i] <= res_df['st_lower_5m'].iloc[i]:\n","        # if res_df['close'].iloc[i] <= res_df['st_lower_4h'].iloc[i]:\n","        # # if res_df['close'].iloc[i] <= res_df['st_upper_5m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # ------- bb zone const. ------- #\n","        # mr_const_cnt += 1\n","        # # if res_df['close'].iloc[i] <= res_df['bb_lower_30m'].iloc[i]:\n","        # if res_df['close'].iloc[i] <= res_df['bb_lower2_30m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # ------- cloud bline ------- #\n","        # mr_const_cnt += 1\n","        # # if res_df['close'].iloc[i] <= res_df['cloud_bline_30m'].iloc[i] and \\\n","        # #   res_df['close'].iloc[i] <= res_df['cloud_bline_3m'].iloc[i]:\n","        # # if res_df['close'].iloc[i] <= res_df['cloud_bline_5m'].iloc[i]:\n","        # # # if res_df['close'].iloc[i] <= res_df['cloud_bline_1m'].iloc[i]:\n","        # # if res_df['close'].iloc[i] <= res_df['cloud_bline_1h'].iloc[i]:\n","        # if res_df['close'].iloc[i] <= res_df['cloud_bline_4h'].iloc[i]:\n","        #   mr_score += 1\n","\n","\n","          # ------- ema alignment ------- #          \n","        # if res_df['ema5_1m'].iloc[i] < res_df['ema5_1m'].iloc[i - 1] < res_df['ema5_1m'].iloc[i - 2]:\n","        # # if res_df['ema5_1m'].iloc[i - 1] < res_df['ema5_1m'].iloc[i - 2]:\n","          # mr_score += 1\n","\n","        # #   # ------- sma alignment ------- #          \n","        # if res_df['sma_1m'].iloc[i] < res_df['sma_1m'].iloc[i - 1]:\n","        # # if res_df['sma_1m'].iloc[i] < res_df['sma_1m'].iloc[i - 1] < res_df['sma_1m'].iloc[i - 2]:\n","          # mr_score += 1\n","\n","        # #   # ------- bb alignment ------- #\n","        # if res_df['bb_lower_1m'].iloc[i] < res_df['bb_lower_1m'].iloc[i - 1]:\n","          # mr_score += 1\n","\n","          # ------- bb_base alignment ------- #\n","        # if res_df['bb_base_5m'].iloc[i] < res_df['bb_base_5m'].iloc[i - 1]:\n","          # mr_score += 1\n","\n","  \n","\n","\n","        \n","          \n","        # -------------- distance protection -------------- #\n","        # tp_dist = (res_df['close'].iloc[i] - short_tp.iloc[i])\n","        # out_dist = (res_df['middle_line'].iloc[i] - res_df['close'].iloc[i])\n","        # if tp_dist / out_dist >= tp_out_ratio:\n","          # mr_score += 1\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","          # mr_score += 1\n","\n","        # -------------- htf data const. -------------- #\n","        # i_min = intmin(res_df.index[i]) # 2020-09-05 00:00:59.999000\n","        # if i_min >= 30:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"59:59.999000\"\n","        # else:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"29:59.999000\"\n","          \n","        #   # -------------- ema -------------- #\n","        # if fifth_df['close'].shift(1).loc[htf_ts] < fifth_df['ema'].shift(1).loc[htf_ts]:\n","          # mr_score += 1         \n","        \n","\n","\n","        # -------------- fisher const. -------------- #\n","        # if res_df['fisher30'].shift(1).iloc[i] < 0:\n","        # if res_df['fisher60'].shift(1).iloc[i] < 0:\n","        # if res_df['fisher120'].shift(1).iloc[i] < 0:\n","          # mr_score += 1\n","\n","         \n","\n","\n","        # -------------- htf st line const. -------------- #        \n","          # ------------ 30m ------------ #\n","        # # if res_df['lower_middle5'].iloc[i] >= res_df['min_upper2'].iloc[i]:\n","        # # if res_df['lower_middle5'].iloc[i] >= res_df['close'].iloc[i]:     \n","        # if res_df['bb_lower'].iloc[i] >= res_df['lower_middle5'].iloc[i] and \\\n","        # res_df['bb_lower'].iloc[i] < res_df['ema1_5'].iloc[i]:\n","\n","        #   # ------------ 4h ------------ #\n","        # # if res_df['lower_middle6'].iloc[i] >= res_df['min_upper2'].iloc[i]:\n","\n","        #   # ------------ 5m & 30m ------------ #\n","        # # if res_df['lower_middle5'].iloc[i] >= res_df['middle_line3'].iloc[i]:\n","        # # if res_df['lower_middle5'].iloc[i] >= res_df['upper_middle3'].iloc[i]:\n","\n","        #   # ------------ 5m & 30m & 4h ------------ #\n","        # # if res_df['lower_middle6'].iloc[i] >= res_df['lower_middle5'].iloc[i] >= res_df['lower_middle3'].iloc[i]:\n","          # mr_score += 1\n","\n","\n","\n","        # -------------- 1d sma const. -------------- #\n","        # if res_df[sma].iloc[i] >= res_df['close'].iloc[i]:\n","          # mr_score += 1\n","\n","\n","        # -------------- cloud lb const.-------------- #   \n","        # if i < cloud_lookback:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # if np.sum(under_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # # if np.sum(under_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # # if np.sum(over_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # # if np.sum(under_top.iloc[i - cloud_lookback:i]) == cloud_lookback:\n","        #   mr_score += 1\n","\n","\n","        # -------------- cloud color const.-------------- #\n","        #               1. senkou_a1 < senkou_b1            #\n","        #               1-1. mutli clouds color 충분히 고려               #        \n","        # if i < cloud_lookback:        \n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # if np.sum(res_df[senkou_a].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[senkou_b].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   np.sum(res_df[\"senkou_a2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback: # and \\\n","        #   # np.sum(res_df[\"senkou_a3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] <= res_df[\"senkou_b5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","          # mr_score += 1\n","\n","\n","\n","        # -------------- st color const.-------------- #\n","        # if np.sum(res_df[['ST1_Trend%s' % basic_st_number, 'ST2_Trend%s' % basic_st_number, 'ST3_Trend%s' % basic_st_number]].iloc[i]) <= -1:\n","        # # if np.sum(res_df[['ST1_Trend%s' % basic_st_number, 'ST2_Trend%s' % basic_st_number, 'ST3_Trend%s' % basic_st_number]].iloc[i]) <= -3:\n","          # mr_score += 1\n","\n","        # -------------- htf st color const.-------------- #\n","        # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) <= -1:\n","        # # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) <= -3:\n","          # mr_score += 1\n","\n","        # -------------- 3rd st const. : st should have 2, 3 or more -------------- #\n","        # if np.sum(res_df[['minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) <= -2:\n","          # mr_score += 1\n","\n","        # -------------- st gap const.-------------- #\n","        # if abs(res_df['ST2_Up%s' % basic_st_number].iloc[i] - res_df['ST1_Up%s' % basic_st_number].iloc[i]) <= config.out_set.approval_st_gap * res_df['st_gap%s' % basic_st_number].iloc[i]:\n","          # mr_score += 1\n","        \n","\n","\n","        # -------------- sar const. -------------- #\n","        # if res_df['sar1'].iloc[i] > res_df['high'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] > res_df['high'].iloc[i] and res_df['sar3'].iloc[i] > res_df['high'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] > res_df['high'].iloc[i]: # and \\\n","        # # if  res_df['sar3'].iloc[i] > res_df['high'].iloc[i]:\n","          # mr_score += 1\n","\n","\n","        # -------------- mr_score summation -------------- #\n","        if mr_score == mr_const_cnt:          \n","          pass\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","\n","        ep_j = initial_i # dynamic ep 를 위한 var.\n","\n","        # -------------- limit waiting : limit_out -------------- #\n","\n","        entry_done = 0\n","        entry_open = 0\n","        prev_sar = None\n","        # for e_j in range(i, len(res_df)): # entry_signal 이 open 기준 (해당 bar 에서 체결 가능함)\n","        if i + 1 >= len(res_df):  # i should be checked if e_j starts from i+1\n","          break\n","        for e_j in range(i + 1, len(res_df)): # entry signal이 close 기준 일 경우\n","      \n","          if not config.ep_set.static_ep:\n","            ep_j = e_j\n","\n","          if config.tp_set.static_tp:\n","            # if config.ep_set.tpout_onexec:\n","            #   tp_j = e_j\n","            # else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = e_j  \n","\n","          #             1. ep 설정 \n","          # -------------- np.inf ep -------------- #\n","          # if short_ep.iloc[initial_i] == np.inf:\n","          #   break\n","\n","\n","          #             1. check ep_out      #\n","          if res_df['low'].iloc[e_j] <= res_df['short_tp'].iloc[tp_j]: # ep_out : tp_done\n","          # if np_timeidx[e_j] % config.ep_set.htf_entry == config.ep_set.htf_entry - 1:\n","            break\n","\n","          #             2. check ep_in       #\n","          if res_df['high'].iloc[e_j] >= res_df['short_ep'].iloc[ep_j]:\n","            entry_done = 1\n","            # print(\"res_df['high'].iloc[e_j] :\", res_df['high'].iloc[e_j])\n","            # print(\"e_j :\", e_j)\n","\n","            #     이미, e_j open 이 ep 보다 높은 경우, entry[ep_j] => -2 로 변경   #\n","            if res_df['open'].iloc[e_j] >= res_df['short_ep'].iloc[ep_j]:\n","              entry_open = 1\n","\n","            break\n","\n","\n","        i = e_j\n","        # print(\"i = e_j :\", i)\n","\n","        if entry_done:      \n","          pass\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","        # ----------------- end wait ----------------- #\n","\n","        # if e_j - initial_i >= 200:\n","        #   print(\"e_j, initial_i :\", e_j, initial_i)\n","        # print(\"e_j - initial_i :\", e_j - initial_i)\n","        # print()\n","\n","        open_list.append(initial_i)\n","        \n","        if config.ep_set.entry_type is 'MARKET':\n","          try:\n","            ep_list = [res_df['close'].iloc[e_j]]\n","          except Exception as e:\n","            # print('error in ep_list (initial) :', e)\n","            ep_list = [res_df['close'].iloc[ep_j]]\n","\n","        else:          \n","          if not entry_open:\n","            ep_list = [res_df['short_ep'].iloc[ep_j]]\n","          \n","          #     Todo    #\n","          #      1. entry_score version 으로 재정의해야함\n","          #      2. below phase exists for open_price entry\n","          else:\n","            #   e_j 가 있는 경우, \n","            try:\n","              ep_list = [res_df['open'].iloc[e_j]]\n","            except Exception as e:\n","              ep_list = [res_df['open'].iloc[ep_j]]\n","\n","        if not config.lvrg_set.static_lvrg:\n","          # config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['high'].rolling(hl_lookback).max().iloc[initial_i] / res_df['close'].iloc[initial_i] - 1)\n","\n","          if config.ep_set.entry_type is 'MARKET':\n","            # config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['short_out'].iloc[ep_j] / res_df['close'].iloc[ep_j] - 1 - fee)\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(res_df['close'].iloc[ep_j] / res_df['short_out'].iloc[ep_j] - 1 - (fee + config.init_set.market_fee))\n","          else:\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['short_out'].iloc[ep_j] / res_df['short_ep'].iloc[ep_j] - 1 - (fee + config.init_set.market_fee))\n","          config.lvrg_set.leverage = min(50, config.lvrg_set.leverage)\n","          if not config.lvrg_set.allow_float:\n","            config.lvrg_set.leverage = int(config.lvrg_set.leverage)\n","          config.lvrg_set.leverage = max(config.lvrg_set.leverage, 1)\n","          leverage_list.append(config.lvrg_set.leverage)\n","\n","        try:\n","          ep_idx_list = [e_j]\n","        except Exception as e:\n","          # print('error in ep_idx_list :', e)        \n","          ep_idx_list = [ep_j]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None\n","        h_i, h_j = None, None\n","        \n","        trade_done = False\n","        out = False\n","        # config.out_set.retouch\n","\n","        #     Todo    #\n","        #      1. future_work : 상단의 retouch 와 겹침 \n","        config.out_set.retouch = False\n","        \n","\n","        # if i == len(res_df) - 1: # if j start from i + 1 \n","        #   open_list.pop()       \n","        # for j in range(i + 1, len(res_df)):\n","\n","        for j in range(i, len(res_df)):\n","\n","          if config.tp_set.static_tp:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              tp_j = e_j\n","            else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = j\n","\n","          if config.out_set.static_out:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              out_j = e_j\n","            else:           \n","              out_j = initial_i\n","          else:\n","            out_j = j\n","\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['high'].iloc[j - 1] <= res_df['sar2'].iloc[j - 1] and res_df['high'].iloc[j] > res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep < ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","          \n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['high'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST2_Up'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] >= res_df['minor_ST3_Up'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","\n","          # -------------- ultimate limit tp -------------- #\n","          if not config.tp_set.non_tp:\n","\n","            #               1. by price line             #\n","            if config.tp_set.tp_type != 'MARKET':\n","\n","              for s_i, short_tp_ in enumerate(short_tps):\n","\n","                if res_df['low'].iloc[j] <= short_tp_.iloc[tp_j] and partial_tp_cnt == s_i: # we use static tp now\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j]:\n","                # if res_df['low'].iloc[j] <= short_tp_.iloc[j] <= res_df['high'].iloc[j]: --> 이건 잘못되었음\n","\n","                  if s_i == len(short_tps) - 1:\n","                    trade_done = 1\n","                  \n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if short_tp_.iloc[j] != short_tp_.iloc[j - 1] and not config.tp_set.static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_open\")\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-short_tp\")\n","\n","                  #         static tp         #\n","                  else:\n","                    \n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #              \n","\n","                    # if res_df['open'].iloc[j] < short_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] < short_tp_.iloc[tp_j]:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp\")\n","\n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","\n","                      # tp = short_tp_.iloc[initial_i]\n","                      tp = short_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-short_tp\")   \n","\n","                  tp_list.append(tp)     \n","                  tp_idx_list.append(j)\n","                  fee += config.init_set.limit_fee\n","\n","\n","            #           2. by signal        #\n","            else:\n","\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","              #       inversion     #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              # ----------- st short ----------- #\n","              # if res_df['close'].iloc[j] <= res_df['short_tp'].iloc[tp_j]:\n","              \n","              # -------------- sar pb tp -------------- #\n","              # if res_df['low'].iloc[j] <= res_df['short_tp'].iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:       \n","\n","              # -------------- fisher tp -------------- #            \n","              # if entry[j] == 1:\n","\n","              \n","              # -------------- timestamp -------------- #\n","              if np_timeidx[j] % config.ep_set.htf_entry == config.ep_set.htf_entry - 1:                  \n","                \n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = 1\n","\n","                if trade_done:\n","                  tp_state_list.append(\"short close tp\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","                fee += config.init_set.market_fee\n","\n","\n","                  \n","          # -------------- out -------------- #\n","          if not trade_done and config.out_set.use_out and j != len(res_df) - 1:\n","\n","            # -------------- macd -------------- #\n","            # if res_df['macd_hist3'].iloc[j] > 0:  #  macd out\n","            # if res_df['macd_hist3'].iloc[i] < 0 and res_df['macd_hist3'].iloc[j] > 0:\n","\n","            # -------------- st config.out_set.retouch -------------- #\n","            # out = 1 상태면 동일 tick 에서 config.out_set.retouch 를 조사할 거기 때문에, 먼저 검사함\n","            # 그리고, out 기준이 close 라 이게 맞음 \n","            # close 가 short_out 보다 올라가있는 상태일테니 low 를 조사하는게 맞음           \n","            # if out and res_df['low'].iloc[j] <= short_out.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","            \n","             # ------- 일정시간 이상, dynamic_out 적용 ------ #\n","            try:\n","              if j - out_idx >= config.out_set.retouch_out_period:\n","                static_short_out = res_df['short_out'].iloc[j]\n","            \n","            except Exception as e:\n","              pass\n","\n","              # ------- static out ------ #\n","            try:\n","              if out and res_df['low'].iloc[j] <= static_short_out:\n","                config.out_set.retouch = 1\n","            except Exception as e:\n","              pass\n","\n","            \n","              # ------- config.out_set.retouch out ------ #\n","            # if out and res_df['low'].iloc[j] <= short_out2.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","\n","            # -------------- st -------------- #\n","            # if res_df['close'].iloc[j] > res_df['middle_line'].iloc[j]:    \n","            # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j]:\n","            # if res_df['close'].iloc[j] > upper_middle.iloc[j]:\n","            # if res_df['close'].iloc[j] > res_df['minor_ST1_Up'].iloc[j]:\n","            if out == 0:              \n","              if config.out_set.hl_out:\n","                if res_df['high'].iloc[j] >= res_df['short_out'].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              else:\n","                if res_df['close'].iloc[j] >= res_df['short_out'].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              # out_idx = j\n","              # static_short_out = short_out.iloc[out_j]\n","              # if config.out_set.second_out:              \n","                # static_short_out = short_out.iloc[out_j] + res_df['st_gap'].iloc[out_j] * config.out_set.second_out_gap\n","            \n","            # if out == 0 and res_df['high'].iloc[j] >= short_out.iloc[out_j]: # check out only once\n","            #   out = 1\n","             \n","\n","            # -------------- sma -------------- #\n","            # if res_df['close'].iloc[j] > res_df[sma].iloc[j]:\n","\n","            # -------------- sar -------------- #\n","            # if res_df['close'].iloc[j] > res_df['minor_ST3_Up'].iloc[j] \\\n","            #   or res_df['sar2'].iloc[j] <= res_df['high'].iloc[j]:\n","            # if res_df['close'].iloc[j] > short_out.iloc[initial_i]: # or \\\n","            #   out = 1\n","              # res_df['sar2_uptrend'].iloc[j] == 1: # or \\\n","\n","            # if res_df['sar2_uptrend'].iloc[j] == 1:\n","\n","            #   if prev_sar is None:\n","            #     prev_sar = res_df['sar2'].iloc[j - 1]\n","              \n","            #   if res_df['close'].iloc[j] > prev_sar:\n","            #     out = 1\n","\n","            # else:\n","            #   if res_df['close'].iloc[j] > res_df['sar2'].iloc[j]:\n","            #     out = 1\n","              \n","            # -------------- hl -------------- #\n","            # if res_df['close'].iloc[j] > short_out.iloc[tp_j]:\n","            \n","            # -------------- stoch -------------- #\n","            # if res_df['stoch'].iloc[j - 2] >= res_df['stoch'].iloc[j - 1] and \\\n","            #   res_df['stoch'].iloc[j - 1] < res_df['stoch'].iloc[j] and \\\n","            #   res_df['stoch'].iloc[j - 1] <= stoch_lower:\n","            #   out = 1\n","\n","            # config.out_set.retouch 1 경우, config.out_set.retouch 조건도 있어야함\n","            if out:\n","              if config.out_set.retouch:\n","                if config.out_set.retouch:\n","                  pass\n","                else:\n","                    continue\n","\n","              else:\n","                pass\n","\n","              if config.out_set.price_restoration:\n","                tp = res_df['short_out'].iloc[out_j]\n","                if config.out_set.second_out:\n","                  tp = res_df['short_out2'].iloc[out_j]\n","                \n","                # if res_df['close'].iloc[j] > tp: # 이 경우를 protect 하는건 insane 임\n","                #   tp = res_df['close'].iloc[j]\n","\n","              else:\n","                \n","                if res_df['open'].iloc[j] >= res_df['short_out'].iloc[out_j]:\n","                  tp = res_df['open'].iloc[j]\n","                else:\n","                  if config.out_set.hl_out:\n","                    tp = res_df['short_out'].iloc[out_j]\n","                  else:\n","                    tp = res_df['close'].iloc[j]\n","                \n","                # if not config.out_set.static_out:\n","                #   if res_df['open'].iloc[j] >= res_df['short_out'].iloc[out_j]: # close 기준이라 이런 조건을 못씀, 차라리 j 를 i 부터 시작\n","                #     tp = res_df['open'].iloc[j]\n","                #   else:\n","                #     tp = res_df['close'].iloc[j]\n","\n","                # else:\n","                #   tp = res_df['close'].iloc[j]\n","\n","              \n","              if config.out_set.retouch: # out 과 open 비교\n","                if config.out_set.second_out:\n","                  if res_df['open'].iloc[j] <= res_df['short_out2'].iloc[out_j]:\n","                    tp = res_df['open'].iloc[j]\n","                else:\n","                  if res_df['open'].iloc[j] <= res_df['short_out'].iloc[out_j]:\n","                    tp = res_df['open'].iloc[j]\n","\n","                try: # static_short_out 인 경우, open 도 고려한 tp set\n","                  if res_df['open'].iloc[j] <= static_short_out:\n","                    tp = res_df['open'].iloc[j]\n","                  else:\n","                    tp = static_short_out\n","                except Exception as e:\n","                  pass\n","\n","              trade_done = 1\n","              tp_state_list.append(\"short close_out\")\n","            \n","\n","              tp_list.append(tp) \n","              tp_idx_list.append(j)\n","              fee += config.init_set.market_fee\n","\n","\n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = 1\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","            fee += config.init_set.market_fee\n","          \n","\n","\n","          # -------------- append trade data -------------- #\n","          if trade_done:\n","\n","            # --------------- tp_ratio info --------------- #\n","            #         Todo        #\n","            #          short_out 에 대한 정보는 존재함,\n","            #          short_tp 에 대한 정보는 존재함,\n","            #       => initial_i 기준으로 ,dynamic | static set 을 tp 와 out 에 각각 적용\n","            #          config.lvrg_set.leverage 는 initial_i 기준으로 적용되니까\n","            #          적용된 tp & out 으로 abs((tp - ep) / (ep - out)) 계산\n","            try:\n","              done_tp = res_df['short_tp'].iloc[ep_j]\n","              done_out = res_df['short_out'].iloc[ep_j]\n","\n","              if done_out <= ep_list[0]: # loss > 1\n","                dr = np.nan\n","                tp_ratio = np.nan\n","              else:                \n","                dr = ((ep_list[0] - done_tp) / (done_out - ep_list[0]))\n","                tp_ratio = ((ep_list[0] - done_tp - tp_fee * ep_list[0]) / (done_out - ep_list[0] + out_fee * ep_list[0]))\n","\n","            except Exception as e:\n","              # pass    \n","              tp_ratio = np.nan  \n","            \n","            tp_ratio_list.append(tp_ratio)\n","            short_tp_ratio_list.append(tp_ratio)     \n","            dr_list.append(dr)\n","            short_dr_list.append(dr)   \n","\n","\n","            # -------------------- partial tp -------------------- #\n","            #        1. len(tp_list) 에 대응하는 qty_list 를 만들어야함    #\n","            #        2. temp_pr_list 를 만들어 총합 + 1 을 pr_list 에 저장      #\n","            #        2-1. temp_pr = sum((ep / tp_list[i] - fee - 1) * qty_list[i])   #\n","            #        3. temp_pr_list 의 첫 tp 에는 r_qty 를 할당함        #\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / config.tp_set.partial_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty * config.lvrg_set.leverage\n","              # temp_pr = (ep_list[0] / tp_list[q_i] - fee - 1) * temp_qty\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","              qty_list.append(temp_qty)\n","\n","            # if len(temp_pr_list) == 1:\n","            #   print(\"qty_list :\", qty_list)\n","            #   print(\"temp_pr_list :\", temp_pr_list)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (sub_ep_ / tp - fee - 1) * config.lvrg_set.leverage\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_tp / h_ep - fee - 1) * config.lvrg_set.leverage  # hedge long\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","            \n","            hh = max(res_df['high'].iloc[i:j + 1])\n","            short_liq = (ep_list[0] / hh - fee - 1) * config.lvrg_set.leverage + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              # ep_tp_list.append((ep, tp_list))  \n","              ep_tp_list.append((ep_list, tp_list))  \n","              # trade_list.append([initial_i, i, j])\n","              trade_list.append((ep_idx_list, tp_idx_list))\n","\n","              liqd_list.append(short_liq)\n","              short_liqd_list.append(short_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))      # hedge 도 ep_tp_list 처럼 변경해주어야하는데 아직 안건드림, 딱히 사용할 일이 없어보여   \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              fee_list.append(fee)\n","              short_list.append(temp_pr)\n","              short_fee_list.append(fee)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_short_list.append(hedge_pr)\n","\n","              i = j\n","              break\n","\n","            else:\n","\n","              # ep_tp_list.append((ep_list, tp_list))\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              # plot_check 때문에, pr_list 까지 하게되면 acc_pr eval 이 꼬이게댐\n","          \n","              # pr_list 를 넣지 않을거니까, open_list 에서 해당 idx 는 pop\n","              open_list.pop()\n","              \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(short_liq)\n","              nontp_short_liqd_list.append(short_liq)\n","              nontp_short_indexs.append(i)\n","              nontp_short_ep_list.append(ep_list[0])\n","\n","              nontp_short_pr = (ep_list[0] / tp - fee - 1) * config.lvrg_set.leverage + 1\n","              nontp_pr_list.append(nontp_short_pr)\n","              nontp_short_pr_list.append(nontp_short_pr)\n","\n","\n","      #                  long  phase                #\n","      elif res_df['entry'][i] == -config.ep_set.short_entry_score: \n","      \n","\n","        initial_i = i\n","\n","        if config.out_set.static_out:\n","          p_i = initial_i\n","        else:\n","          p_i = i\n","\n","        # -------------- tr scheduling -------------- #\n","        # if config.ep_set.entry_type == \"MARKET\":\n","\n","        #   mr_const_cnt += 1\n","        #   # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i] + out_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","        #   if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i] + tp_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","        #   # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i] - tp_fee * res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i] + out_fee * res_df['close'].iloc[i]) == config.ep_set.tr_thresh:\n","        #   # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i] - out_fee * res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i] + out_fee * res_df['close'].iloc[i]) >= config.ep_set.tr_thresh:\n","\n","        #     mr_score += 1\n","\n","\n","        # -------------- dr scheduling -------------- #\n","        # mr_const_cnt += 1        \n","        # if (res_df['long_tp'].iloc[i] - res_df['close'].iloc[i]) / (res_df['close'].iloc[i] - res_df['long_out'].iloc[i]) <= config.ep_set.tr_thresh * (1 + config.ep_set.dr_error): # 일반적으로 dr 상에서 tp 비율이 더 커짐 (tr 보다)\n","        #   mr_score += 1\n","\n","        # -------------- ep limit -------------- #    \n","        # mr_const_cnt += 1\n","        # # if (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        # if config.ep_set.min_eplim_pct < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        # # if 0 < (res_df['open'].iloc[i] - res_df['long_ep'].iloc[i]) / res_df['open'].iloc[i] < config.ep_set.max_eplim_pct:\n","        #   # if res_df['st_gap_15m'].iloc[i] / res_df['open'].iloc[i] < 0:\n","        #   #   print(\"i, res_df['st_gap_15m'].iloc[i] :\", i, res_df['st_gap_15m'].iloc[i])\n","        #   mr_score += 1\n","\n","\n","          \n","        # -------------- mr -------------- #    \n","          #          1. find prev out         #\n","          #          2. count entry til prev out         #\n","        # prev_entry_cnt = 0\n","        # for back_i in range(i - 1, 0, -1):\n","        #   if res_df['entry'][back_i] == -1:\n","        #     break\n","\n","        #   elif res_df['entry'][back_i] == 1:\n","        #     prev_entry_cnt += 1\n","          \n","        # mr_const_cnt += 1\n","        # if prev_entry_cnt <= config.ep_set.entry_incycle:\n","        # # if prev_entry_cnt >= config.ep_set.entry_incycle:\n","        #   mr_score += 1\n","\n","        \n","        # -------------- bbwp const. -------------- #\n","        # if res_df['bbwp'].iloc[i] <= config.ep_set.bbwp_thresh:\n","        # if res_df['bbwp'].iloc[i] >= config.ep_set.bbwp_thresh:\n","          # mr_score += 1\n","          \n","\n","        # -------------- ma const. -------------- #\n","        # ------- ema const. ------- #\n","        # if res_df['close'].shift(0).iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] > res_df['ema5'].shift(1).iloc[i]: # and \\\n","        # if res_df['close'].shift(1).iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","        # if long_ep.iloc[i] > res_df['ema5'].shift(0).iloc[i]: # and \\\n","          # mr_score += 1\n","\n","        # ------- sma const. ------- #\n","        # mr_const_cnt += 1\n","        # if res_df['close'].iloc[i] >= res_df['sma_1m'].iloc[i]: # and \\\n","        # # if res_df['close'].iloc[i] >= res_df['sma_30m'].iloc[i]: # and \\\n","        #   mr_score += 1\n","\n","        # ------- sar zone const. ------- #\n","        # mr_const_cnt += 1\n","        # if res_df['sar_uptrend_30m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # ------- st zone const. ------- #\n","        # mr_const_cnt += 1\n","        # if res_df['close'].iloc[i] >= res_df['st_upper_4h'].iloc[i]:\n","        # # if res_df['close'].iloc[i] <= res_df['st_base_4h'].iloc[i] and \\\n","        # #   res_df['close'].iloc[i] <= res_df['st_base_30m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        # ------- bb zone const. ------- #\n","        # mr_const_cnt += 1\n","        # # if res_df['close'].iloc[i] >= res_df['bb_upper_30m'].iloc[i]:\n","        # if res_df['close'].iloc[i] >= res_df['bb_upper2_30m'].iloc[i]:\n","        #   mr_score += 1\n","\n","        \n","        # ------- cloud bline ------- #\n","        # mr_const_cnt += 1\n","        # # # if res_df['close'].iloc[i] >= res_df['cloud_bline_30m'].iloc[i] and \\\n","        # # #   res_df['close'].iloc[i] >= res_df['cloud_bline_3m'].iloc[i]:\n","        # # # if res_df['close'].iloc[i] >= res_df['cloud_bline_5m'].iloc[i]:\n","        # # # # if res_df['close'].iloc[i] >= res_df['cloud_bline_1m'].iloc[i]:\n","        # if res_df['close'].iloc[i] >= res_df['cloud_bline_1h'].iloc[i]:\n","        # # if res_df['close'].iloc[i] >= res_df['cloud_bline_4h'].iloc[i]:\n","        #   mr_score += 1\n","\n","\n","        # ------- ema alignment ------- #\n","        # if res_df['ema5_1m'].iloc[i] > res_df['ema5_1m'].iloc[i- 1] > res_df['ema5_1m'].iloc[i - 2]:\n","        # # if res_df['ema5_1m'].iloc[i- 1] > res_df['ema5_1m'].iloc[i - 2]:\n","          # mr_score += 1\n","\n","        #   # ------- sma alignment ------- #\n","        # if res_df['sma_1m'].iloc[i] > res_df['sma_1m'].iloc[i- 1]:\n","        # # if res_df['sma_1m'].iloc[i] > res_df['sma_1m'].iloc[i- 1] > res_df['sma_1m'].iloc[i - 2]:        \n","          # mr_score += 1\n","\n","        # # ------- bb alignment ------- #\n","        # if res_df['bb_upper_1m'].iloc[i] > res_df['bb_upper_1m'].iloc[i - 1]:\n","          # mr_score += 1\n","          \n","        # ------- bb_base alignment ------- #\n","        # if res_df['bb_base_5m'].iloc[i] > res_df['bb_base_5m'].iloc[i - 1]:\n","          # mr_score += 1\n","\n","        \n","\n","\n","\n","\n","\n","        # -------------- distance protection -------------- #\n","        # tp_dist = (long_tp.iloc[i] - res_df['close'].iloc[i])\n","        # out_dist = (res_df['close'].iloc[i] - res_df['middle_line'].iloc[i])\n","        # if tp_dist / out_dist >= tp_out_ratio:\n","          # mr_score += 1\n","\n","        # -------------- feature dist const. -------------- #\n","        # if initial_i < input_size:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","          \n","        # entry_input_x = min_max_scale(res_df[selected_price_colname].iloc[initial_i - input_size:initial_i].values)\n","       \n","        # re_entry_input_x = expand_dims(entry_input_x)\n","\n","        # entry_vector = model.predict(re_entry_input_x, verbose=0)\n","        # # print(test_result.shape)\n","\n","        # f_dist = vector_dist(entry_vector, selected_vector)\n","        # print(\"f_dist :\", f_dist)\n","\n","        # if f_dist < fdist_thresh:\n","          # mr_score += 1\n","\n","\n","        # -------------- htf data const. -------------- #\n","        # i_min = intmin(res_df.index[i]) # 2020-09-05 00:00:59.999000        \n","        # if i_min >= 30:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"59:59.999000\"\n","        # else:\n","        #   htf_ts = str(res_df.index[i])[:-12] + \"29:59.999000\"\n","          \n","        #   # -------------- ema -------------- #\n","        # if fifth_df['close'].shift(1).loc[htf_ts] > fifth_df['ema'].shift(1).loc[htf_ts]:\n","          # mr_score += 1    \n","        \n","        # -------------- fisher const. -------------- #\n","        # # if res_df['fisher30'].shift(1).iloc[i] > 0:\n","        # # if res_df['fisher60'].shift(1).iloc[i] > 0:\n","        # if res_df['fisher120'].shift(1).iloc[i] > 0:\n","          # mr_score += 1\n","\n","\n","\n","        # -------------- htf st line const. -------------- #\n","    \n","          # ------------ 30m ------------ #\n","        # # if res_df['upper_middle5'].iloc[i] <= res_df['max_lower2'].iloc[i]:\n","        # # if res_df['upper_middle5'].iloc[i] <= res_df['close'].iloc[i]:\n","        # if res_df['upper_middle5'].iloc[i] >= res_df['bb_upper'].iloc[i] and \\\n","        # res_df['bb_upper'].iloc[i] > res_df['ema1_5'].iloc[i]:\n","        \n","        #   # ------------ 4h ------------ #\n","        # # if res_df['upper_middle6'].iloc[i] <= res_df['max_lower2'].iloc[i]:\n","\n","        #  # ------------ 5m & 30m ------------ #\n","        # # if res_df['upper_middle5'].iloc[i] <= res_df['middle_line3'].iloc[i]:\n","        # # if res_df['upper_middle5'].iloc[i] <= res_df['lower_middle3'].iloc[i]:\n","        \n","        #  # ------------ 5m & 30m & 4h ------------ #        \n","        # # if res_df['upper_middle6'].iloc[i] <= res_df['upper_middle5'].iloc[i] <= res_df['upper_middle3'].iloc[i]:\n","\n","          # mr_score += 1\n","\n","\n","        # -------------- 1d sma const. -------------- #\n","        # if res_df[sma].iloc[i] <= res_df['close'].iloc[i]:\n","          # mr_score += 1\n","\n","\n","        # -------------- cloud const. -------------- #     \n","        # if i < cloud_lookback:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","        \n","        # # if np.sum(under_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # # if np.sum(under_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # if np.sum(over_bottom.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        # # if np.sum(over_top.iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","        #  mr_score += 1  \n","\n","\n","        # -------------- cloud color const. -------------- #\n","        #               1. senkou_a1 >= senkou_b1            #\n","        #               1-1. mutli clouds color 충분히 고려               #\n","        # if i < cloud_lookback:\n","        #   i += 1\n","        #   if i >= len(res_df):\n","        #     break\n","        #   continue\n","\n","        # if np.sum(res_df[senkou_a].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[senkou_b].shift(cloud_shift_size).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   np.sum(res_df[\"senkou_a2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b2\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback: # and \\\n","        #   # np.sum(res_df[\"senkou_a3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b3\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b4\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback and \\\n","        #   # np.sum(res_df[\"senkou_a5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1] >= res_df[\"senkou_b5\"].shift(0).iloc[i + 1 - cloud_lookback:i + 1]) == cloud_lookback:\n","          # mr_score += 1\n","\n","\n","        # -------------- st color const. -------------- #\n","        # if np.sum(res_df[['ST1_Trend%s' % basic_st_number, 'ST2_Trend%s' % basic_st_number, 'ST3_Trend%s' % basic_st_number]].iloc[i]) >= 1:\n","        # # if np.sum(res_df[['ST1_Trend%s' % basic_st_number, 'ST2_Trend%s' % basic_st_number, 'ST3_Trend%s' % basic_st_number]].iloc[i]) >= 3:\n","          # mr_score += 1\n","\n","        # -------------- htf st color const. -------------- #\n","        # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) >= 1:\n","        # # if np.sum(res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[i]) >= 3:\n","          # mr_score += 1\n","\n","        # -------------- 3rd st const. : st should have 2, 3 or more -------------- #\n","        # if np.sum(res_df[['minor_ST2_Trend', 'minor_ST3_Trend']].iloc[i]) >= 2:\n","          # mr_score += 1\n","\n","          # -------------- st gap const.-------------- #\n","        # if abs(res_df['ST2_Down%s' % basic_st_number].iloc[i] - res_df['ST1_Down%s' % basic_st_number].iloc[i]) <= config.out_set.approval_st_gap * res_df['st_gap%s' % basic_st_number].iloc[i]:\n","          # mr_score += 1\n","\n","        # -------------- sar const. -------------- #\n","        # # if res_df['sar2'].iloc[i] < res_df['low'].iloc[i] and res_df['sar3'].iloc[i] < res_df['low'].iloc[i]:\n","        # if res_df['sar1'].iloc[i] < res_df['low'].iloc[i]:\n","        # # if res_df['sar2'].iloc[i] < res_df['low'].iloc[i]: # and \\\n","        # # if  res_df['sar3'].iloc[i] < res_df['low'].iloc[i]:\n","          # mr_score += 1\n","\n","\n","        # -------------- mr_score summation -------------- #\n","        if mr_score == mr_const_cnt:        \n","          pass\n","        \n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            break\n","          continue\n","\n","\n","        ep_j = initial_i\n","      \n","        # -------------- limit waiting const. -------------- #      \n","\n","        # print(\"i before :\", i)\n","\n","        # i in continue : 429331\n","        # i before : 429360\n","\n","        entry_done = 0\n","        entry_open = 0\n","        prev_sar = None\n","\n","        # for e_j in range(i, len(res_df)):   \n","\n","        if i + 1 >= len(res_df):  # i should be checked if e_j starts from i+1\n","          break\n","        for e_j in range(i + 1, len(res_df)):  # entry 가 close 기준일 경우 사용 (open 기준일 경우 i 부터 시작해도 무방함)\n","          \n","          if not config.ep_set.static_ep:\n","            ep_j = e_j  \n","          \n","          if config.tp_set.static_tp:\n","            # if config.ep_set.tpout_onexec:\n","            #   tp_j = e_j\n","            # else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = e_j  \n","\n","          \n","          #          np.inf ep         #\n","          # if long_ep.iloc[initial_i] == np.inf:\n","          #   break\n","          \n","          #          1. check ep_out          #\n","          if res_df['high'].iloc[e_j] >= res_df['long_tp'].iloc[tp_j]:\n","          # if np_timeidx[e_j] % config.ep_set.htf_entry == config.ep_set.htf_entry - 1:\n","            break\n","\n","          #          2. check ep_in          #\n","          if res_df['low'].iloc[e_j] <= res_df['long_ep'].iloc[ep_j]:\n","            entry_done = 1\n","            # print(\"e_j :\", e_j)\n","            \n","            #     이미, e_j open 이 ep 보다 낮은 경우, entry[initial_i] => -2 로 변경   #\n","            if res_df['open'].iloc[e_j] <= res_df['long_ep'].iloc[ep_j]:\n","              entry_open = 1\n","\n","            break\n","\n","\n","        i = e_j\n","        # print(\"i = e_j :\", i)\n","\n","        if entry_done:      \n","          pass\n","          # print(\"i, entry_done :\", i, entry_done)\n","\n","        else:\n","          i += 1\n","          if i >= len(res_df):\n","            # print(\"i :\", i)\n","            break\n","\n","          # print(\"i in continue :\", i)          \n","          continue\n","\n","\n","        # ---------------- end wait ---------------- #\n","        # if e_j - initial_i >= 200:\n","        #   print(\"e_j, initial_i :\", e_j, initial_i)\n","\n","        open_list.append(initial_i)\n","\n","        if config.ep_set.entry_type is 'MARKET':\n","          try:\n","            ep_list = [res_df['close'].iloc[e_j]]\n","          except Exception as e:\n","            # print('error in ep_list (initial) :', e)\n","            ep_list = [res_df['close'].iloc[ep_j]]\n","        else:\n","          if not entry_open:\n","            ep_list = [res_df['long_ep'].iloc[ep_j]]\n","          else:\n","            try:\n","              ep_list = [res_df['open'].iloc[e_j]]\n","            except Exception as e:\n","              ep_list = [res_df['open'].iloc[ep_j]]\n","\n","        if not config.lvrg_set.static_lvrg:\n","          # config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['close'].iloc[initial_i] / res_df['low'].rolling(hl_lookback).min().iloc[initial_i] - 1)\n","          if config.ep_set.entry_type is 'MARKET':\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / abs(res_df['long_out'].iloc[ep_j] / res_df['close'].iloc[ep_j] - 1 - (fee + config.init_set.market_fee))\n","          else:\n","            config.lvrg_set.leverage = config.lvrg_set.target_pct / (res_df['long_ep'].iloc[ep_j] / res_df['long_out'].iloc[ep_j] - 1 - (fee + config.init_set.market_fee))\n","          \n","          config.lvrg_set.leverage = min(50, config.lvrg_set.leverage)\n","          if not config.lvrg_set.allow_float:\n","            config.lvrg_set.leverage = int(config.lvrg_set.leverage)\n","          config.lvrg_set.leverage = max(config.lvrg_set.leverage, 1)\n","          leverage_list.append(config.lvrg_set.leverage)\n","          \n","        try:\n","          ep_idx_list = [e_j]\n","        except Exception as e:\n","          # print('error in ep_idx_list :', e)\n","          ep_idx_list = [ep_j]\n","\n","        tp_list = []\n","        tp_idx_list = []\n","\n","        partial_tp_cnt = 0\n","        hedge_cnt = 1\n","\n","        h_ep, h_tp = None, None        \n","        h_i, h_j = None, None      \n","\n","        trade_done = False\n","        out = False          \n","        config.out_set.retouch = False\n","\n","\n","        # if i == len(res_df) - 1: # if j start from i + 1 \n","        #   open_list.pop()\n","        # for j in range(i + 1, len(res_df)):\n","\n","        for j in range(i, len(res_df)):  \n","          \n","          if config.tp_set.static_tp:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              tp_j = e_j\n","            else:\n","              tp_j = initial_i\n","          else:\n","            tp_j = j\n","\n","          if config.out_set.static_out:\n","            if not config.ep_set.static_ep and config.ep_set.entry_type == \"LIMIT\" and config.ep_set.tpout_onexec:\n","              out_j = e_j\n","            else:           \n","              out_j = initial_i\n","          else:\n","            out_j = j   \n","\n","          # -------------- hedge only once -------------- #\n","          #             일단, h_quantity 는 초기 진입과 동일하게 설정         #\n","          # if res_df['low'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST2_Down'].iloc[j] and hedge_cnt == 1:\n","          # if res_df['close'].iloc[j] <= res_df['minor_ST3_Down'].iloc[j] and hedge_cnt == 1:\n","\n","          #   h_ep = res_df['close'].iloc[j]\n","          #   hedge_cnt -= 1\n","          #   h_i = j\n","\n","          # -------------- sub ep -------------- #\n","          # if res_df['low'].iloc[j - 1] >= res_df['sar2'].iloc[j - 1] and res_df['low'].iloc[j] < res_df['sar2'].iloc[j]:\n","            \n","          #   sub_ep = res_df['sar2'].iloc[j - 1]\n","\n","          #   if sub_ep > ep_list[-1]:\n","          #     ep_list.append(sub_ep)\n","          #     ep_idx_list.append(j)\n","\n","\n","          # -------------- ultimate tp -------------- #\n","          if not config.tp_set.non_tp:\n","            #            1. by level          #\n","            if config.tp_set.tp_type != 'MARKET':\n","\n","              for l_i, long_tp_ in enumerate(long_tps):\n","\n","                if res_df['high'].iloc[j] >= long_tp_.iloc[tp_j] and partial_tp_cnt == l_i:\n","                # if res_df['high'].iloc[j] >= long_tp.iloc[j]:\n","\n","                  if l_i == len(long_tps) - 1:\n","                    trade_done = 1\n","\n","                  partial_tp_cnt += 1\n","\n","                  #         dynamic tp        #\n","                  # if 0:\n","                  if long_tp_.iloc[j] != long_tp_.iloc[j - 1] and not config.tp_set.static_tp:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[j]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_open\")\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[j]\n","                      # tp = res_df['open'].iloc[j]\n","                      \n","                      if trade_done:\n","                        tp_state_list.append(\"d-long_tp\")\n","\n","                  #         static tp         #\n","                  else:\n","\n","                    #   tp limit 이 불가한 경우 = open 이 이미, tp 를 넘은 경우 # \n","                    #   non_inversion 의 경우, short_tp 가 가능함   #\n","\n","                    if res_df['open'].iloc[j] >= long_tp_.iloc[tp_j]:\n","                    # if res_df['open'].iloc[j] >= long_tp_.iloc[initial_i]:\n","\n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp\")\n","\n","                    \n","                    #   tp limit 이 가능한 경우 = open 이 아직, tp 를 넘지 않은 경우 # \n","                    else:\n","                      \n","                      # tp = long_tp_.iloc[initial_i]\n","                      tp = long_tp_.iloc[tp_j]\n","\n","                      # tp = res_df['open'].iloc[j]\n","\n","                      if trade_done:\n","                        tp_state_list.append(\"s-long_tp\")         \n","                  \n","                  tp_list.append(tp)\n","                  tp_idx_list.append(j)\n","                  fee += config.init_set.limit_fee\n","\n","            #           2. by time        #\n","            else:\n","\n","              # -------------- sar tp -------------- #\n","              # if (res_df['low'].iloc[j] <= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['low'].iloc[j - 1] > res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['low'].iloc[j - 2] > res_df['sar2'].iloc[j - 2]):\n","              \n","              #       inversion     #\n","              # if (res_df['high'].iloc[j] >= res_df['sar2'].iloc[j]) & \\\n","              #   (res_df['high'].iloc[j - 1] < res_df['sar2'].iloc[j - 1]) & \\\n","              #   (res_df['high'].iloc[j - 2] < res_df['sar2'].iloc[j - 2]):\n","\n","\n","              # ----------- st long ----------- #\n","              # if res_df['close'].iloc[j] >= res_df['long_tp'].iloc[tp_j]:\n","\n","              # -------------- sar pb tp -------------- #\n","              # if res_df['high'].iloc[j] >= res_df['long_tp'].iloc[initial_i]:\n","\n","              # -------------- st tp -------------- #\n","              # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","\n","              # -------------- fisher tp -------------- #\n","              # if entry[j] == -1:\n","              \n","              # -------------- timestamp -------------- #\n","              if np_timeidx[j] % config.ep_set.htf_entry == config.ep_set.htf_entry - 1:\n","                \n","                tp = res_df['close'].iloc[j]\n","                # tp = res_df['open'].iloc[j]\n","                trade_done = 1\n","\n","                if trade_done:\n","                  tp_state_list.append(\"long close tp\")\n","\n","                tp_list.append(tp) \n","                tp_idx_list.append(j)\n","                fee += config.init_set.market_fee\n","\n","\n","\n","          # -------------- out -------------- #\n","          if not trade_done and config.out_set.use_out and j != len(res_df) - 1:              \n","\n","            # -------------- macd -------------- #\n","            # if res_df['macd_hist3'].iloc[j] < 0:\n","            # # if res_df['macd_hist3'].iloc[i] > 0 and res_df['macd_hist3'].iloc[j] < 0:\n","\n","            # -------------- st config.out_set.retouch -------------- #\n","            # out = 1 상태면 동일 tick 에서 config.out_set.retouch 를 조사할 거기 때문에, 먼저 검사함\n","            # 그리고, out 기준이 close 라 이게 맞음 \n","            # close 가 long_out 보다 내려가있는 상태일테니 high 를 조사하는게 맞음           \n","            # if out and res_df['high'].iloc[j] >= long_out.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","            \n","            # ------- 일정시간 이상, dynamic_out 적용 ------ #\n","            try:\n","              if j - out_idx >= config.out_set.retouch_out_period:\n","                static_long_out = res_df['long_out'].iloc[j]\n","            \n","            except Exception as e:\n","              pass\n","\n","              # ------- static out ------ #\n","            try:\n","              if out and res_df['high'].iloc[j] >= static_long_out:\n","                config.out_set.retouch = 1\n","            except Exception as e:\n","              pass\n","\n","              # ------- config.out_set.retouch out ------ #\n","            # if out and res_df['high'].iloc[j] >= long_out2.iloc[out_j]:\n","            #   config.out_set.retouch = 1\n","\n","\n","\n","            # -------------- st -------------- #\n","            # if res_df['close'].iloc[j] < res_df['middle_line'].iloc[j]:\n","            # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j]:\n","            # if res_df['close'].iloc[j] < lower_middle.iloc[j]:\n","            # if res_df['close'].iloc[j] < res_df['minor_ST1_Down'].iloc[j]:\n","            if out == 0:\n","              if config.out_set.hl_out:\n","                if res_df['low'].iloc[j] <= res_df['long_out'].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              else:\n","                if res_df['close'].iloc[j] <= res_df['long_out'].iloc[out_j]: # check out only once\n","                  out = 1\n","\n","              # out_idx = j\n","              # static_long_out = long_out.iloc[out_j]\n","              # if config.out_set.second_out:\n","              # static_long_out = long_out.iloc[out_j] - res_df['st_gap'].iloc[out_j] * config.out_set.second_out_gap\n","\n","            # if out == 0 and res_df['low'].iloc[j] <= long_out.iloc[out_j]: # check out only once\n","            #   out = 1            \n","            \n","\n","\n","            # -------------- sma -------------- #\n","            # if res_df['close'].iloc[j] < res_df[sma].iloc[j]:\n","\n","            # -------------- sar -------------- #\n","            # if res_df['close'].iloc[j] < res_df['minor_ST3_Down'].iloc[j] \\\n","            #   or res_df['sar2'].iloc[j] >= res_df['low'].iloc[j]:\n","            # if res_df['close'].iloc[j] < long_out.iloc[initial_i]: # or \\\n","            #   #  res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","            #   #  res_df['sar2_uptrend'].iloc[j] == 0 or \\\n","            #   out = 1\n","            \n","            # if res_df['sar2_uptrend'].iloc[j] == 0:\n","\n","            #     if prev_sar is None:\n","            #       prev_sar = res_df['sar2'].iloc[j - 1]\n","                \n","            #     if res_df['close'].iloc[j] < prev_sar:\n","            #       out = 1\n","\n","            # else:\n","            #   if res_df['close'].iloc[j] < res_df['sar2'].iloc[j]:\n","            #     out = 1\n","\n","            # -------------- hl -------------- #\n","            # if res_df['close'].iloc[j] < long_out.iloc[tp_j]:\n","\n","            # -------------- stoch -------------- #\n","            # if res_df['stoch'].iloc[j - 2] <= res_df['stoch'].iloc[j - 1] and \\\n","            #   res_df['stoch'].iloc[j - 1] > res_df['stoch'].iloc[j] and \\\n","            #   res_df['stoch'].iloc[j - 1] >= stoch_upper:\n","            #   out = 1\n","\n","            # config.out_set.retouch 1 경우, config.out_set.retouch 조건도 있어야함\n","            if out:\n","              if config.out_set.retouch:\n","                if config.out_set.retouch:\n","                  pass\n","                else:\n","                    continue\n","\n","              else:\n","                pass\n","\n","              if config.out_set.price_restoration:\n","                tp = res_df['long_out'].iloc[out_j]\n","                if config.out_set.second_out:\n","                  tp = res_df['long_out2'].iloc[out_j]\n","\n","                # if res_df['close'].iloc[j] < tp: # 이 경우를 protect 하는건 insane 임\n","                # # if res_df['high'].iloc[j] < tp: # --> config.out_set.hl_out 사용시 이 조건은 valid 함\n","                #   tp = res_df['close'].iloc[j]\n","\n","              else:\n","\n","                if res_df['open'].iloc[j] <= res_df['long_out'].iloc[out_j]:\n","                  tp = res_df['open'].iloc[j]\n","                else:\n","                  if config.out_set.hl_out:\n","                    tp = res_df['long_out'].iloc[out_j]\n","                  else:\n","                    tp = res_df['close'].iloc[j]\n","\n","                # if not config.out_set.static_out:\n","                #   if res_df['open'].iloc[j] <= res_df['long_out'].iloc[out_j]: # dynamic close out 의 open 고려\n","                #     tp = res_df['open'].iloc[j]\n","                #   else:\n","                #     tp = res_df['close'].iloc[j]\n","\n","                # else:\n","                #   tp = res_df['close'].iloc[j]\n","\n","              if config.out_set.retouch: # out 과 open 비교\n","                if config.out_set.second_out:  # long_out = sell\n","                # config.out_set.second_out 은 기본적으로 limit 이라 이 구조가 가능함\n","                  if res_df['open'].iloc[j] >= res_df['long_out2'].iloc[out_j]: # dynamic_out 일 경우 고려해야함\n","                    tp = res_df['open'].iloc[j]\n","                else:\n","                  if res_df['open'].iloc[j] >= res_df['long_out'].iloc[out_j]: # dynamic_out 일 경우 고려해야함\n","                    tp = res_df['open'].iloc[j]\n","\n","                try:\n","                  if res_df['open'].iloc[j] >= static_long_out:\n","                    tp = res_df['open'].iloc[j]\n","                  else:\n","                    tp = static_long_out\n","                except Exception as e:\n","                  pass\n","\n","              # tp = res_df['open'].iloc[j]\n","              tp_state_list.append(\"long close_out\")\n","              trade_done = 1\n","\n","              tp_list.append(tp)\n","              tp_idx_list.append(j)\n","              fee += config.init_set.market_fee\n","\n","          \n","          # -------------- non tp -------------- #\n","          if j == len(res_df) - 1:\n","            trade_done = 1\n","            tp = res_df['close'].iloc[j]\n","            tp_list.append(tp) \n","            tp_idx_list.append(j)\n","            fee += config.init_set.market_fee\n","\n","\n","          if trade_done:\n","\n","            # --------------- tp_ratio info --------------- #\n","            try:\n","              done_tp = res_df['long_tp'].iloc[ep_j]\n","              done_out = res_df['long_out'].iloc[ep_j]\n","\n","              if done_out >= ep_list[0]: # loss >= 1\n","                tp_ratio = np.nan\n","                dr = np.nan\n","              else:\n","                tp_ratio = ((done_tp - ep_list[0] - tp_fee * ep_list[0]) / (ep_list[0] - done_out + out_fee * ep_list[0]))                \n","                dr = ((done_tp - ep_list[0]) / (ep_list[0] - done_out))                \n","\n","            except Exception as e:\n","              # pass \n","              tp_ratio = np.nan\n","            \n","            tp_ratio_list.append(tp_ratio)\n","            long_tp_ratio_list.append(tp_ratio)\n","            dr_list.append(dr)\n","            long_dr_list.append(dr)\n","\n","\n","            qty_list = []\n","            temp_pr_list = []\n","            r_qty = 1\n","            for q_i in range(len(tp_list) - 1, -1, -1):\n","\n","              if len(tp_list) == 1:\n","                temp_qty = r_qty\n","              else:\n","                if q_i !=0:\n","                  temp_qty = r_qty / config.tp_set.partial_qty_divider\n","                else:\n","                  temp_qty = r_qty\n","\n","              # temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty\n","              temp_pr = (tp_list[q_i] / ep_list[0] - fee - 1) * temp_qty * config.lvrg_set.leverage\n","              r_qty -= temp_qty\n","\n","              temp_pr_list.append(temp_pr)\n","\n","            temp_pr = sum(temp_pr_list) + 1\n","\n","            # -------------------- sub ep -> pr calc -------------------- #\n","            if len(ep_list) > 1:\n","            \n","              p_ep_pr = []\n","              for sub_ep_ in ep_list:\n","                sub_pr = (tp / sub_ep_ - fee - 1) * config.lvrg_set.leverage\n","                p_ep_pr.append(sub_pr)\n","\n","              temp_pr = sum(p_ep_pr) + 1\n","\n","              print(\"temp_pr :\", temp_pr)\n","\n","            # ------------ hedge + non_hedge pr summation ------------ #\n","            #         hedge pr direction is opposite to the origin       #\n","            hedge_pr = 1\n","            if hedge_cnt == 0:\n","\n","              #       hedge tp      #\n","              h_tp = res_df['close'].iloc[j]\n","              hedge_pr = (h_ep / h_tp - fee - 1) * config.lvrg_set.leverage  # hedge short\n","              temp_pr += hedge_pr\n","              h_j = j\n","\n","\n","            ll = min(res_df['low'].iloc[i:j + 1])\n","            long_liq = (ll / ep_list[0] - fee - 1) * config.lvrg_set.leverage + 1\n","\n","            if j != len(res_df) - 1:\n","\n","              ep_tp_list.append((ep_list, tp_list))\n","              trade_list.append((ep_idx_list, tp_idx_list))\n","\n","              liqd_list.append(long_liq)\n","              long_liqd_list.append(long_liq)\n","\n","              h_ep_tp_list.append((h_ep, h_tp))        \n","              h_trade_list.append([initial_i, h_i, h_j])                \n","\n","              pr_list.append(temp_pr)\n","              fee_list.append(fee)\n","              long_list.append(temp_pr)\n","              long_fee_list.append(fee)\n","\n","              h_pr_list.append(hedge_pr)\n","              h_long_list.append(hedge_pr)                    \n","\n","              i = j\n","              break\n","            \n","            else:\n","\n","              # ep_tp_list.append((ep_list, tp_list))\n","              # trade_list.append((ep_idx_list, tp_idx_list))\n","              \n","              # pr_list 를 넣지 않을거니까, open_list 에서 해당 idx 는 pop\n","              open_list.pop()\n","          \n","              #         tp 미체결 survey        #\n","              nontp_liqd_list.append(long_liq)\n","              nontp_long_liqd_list.append(long_liq)\n","              nontp_long_indexs.append(i)\n","              nontp_long_ep_list.append(ep_list[0])\n","              \n","              nontp_long_pr = (tp / ep_list[0] - fee - 1) * config.lvrg_set.leverage + 1\n","              nontp_pr_list.append(nontp_long_pr)\n","              nontp_long_pr_list.append(nontp_long_pr)\n","\n","            if len(open_list) > len(trade_list):\n","              print('debug from index :', i)\n","              print(len(open_list), len(trade_list))\n","              print(\"len(res_df) :\", len(res_df))\n","              assert len(open_list) == len(trade_list), 'stopped'\n","      \n","      i += 1  # if entry starts with prev trade's close, do not use it ! \n","      # print(\"i in end :\", i)\n","      if i >= len(res_df):\n","        break\n","\n","\n","\n","    # -------------------- result analysis -------------------- #\n","    # try:\n","    plt.style.use('default')\n","    # mpl.rcParams.update(mpl.rcParamsDefault)\n","\n","    plt.figure(figsize=(16, 12))\n","    # plt.figure(figsize=(12, 8))\n","    # plt.figure(figsize=(10, 6))\n","    plt.suptitle(key)\n","\n","    try:\n","      np_pr = np.array(pr_list)\n","      # np_pr = (np.array(pr_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      # ----- fake_pr ----- #\n","      # np_pr = np.where(np_pr > 1, 1 + (np_pr - 1) * 1.5, np_pr)\n","\n","      total_pr = np.cumprod(np_pr)\n","\n","      for_sum_pr = np_pr - 1\n","      for_sum_pr[0] = 1\n","      sum_pr = np.cumsum(for_sum_pr)\n","      sum_pr = np.where(sum_pr < 0, 0, sum_pr)\n","\n","      wr = len(np_pr[np_pr > 1]) / len(np_pr[np_pr != 1])\n","\n","      # mean_profit = np.mean(np_pr[np_pr > 1])\n","      # mean_loss = np.mean(np_pr[np_pr < 1])\n","      # cumprod_profit = np.cumprod(np_pr[np_pr > 1])[-1]\n","      # cumprod_loss = np.cumprod(np_pr[np_pr < 1])[-1]\n","      # pr_tr = cumprod_profit * cumprod_loss\n","\n","      np_tp_ratio_list = np.array(tp_ratio_list) # 초기에 tr 을 정하는거라 mean 사용하는게 맞음\n","      mean_tr = np.mean(np_tp_ratio_list[np.isnan(np_tp_ratio_list) == 0])\n","\n","      np_dr_list = np.array(dr_list) # 초기에 tr 을 정하는거라 mean 사용하는게 맞음\n","      mean_dr = np.mean(np_dr_list[np.isnan(np_dr_list) == 0])\n","\n","\n","      # pr_gap = (np_pr - 1) / config.lvrg_set.leverage + fee\n","      # tp_gap_ = pr_gap[pr_gap > 0]\n","      # # mean_config.tp_set.tp_gap = np.mean(pr_gap[pr_gap > 0])\n","      # mean_ls_gap = np.mean(pr_gap[pr_gap < 0])\n","\n","      # ---- profit fee ratio ---- #\n","      # mean_pgfr = np.mean((tp_gap_ - fee) / abs(tp_gap_ + fee))\n","\n","      # plt.subplot(121)\n","      plt.subplot(231)\n","      plt.plot(total_pr)\n","      plt.plot(sum_pr, color='gold')\n","      if len(nontp_liqd_list) != 0:\n","        plt.title(\"wr : %.3f\\nlen(td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_liqd_cnt : %s\\nnontp_liqd : %.3f\\nontp_liqd_pr : %.3f\" \n","                  % (wr, len(np_pr[np_pr != 1]), np.min(np_pr), total_pr[-1], sum_pr[-1], config.lvrg_set.leverage, min(liqd_list), mean_tr, mean_dr, len(nontp_liqd_list), min(nontp_liqd_list), min(nontp_pr_list)))\n","      else:\n","        plt.title(\"wr : %.3f\\nlen(td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_liqd_cnt : %s\" \n","                  % (wr, len(np_pr[np_pr != 1]), np.min(np_pr), total_pr[-1], sum_pr[-1], config.lvrg_set.leverage, min(liqd_list), mean_tr, mean_dr, len(nontp_liqd_list)))\n","      # plt.show()\n","      print('supblot231 passed')\n","\n","    except Exception as e:\n","      print(\"error in 231 :\", e)\n","\n","\n","    try:\n","      #         short only      #\n","      short_np_pr = np.array(short_list)\n","\n","      total_short_pr = np.cumprod(short_np_pr)\n","      \n","      short_for_sum_pr = short_np_pr - 1\n","      short_for_sum_pr[0] = 1\n","      short_sum_pr = np.cumsum(short_for_sum_pr)\n","      short_sum_pr = np.where(short_sum_pr < 0, 0, short_sum_pr)\n","\n","      short_wr = len(short_np_pr[short_np_pr > 1]) / len(short_np_pr[short_np_pr != 1])\n","      \n","      # short_cumprod_profit = np.cumprod(short_np_pr[short_np_pr > 1])[-1]\n","      # short_cumprod_loss = np.cumprod(short_np_pr[short_np_pr < 1])[-1]\n","      # short_pr_tr = short_cumprod_profit * short_cumprod_loss\n","\n","      np_short_tp_ratio_list = np.array(short_tp_ratio_list)\n","      mean_short_tr = np.mean(np_short_tp_ratio_list[np.isnan(np_short_tp_ratio_list) == 0])\n","      \n","      np_short_dr_list = np.array(short_dr_list)\n","      mean_short_dr = np.mean(np_short_dr_list[np.isnan(np_short_dr_list) == 0])\n","      \n","      # short_pr_gap = (short_np_pr - 1) / config.lvrg_set.leverage + fee\n","      # short_tp_gap = short_pr_gap[short_pr_gap > 0]\n","      # # mean_short_tp_gap = np.mean(short_pr_gap[short_pr_gap > 0])\n","      # # mean_short_ls_gap = np.mean(short_pr_gap[short_pr_gap < 0])\n","\n","      # mean_short_pgfr = np.mean((short_tp_gap - fee) / abs(short_tp_gap + fee))\n","      \n","      plt.subplot(232)\n","      plt.plot(total_short_pr)\n","      plt.plot(short_sum_pr, color='gold')\n","      if len(nontp_short_liqd_list) != 0:   \n","\n","        max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","        \n","        plt.title(\"wr : %.3f\\nlen(short_td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_short_liqd_cnt : %s\\nnontp_short_liqd : %.3f\\nontp_short_liqd_pr : %.3f\\nmax_nontp_short_term : %s\"  \n","                  % (short_wr, len(short_np_pr[short_np_pr != 1]), np.min(short_np_pr), total_short_pr[-1], short_sum_pr[-1], config.lvrg_set.leverage, min(short_liqd_list), mean_short_tr, mean_short_dr, \n","                     len(nontp_short_liqd_list), min(nontp_short_liqd_list), min(nontp_short_pr_list), max_nontp_short_term))\n","      else:\n","        plt.title(\"wr : %.3f\\nlen(short_td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_short_liqd_cnt : %s\"  \n","                  % (short_wr, len(short_np_pr[short_np_pr != 1]), np.min(short_np_pr), total_short_pr[-1], short_sum_pr[-1], config.lvrg_set.leverage, min(short_liqd_list), mean_short_tr, mean_short_dr, len(nontp_short_liqd_list)))\n","\n","      print('supblot232 passed')\n","    \n","    except Exception as e:\n","      print(\"error in 232 :\", e)\n","\n","    try:\n","      #         long only      #\n","      long_np_pr = np.array(long_list)\n","      # long_np_pr = (np.array(long_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      total_long_pr = np.cumprod(long_np_pr)\n","      \n","      long_for_sum_pr = long_np_pr - 1\n","      long_for_sum_pr[0] = 1\n","      long_sum_pr = np.cumsum(long_for_sum_pr)\n","      long_sum_pr = np.where(long_sum_pr < 0, 0, long_sum_pr)\n","\n","      long_wr = len(long_np_pr[long_np_pr > 1]) / len(long_np_pr[long_np_pr != 1])\n","      \n","      # long_cumprod_profit = np.cumprod(long_np_pr[long_np_pr > 1])[-1]\n","      # long_cumprod_loss = np.cumprod(long_np_pr[long_np_pr < 1])[-1]\n","      # long_pr_tr = long_cumprod_profit * long_cumprod_loss\n","\n","      np_long_tp_ratio_list = np.array(long_tp_ratio_list)\n","      mean_long_tr = np.mean(np_long_tp_ratio_list[np.isnan(np_long_tp_ratio_list) == 0])\n","      \n","      np_long_dr_list = np.array(long_dr_list)\n","      mean_long_dr = np.mean(np_long_dr_list[np.isnan(np_long_dr_list) == 0])\n","\n","      # long_pr_gap = (long_np_pr - 1) / config.lvrg_set.leverage + fee\n","      # long_tp_gap = long_pr_gap[long_pr_gap > 0]\n","      # # mean_long_tp_gap = np.mean(long_pr_gap[long_pr_gap > 0])\n","      # # mean_long_ls_gap = np.mean(long_pr_gap[long_pr_gap < 0])\n","\n","      # mean_long_pgfr = np.mean((long_tp_gap - fee) / abs(long_tp_gap + fee))\n","\n","      plt.subplot(233)\n","      plt.plot(total_long_pr)\n","      plt.plot(long_sum_pr, color='gold')\n","      if len(nontp_long_liqd_list) != 0:\n","\n","        max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","        plt.title(\"wr : %.3f\\nlen(long_td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_long_liqd_cnt : %s\\nnontp_long_liqd : %.3f\\nontp_long_liqd_pr : %.3f\\nmax_nontp_long_term : %s\"   \n","                  % (long_wr, len(long_np_pr[long_np_pr != 1]), np.min(long_np_pr), total_long_pr[-1], long_sum_pr[-1], config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr, \n","                     len(nontp_long_liqd_list), min(nontp_long_liqd_list), min(nontp_long_pr_list), max_nontp_long_term))\n","      else:\n","        plt.title(\"wr : %.3f\\nlen(long_td) : %s\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\\n leverage %s\\nliqd : %.3f\\nmean_tr : %.3f\\n mean_dr : %.3f\\n nontp_long_liqd_cnt : %s\"   \n","                  % (long_wr, len(long_np_pr[long_np_pr != 1]), np.min(long_np_pr), total_long_pr[-1], long_sum_pr[-1], config.lvrg_set.leverage, min(long_liqd_list), mean_long_tr, mean_long_dr, len(nontp_long_liqd_list)))\n","\n","      print('supblot233 passed')\n","\n","    except Exception as e:\n","      print(\"error in 233 :\", e)\n","\n","\n","    try:\n","      #     reversion adjustment      #\n","      # rev_np_pr = 1 / (np.array(pr_list) + fee) - fee\n","      rev_fee = tp_fee + out_fee - np.array(fee_list)\n","      rev_np_pr = (1 / ((np.array(pr_list) - 1) / config.lvrg_set.leverage + np.array(fee_list) + 1) - rev_fee - 1) * config.lvrg_set.leverage + 1\n","      # rev_np_pr = (1 / (np.array(pr_list) + fee) - fee - 1) * config.lvrg_set.leverage + 1\n","          \n","      rev_total_pr = np.cumprod(rev_np_pr)\n","      rev_wr = len(rev_np_pr[rev_np_pr > 1]) / len(rev_np_pr[rev_np_pr != 1])\n","\n","      rev_total_for_sum_pr = rev_np_pr - 1\n","      rev_total_for_sum_pr[0] = 1\n","      rev_total_sum_pr = np.cumsum(rev_total_for_sum_pr)\n","      rev_total_sum_pr = np.where(rev_total_sum_pr < 0, 0, rev_total_sum_pr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(234)\n","      plt.plot(rev_total_pr)\n","      plt.plot(rev_total_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\" % (rev_wr, np.min(rev_np_pr), rev_total_pr[-1], rev_total_sum_pr[-1]))\n","\n","    except Exception as e:\n","      print(\"error in 234 :\", e)\n","\n","    try:\n","      #         short       #\n","      # rev_short_np_pr = 1 / (np.array(short_list) + fee) - fee\n","      rev_short_fee = tp_fee + out_fee - np.array(short_fee_list)\n","      rev_short_np_pr = (1 / ((np.array(short_list) - 1) / config.lvrg_set.leverage + np.array(short_fee_list) + 1) - rev_short_fee - 1) * config.lvrg_set.leverage + 1\n","      # rev_short_np_pr = (1 / (np.array(short_list) + fee) - fee - 1) * config.lvrg_set.leverage + 1\n","          \n","      rev_total_short_pr = np.cumprod(rev_short_np_pr)\n","      rev_short_wr = len(rev_short_np_pr[rev_short_np_pr > 1]) / len(rev_short_np_pr[rev_short_np_pr != 1])\n","\n","      rev_short_for_sum_pr = rev_short_np_pr - 1\n","      rev_short_for_sum_pr[0] = 1\n","      rev_short_sum_pr = np.cumsum(rev_short_for_sum_pr)\n","      rev_short_sum_pr = np.where(rev_short_sum_pr < 0, 0, rev_short_sum_pr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(235)\n","      plt.plot(rev_total_short_pr)\n","      plt.plot(rev_short_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\" % (rev_short_wr, np.min(rev_short_np_pr), rev_total_short_pr[-1], rev_short_sum_pr[-1]))\n","\n","    except Exception as e:\n","      print(\"error in 235 :\", e)\n","\n","    try:\n","      #         long       #\n","      # rev_long_np_pr = 1 / (np.array(long_list) + fee) - fee\n","      rev_long_fee = tp_fee + out_fee - np.array(long_fee_list)\n","      rev_long_np_pr = (1 / ((np.array(long_list) - 1) / config.lvrg_set.leverage + np.array(long_fee_list) + 1) - rev_long_fee - 1) * config.lvrg_set.leverage + 1\n","          \n","      rev_total_long_pr = np.cumprod(rev_long_np_pr)\n","      rev_long_wr = len(rev_long_np_pr[rev_long_np_pr > 1]) / len(rev_long_np_pr[rev_long_np_pr != 1])\n","\n","      rev_long_for_sum_pr = rev_long_np_pr - 1\n","      rev_long_for_sum_pr[0] = 1\n","      rev_long_sum_pr = np.cumsum(rev_long_for_sum_pr)\n","      rev_long_sum_pr = np.where(rev_long_sum_pr < 0, 0, rev_long_sum_pr)\n","\n","      # plt.subplot(122)\n","      plt.subplot(236)\n","      plt.plot(rev_total_long_pr)\n","      plt.plot(rev_long_sum_pr, color='gold')\n","\n","      plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n sum_pr : %.3f\" % (rev_long_wr, np.min(rev_long_np_pr), rev_total_long_pr[-1], rev_long_sum_pr[-1]))\n","      \n","    except Exception as e:\n","      print(\"error in 236 :\", e)\n","\n","    plt.show()\n","    \n","\n","    try:\n","\n","      h_np_pr = np.array(h_pr_list)\n","      # h_rev_np_pr = 1 / (np.array(h_pr_list) + fee) - fee    # define, for plot_check below cell\n","      h_rev_np_pr = (1 / ((np.array(h_pr_list) - 1) / config.lvrg_set.leverage + np.array(fee_list) + 1) - np.array(fee_list) - 1) * config.lvrg_set.leverage + 1\n","\n","      # --------------------- h pr plot --------------------- #\n","      if len(h_np_pr[h_np_pr != 1]) != 0:\n","\n","        plt.figure(figsize=(16, 12))\n","        plt.suptitle(key + \" hedge\")\n","\n","        h_total_pr = np.cumprod(h_np_pr)\n","        h_wr = len(h_np_pr[h_np_pr > 1]) / len(h_np_pr[h_np_pr != 1])\n","\n","        # plt.subplot(121)\n","        plt.subplot(231)\n","        plt.plot(h_total_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_wr, np.min(h_np_pr), h_total_pr[-1], config.lvrg_set.leverage))\n","        # plt.show()\n","\n","        #         short only      #\n","        h_short_np_pr = np.array(h_short_list)\n","\n","        h_total_short_pr = np.cumprod(h_short_np_pr)\n","        h_short_wr = len(h_short_np_pr[h_short_np_pr > 1]) / len(h_short_np_pr[h_short_np_pr != 1])\n","        \n","        plt.subplot(232)\n","        plt.plot(h_total_short_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_short_wr, np.min(h_short_np_pr), h_total_short_pr[-1], config.lvrg_set.leverage))\n","\n","        #         long only      #\n","        h_long_np_pr = np.array(h_long_list)\n","\n","        h_total_long_pr = np.cumprod(h_long_np_pr)\n","        h_long_wr = len(h_long_np_pr[h_long_np_pr > 1]) / len(h_long_np_pr[h_long_np_pr != 1])\n","        \n","        plt.subplot(233)\n","        plt.plot(h_total_long_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_long_wr, np.min(h_long_np_pr), h_total_long_pr[-1], config.lvrg_set.leverage))\n","\n","\n","        #     reversion adjustment      #\n","            \n","        h_rev_total_pr = np.cumprod(h_rev_np_pr)\n","        h_rev_wr = len(h_rev_np_pr[h_rev_np_pr > 1]) / len(h_rev_np_pr[h_rev_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(234)\n","        plt.plot(h_rev_total_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_rev_wr, np.min(h_rev_np_pr), h_rev_total_pr[-1], config.lvrg_set.leverage))\n","\n","        #         short       #\n","        # h_rev_short_np_pr = 1 / (np.array(h_short_list) + fee) - fee\n","        h_rev_short_np_pr =  (1 / ((np.array(h_short_list) - 1) / config.lvrg_set.leverage + np.array(short_fee_list) + 1) - np.array(short_fee_list) - 1) * config.lvrg_set.leverage + 1\n","           \n","        h_rev_total_short_pr = np.cumprod(h_rev_short_np_pr)\n","        h_rev_short_wr = len(h_rev_short_np_pr[h_rev_short_np_pr > 1]) / len(h_rev_short_np_pr[h_rev_short_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(235)\n","        plt.plot(h_rev_total_short_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_rev_short_wr, np.min(h_rev_short_np_pr), h_rev_total_short_pr[-1], config.lvrg_set.leverage))\n","\n","        #         long       #\n","        # h_rev_long_np_pr = 1 / (np.array(h_long_list) + fee) - fee\n","        h_rev_long_np_pr =  (1 / ((np.array(h_long_list) - 1) / config.lvrg_set.leverage + np.array(long_fee_list) + 1) - np.array(long_fee_list) - 1) * config.lvrg_set.leverage + 1\n","            \n","        h_rev_total_long_pr = np.cumprod(h_rev_long_np_pr)\n","        h_rev_long_wr = len(h_rev_long_np_pr[h_rev_long_np_pr > 1]) / len(h_rev_long_np_pr[h_rev_long_np_pr != 1])\n","\n","        # plt.subplot(122)\n","        plt.subplot(236)\n","        plt.plot(h_rev_total_long_pr)\n","        plt.title(\"wr : %.3f\\nmin_pr : %.3f\\nacc_pr : %.3f\\n leverage %s\" % (h_rev_long_wr, np.min(h_rev_long_np_pr), h_rev_total_long_pr[-1], config.lvrg_set.leverage))\n","        \n","        plt.show()\n","          \n","    except Exception as e:\n","      print('error in h_pr plot :', e)   \n","    \n","\n","    print()\n","\n","  # break # pair loop"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2Gjv019AEz8"},"source":["##### frequency check"]},{"cell_type":"code","metadata":{"id":"atdBjod9-e21"},"source":["total_len = np.zeros(len(res_df))\n","print(total_len)\n","np_trade_list = np.array(trade_list)\n","# print(np_trade_list.shape)\n","print(np_trade_list[:, [0], [0]].shape)\n","total_len[np_trade_list[:, [0], [0]]] = 1\n","\n","plt.plot(total_len)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-IbP_Z3Dlwk4"},"source":["### nontp survey"]},{"cell_type":"markdown","metadata":{"id":"FxJ1y8v2fkCR"},"source":["##### term & liqd"]},{"cell_type":"code","metadata":{"id":"-qIWa48pl1GO"},"source":["# print(nontp_long_indexs)\n","\n","plot_size = 100\n","\n","for s_i in range(plot_size, len(trade_list), plot_size):\n","\n","  slice_trade_list = trade_list[s_i - plot_size:s_i]\n","  slice_liqd_list = liqd_list[s_i - plot_size:s_i]\n","\n","  # print(len(slice_trade_list))\n","  np_trade = np.array(slice_trade_list)\n","  trade_term = np_trade[:, [2]] - np_trade[:, [1]]\n","\n","  plt.figure(figsize=(5, 10))\n","  plt.subplot(211)\n","  plt.bar(np.arange(len(trade_term)), trade_term.reshape(-1,), width=1, color='b')\n","\n","  # plt.plot(trade_term.reshape(-1,))\n","  plt.ylim(0, 1000)\n","  # plt.show()\n","  # print()\n","\n","  plt.subplot(212)\n","  # print(len(liqd_list))\n","  # plt.bar(np.arange(len(liqd_list)), liqd_list)\n","  plt.bar(np.arange(len(slice_liqd_list)), np.array(slice_liqd_list), width=1, color='r')\n","  # plt.plot(slice_liqd_list)\n","  plt.show()\n","\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBwVaUkvfnOd"},"source":["##### check nontp index"]},{"cell_type":"code","metadata":{"id":"mRCMBOU4frNY"},"source":["# np_nontp_short_indexs = np.array(nontp_short_indexs)\n","# np_nontp_long_indexs = np.array(nontp_long_indexs)\n","\n","# short_til_term = len(res_df) - np_nontp_short_indexs\n","# long_til_term = len(res_df) - np_nontp_long_indexs\n","\n","max_nontp_short_term = len(res_df) - nontp_short_indexs[0]\n","max_nontp_long_term = len(res_df) - nontp_long_indexs[0]\n","\n","print(max_nontp_long_term)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNQxkb06ZdTe"},"source":["# traded section plot"]},{"cell_type":"markdown","metadata":{"id":"UmH_Pb5BZUtm"},"source":["## plot with off-color st with dash"]},{"cell_type":"markdown","metadata":{"id":"5z4L3MMYmUI0"},"source":["### sorted plot_check"]},{"cell_type":"code","metadata":{"id":"L9LdjV2uUWnp"},"source":["plot_pr_list[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv1MM2MemZnF"},"source":["assert len(open_list) == len(trade_list), \"len(open_list) != len(trade_list)\"\n","\n","save_plot = 0\n","pr_sort = 1\n","pr_descend = 0\n","\n","inversion = 0\n","hedge = 0\n","\n","if save_plot:\n","  plot_check_dir = current_path + \"plot_check/\" +  key.replace(\".xlsx\", \"\")\n","  try:\n","    os.mkdir(plot_check_dir)\n","  except:\n","\n","    #     remove existing dir   #\n","    shutil.rmtree(plot_check_dir)\n","    print(plot_check_dir, 'removed !')\n","    os.mkdir(plot_check_dir)\n","    # pass\n","    \n","\n","prev_plotsize = 90\n","post_plotsize = 70\n","\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    try:\n","      h_plot_pr_list = h_np_pr\n","    except Exception as e:\n","      print(\"error in h_plot_pr :\", e)\n","      h_plot_pr_list = np_pr\n","\n","\n","# 'ST1_Up_%s' % basic_st_interval, 'ST1_Down_%s' % basic_st_interval, 'ST2_Up_%s' % basic_st_interval, 'ST2_Down_%s' % basic_st_interval, 'ST3_Up_%s' % basic_st_interval, 'ST3_Down_%s' % basic_st_interval,\n","\n","# --------------------- st level --------------------- #\n","basic_st_interval = '15m' # 5, 6 이라면 겹치지 않게 2로 설정\n","basic_st_list = ['st_base_%s' % basic_st_interval, 'st_upper_%s' % basic_st_interval, 'st_lower_%s' % basic_st_interval\n","                 , 'st_upper2_%s' % basic_st_interval, 'st_lower2_%s' % basic_st_interval]\n","\n","ohlc_list = ['open', 'high', 'low', 'close'] # + basic_st_list\n","\n","mmh_list = ['mmh_st1_1m', 'mmh_st2_1m']\n","norm_st_list = ['norm_st_up_1m', 'norm_st_down_1m']\n","\n","pline_interval = '4h'\n","pline_list = ['st_base_%s' % pline_interval, 'st_upper_%s' % pline_interval, 'st_lower_%s' % pline_interval\n","                 , 'st_upper2_%s' % pline_interval, 'st_lower2_%s' % pline_interval]\n","\n","pline_interval2 = '4h'\n","pline_list2 = ['st_base_%s' % pline_interval2, 'st_upper_%s' % pline_interval2, 'st_lower_%s' % pline_interval2\n","                 , 'st_upper2_%s' % pline_interval2, 'st_lower2_%s' % pline_interval2]\n","\n","# --------------------- dc & bb level --------------------- #\n","dc_interval = '15m'\n","# dc_list = ['dc_base_%s' % dc_interval, 'dc_upper_%s' % dc_interval, 'dc_lower_%s' % dc_interval, 'dc_upper2_%s' % dc_interval, \n","dc_list = ['dc_upper_%s' % dc_interval, 'dc_lower_%s' % dc_interval, 'dc_upper2_%s' % dc_interval, \n","           'dc_lower2_%s' % dc_interval]\n","\n","bb_interval = '5m'\n","bb_list = ['bb_base_%s' % bb_interval, 'bb_upper_%s' % bb_interval, 'bb_lower_%s' % bb_interval, 'bb_upper2_%s' % bb_interval, \n","           'bb_lower2_%s' % bb_interval, 'bb_upper3_%s' % bb_interval, 'bb_lower3_%s' % bb_interval]\n","hbb_interval = '30m'\n","hbb_list = ['bb_base_%s' % hbb_interval, 'bb_upper_%s' % hbb_interval, 'bb_lower_%s' % hbb_interval, 'bb_upper2_%s' % hbb_interval, \n","            'bb_lower2_%s' % hbb_interval, 'bb_upper3_%s' % hbb_interval, 'bb_lower3_%s' % hbb_interval]\n","bbwp_list = ['bbwp', 'bbwp_ma']\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1']\n","senkoub_list = ['senkou_b1']\n","\n","sar_list = ['sar_1m']\n","\n","# ma_list = ['sma1', 'sma4']\n","sma_list = ['sma_1m']\n","\n","# -------------- price rolling indi. -------------- #\n","ema_list = ['ema5_1m']\n","# cb_list = ['cloud_bline_1m']\n","cb_list = ['cloud_bline_3m']\n","# cb_list = ['cloud_bline_5m']\n","\n","\n","\n","# -------------- under price phase -------------- #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist%s' % basic_st_interval]\n","# macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3']\n","# trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix%s' % basic_st_interval]\n","trix_list = ['trix1', 'trix2', 'trix3']\n","stoch_list = ['stoch_5m']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","emaroc_list = ['ema_roc']\n","\n","\n","# -------------- summation -------------- #\n","\n","input_colname = ohlc_list + basic_st_list + pline_list + bb_list + hbb_list + sma_list + cb_list + stoch_list + sar_list + dc_list\n","# input_colname = ohlc_list + mmh_list + norm_st_list \n","\n","yrange_colname = ohlc_list + basic_st_list + pline_list # currently just used for ymin, ymax\n","# yrange_colname = ohlc_list + bb_list + hbb_list # currently just used for ymin, ymax\n","\n","\n","# aggr_obj = dict(zip(plot_pr_list, open_list, enumerate(trade_list)))\n","aggr_obj = dict(zip(plot_pr_list, zip(open_list, enumerate(trade_list))))\n","\n","sorted_obj = sorted(aggr_obj.items(), key=(lambda x: x[0]), reverse=pr_descend)\n","# print(aggr_obj)\n","# print(sorted_obj)\n","\n","if pr_sort:\n","  iter_obj = sorted_obj\n","else:\n","  iter_obj = aggr_obj.items()\n","\n","for temp_pr, (open_idx, (t_i, (ep_idx_list_, tp_idx_list_))) in iter_obj:  # 0.699700153073042, (291402, (3014, ([370012], [370014])))\n","\n","  # print(i, j)\n","  # print(\"open_idx :\", open_idx\n","  print(\"np_timeidx[open_idx] :\", np_timeidx[open_idx])\n","\n","  # if not(i >= prev_plotsize):\n","  #   continue\n","\n","  # if open_idx == 63901:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  # if not 'long' in tp_state_list[t_i]:\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > short_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # print(\"t_i :\", t_i)\n","  # print(\"temp_pr :\", temp_pr)\n","  # print(\"plot_pr_list[t_i] :\", plot_pr_list[t_i])\n","  # break\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","  plot_df = res_df.iloc[open_idx - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  # st_trend_plot_df = res_df[['ST1_Trend%s' % basic_st_interval, 'ST2_Trend%s' % basic_st_interval, 'ST3_Trend%s' % basic_st_interval]].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  y_max = max(np.max(plot_df[yrange_colname]))\n","  y_min = min(np.min(plot_df[yrange_colname]))\n","\n","  if np.isnan(y_max) or np.isnan(y_min):\n","    print('continued in yminmax')\n","    continue\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","\n","  # fig = trendln.plot_support_resistance(plot_df['close'], accuracy=8, fromwindows=0, numbest=1,  window=30) # requires matplotlib - pip install matplotlib\n","  \n","  plt.style.use('dark_background')\n","\n","  # fig = plt.figure(figsize=(12, 16))\n","  fig = plt.figure(figsize=(14, 18))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='#26a69a', colordown='#ef5350')\n","\n","  # ---------- plot basic st_line ---------- #\n","  alpha = 1\n","  lw = 1\n","  for sm_i, item in enumerate(basic_st_list):\n","    if sm_i == 0:\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","    else:\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","    \n","  alpha = 0.3\n","  plt.fill_between(np.arange(len(plot_df)), plot_df['st_upper2_%s' % basic_st_interval].values, plot_df['st_upper_%s' % basic_st_interval].values, \n","                      where=plot_df['st_upper2_%s' % basic_st_interval].values >= plot_df['st_upper_%s' % basic_st_interval].values, facecolor='#00ff00', alpha=alpha)                      \n","  plt.fill_between(np.arange(len(plot_df)), plot_df['st_lower2_%s' % basic_st_interval].values, plot_df['st_lower_%s' % basic_st_interval].values, \n","                      where=plot_df['st_lower2_%s' % basic_st_interval].values <= plot_df['st_lower_%s' % basic_st_interval].values, facecolor='#00ff00', alpha=alpha)\n","  \n","  # ---------- plot pline ---------- #\n","\n","  alpha = 1\n","  lw = 2\n","  for sm_i, item in enumerate(pline_list):\n","    if sm_i == 0:\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","    else:\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","  \n","  alpha = 0.3\n","  plt.fill_between(np.arange(len(plot_df)), plot_df['st_upper2_%s' % pline_interval].values, plot_df['st_upper_%s' % pline_interval].values, \n","                      where=plot_df['st_upper2_%s' % pline_interval].values >= plot_df['st_upper_%s' % pline_interval].values, facecolor='#2962ff', alpha=alpha)                      \n","  plt.fill_between(np.arange(len(plot_df)), plot_df['st_lower2_%s' % pline_interval].values, plot_df['st_lower_%s' % pline_interval].values, \n","                      where=plot_df['st_lower2_%s' % pline_interval].values <= plot_df['st_lower_%s' % pline_interval].values, facecolor='#2962ff', alpha=alpha)\n","  \n","  # ---------- plot pline2 ---------- #\n","  # alpha = 1\n","  # lw = 4\n","  # for sm_i, item in enumerate(pline_list2):\n","  #   if sm_i == 0:\n","  #     plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffeb3b', linewidth=lw)\n","  #   else:\n","  #     plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","  \n","  # alpha = 0.3\n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['st_upper2_%s' % pline_interval2].values, plot_df['st_upper_%s' % pline_interval2].values, \n","  #                     where=plot_df['st_upper2_%s' % pline_interval2].values >= plot_df['st_upper_%s' % pline_interval2].values, facecolor='#00ff00', alpha=alpha)                      \n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['st_lower2_%s' % pline_interval2].values, plot_df['st_lower_%s' % pline_interval2].values, \n","  #                     where=plot_df['st_lower2_%s' % pline_interval2].values <= plot_df['st_lower_%s' % pline_interval2].values, facecolor='#00ff00', alpha=alpha)\n","  \n","\n","  # ---------- mmh pline ---------- #\n","\n","  # plt.step(plot_df[['mmh_st1']].values, 'fuchsia', alpha=1, linewidth=1) \n","  # plt.step(plot_df[['mmh_st2']].values, 'g', linestyle='-', alpha=1, linewidth=1) \n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_df[['norm_st_up']].values, linestyle='-', linewidth=2, color='r') \n","  # plt.step(np.arange(len(plot_df)), plot_df[['norm_st_down']].values, linestyle='-', linewidth=2, color='b') \n","\n","  # ---------------------- on price indicator part end ---------------------- #\n","\n","  # ---------------------- ma ---------------------- #\n","   # --------- ema --------- #\n","  # alpha = 1\n","  # for sm_i, item in enumerate(ema_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#03ed30', linewidth=lw)\n","  #   alpha -= 0.2\n","\n","  #   # --------- sma --------- #\n","  # alpha = 1\n","  # for sm_i, sma in enumerate(sma_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 4\n","  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='#e91e63', linewidth=lw)\n","  #   alpha -= 0.2\n","\n","  \n","  # ---------------------- cb ---------------------- #\n","  # alpha = 1\n","  # for sm_i, item in enumerate(cb_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#5b9cf6', linewidth=lw)\n","  #   alpha -= 0.2\n","  \n","  # ---------------------- dc ---------------------- #\n","  alpha = 1\n","  lw = 2\n","  for sm_i, item in enumerate(dc_list):\n","    if sm_i == 0:\n","      # plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#FF6D00', linewidth=lw)\n","      pass\n","    else:\n","      plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#2962FF', linewidth=lw)\n","\n","  # ---------------------- bb ---------------------- #\n","  # alpha = 1\n","  # lw = 1\n","  # for sm_i, item in enumerate(bb_list):\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#ffffff', linewidth=lw)\n","\n","  # alpha = 0.2\n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['bb_upper3_%s' % bb_interval].values, plot_df['bb_upper_%s' % bb_interval].values, \n","  #                     where=plot_df['bb_upper3_%s' % bb_interval].values >= plot_df['bb_upper_%s' % bb_interval].values, facecolor='#ffffff', alpha=alpha)                      \n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['bb_lower3_%s' % bb_interval].values, plot_df['bb_lower_%s' % bb_interval].values, \n","  #                     where=plot_df['bb_lower3_%s' % bb_interval].values <= plot_df['bb_lower_%s' % bb_interval].values, facecolor='#ffffff', alpha=alpha)\n","\n","  # ---------------------- hbb ---------------------- #\n","  # alpha = 1\n","  # lw = 6\n","  # for sm_i, item in enumerate(hbb_list):\n","  #   plt.step(np.arange(len(plot_df)), plot_df[item].values, alpha=alpha, color='#e91e63', linewidth=lw)\n","  \n","  # alpha = 0.3\n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['bb_upper3_%s' % hbb_interval].values, plot_df['bb_upper_%s' % hbb_interval].values, \n","  #                     where=plot_df['bb_upper3_%s' % hbb_interval].values >= plot_df['bb_upper_%s' % hbb_interval].values, facecolor='#e91e63', alpha=alpha)                      \n","  # plt.fill_between(np.arange(len(plot_df)), plot_df['bb_lower3_%s' % hbb_interval].values, plot_df['bb_lower_%s' % hbb_interval].values, \n","  #                     where=plot_df['bb_lower3_%s' % hbb_interval].values <= plot_df['bb_lower_%s' % hbb_interval].values, facecolor='#e91e63', alpha=alpha)\n","  \n","  #               sar               #\n","  # alpha = 1\n","  # markersize = 5\n","  # for sar in sar_list:\n","  #   plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","  #   markersize += 1\n","  #   alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  # alpha = 0.7\n","  # for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","  #                     where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","  #   plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","  #                     where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","  #   alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  # if i != initial_i:\n","  # if len(ep_idx_list_) > 1:\n","  \n","  # ------------- initial order ------------- #\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='#ffeb3b')\n","  plt.axvline(prev_plotsize, alpha=0.5, linestyle='--', color='#ffeb3b')\n","\n","  for ep_i in range(len(ep_idx_list_)):\n","    # plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0]), alpha=0.7, linestyle='--', color='#ffeb3b')\n","    plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - open_idx), alpha=0.7, linestyle='--', color='#ffeb3b')\n","\n","  # plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","\n","  x0,x1 = plt.gca().get_xlim()\n","\n","  # ep_xmin = (prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0])) / x1\n","  ep_xmin = (prev_plotsize + (ep_idx_list_[ep_i] - open_idx)) / x1\n","  plt.axhline(ep_tp_list[t_i][0], linestyle='--', xmin=ep_xmin, xmax=1, alpha=1, color='lime')  # ep line axhline  \n","  plt.text(x1, ep_tp_list[t_i][0][0], ' ep :\\n %s' % ep_tp_list[t_i][0][0], ha='left', va='center', fontweight='bold') # ep line label\n","\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","\n","    # tp_xmin = (prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0])) / x1\n","    tp_xmin = (prev_plotsize + (tp_idx_list_[sub_i] - open_idx)) / x1\n","    plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='--', xmin=tp_xmin , xmax=1, alpha=1, color='lime')  # tp line axhline\n","    plt.text(x1, ep_tp_list[t_i][1][sub_i], ' tp :\\n %s' % ep_tp_list[t_i][1][sub_i], ha='left', va='center', fontweight='bold') # tp line label\n","     \n","    # plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0]), alpha=1., linestyle='--', color='#ffeb3b', zorder=2)\n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - open_idx), alpha=1., linestyle='--', color='#ffeb3b', zorder=2)\n","\n","\n","  #         hedge ep & tp         #\n","  h_i = h_trade_list[t_i][1]\n","  if h_i is not None:\n","    # plt.axvline(prev_plotsize + (h_i - ep_idx_list_[0]), linestyle='--')\n","    plt.axvline(prev_plotsize + (h_i - open_idx), linestyle='--')\n","    plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","    plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  temp_pr = plot_pr_list[t_i]\n","  # if temp_pr > 1:\n","  #   temp_pr_gap = (temp_pr - 1) / lvrg + fee\n","  #   pgfr = (temp_pr_gap - fee) / abs(temp_pr_gap + fee)\n","  # else:\n","  #   pgfr = np.nan\n","\n","  #         check pr        #\n","  if not config.lvrg_set.static_lvrg:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\n lvrg : %s\\ntp_ratio : %.3f\\n dr : %.3f\\n fee : %.4f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], \n","                                                                                                h_plot_pr_list[t_i], leverage_list[t_i], tp_ratio_list[t_i], dr_list[t_i], fee_list[t_i]))\n","  else:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\n tp_ratio : %.3f\\n dr : %.3f\\n fee : %.4f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], \n","                                                                                     h_plot_pr_list[t_i], tp_ratio_list[t_i], dr_list[t_i], fee_list[t_i]))\n","\n","  print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee - 1) * config.lvrg_set.leverage + 1)\n","  print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee - 1) * config.lvrg_set.leverage + 1)\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # ---------------------- outer price indi. ---------------------- #\n","  #           macd          #\n","  # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","    \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for stoch_ in stoch_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[stoch_].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(stoch_upper, linestyle='--')\n","  # plt.axhline(stoch_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- cctbbo ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for cctbbo in cctbbo_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(cctbbo_upper, linestyle='--')\n","  # plt.axhline(cctbbo_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- ema_roc ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for emaroc in emaroc_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","  \n","  # ---------- bbw ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for bbwp_ in bbwp_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[bbwp_].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(bbwp_thresh, linestyle='--')\n","\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_idx), alpha=0.5, linestyle='--', color='lime')\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  if not save_plot:\n","    plt.show()\n","  \n","  else:\n","    # ---------- save mode ---------- #\n","    fig_name = plot_check_dir +  \"/%s.png\" % t_i\n","    plt.savefig(fig_name)\n","    print(fig_name, \"saved !\")\n","\n","  \n","  plt.close()\n","  print()\n","\n","  # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59nW2aKYzkN8"},"source":["### plot all indicator (stepline ver.)"]},{"cell_type":"code","metadata":{"id":"JDH4rXgNzno6"},"source":["save_plot = False\n","\n","\n","if save_plot:\n","  plot_check_dir = current_path + \"plot_check/\" +  key.replace(\".xlsx\", \"\")\n","  try:\n","    os.mkdir(plot_check_dir)\n","  except:\n","\n","    #     remove existing dir   #\n","    shutil.rmtree(plot_check_dir)\n","    print(plot_check_dir, 'removed !')\n","    os.mkdir(plot_check_dir)\n","    # pass\n","    \n","# prev_plotsize = 120\n","prev_plotsize = 150\n","post_plotsize = 20\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    try:\n","      h_plot_pr_list = h_np_pr\n","    except Exception as e:\n","      print(\"error in h_plot_pr :\", e)\n","      h_plot_pr_list = np_pr\n","\n","\n","#         select plot columns       #\n","major_st_list = ['major_ST1_Up', 'major_ST1_Down', 'major_ST2_Up', 'major_ST2_Down', 'major_ST3_Up', 'major_ST3_Down',\n","                 'major_middle_line', 'major_upper_middle', 'major_lower_middle']\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower'] # + major_st_list\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1',  'senkou_a2']\n","senkoub_list = ['senkou_b1',  'senkou_b2']\n","\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1']\n","\n","# ma_list = ['sma1', 'sma4']\n","ma_list = ['ema5']\n","\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","# macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3']\n","# trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","trix_list = ['trix1', 'trix2', 'trix3']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher30', 'fisher60', 'fisher120']\n","cctbbo_list = ['cctbbo']\n","emaroc_list = ['ema_roc']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + ma_list\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + ma_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","input_colname = basic_list + major_st_list + senkoua_list + senkoub_list + sar_list + stoch_list + fisher_list + emaroc_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list # currently just used for ymin, ymax\n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","\n","# for t_i, (initial_i, i, j) in enumerate(trade_list):\n","for t_i, (ep_idx_list_, tp_idx_list_) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # if 100 < i < 1860:\n","  if ep_idx_list_[0] == 370530:\n","    pass\n","  else:\n","    continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > short_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + post_plotsize, input_cols]\n","  plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  # st_trend_plot_df = res_df.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize, [7, 10, 13]]\n","  # st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  st_trend_plot_df = res_df[['minor_ST1_Trend', 'minor_ST2_Trend', 'minor_ST3_Trend', 'major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  # htf_st_trend_plot_df = res_df[['major_ST1_Trend', 'major_ST2_Trend', 'major_ST3_Trend']].iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","\n","  if np.isnan(y_max) or np.isnan(y_min):\n","    continue\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","  \n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, plot_df['minor_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, plot_df['minor_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, plot_df['minor_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, plot_df['minor_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, plot_df['minor_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, plot_df['minor_ST3_Down'], np.nan)\n","\n","  plot_df[\"off_color_upper_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, plot_df['major_ST1_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, plot_df['major_ST2_Up'], np.nan)\n","  plot_df[\"off_color_upper_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, plot_df['major_ST3_Up'], np.nan)\n","  plot_df[\"off_color_lower_hst1\"] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, plot_df['major_ST1_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst2\"] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, plot_df['major_ST2_Down'], np.nan)\n","  plot_df[\"off_color_lower_hst3\"] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, plot_df['major_ST3_Down'], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df['minor_ST1_Up'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == 1, np.nan, plot_df['minor_ST1_Up'])\n","  plot_df['minor_ST2_Up'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == 1, np.nan, plot_df['minor_ST2_Up'])\n","  plot_df['minor_ST3_Up'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == 1, np.nan, plot_df['minor_ST3_Up'])\n","  plot_df['minor_ST1_Down'] = np.where(st_trend_plot_df['minor_ST1_Trend'] == -1, np.nan, plot_df['minor_ST1_Down'])\n","  plot_df['minor_ST2_Down'] = np.where(st_trend_plot_df['minor_ST2_Trend'] == -1, np.nan, plot_df['minor_ST2_Down'])\n","  plot_df['minor_ST3_Down'] = np.where(st_trend_plot_df['minor_ST3_Trend'] == -1, np.nan, plot_df['minor_ST3_Down'])\n","\n","  plot_df['major_ST1_Up'] = np.where(st_trend_plot_df['major_ST1_Trend'] == 1, np.nan, plot_df['major_ST1_Up'])\n","  plot_df['major_ST2_Up'] = np.where(st_trend_plot_df['major_ST2_Trend'] == 1, np.nan, plot_df['major_ST2_Up'])\n","  plot_df['major_ST3_Up'] = np.where(st_trend_plot_df['major_ST3_Trend'] == 1, np.nan, plot_df['major_ST3_Up'])\n","  plot_df['major_ST1_Down'] = np.where(st_trend_plot_df['major_ST1_Trend'] == -1, np.nan, plot_df['major_ST1_Down'])\n","  plot_df['major_ST2_Down'] = np.where(st_trend_plot_df['major_ST2_Trend'] == -1, np.nan, plot_df['major_ST2_Down'])\n","  plot_df['major_ST3_Down'] = np.where(st_trend_plot_df['major_ST3_Trend'] == -1, np.nan, plot_df['major_ST3_Down'])\n","\n","\n","  plot_short_ep = short_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_ep = long_ep.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]\n","  plot_long_tp = long_tp.iloc[ep_idx_list_[0] - prev_plotsize:tp_idx_list_[-1] + post_plotsize]  \n","\n","\n","  # fig = trendln.plot_support_resistance(plot_df['close'], accuracy=8, fromwindows=False, numbest=1,  window=30) # requires matplotlib - pip install matplotlib\n","\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  plt.step(plot_df[['minor_ST1_Up', 'minor_ST2_Up', 'minor_ST3_Up']].values, 'r', alpha=1)  # upper on color\n","  plt.step(plot_df[['minor_ST1_Down', 'minor_ST2_Down', 'minor_ST3_Down']].values, 'b', alpha=1)  # lower on color\n","  \n","  plt.step(plot_df[['major_ST1_Up', 'major_ST2_Up', 'major_ST3_Up']].values, 'r', alpha=1, linewidth=3)  # major upper on color\n","  plt.step(plot_df[['major_ST1_Down', 'major_ST2_Down', 'major_ST3_Down']].values, 'b', alpha=1, linewidth=3)  # major lower on color\n","\n","  plt.step(plot_df[['middle_line']].values, 'fuchsia', alpha=1)  # middle \n","  plt.step(plot_df[['major_middle_line']].values, 'fuchsia', alpha=1, linewidth=3)  # major_middle \n","  \n","  plt.step(plot_df[['off_color_upper_st1', 'off_color_upper_st2', 'off_color_upper_st3']].values, 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df[['off_color_lower_st1', 'off_color_lower_st2', 'off_color_lower_st3']].values, 'b', alpha=1, linestyle=':')  # lower off color\n","  \n","  plt.step(plot_df[['off_color_upper_hst1', 'off_color_upper_hst2', 'off_color_upper_hst3']].values, 'r', alpha=1, linestyle=':', linewidth=3)  # major upper off color\n","  plt.step(plot_df[['off_color_lower_hst1', 'off_color_lower_hst2', 'off_color_lower_hst3']].values, 'b', alpha=1, linestyle=':', linewidth=3)  # major lower off color\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_long_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  plt.step(plot_df[['major_upper_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  plt.step(plot_df[['major_lower_middle']].values, 'g', linestyle='--', alpha=1, linewidth=3)  # major_middle \n","  \n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- on price indicator part ---------------------- #\n","\n","  # ---------------------- sma ---------------------- #\n","  # alpha = 1\n","  # for sm_i, sma in enumerate(ma_list):\n","  #   if sm_i > 0:\n","  #     lw = 5\n","  #   else:\n","  #     lw = 2\n","  #   plt.step(np.arange(len(plot_df)), plot_df[sma].values, alpha=alpha, color='black', linewidth=lw)\n","  #   alpha -= 0.2\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  # if i != initial_i:\n","  # if len(ep_idx_list_) > 1:\n","  \n","  # ------------- initial order ------------- #\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  for ep_i in range(len(ep_idx_list_)):\n","    plt.axvline(prev_plotsize + (ep_idx_list_[ep_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","  # plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  for sub_i in range(len(ep_tp_list[t_i][1])):\n","    plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline  \n","    plt.axvline(prev_plotsize + (tp_idx_list_[sub_i] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","\n","\n","  #         hedge ep & tp         #\n","  h_i = h_trade_list[t_i][1]\n","  if h_i is not None:\n","    plt.axvline(prev_plotsize + (h_i - ep_idx_list_[0]), linestyle='--')\n","    plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","    plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  if not static_lvrg:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\nlvrg : %s\\ntp_ratio : %.2f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i], lvrg_list[t_i], tp_ratio_list[t_i]))\n","  else:\n","    plt.title(\"%s ~ %s -> %.5f\\n %s\\n h_pr : %.5f\\ntp_ratio : %.2f\" % (ep_idx_list_[0], tp_idx_list_[-1], plot_pr_list[t_i], tp_state_list[t_i], h_plot_pr_list[t_i], tp_ratio_list[t_i]))\n","\n","  print(\"short real pr :\", (ep_tp_list[t_i][0] / ep_tp_list[t_i][1][sub_i] - fee - 1) * lvrg + 1)\n","  print(\"long real pr :\", (ep_tp_list[t_i][1][sub_i] / ep_tp_list[t_i][0] - fee - 1) * lvrg + 1)\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # ---------------------- outer price indi. ---------------------- #\n","  #           macd          #\n","  # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","    \n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=0.5, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for stoch in stoch_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(stoch_upper, linestyle='--')\n","  # plt.axhline(stoch_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- cctbbo ---------- #  \n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for cctbbo in cctbbo_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[cctbbo].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(50, linestyle='--')\n","  # plt.axhline(cctbbo_upper, linestyle='--')\n","  # plt.axhline(cctbbo_lower, linestyle='--')\n","  # plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  # plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","\n","  # ---------- ema_roc ---------- #  \n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for emaroc in emaroc_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[emaroc].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axvline(prev_plotsize + (tp_idx_list_[-1] - ep_idx_list_[0]), alpha=1, linestyle='--')\n","  plt.axvline(prev_plotsize - (ep_idx_list_[0] - open_list[t_i]), alpha=0.5, linestyle='--', color='lime')\n","  plt.axhline(0, linestyle='--')\n","\n","\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  if not save_plot:\n","    plt.show()\n","  \n","  else:\n","    # ---------- save mode ---------- #\n","    fig_name = plot_check_dir +  \"/%s.png\" % t_i\n","    plt.savefig(fig_name)\n","    print(fig_name, \"saved !\")\n","\n","  \n","  plt.close()\n","  print()\n","\n","  # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGuJu2j4Aby9"},"source":["# print()\n","for item in os.listdir(current_path + \"plot_check/\"):\n","  if item.endswith('png'):\n","    os.remove(current_path + \"plot_check/\" + item)\n","    print(current_path + \"plot_check/\" + item, \"removed !\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj9X6S1jJjER"},"source":["### plot nontp case"]},{"cell_type":"code","metadata":{"id":"Gb1jGrS4Jl8A"},"source":["prev_plotsize = 50\n","\n","# inversion = True\n","inversion = False\n","\n","# hedge = True\n","# hedge = False\n","\n","short_ver = False\n","\n","\n","if inversion:  \n","\n","    plot_pr_list = rev_np_pr\n","    h_plot_pr_list = h_rev_np_pr  # hedge\n","\n","else:\n","\n","    plot_pr_list = np_pr\n","    h_plot_pr_list = h_np_pr\n","\n","\n","\n","#         select plot columns       #\n","# basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","# sar_cols = [15, 18] # 15 ~ 19\n","# ichimoku_cols = [20, 21]  # 20 ~ 29\n","# # ichimoku_cols = [22, 23]  # 20 ~ 29\n","# ichimoku_cols2 = [22, 23]  # 20 ~ 29\n","# macd_cols = [30]  # 30 ~ 34\n","\n","# print(res_df.columns[basic_cols])\n","# break\n","\n","basic_list = ['open', 'high', 'low', 'close', 'minor_ST1_Up', 'minor_ST1_Down',\n","       'minor_ST2_Up', 'minor_ST2_Down', 'minor_ST3_Up', 'minor_ST3_Down',\n","       'middle_line', 'min_upper', 'max_lower']\n","# senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","# senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","# sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","sar_list = ['sar1', 'sar2', 'sar3']\n","\n","#     -------------- under price phase --------------    #\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","trix_list = ['trix1', 'trix2', 'trix3', 'trix4', 'trix5']\n","stoch_list = ['stoch']\n","fisher_list = ['fisher']\n","cctbbo_list = ['cctbbo']\n","\n","\n","#       \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + trix_list\n","input_colname = basic_list + senkoua_list + senkoub_list + sar_list + macd_list + stoch_list + fisher_list + cctbbo_list\n","price_colname = basic_list + senkoua_list + senkoub_list + sar_list \n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","if short_ver:\n","  nontp_indexs = nontp_short_indexs\n","  nontp_liqd_list = nontp_short_liqd_list\n","  nontp_pr_list = nontp_short_pr_list\n","  nontp_ep = nontp_short_ep_list\n","else:\n","  nontp_indexs = nontp_long_indexs\n","  nontp_liqd_list = nontp_long_liqd_list\n","  nontp_pr_list = nontp_long_pr_list\n","  nontp_ep = nontp_long_ep_list\n","\n","\n","for t_i, i in enumerate(nontp_indexs):\n","\n","  j = len(res_df) - 1\n","\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i == 1536:\n","  # # if 1800 < i < 1860:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","  # if (entry[i] == -1) and res_df['close'].iloc[i - 1] > upper_ep.iloc[i]:\n","  #   pass\n","  # else:\n","  #   continue\n","\n","  # if plot_pr_list[t_i] > 0.5:\n","  # if plot_pr_list[t_i] > 1.0:\n","  # # if plot_pr_list[t_i] < 1.0:\n","  #   continue\n","\n","  # plot_df = res_df.iloc[i - prev_plotsize:j + 1, input_cols]\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1][input_colname]\n","\n","\n","  #       keep off-color st with another variable         #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","\n","  # y_max = np.max(plot_df.iloc[:, [4, 6, 8]])\n","  # y_min = np.min(plot_df.iloc[:, [5, 7, 9]])\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  \n","  # y_max = max(np.max(plot_df.iloc[:, [4, 6, 8]]))\n","  # y_min = min(np.min(plot_df.iloc[:, [5, 7, 9]]))\n","  \n","  y_max = max(np.max(plot_df[price_colname]))\n","  y_min = min(np.min(plot_df[price_colname]))\n","  # print(\"y_max, y_min :\", y_max, y_min)\n","  # break\n","\n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, plot_df.iloc[:, [4]], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, plot_df.iloc[:, [6]], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, plot_df.iloc[:, [8]], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, plot_df.iloc[:, [5]], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, plot_df.iloc[:, [7]], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, plot_df.iloc[:, [9]], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[i - prev_plotsize:j + 1]\n","  plot_long_tp = long_tp.iloc[i - prev_plotsize:j + 1]  \n","\n","\n","\n","  # fig = plt.figure(figsize=(12, 16))\n","  fig = plt.figure(figsize=(12, 16))\n","  \n","  gs = gridspec.GridSpec(nrows=3, # row 몇 개 \n","                       ncols=1, # col 몇 개 \n","                       height_ratios=[3, 1, 1]\n","                      )\n","  \n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  # ax = fig.add_subplot(311)\n","  ax = fig.add_subplot(gs[0])\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.step(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  # plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  plt.step(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower on color\n","  plt.step(plot_df.values[:, [10]], 'fuchsia', alpha=1)  # middle\n","  \n","  plt.step(plot_df.values[:, -6:-3], 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.step(plot_df.values[:, -3:], 'b', alpha=1, linestyle=':')  # lower off color\n","\n","\n","\n","  # plt.step(np.arange(len(plot_df)), plot_upper_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","  # plt.step(np.arange(len(plot_df)),plot_lower_ep.values, alpha=1, linestyle='--', color='y')  # ep\n","\n","  plt.step(np.arange(len(plot_df)), plot_upper_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","  plt.step(np.arange(len(plot_df)), plot_lower_middle.values, alpha=1, linestyle='--', color='g')  # 2nd middle\n","\n","  # plt.step(np.arange(len(plot_df)), plot_short_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","  # plt.step(np.arange(len(plot_df)), plot_long_tp.values, alpha=1, linestyle=':', color='y')  # tp\n","\n","\n","\n","  # ---------------------- indicator part ---------------------- #\n","  \n","  #               sar               #\n","  alpha = 1\n","  markersize = 5\n","  for sar in sar_list:\n","    plt.step(plot_df[sar].values, 'c*', alpha=alpha, markersize=markersize, color='dodgerblue')  # sar mic\n","    markersize += 1\n","    alpha -= 0.1\n","\n","  # plt.step(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  #               cloud               #\n","  alpha = 0.7\n","  for senkoua, senkoub in zip(senkoua_list, senkoub_list):\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values, # ichimoku\n","                      where=plot_df[senkoua].values >= plot_df[senkoub].values, facecolor='g', alpha=alpha) # ichimoku\n","    plt.fill_between(np.arange(len(plot_df)), plot_df[senkoua].values, plot_df[senkoub].values,\n","                      where=plot_df[senkoua].values <= plot_df[senkoub].values, facecolor='r', alpha=alpha)  \n","    alpha -= 0.05\n","  \n","  # ------------------------------------------------------------- #\n","\n","\n","  #       ep & tp     #\n","  if i != initial_i:\n","    plt.axvline(prev_plotsize - (i - initial_i), alpha=0.5, linestyle='--')\n","  plt.axvline(prev_plotsize, alpha=0.5, linestyle='--')\n","  plt.axhline(nontp_ep[t_i], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='lime')  # ep line axhline\n","\n","  # for sub_i in range(len(ep_tp_list[t_i][1])):\n","  #   plt.axhline(ep_tp_list[t_i][1][sub_i], linestyle='-', xmin=0.75 + 0.05 * (sub_i + 1) , xmax=1, linewidth=3, color='lime')  # tp line axhline\n","    # plt.axhline(ep_tp_list[t_i][1], linestyle='-', xmin=0.9, xmax=1, linewidth=3)  # tp line axhline    \n","\n","  #         hedge ep & tp         #\n","  # h_i = h_trade_list[t_i][1]\n","  # if h_i is not None:\n","  #   plt.axvline(prev_plotsize + (h_i - i), linestyle='--')\n","  #   plt.axhline(h_ep_tp_list[t_i][0], linestyle='-', xmin=0.75, xmax=1, linewidth=3, color='magenta')  # ep line axhline\n","  #   plt.axhline(h_ep_tp_list[t_i][1], linestyle='-', xmin=0.85, xmax=1, linewidth=3, color='magenta')  # tp line axhline\n","\n","  \n","  #         check pr        #\n","  plt.title(\"%s ~ %s -> liqd : %.2f\\npr : %.2f\" % (i, j, nontp_liqd_list[t_i], nontp_pr_list[t_i]))\n","\n","  #           y lim         #\n","  plt.ylim(y_min, y_max)\n","\n","\n","  # #           macd          #\n","  # # plt.subplot(312)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for macd in macd_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[macd].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  # #           trix          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[2])\n","  # alpha = 1\n","  # for trix in trix_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[trix].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","\n","  \n","  #           fisher          #  \n","  # # plt.subplot(313)\n","  # plt.subplot(gs[1])\n","  # alpha = 1\n","  # for fisher in fisher_list:\n","  #   plt.step(np.arange(len(plot_df)), plot_df[fisher].values, 'g', alpha=alpha)\n","  #   # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","  #   alpha -= 0.2\n","  # plt.axvline(prev_plotsize, linestyle='--')\n","  # plt.axhline(0, linestyle='--')\n","  # plt.axhline(fisher_upper, linestyle='--')\n","  # plt.axhline(fisher_lower, linestyle='--')\n","\n","  #           stoch          #  \n","  # plt.subplot(313)\n","  plt.subplot(gs[1])\n","  alpha = 1\n","  for stoch in stoch_list:\n","    plt.step(np.arange(len(plot_df)), plot_df[stoch].values, 'g', alpha=alpha)\n","    # plt.fill_between(np.arange(len(plot_df)), 0, plot_df[macd].values, facecolor='g', alpha=alpha) \n","    alpha -= 0.2\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(50, linestyle='--')\n","  plt.axhline(stoch_upper, linestyle='--')\n","  plt.axhline(stoch_lower, linestyle='--')\n","\n","\n","\n","  # ---------------------- plot ---------------------- #\n","\n","  plt.show()\n","  # plt.draw()\n","  plt.close()\n","  print()\n","\n","  # break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXqR5bwGzqDW"},"source":["### specific plot v1"]},{"cell_type":"code","metadata":{"id":"UiCTTXJpZX1i"},"source":["prev_plotsize = 50\n","\n","# inversion = True\n","inversion = False\n","\n","if inversion:\n","  plot_pr_list = rev_np_pr\n","else:\n","  plot_pr_list = np_pr\n","\n","\n","\n","#         select plot columns       #\n","basic_cols = [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14] # you don't need to touch\n","\n","sar_cols = [15, 18] # 15 ~ 19\n","ichimoku_cols = [20, 21]  # 20 ~ 29\n","# ichimoku_cols = [22, 23]  # 20 ~ 29\n","ichimoku_cols2 = [22, 23]  # 20 ~ 29\n","macd_cols = [30]  # 30 ~ 34\n","\n","\n","senkoua_list = ['senkou_a1', 'senkou_a2', 'senkou_a3', 'senkou_a4', 'senkou_a5']\n","senkoub_list = ['senkou_b1', 'senkou_b2', 'senkou_b3', 'senkou_b4', 'senkou_b5']\n","sar_list = ['sar1', 'sar2', 'sar3', 'sar4', 'sar5']\n","macd_list = ['macd_hist1', 'macd_hist2', 'macd_hist3', 'macd_hist4', 'macd_hist5']\n","\n","input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols + ichimoku_cols2\n","# input_cols = basic_cols + sar_cols + ichimoku_cols + macd_cols\n","\n","\n","\n","\n","for t_i, (i, j) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if i <= 4860:\n","  # if i != 257:\n","  #   continue\n","\n","  # if tp_state_list[t_i] != 'd-open':\n","  #   continue\n","\n","\n","  if plot_pr_list[t_i] > 1.0:\n","  # if plot_pr_list[t_i] < 1.0:\n","    continue\n","\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1, input_cols]\n","\n","\n","  #       keep off-color st with another variable         #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","\n","  plot_df[\"off_color_upper_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, plot_df.iloc[:, [4]], np.nan)\n","  plot_df[\"off_color_upper_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, plot_df.iloc[:, [6]], np.nan)\n","  plot_df[\"off_color_upper_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, plot_df.iloc[:, [8]], np.nan)\n","  plot_df[\"off_color_lower_st1\"] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, plot_df.iloc[:, [5]], np.nan)\n","  plot_df[\"off_color_lower_st2\"] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, plot_df.iloc[:, [7]], np.nan)\n","  plot_df[\"off_color_lower_st3\"] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, plot_df.iloc[:, [9]], np.nan)\n","\n","\n","  #       replace st values with np.nan, using st trend     #\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  plot_upper_middle = (plot_df['middle_line'] + plot_df['min_upper']) / 2\n","  plot_lower_middle = (plot_df['middle_line'] + plot_df['max_lower']) / 2\n","\n","  plot_short_tp = short_tp.iloc[i - prev_plotsize:j + 1]\n","  plot_long_tp = long_tp.iloc[i - prev_plotsize:j + 1]  \n","\n","\n","\n","  fig = plt.figure(figsize=(12, 16))\n","  # fig = plt.figure(figsize=(8, 12))\n","  # ax = fig.add_subplot(111)\n","  ax = fig.add_subplot(211)\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper on color\n","  plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower on color\n","  plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","  \n","  plt.plot(plot_df.values[:, -6:-3], 'r', alpha=1, linestyle=':')  # upper off color\n","  plt.plot(plot_df.values[:, -3:], 'b', alpha=1, linestyle=':')  # lower off color\n","\n","  plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","  # plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  plt.plot(plot_upper_ep.values, alpha=1, linestyle='--')  # ep\n","  plt.plot(plot_lower_ep.values, alpha=1, linestyle='--')  # ep\n","\n","  plt.plot(plot_upper_middle.values, alpha=1, linestyle='--')  # middle\n","  plt.plot(plot_lower_middle.values, alpha=1, linestyle='--')  # middle\n","\n","  plt.plot(plot_short_tp.values, alpha=1, linestyle=':')  # tp\n","  plt.plot(plot_long_tp.values, alpha=1, linestyle=':')  # tp\n","\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14], # ichimoku\n","                    where=plot_df.values[:, 13] >= plot_df.values[:, 14], facecolor='g', alpha=0.5) # ichimoku\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 13], plot_df.values[:, 14],\n","                    where=plot_df.values[:, 13] <= plot_df.values[:, 14], facecolor='r', alpha=0.5)  \n","  \n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 16], plot_df.values[:, 17], # ichimoku\n","                    where=plot_df.values[:, 16] >= plot_df.values[:, 17], facecolor='g', alpha=0.3) # ichimoku\n","  plt.fill_between(np.arange(len(plot_df)), plot_df.values[:, 16], plot_df.values[:, 17],\n","                    where=plot_df.values[:, 16] <= plot_df.values[:, 17], facecolor='r', alpha=0.3)\n","\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(ep_tp_list[t_i][1], linestyle='-')  # tp line axhline\n","  plt.title(\"%s ~ %s -> %.5f\\n %s\" % (i, j, plot_pr_list[t_i], tp_state_list[t_i]))\n","\n","\n","  plt.subplot(212)\n","  plt.plot(plot_df.values[:, [15]], 'g', alpha=1)  # middle\n","  plt.axvline(prev_plotsize, linestyle='--')\n","  plt.axhline(0, linestyle='--')\n","\n","  plt.show()\n","  # plt.draw()\n","  plt.close()\n","  print()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-g7YY5BvMcLS"},"source":["### show detail values"]},{"cell_type":"code","metadata":{"id":"5TxQ3rDnKMa7"},"source":["i, j = 27267, 27268\n","print(\"upper_ep.iloc[i] :\", upper_ep.iloc[i])\n","print(\"short_tp.iloc[j] :\", short_tp.iloc[j])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AIl6EBuZNOL"},"source":["## none plot off-color st"]},{"cell_type":"code","metadata":{"id":"yaVxrNGzZgrF"},"source":["prev_plotsize = 50\n","\n","for t_i, (i, j) in enumerate(trade_list):\n","  # print(i, j)\n","\n","  if not(i >= prev_plotsize):\n","    continue\n","\n","  # if pr_list[t_i] >= 1:\n","  #   continue\n","\n","  plot_df = res_df.iloc[i - prev_plotsize:j + 1, [0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 16]]\n","\n","  #       replace st values with np.nan, using st trend     #\n","  st_trend_plot_df = res_df.iloc[i - prev_plotsize:j + 1, [7, 10, 13]]\n","  plot_df.iloc[:, [4]] = np.where(st_trend_plot_df.iloc[:, [0]] == 1, np.nan, plot_df.iloc[:, [4]])\n","  plot_df.iloc[:, [6]] = np.where(st_trend_plot_df.iloc[:, [1]] == 1, np.nan, plot_df.iloc[:, [6]])\n","  plot_df.iloc[:, [8]] = np.where(st_trend_plot_df.iloc[:, [2]] == 1, np.nan, plot_df.iloc[:, [8]])\n","  plot_df.iloc[:, [5]] = np.where(st_trend_plot_df.iloc[:, [0]] == -1, np.nan, plot_df.iloc[:, [5]])\n","  plot_df.iloc[:, [7]] = np.where(st_trend_plot_df.iloc[:, [1]] == -1, np.nan, plot_df.iloc[:, [7]])\n","  plot_df.iloc[:, [9]] = np.where(st_trend_plot_df.iloc[:, [2]] == -1, np.nan, plot_df.iloc[:, [9]])\n","\n","\n","  plot_upper_ep = upper_ep.iloc[i - prev_plotsize:j + 1]\n","  plot_lower_ep = lower_ep.iloc[i - prev_plotsize:j + 1]\n","\n","  fig = plt.figure(figsize=(8, 6))\n","  ax = fig.add_subplot(111)\n","\n","  # fig.show()\n","  # fig.canvas.draw()\n","\n","  temp_ohlc = plot_df.values[:, :4]\n","  index = np.arange(len(temp_ohlc))\n","  candle = np.hstack((np.reshape(index, (-1, 1)), temp_ohlc))\n","  mf.candlestick_ohlc(ax, candle, width=0.5, colorup='r', colordown='b')\n","\n","  # print(plot_df.values[:, 4:])\n","  plt.plot(plot_df.values[:, [4, 6, 8]], 'r', alpha=1)  # upper\n","  plt.plot(plot_df.values[:, [5, 7, 9]], 'b', alpha=1)  # lower\n","  plt.plot(plot_df.values[:, [10]], 'g', alpha=1)  # middle\n","\n","  plt.plot(plot_df.values[:, [11]], 'c*', alpha=1, markersize=5)  # sar mic\n","  plt.plot(plot_df.values[:, [12]], 'co', alpha=1, markersize=7)  # sar mac\n","\n","  plt.plot(plot_upper_ep.values, alpha=1, linestyle='--')  # ep\n","  plt.plot(plot_lower_ep.values, alpha=1, linestyle='--')  # ep\n","\n","  plt.axvline(prev_plotsize, linestyle='--')\n","\n","  plt.title(\"%s ~ %s -> %.5f\" % (i, j, pr_list[t_i]))\n","  plt.show()\n","  # plt.draw()\n","  plt.close()"],"execution_count":null,"outputs":[]}]}