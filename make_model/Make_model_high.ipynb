{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press model num :17\n",
      "(455547, 54, 5)\n",
      "(455547, 1)\n",
      "50743.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318882, 54, 5, 1)\n",
      "(68332, 54, 5, 1)\n",
      "(68333, 54, 5, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318882, 2)\n",
      "(68332, 2)\n",
      "(68333, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 54, 5, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 54, 5, 100)        1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 54, 5, 100)        400       \n",
      "_________________________________________________________________\n",
      "pool1_1 (MaxPooling2D)       (None, 27, 2, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 27, 2, 100)        90100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 2, 100)        400       \n",
      "_________________________________________________________________\n",
      "pool2_1 (MaxPooling2D)       (None, 13, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "drop2_1 (Dropout)            (None, 13, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1300)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               130100    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 222,202\n",
      "Trainable params: 221,802\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      " - 49s - loss: 0.3681 - accuracy: 0.8850 - val_loss: 0.3580 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35799, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      " - 47s - loss: 0.3513 - accuracy: 0.8875 - val_loss: 0.3181 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35799 to 0.31813, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "Epoch 3/100\n",
      " - 47s - loss: 0.3498 - accuracy: 0.8875 - val_loss: 0.3560 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31813\n",
      "Epoch 4/100\n",
      " - 47s - loss: 0.3495 - accuracy: 0.8875 - val_loss: 0.3022 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31813 to 0.30219, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "Epoch 5/100\n",
      " - 47s - loss: 0.3491 - accuracy: 0.8875 - val_loss: 0.2642 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30219 to 0.26422, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "Epoch 6/100\n",
      " - 47s - loss: 0.3488 - accuracy: 0.8875 - val_loss: 0.2677 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26422\n",
      "Epoch 7/100\n",
      " - 47s - loss: 0.3488 - accuracy: 0.8875 - val_loss: 0.2259 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26422 to 0.22591, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "Epoch 8/100\n",
      " - 46s - loss: 0.3486 - accuracy: 0.8875 - val_loss: 0.3012 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22591\n",
      "Epoch 9/100\n",
      " - 46s - loss: 0.3483 - accuracy: 0.8875 - val_loss: 0.3586 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22591\n",
      "Epoch 10/100\n",
      " - 47s - loss: 0.3483 - accuracy: 0.8875 - val_loss: 0.3037 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22591\n",
      "Epoch 11/100\n",
      " - 47s - loss: 0.3484 - accuracy: 0.8875 - val_loss: 0.3795 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22591\n",
      "Epoch 12/100\n",
      " - 46s - loss: 0.3482 - accuracy: 0.8875 - val_loss: 0.3948 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.22591\n",
      "Epoch 13/100\n",
      " - 47s - loss: 0.3481 - accuracy: 0.8875 - val_loss: 0.1972 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.22591 to 0.19717, saving model to model/rapid_ascending_high 54_17.hdf5\n",
      "Epoch 14/100\n",
      " - 48s - loss: 0.3481 - accuracy: 0.8875 - val_loss: 0.3171 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19717\n",
      "Epoch 15/100\n",
      " - 47s - loss: 0.3479 - accuracy: 0.8875 - val_loss: 0.3723 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19717\n",
      "Epoch 16/100\n",
      " - 47s - loss: 0.3479 - accuracy: 0.8875 - val_loss: 0.3833 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19717\n",
      "Epoch 17/100\n",
      " - 47s - loss: 0.3479 - accuracy: 0.8875 - val_loss: 0.3372 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.19717\n",
      "Epoch 18/100\n",
      " - 46s - loss: 0.3478 - accuracy: 0.8875 - val_loss: 0.2852 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19717\n",
      "Epoch 19/100\n",
      " - 46s - loss: 0.3478 - accuracy: 0.8875 - val_loss: 0.3152 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19717\n",
      "Epoch 20/100\n",
      " - 47s - loss: 0.3478 - accuracy: 0.8875 - val_loss: 0.2639 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19717\n",
      "Epoch 21/100\n",
      " - 46s - loss: 0.3476 - accuracy: 0.8875 - val_loss: 0.3102 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.19717\n",
      "Epoch 22/100\n",
      " - 46s - loss: 0.3476 - accuracy: 0.8875 - val_loss: 0.3102 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.19717\n",
      "Epoch 23/100\n",
      " - 46s - loss: 0.3477 - accuracy: 0.8875 - val_loss: 0.3609 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.19717\n",
      "Epoch 24/100\n",
      " - 46s - loss: 0.3475 - accuracy: 0.8875 - val_loss: 0.3360 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19717\n",
      "Epoch 25/100\n",
      " - 47s - loss: 0.3478 - accuracy: 0.8875 - val_loss: 0.3463 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.19717\n",
      "Epoch 26/100\n",
      " - 46s - loss: 0.3475 - accuracy: 0.8875 - val_loss: 0.3553 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.19717\n",
      "Epoch 27/100\n",
      " - 46s - loss: 0.3475 - accuracy: 0.8875 - val_loss: 0.3318 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.19717\n",
      "Epoch 28/100\n",
      " - 46s - loss: 0.3474 - accuracy: 0.8875 - val_loss: 0.3611 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.19717\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import scipy.misc \n",
    "from math import sqrt \n",
    "import itertools\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# input_data_length = int(input('input_data_length : '))\n",
    "input_data_length = 54\n",
    "model_num = input('Press model num :')\n",
    "\n",
    "Made_X = np.load('Made_X/Made_X %s_%s.npy' % (input_data_length, model_num))\n",
    "Made_Y = np.load('Made_X_high/Made_Y %s_%s.npy' % (input_data_length, model_num))\n",
    "\n",
    "print(Made_X.shape)\n",
    "print(Made_Y.shape)\n",
    "print(np.sum(Made_Y))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Made_Y)\n",
    "plt.show()\n",
    "\n",
    "row = Made_X.shape[1]\n",
    "col = Made_X.shape[2]\n",
    "\n",
    "total_len = len(Made_X)\n",
    "train_len = int(total_len * 0.7)\n",
    "val_len = int(total_len * 0.15)\n",
    "test_len = total_len - (train_len + val_len)\n",
    "\n",
    "X_train = Made_X[:train_len].astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "X_val = Made_X[train_len:train_len + val_len].astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "X_test = Made_X[train_len + val_len:].astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "Y_train = Made_Y[:train_len].astype('float32')\n",
    "Y_val = Made_Y[train_len:train_len + val_len].astype('float32')\n",
    "Y_test = Made_Y[train_len + val_len:].astype('float32')\n",
    "num_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "datagen = ImageDataGenerator( \n",
    "    rotation_range = 60,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.6,\n",
    "    height_shift_range=0.6,\n",
    "    fill_mode = 'nearest'\n",
    "    )\n",
    "\n",
    "testgen = ImageDataGenerator( \n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "batch_size = 128\n",
    "\n",
    "for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n",
    "    for i in range(0, 9): \n",
    "        pyplot.axis('off') \n",
    "        pyplot.subplot(330 + 1 + i) \n",
    "        pyplot.imshow(X_batch[i].reshape(input_data_length, col), cmap=pyplot.get_cmap('gray'))\n",
    "#         pyplot.imresize(row * 5, col * 5)\n",
    "    pyplot.axis('off') \n",
    "    pyplot.show() \n",
    "    break\n",
    "    \n",
    "    \n",
    "train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n",
    "val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, Y_test, batch_size=batch_size)\n",
    "\n",
    "print(len(train_flow))\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Input, Dense, Flatten, Dropout, BatchNormalization, Conv1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def FER_Model(input_shape=(input_data_length, col, 1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    conv1_fit = 100\n",
    "    conv2_fit = 100\n",
    "    conv3_fit = 128\n",
    "    # conv4_fit = 256\n",
    "    # conv5_fit = 256\n",
    "\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(conv1_fit, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    # conv1_2 = Conv2D(conv1_fit, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    # conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_1)\n",
    "    # drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n",
    "\n",
    "    #the 2-nd block\n",
    "    conv2_1 = Conv2D(conv2_fit, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(pool1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    # conv2_2 = Conv2D(conv2_fit, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    # conv2_2 = BatchNormalization()(conv2_2)\n",
    "    # conv2_3 = Conv2D(conv2_fit, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    # conv2_3 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_1)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n",
    "\n",
    "    #Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop2_1)\n",
    "    dense = Dense(100, activation='relu', name='dense')(flatten)\n",
    "    output = Dense(num_classes, activation='softmax', name = 'output')(dense)\n",
    "\n",
    "    # create model \n",
    "    model = Model(inputs =visible, outputs = output)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = FER_Model()\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# callbacks log 를 저장시키는 방법 예시\n",
    "from keras.callbacks import Callback\n",
    "import pickle\n",
    "\n",
    "class Checkpoint_History(Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []      \n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "    \n",
    "    \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "filepath=\"model/rapid_ascending_high %s_%s.hdf5\" % (input_data_length, model_num)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "checkpoint3 = EarlyStopping(monitor='val_loss', patience=15)\n",
    "callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n",
    "\n",
    "# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n",
    "\n",
    "# we iterate 200 times over the entire training set\n",
    "num_epochs = 100\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=2,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=val_flow,  \n",
    "                    validation_steps=len(X_val) / batch_size,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model/rapid_ascending_high %s_%s.hdf5' % (input_data_length, model_num))\n",
    "# model = load_model('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.hdf5' % input_data_length)\n",
    "loss = model.evaluate_generator(test_flow, steps=len(X_test) / batch_size) \n",
    "print(\"Test Loss \" + str(loss[0]))\n",
    "print(\"Test Acc: \" + str(loss[1]))\n",
    "\n",
    "loss = model.evaluate(X_val, Y_val) \n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "print(\"Val Loss \" + str(loss[0]))\n",
    "print(\"Val Acc: \" + str(loss[1]))\n",
    "\n",
    "#     Prediction    #\n",
    "Y_pred_ = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Y_pred = Y_pred_[:,[-1]]\n",
    "# print(Y_pred.shape)\n",
    "# print(Y_test.shape)\n",
    "Y_pred = np.argmax(Y_pred_, axis=1)\n",
    "t_te = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#     Manual processing     #\n",
    "Y_pred_one = Y_pred_[:, [-1]]\n",
    "max_value = np.max(Y_pred_one)\n",
    "print(max_value)\n",
    "\n",
    "limit_line = 0.9\n",
    "Y_pred_one = np.where(Y_pred_one > max_value * limit_line, 1, 0)\n",
    "\n",
    "# print(Y_pred_one)\n",
    "Y_pred_one = Y_pred_one.reshape(-1,)\n",
    "# print(Y_pred_1)\n",
    "# print(Y_pred.shape)\n",
    "# print(t_te.shape)\n",
    "\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(Y_test, 'purple', label='test')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(Y_pred_one, 'y', label='pred')\n",
    "plt.show()\n",
    "# plt.savefig('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.png' % input_data_length)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
