{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press model num :64\n",
      "(25070, 300, 300, 3)\n",
      "(25070, 1)\n",
      "(17549, 300, 300, 3)\n",
      "(3761, 300, 300, 3)\n",
      "(3760, 300, 300, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lab23/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "{0: 0.33568613948506065, 1: 99.14689265536722, 2: 91.40104166666667}\n",
      "(17549, 3)\n",
      "(3761, 3)\n",
      "(3760, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 300, 300, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 150, 150, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 75, 75, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 37, 128)       32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2654272   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 3,058,179\n",
      "Trainable params: 3,058,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      " - 192s - loss: 1.1997 - accuracy: 0.2027 - val_loss: 0.6357 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63570, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      " - 182s - loss: 0.9368 - accuracy: 0.5205 - val_loss: 0.9412 - val_accuracy: 0.6543\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.63570\n",
      "Epoch 3/100\n",
      " - 183s - loss: 0.6867 - accuracy: 0.5748 - val_loss: 0.6304 - val_accuracy: 0.7753\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63570 to 0.63043, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 4/100\n",
      " - 182s - loss: 0.4682 - accuracy: 0.6994 - val_loss: 0.4920 - val_accuracy: 0.7091\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63043 to 0.49205, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 5/100\n",
      " - 181s - loss: 0.3168 - accuracy: 0.7877 - val_loss: 0.3813 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49205 to 0.38129, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 6/100\n",
      " - 182s - loss: 0.2416 - accuracy: 0.8224 - val_loss: 0.3624 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38129 to 0.36237, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 7/100\n",
      " - 183s - loss: 0.2381 - accuracy: 0.8379 - val_loss: 0.7723 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36237\n",
      "Epoch 8/100\n",
      " - 182s - loss: 0.1385 - accuracy: 0.9051 - val_loss: 0.6708 - val_accuracy: 0.8040\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36237\n",
      "Epoch 9/100\n",
      " - 182s - loss: 0.1170 - accuracy: 0.9109 - val_loss: 0.1679 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36237 to 0.16792, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 10/100\n",
      " - 182s - loss: 0.0637 - accuracy: 0.9516 - val_loss: 0.1451 - val_accuracy: 0.9322\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.16792 to 0.14513, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 11/100\n",
      " - 182s - loss: 0.0458 - accuracy: 0.9659 - val_loss: 0.0924 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.14513 to 0.09240, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 12/100\n",
      " - 182s - loss: 0.0307 - accuracy: 0.9783 - val_loss: 0.1535 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09240\n",
      "Epoch 13/100\n",
      " - 182s - loss: 0.0308 - accuracy: 0.9760 - val_loss: 0.4992 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09240\n",
      "Epoch 14/100\n",
      " - 183s - loss: 0.0343 - accuracy: 0.9769 - val_loss: 0.0558 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09240 to 0.05583, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 15/100\n",
      " - 182s - loss: 0.0444 - accuracy: 0.9698 - val_loss: 0.2470 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05583\n",
      "Epoch 16/100\n",
      " - 183s - loss: 0.0542 - accuracy: 0.9630 - val_loss: 0.4711 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05583\n",
      "Epoch 17/100\n",
      " - 183s - loss: 0.0881 - accuracy: 0.9401 - val_loss: 0.1636 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05583\n",
      "Epoch 18/100\n",
      " - 182s - loss: 0.0835 - accuracy: 0.9466 - val_loss: 0.5861 - val_accuracy: 0.9556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05583\n",
      "Epoch 19/100\n",
      " - 182s - loss: 0.0363 - accuracy: 0.9748 - val_loss: 0.0185 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05583 to 0.01854, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 20/100\n",
      " - 183s - loss: 0.0231 - accuracy: 0.9836 - val_loss: 0.0531 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01854\n",
      "Epoch 21/100\n",
      " - 183s - loss: 0.0110 - accuracy: 0.9921 - val_loss: 0.1233 - val_accuracy: 0.9761\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01854\n",
      "Epoch 22/100\n",
      " - 183s - loss: 0.0070 - accuracy: 0.9949 - val_loss: 0.5393 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01854\n",
      "Epoch 23/100\n",
      " - 183s - loss: 0.0044 - accuracy: 0.9970 - val_loss: 0.8118 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01854\n",
      "Epoch 24/100\n",
      " - 184s - loss: 0.0029 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01854 to 0.00152, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 25/100\n",
      " - 184s - loss: 0.0019 - accuracy: 0.9986 - val_loss: 6.9122e-05 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00152 to 0.00007, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 26/100\n",
      " - 184s - loss: 0.0013 - accuracy: 0.9991 - val_loss: 0.4247 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00007\n",
      "Epoch 27/100\n",
      " - 183s - loss: 8.6774e-04 - accuracy: 0.9995 - val_loss: 4.2774e-05 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00007 to 0.00004, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 28/100\n",
      " - 186s - loss: 5.6424e-04 - accuracy: 0.9998 - val_loss: 0.3992 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00004\n",
      "Epoch 29/100\n",
      " - 191s - loss: 4.3195e-04 - accuracy: 0.9999 - val_loss: 1.3370 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00004\n",
      "Epoch 30/100\n",
      " - 215s - loss: 2.7959e-04 - accuracy: 0.9999 - val_loss: 1.8345e-04 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00004\n",
      "Epoch 31/100\n",
      " - 215s - loss: 1.9598e-04 - accuracy: 1.0000 - val_loss: 1.4223e-05 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00004 to 0.00001, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 32/100\n",
      " - 213s - loss: 1.4397e-04 - accuracy: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00001\n",
      "Epoch 33/100\n",
      " - 215s - loss: 1.1231e-04 - accuracy: 1.0000 - val_loss: 1.1313e-04 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00001\n",
      "Epoch 34/100\n",
      " - 214s - loss: 9.0803e-05 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00001\n",
      "Epoch 35/100\n",
      " - 215s - loss: 7.1789e-05 - accuracy: 1.0000 - val_loss: 3.6887e-05 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00001\n",
      "Epoch 36/100\n",
      " - 212s - loss: 5.9461e-05 - accuracy: 1.0000 - val_loss: 2.5041e-05 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00001\n",
      "Epoch 37/100\n",
      " - 212s - loss: 4.9909e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00001\n",
      "Epoch 38/100\n",
      " - 214s - loss: 4.0042e-05 - accuracy: 1.0000 - val_loss: 0.9198 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00001\n",
      "Epoch 39/100\n",
      " - 213s - loss: 3.3066e-05 - accuracy: 1.0000 - val_loss: 2.5520e-06 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00001 to 0.00000, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 40/100\n",
      " - 214s - loss: 2.7871e-05 - accuracy: 1.0000 - val_loss: 2.5758e-04 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00000\n",
      "Epoch 41/100\n",
      " - 212s - loss: 2.3831e-05 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00000\n",
      "Epoch 42/100\n",
      " - 215s - loss: 2.1346e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00000\n",
      "Epoch 43/100\n",
      " - 214s - loss: 1.7009e-05 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00000\n",
      "Epoch 44/100\n",
      " - 212s - loss: 1.3825e-05 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00000\n",
      "Epoch 45/100\n",
      " - 214s - loss: 1.1660e-05 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00000\n",
      "Epoch 46/100\n",
      " - 212s - loss: 9.7418e-06 - accuracy: 1.0000 - val_loss: 9.5695e-05 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00000\n",
      "Epoch 47/100\n",
      " - 205s - loss: 8.2102e-06 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00000\n",
      "Epoch 48/100\n",
      " - 206s - loss: 6.9658e-06 - accuracy: 1.0000 - val_loss: 6.4906e-05 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00000\n",
      "Epoch 49/100\n",
      " - 205s - loss: 6.0098e-06 - accuracy: 1.0000 - val_loss: 5.8677e-04 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00000\n",
      "Epoch 50/100\n",
      " - 205s - loss: 5.0636e-06 - accuracy: 1.0000 - val_loss: 2.8221e-07 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 51/100\n",
      " - 207s - loss: 4.3504e-06 - accuracy: 1.0000 - val_loss: 7.1768e-07 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00000\n",
      "Epoch 52/100\n",
      " - 205s - loss: 3.5752e-06 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00000\n",
      "Epoch 53/100\n",
      " - 206s - loss: 3.1093e-06 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00000\n",
      "Epoch 54/100\n",
      " - 203s - loss: 2.6341e-06 - accuracy: 1.0000 - val_loss: 8.1364e-04 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00000\n",
      "Epoch 55/100\n",
      " - 206s - loss: 2.3061e-06 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00000\n",
      "Epoch 56/100\n",
      " - 205s - loss: 1.9230e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to model/rapid_ascending 30_64_chart.hdf5\n",
      "Epoch 57/100\n",
      " - 207s - loss: 1.6327e-06 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00000\n",
      "Epoch 58/100\n",
      " - 208s - loss: 1.3869e-06 - accuracy: 1.0000 - val_loss: 2.3403 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00000\n",
      "Epoch 59/100\n",
      " - 205s - loss: 1.1964e-06 - accuracy: 1.0000 - val_loss: 1.2164e-07 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00000\n",
      "Epoch 60/100\n",
      " - 207s - loss: 1.0168e-06 - accuracy: 1.0000 - val_loss: 1.8003e-07 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00000\n",
      "Epoch 61/100\n",
      " - 205s - loss: 8.5692e-07 - accuracy: 1.0000 - val_loss: 3.6544e-04 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00000\n",
      "Epoch 62/100\n",
      " - 204s - loss: 7.4461e-07 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00000\n",
      "Epoch 63/100\n",
      " - 205s - loss: 6.3246e-07 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00000\n",
      "Epoch 64/100\n",
      " - 206s - loss: 5.4031e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00000\n",
      "Epoch 65/100\n",
      " - 209s - loss: 4.6535e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00000\n",
      "Epoch 66/100\n",
      " - 214s - loss: 3.9233e-07 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00000\n",
      "Epoch 67/100\n",
      " - 215s - loss: 3.3865e-07 - accuracy: 1.0000 - val_loss: 3.1868e-06 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00000\n",
      "Epoch 68/100\n",
      " - 215s - loss: 2.8940e-07 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00000\n",
      "Epoch 69/100\n",
      " - 212s - loss: 2.4931e-07 - accuracy: 1.0000 - val_loss: 5.4245e-06 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00000\n",
      "Epoch 70/100\n",
      " - 214s - loss: 2.1440e-07 - accuracy: 1.0000 - val_loss: 5.6268e-06 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00000\n",
      "Epoch 71/100\n",
      " - 212s - loss: 1.8753e-07 - accuracy: 1.0000 - val_loss: 3.4696 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc \n",
    "from math import sqrt \n",
    "import itertools\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "input_data_length = 30\n",
    "model_num = input('Press model num :')\n",
    "\n",
    "Made_X = np.load('Made_X/Made_X %s_%s.npy' % (input_data_length,\n",
    "                                              model_num)).astype(np.float32) / 255.\n",
    "Made_Y = np.load('Made_X/Made_Y %s_%s.npy' % (input_data_length,\n",
    "                                              model_num)).astype(np.float32)\n",
    "\n",
    "print(Made_X.shape)\n",
    "print(Made_Y.shape)\n",
    "\n",
    "row = Made_X.shape[1]\n",
    "col = Made_X.shape[2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Made_X, Made_Y, test_size=0.3,\n",
    "                                                   shuffle=False)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# Data Class Weight\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(Y_train[:, 0])\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  np.unique(Y_train[:, 0]),\n",
    "                                                  Y_train[:, 0])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)\n",
    "\n",
    "num_classes = 3\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "datagen = ImageDataGenerator( \n",
    "#     rotation_range = 60,\n",
    "#     zoom_range = 0.6,\n",
    "#     shear_range = 0.6,\n",
    "#     horizontal_flip = True,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "    fill_mode = 'nearest'\n",
    "    )\n",
    "\n",
    "testgen = ImageDataGenerator( \n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64\n",
    "\n",
    "for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n",
    "    for i in range(0, 9): \n",
    "        plt.axis('off') \n",
    "        plt.subplot(330 + 1 + i) \n",
    "        plt.imshow(X_batch[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off') \n",
    "    plt.show() \n",
    "    break\n",
    "    \n",
    "    \n",
    "train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n",
    "val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, Y_test, batch_size=batch_size)\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "import keras.layers as layers\n",
    "# from keras.layers import LSTM, TimeDistributed, Input, Dense, Flatten, Dropout, BatchNormalization, Conv1D, LeakyReLU\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.pooling import MaxPooling2D, MaxPooling1D\n",
    "# from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def FER_Model(input_shape=(row, col, 3)):\n",
    "    # first input model\n",
    "    visible = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    net = layers.Conv2D(64, kernel_size=3, padding='same')(visible)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_1 = net\n",
    "\n",
    "    net = layers.Conv2D(128, kernel_size=3, padding='same')(net)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_2 = net\n",
    "\n",
    "    net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_3 = net\n",
    "\n",
    "    net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    net = layers.Flatten()(net)\n",
    "    net = layers.Dense(64)(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.Dense(num_classes, activation='softmax')(net)\n",
    "\n",
    "    # create model \n",
    "    model = Model(inputs =visible, outputs = net)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = FER_Model()\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model('model/rapid_ascending %s_%s_chart.hdf5' % (input_data_length, model_num))\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "       \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "filepath=\"model/rapid_ascending %s_%s_chart.hdf5\" % (input_data_length, model_num)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "checkpoint3 = EarlyStopping(monitor='val_loss', patience=15)\n",
    "callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n",
    "\n",
    "# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n",
    "\n",
    "# we iterate 200 times over the entire training set\n",
    "num_epochs = 100\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=2,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    class_weight=class_weights,\n",
    "                    validation_data=val_flow,  \n",
    "                    validation_steps=len(X_val) / batch_size,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model/rapid_ascending %s_%s_chart.hdf5' % (input_data_length, model_num))\n",
    "# model = load_model('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.hdf5' % input_data_length)\n",
    "# loss = model.evaluate_generator(test_flow, steps=len(X_test) / batch_size) \n",
    "# print(\"Test Loss \" + str(loss[0]))\n",
    "# print(\"Test Acc: \" + str(loss[1]))\n",
    "\n",
    "# loss = model.evaluate(X_val, Y_val) \n",
    "# print(X_val.shape)\n",
    "# print(Y_val.shape)\n",
    "\n",
    "# print(\"Val Loss \" + str(loss[0]))\n",
    "# print(\"Val Acc: \" + str(loss[1]))\n",
    "\n",
    "#     Prediction    #\n",
    "Y_pred_ = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Y_pred = Y_pred_[:,[-1]]\n",
    "# print(Y_pred.shape)\n",
    "# print(Y_test.shape)\n",
    "Y_pred = np.argmax(Y_pred_, axis=1)\n",
    "t_te = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#     Manual processing     #\n",
    "Y_pred_one = Y_pred_[:, [-1]]\n",
    "print(Y_pred_)\n",
    "max_value = np.max(Y_pred_, axis=0)\n",
    "print(max_value)\n",
    "\n",
    "limit_line = 0.9\n",
    "Y_pred_one = np.where(Y_pred_one > max_value * limit_line, 1, 0)\n",
    "\n",
    "# print(Y_pred_one)\n",
    "Y_pred_one = Y_pred_one.reshape(-1,)\n",
    "# print(Y_pred_1)\n",
    "# print(Y_pred.shape)\n",
    "# print(t_te.shape)\n",
    "\n",
    "# fail = 0\n",
    "# fail2 = 0\n",
    "# for i in range(len(Y_pred)):\n",
    "#   if Y_pred_1[i] != t_te[i]:\n",
    "#     fail += 1\n",
    "\n",
    "#   if Y_pred[i] != t_te[i]:\n",
    "#     fail2 += 1\n",
    "\n",
    "# print(1 - fail / len(Y_pred))\n",
    "# print(1 - fail2 / len(Y_pred))\n",
    "\n",
    "# print(np.sum(Y_pred), np.sum(t_te))\n",
    "# print('Y_pred / Y_test :', np.sum(Y_pred) / np.sum(t_te))\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(Y_test, 'purple', label='test')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(Y_pred_one, 'y', label='pred')\n",
    "plt.show()\n",
    "# plt.savefig('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.png' % input_data_length)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
