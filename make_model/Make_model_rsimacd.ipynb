{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238688, 30, 5)\n",
      "(238688, 1)\n",
      "(167081, 30, 5, 1)\n",
      "(71607, 30, 5, 1)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "{0: 0.8092657173302334, 1: 1.308366352915381}\n",
      "(167081, 2)\n",
      "(71607, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAADnCAYAAAAXbUOsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAQ80lEQVR4nO3dO49V1RvH8S8qchEGQRQRMIhKAppgjPQ2JsbCxphoYaUvwc7Cd+AbsNDOxlhYqomXhsJLHOKFQZAo4HAdhxkYbur8C31mP2vY/302R5BZJ99PYzwbyUmWe53fuj1r2fz8PJIUbrvVX0DS0mKnIKlgpyCpYKcgqWCnIKlwR9fDS5cuzQO89tprAPz0008Lz3bt2gXAxMQEAPv27Vt2c76ibrQPPvhgHuCNN94AYM2aNQvPvvrqq+Kz2dlZ27UiV69enQfYu3cvAJcuXVp4Njs7C8DFixcBmJqaam1bk4KkQmdSOHnyJAC33347AGvXrl14duHChZv4tXQzLV++HIA77vi7+f/444+FZ3feeect+U66MaJtV65cCcCff/658Oy22/plAJOCpEJnUhgbGwPg6tWrQNP7gEmhZvfeey/QjDdzu+ZfFtXn008/Bdrfz77vrElBUqEzKVy+fBmAK1euAM3cAsD58+dv4tfSzfTNN98ATbvG3ALAX3/9dUu+k26MZcv+XlBoa9uYO8qftTEpSCrYKUgqdOaIu+66C4Dp6WmgXK6KjRAuYdXnpZdeAuDtt98GmolkgLvvvvuaz1SPEydOAM3wIYYT0H9oaFKQVOhMCmfPngXgzJkzAGzYsGHhWSxvmBTqc/ToUaDZzJJ/TSy6U7fFk4h5iTm3cxeTgqTCoANRAJw7dw6AFStWLDzLW2NVl5g3iKSQl5pVt5gLioTQd2tzZlKQVOhMCrHCEKlgbm5u4VkcvFB9jh8/DjTtmcehkQ4HbXDR0hSbCuOdzUmh73yRSUFSofPn4L777gOaMWeeR8jzC6rL999/DzTt6erD6IiVwlgdzG0b8w2DVgxNCpIKnUkhdkCtWrXqmmex29EDNPV55JFHgPZfjPjMxFCnSAOxozH+eT1MCpIKnUnh119/BZpViJwYYuY6F+hQHWL1IVJeHnf+m/Vt3Xo7duwAmtXBnOT7zgPa8pIKnUlh06ZNAGzcuBFoiq5Asysul5BWHeIMS8wftBVudcdqnXbv3g20v5+RFAa9syYFSQU7BUmFzuHD77//DjS3BeVlqoiZDh/qE8OHmEDOE1Cx6cXNaXX6+uuvi3/Ph936Vuo2KUgqdCaFY8eOAU0qsKDKaIiJ47ZDbbZx3eIWt7ZNaJEUBpXaMylIKvQqshJjz2xmZubmfCPddKdPnwaaX5G8wSU+61u6S0tLbBuIo+95HsE5BUlD6UwKsYFl8SoENCkif6Y6RHvGr0qeR4g2d26hTouPTOfVB4usSBpKZ1KIQzFR4imX6HLMWa+HHnoIaA6z5V+Q+Mwj8XV6+umnAXjnnXeA8s7XWG3KxxXamBQkFTqTQsxWRon3PM50x1u9Ll68CHQfnTYJ1un+++8HYPPmzQBMTk5e82cG3RhvUpBU6EwKsbIQKw25xHtbiTbVYf/+/UDTrjkB9i3uqaUp5v3ifEt+Z/ueUzIpSCrYKUgqdA4f1q9fX/x7XsowXtZry5Ytxb/n5UdrM9Yt2nL16tVAubmwbdKxjf8HSCp0JoVY3oh6b/lAxbp16675THXYuXMnANu2bQOabc/QHKuenp7+77+Y/rWowB4TjDnR9z3EaFKQVOhMCidOnADa7xw0IdQr7giNVJCLbgxzo5CWjpgTivm//M7GprWBf8eN/1qSataZFOLYZRykyOkgNkl4P0B9xsfHgWbeIK84TE1N3ZLvpBsj3tkojJTnFCIpDDqiYFKQVOhMCnGkNtY685bJ6G1MCvWJGeqTJ08CzQ3i0CQFi+fUKdJAJIUo5ArNfJFJQdJ16UwKsfOtLRW4861ejz/+ONCeBuKXpW/pLi0tZ8+eBZo9CbmMf99U75stqdCZFI4cOQLA2NgYUO6Rz6XZVJcff/wRaHYy5jmFGIs6p1CnmCeKY9J99yZkJgVJhV77FOLEVS7S4JxCvV544QUAPvnkEwAmJiYWnj355JMAHDx48L//YvrX4kxSW2GkvnyzJRXsFCQVrmubc9wJAN4LULMffvgBaNozjsYDnDp16pZ8J90YUXk9DkTlIX/fCt0mBUmFzqSwffv2v//QP8uP+XCFR6frFUeno33zZNTx48dvxVfSDRKbzmKjUj4Wn++V7GJSkFToTAoPP/ww0NzxkAtweINQveJm4hCb06AZk6pO8V7GnF9+Z00KkoayzIMvkjKTgqSCnYKkgp2CpIKdgqSCnYKkgp2CpIKdgqSCnYKkgp2CpIKdgqSCnYKkgp2CpELn0elXXnllHuDDDz8EyiIrcWdAfDY3N+dZ6kq8++678wCvvvoqUJbWe/nll4GmWMd7771nu1ZkcnJyHmDv3r1AeStUFFyJf87MzLS2rUlBUqEzKUSBhuhtcpEGj1zXK25/irJs09PTC8/i3oD8meoRBZGi2Eq+n6XvO2tSkFToVeI9ykTnXscS7/WK+wUjAeZ7QYe5e1BLx+nTp4t/z2UTTQqShtKZFB544AGgWWHI6SCvRKgucct0XAKT5w/i3tC4TER1iTa95557gLIQb6SGmZmZzr/DpCCpYKcgqdBrorHt2vm+NeS19IyPjwPNknOeaFx8J4TqEpsKY6iQh/n5XskuJgVJhc6kEJMVXbdBuYmpPo8++ijQ3Aea2zffPaj67NixA4CNGzcCcObMmYVnkQwHpUGTgqRCZ1I4evQo0J4GYnnSOyXrE3dHrl+/HoDZ2dmFZ7EFOn+mesT8UGxXz/MI58+f7/V3mBQkFTqTwmOPPfb3H/qn94kxKDSrD253rk9saIkxZl5Jcptz3Y4cOQLA3NwcAMuXL1941jf9mRQkFTqTQoh9CnluwVWHekW6iy2xedtrHL11TqFOMU+0YsUKoEz3fZkUJBU6k0IclGlLCsP0QFoaNmzYADSHn2JuAdp3r6oesaMxDrTl1UF3NEoaSq85hTBMwQYtPbFeHb8cefUhZq1Vt0h/OflFUZ1BadCkIKnQmRRid1skBHcvjob4pcjlv4NnH+oWK0oxX5TbM1YkBrWxSUFSwU5BUuG6jk47fBgN0Y5t93nExiaXJuu0uLhKXhCIdnb4IOm6DL0kqdHh8vLoiHsf8oa00LdCt0lBUqFXUoiE4IGo0RC/ItGG+fi77Vq3KHMQc0K5bdve4zYmBUmFzqSwefNmoH0mum+vo6UnDrrFoTbL9Y+OKKrS9c4OYlKQVOhMCnv27Pn7D/0zTsnbYtvGLKrD9u3bgWZLbD5SG/dM9j1mq6Vl8WG3fNFPW/m9NiYFSYXOpBCXRsRBijx/0JYeVIepqSmgSQU57eVfFtUn3tm2NNB37sikIKnQ+bMQY8749fBXZDTEqlLsj8+XkKpukQZi92J+Z+PMQy773sakIKlgpyCp0KvyUvwzT0hFBHHpqj4RMVeuXAmUh2c89Fa33377DWiGCnkTU9/tAyYFSYVeM4eRCmJpEtzeXLO4TTx+RfLEk0vMdYvl5rYbpiM95Pe4jUlBUqEzKRw7dgxoUkHb8obqs2vXLgA+/vhjYPASleqxdetWoJnry8vNfdO9SUFSodecQsxa5plp75Ks18GDB4FmTiEnQOeK6jY5OQk0K0p9S7BlJgVJhc6ksLi0U17z9BelftGebSXeVae1a9cCTUIYZgu7SUFSoTMpjI+PA81MZk4KfQs2aOl57rnnAPjiiy+Acn7IS2BGQ6wODrNb1f8DJBU6k8LY2BjQ3sO4R75eMR8UKc/Vh9ERK0sxN5R3qFpkRdJQeu1obCvYEONQx6D1iV+MSHttxT1Vp7gUOlYd8mrSoDMPwTdaUsFOQVKhc/gQGyHahggOG+r15ZdfAjA3NweUbRmfWY+zTnHYbdWqVUA50RjDh0GHGX2zJRU6fw6il2k7EOWSZL22bNkCNEem8zJk22eqx+zsLNCU2svlEiP9mRQkXZfOpNB2YGbxM9Vn9+7dADzzzDMAfPvttwvPYh5p//79//0X078WWwUi8eUt7G5zljSUZY4dJWUmBUkFOwVJBTsFSQU7BUkFOwVJBTsFSQU7BUkFOwVJBTsFSQU7BUkFOwVJBTsFSYXOo9OHDx+eh+Ym23wv3Ysvvgg0RzQPHTpk1ZVKvPXWW/MAr7/+OlAWVHniiSeAprDO+Pi47VqRAwcOzAO8//77AExNTS0827dvX/HZxMREa9uaFCQVelXnjPJNubCKtxPXa8eOHUBTsivf9RAlu7z/oU6R+uL9zOk+l2brYlKQVOhMClHKKXodbyceLW0lu2zXukUZ99WrVwPeJSnpBuhMCnEvXdwpmecR/EWpV1wUEuNNk8LoiPQXiSHPKfTl/wGSCnYKkgq9liQjXnor1GiIZauImnkyyuredYsl5bGxMaBs22jvQUwKkgqdSSGWMNp6mOiR/GWpz4kTJ4CmffMN07Zn3eJdffDBB4FycSDSQ9763MakIKnQa/NSbIS4fPnywrNY6sifqQ6xJHn+/HmgXIacm5u75jPVI9otbhaPNoZmmXLg33Hjv5akmnUmhUgB0cO4eWk0rFu3DmjGn7ldY37BA291ijmhOOwWbQ0eiJI0pF77FGJ/Qj5Q4Sx1/SIV5LXsSIAmhTpFm27cuBGAmZmZhWceiJI0lM6kcPz48f/7zFWHes3OzgKwdu1aAC5cuLDwLMaiedZa9YgEHytMsTcBmmJJg5gUJBV6zSlEKsg7G6PXybvhVIdoz2i73K7OJdQt2i/mAWOPEcDFixd7/R0mBUmFzp/5Q4cOAbBmzRqgXPOMnW95zKI6bN26FWhWGjz7MDrivYz5opwC49kgJgVJBTsFSYXO4cOmTZsAOHv2LFAeqDBm1itu/Go7Op3rNao+MdEYk8m5MJLbnCUNpTMpHDhwAGh6n7xNMpY38uSj6tK2fV11i4QQk4ptN0QNqvBsUpBU6LUkGT1LbIGFcmus6rJnzx6gmRfK4043L9Vt8+bNAJw5cwYo2zYOvpkUJF2XzqQQySAKPeaCj5Z7r9fPP//8f5+ZFOoWxw/iQFueL/JAlKShdCaFmK2M+YPp6enmP/Qg1MjIpfXcf1K306dPA827mrc5X7lypdffYVKQVOiVFBYnBuh/BZWWnsXXAOZ00PaZ6hG7j0+ePAmUKw0enZY0lF4TAzEWMSmMhsUrR64kjY5YdYiVwjhCDf1XlkwKkgp2CpIKvYYPMVTImx9y7TfVzeHD6Dh8+DDQDCPOnTu38KxvO5sUJBU6k8Li45d5oqLvDbZaep5//nkA3nzzzWueuRRZt++++w5o7n3IE41uc5Y0lF5zCnEwKpfqiqSQ7yFUHSYmJm71V9BNEvMGp06dAmD9+vULz1ySlDSUXkkhDj+1bYdVfbZt2wY0CTCPNaNd+x6e0dLy0UcfAbBz506gKbZyPUwKkgq9iqy0le1ylrpeMbaMortxCzU0x6hNCnWKUnuxcphvD4+b3gYxKUgqdCaF2LUYR6edUxgNXbdO913L1tIU72ikwXxcOhde7mJSkFToTApxO/HRo0eBMilEQUh/Werzyy+/AM2+k1yOzbmEukWCX3x9HPQvoWhSkFTodfYhep/c07j6UL+26wDdoVq3SHqREHJS6MukIKlgpyCp0Dl8eOqppwD47LPPgPJAhUuS9YrjtDFsyEPBmHT0pqg6LT6omCeO84RyF5OCpEJnUnj22WcB+Pzzz4Gyp8nHqFWXKNHV1oa2a91i63ocnc6Jb9Bt08GkIKnQmRSOHDkCtG9QcumqXnEwpm3+wBui6rZp0yYAJicngfI9jWMLg95dk4KkwjJ/ESRlJgVJBTsFSQU7BUkFOwVJBTsFSQU7BUmF/wE0AK6xeJ2MHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 30, 5, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 5, 64)         640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 2, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 2, 128)        73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 15, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                57408     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 132,034\n",
      "Trainable params: 132,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " - 6s - loss: 0.4569 - accuracy: 0.7717 - val_loss: 0.4055 - val_accuracy: 0.7952\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79520, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 2/500\n",
      " - 5s - loss: 0.4095 - accuracy: 0.7967 - val_loss: 0.4079 - val_accuracy: 0.7997\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.79520 to 0.79968, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 3/500\n",
      " - 5s - loss: 0.3953 - accuracy: 0.8041 - val_loss: 0.5795 - val_accuracy: 0.8132\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79968 to 0.81320, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 4/500\n",
      " - 5s - loss: 0.3886 - accuracy: 0.8093 - val_loss: 0.3661 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.81320\n",
      "Epoch 5/500\n",
      " - 5s - loss: 0.3846 - accuracy: 0.8120 - val_loss: 0.2807 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81320\n",
      "Epoch 6/500\n",
      " - 5s - loss: 0.3810 - accuracy: 0.8150 - val_loss: 0.4493 - val_accuracy: 0.8062\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81320\n",
      "Epoch 7/500\n",
      " - 5s - loss: 0.3785 - accuracy: 0.8172 - val_loss: 0.6398 - val_accuracy: 0.8122\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81320\n",
      "Epoch 8/500\n",
      " - 5s - loss: 0.3764 - accuracy: 0.8186 - val_loss: 0.3551 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81320 to 0.81981, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 9/500\n",
      " - 5s - loss: 0.3745 - accuracy: 0.8203 - val_loss: 0.3166 - val_accuracy: 0.8169\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81981\n",
      "Epoch 10/500\n",
      " - 5s - loss: 0.3725 - accuracy: 0.8210 - val_loss: 0.3886 - val_accuracy: 0.8157\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81981\n",
      "Epoch 11/500\n",
      " - 5s - loss: 0.3714 - accuracy: 0.8219 - val_loss: 0.4180 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81981 to 0.82144, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 12/500\n",
      " - 5s - loss: 0.3698 - accuracy: 0.8232 - val_loss: 0.6588 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82144\n",
      "Epoch 13/500\n",
      " - 5s - loss: 0.3684 - accuracy: 0.8235 - val_loss: 0.2813 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82144 to 0.82690, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 14/500\n",
      " - 5s - loss: 0.3672 - accuracy: 0.8244 - val_loss: 0.5855 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82690\n",
      "Epoch 15/500\n",
      " - 5s - loss: 0.3664 - accuracy: 0.8249 - val_loss: 0.2837 - val_accuracy: 0.8233\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82690\n",
      "Epoch 16/500\n",
      " - 5s - loss: 0.3651 - accuracy: 0.8256 - val_loss: 0.3201 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82690\n",
      "Epoch 17/500\n",
      " - 5s - loss: 0.3642 - accuracy: 0.8262 - val_loss: 0.4471 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82690 to 0.82817, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 18/500\n",
      " - 5s - loss: 0.3636 - accuracy: 0.8265 - val_loss: 0.3071 - val_accuracy: 0.8158\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82817\n",
      "Epoch 19/500\n",
      " - 5s - loss: 0.3629 - accuracy: 0.8269 - val_loss: 0.3981 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82817\n",
      "Epoch 20/500\n",
      " - 5s - loss: 0.3626 - accuracy: 0.8270 - val_loss: 0.4147 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82817\n",
      "Epoch 21/500\n",
      " - 5s - loss: 0.3617 - accuracy: 0.8280 - val_loss: 0.4353 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.82817 to 0.82918, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 22/500\n",
      " - 5s - loss: 0.3607 - accuracy: 0.8283 - val_loss: 0.2517 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82918\n",
      "Epoch 23/500\n",
      " - 5s - loss: 0.3605 - accuracy: 0.8284 - val_loss: 0.4878 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82918\n",
      "Epoch 24/500\n",
      " - 5s - loss: 0.3597 - accuracy: 0.8284 - val_loss: 0.4209 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82918\n",
      "Epoch 25/500\n",
      " - 5s - loss: 0.3593 - accuracy: 0.8289 - val_loss: 0.2451 - val_accuracy: 0.8235\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82918\n",
      "Epoch 26/500\n",
      " - 5s - loss: 0.3581 - accuracy: 0.8295 - val_loss: 0.2305 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82918\n",
      "Epoch 27/500\n",
      " - 5s - loss: 0.3580 - accuracy: 0.8293 - val_loss: 0.4158 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.82918 to 0.82979, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 28/500\n",
      " - 5s - loss: 0.3576 - accuracy: 0.8297 - val_loss: 0.2504 - val_accuracy: 0.8316\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.82979 to 0.83164, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 29/500\n",
      " - 5s - loss: 0.3570 - accuracy: 0.8294 - val_loss: 0.4603 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83164\n",
      "Epoch 30/500\n",
      " - 5s - loss: 0.3564 - accuracy: 0.8295 - val_loss: 0.3739 - val_accuracy: 0.8227\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83164\n",
      "Epoch 31/500\n",
      " - 5s - loss: 0.3560 - accuracy: 0.8306 - val_loss: 0.2765 - val_accuracy: 0.8216\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83164\n",
      "Epoch 32/500\n",
      " - 5s - loss: 0.3552 - accuracy: 0.8307 - val_loss: 0.3724 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.83164 to 0.83328, saving model to model/rapid_ascending 30_85_rsimacd.hdf5\n",
      "Epoch 33/500\n",
      " - 5s - loss: 0.3549 - accuracy: 0.8304 - val_loss: 0.3909 - val_accuracy: 0.8227\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.83328\n",
      "Epoch 34/500\n",
      " - 5s - loss: 0.3542 - accuracy: 0.8312 - val_loss: 0.3340 - val_accuracy: 0.8305\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.83328\n",
      "Epoch 35/500\n",
      " - 5s - loss: 0.3541 - accuracy: 0.8317 - val_loss: 0.5093 - val_accuracy: 0.8174\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.83328\n",
      "Epoch 36/500\n",
      " - 5s - loss: 0.3535 - accuracy: 0.8319 - val_loss: 0.2651 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.83328\n",
      "Epoch 37/500\n",
      " - 5s - loss: 0.3526 - accuracy: 0.8322 - val_loss: 0.3644 - val_accuracy: 0.8289\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.83328\n",
      "Epoch 38/500\n",
      " - 5s - loss: 0.3526 - accuracy: 0.8325 - val_loss: 0.3678 - val_accuracy: 0.8212\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.83328\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.3518 - accuracy: 0.8332 - val_loss: 0.3010 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.83328\n",
      "Epoch 40/500\n",
      " - 5s - loss: 0.3514 - accuracy: 0.8327 - val_loss: 0.4023 - val_accuracy: 0.8244\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.83328\n",
      "Epoch 41/500\n",
      " - 5s - loss: 0.3511 - accuracy: 0.8325 - val_loss: 0.3922 - val_accuracy: 0.8262\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.83328\n",
      "Epoch 42/500\n",
      " - 5s - loss: 0.3506 - accuracy: 0.8329 - val_loss: 0.3246 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.83328\n",
      "Epoch 43/500\n",
      " - 5s - loss: 0.3500 - accuracy: 0.8335 - val_loss: 0.2435 - val_accuracy: 0.8289\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.83328\n",
      "Epoch 44/500\n",
      " - 5s - loss: 0.3492 - accuracy: 0.8341 - val_loss: 0.3093 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.83328\n",
      "Epoch 45/500\n",
      " - 5s - loss: 0.3493 - accuracy: 0.8339 - val_loss: 0.3007 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.83328\n",
      "Epoch 46/500\n",
      " - 5s - loss: 0.3489 - accuracy: 0.8342 - val_loss: 0.3219 - val_accuracy: 0.8270\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.83328\n",
      "Epoch 47/500\n",
      " - 5s - loss: 0.3481 - accuracy: 0.8347 - val_loss: 0.4253 - val_accuracy: 0.8202\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.83328\n",
      "Epoch 48/500\n",
      " - 5s - loss: 0.3478 - accuracy: 0.8342 - val_loss: 0.4583 - val_accuracy: 0.8262\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.83328\n",
      "Epoch 49/500\n",
      " - 5s - loss: 0.3478 - accuracy: 0.8348 - val_loss: 0.4351 - val_accuracy: 0.8285\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.83328\n",
      "Epoch 50/500\n",
      " - 5s - loss: 0.3468 - accuracy: 0.8348 - val_loss: 0.4355 - val_accuracy: 0.8249\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.83328\n",
      "Epoch 51/500\n",
      " - 5s - loss: 0.3466 - accuracy: 0.8350 - val_loss: 0.2900 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.83328\n",
      "Epoch 52/500\n",
      " - 5s - loss: 0.3460 - accuracy: 0.8355 - val_loss: 0.4044 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.83328\n",
      "Epoch 53/500\n",
      " - 5s - loss: 0.3456 - accuracy: 0.8355 - val_loss: 0.3143 - val_accuracy: 0.8138\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.83328\n",
      "Epoch 54/500\n",
      " - 5s - loss: 0.3452 - accuracy: 0.8358 - val_loss: 0.4375 - val_accuracy: 0.8267\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.83328\n",
      "Epoch 55/500\n",
      " - 5s - loss: 0.3444 - accuracy: 0.8361 - val_loss: 0.3970 - val_accuracy: 0.8199\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.83328\n",
      "Epoch 56/500\n",
      " - 5s - loss: 0.3446 - accuracy: 0.8368 - val_loss: 0.4819 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.83328\n",
      "Epoch 57/500\n",
      " - 5s - loss: 0.3439 - accuracy: 0.8357 - val_loss: 0.3883 - val_accuracy: 0.8299\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.83328\n",
      "Epoch 58/500\n",
      " - 5s - loss: 0.3437 - accuracy: 0.8365 - val_loss: 0.4904 - val_accuracy: 0.7987\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.83328\n",
      "Epoch 59/500\n",
      " - 5s - loss: 0.3428 - accuracy: 0.8370 - val_loss: 0.3282 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.83328\n",
      "Epoch 60/500\n",
      " - 5s - loss: 0.3425 - accuracy: 0.8372 - val_loss: 0.4694 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.83328\n",
      "Epoch 61/500\n",
      " - 5s - loss: 0.3420 - accuracy: 0.8374 - val_loss: 0.3776 - val_accuracy: 0.8284\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.83328\n",
      "Epoch 62/500\n",
      " - 5s - loss: 0.3422 - accuracy: 0.8377 - val_loss: 0.3694 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.83328\n",
      "Epoch 63/500\n",
      " - 5s - loss: 0.3418 - accuracy: 0.8373 - val_loss: 0.4541 - val_accuracy: 0.8228\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.83328\n",
      "Epoch 64/500\n",
      " - 5s - loss: 0.3410 - accuracy: 0.8384 - val_loss: 0.4064 - val_accuracy: 0.8253\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.83328\n",
      "Epoch 65/500\n",
      " - 5s - loss: 0.3409 - accuracy: 0.8383 - val_loss: 0.4275 - val_accuracy: 0.8230\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.83328\n",
      "Epoch 66/500\n",
      " - 5s - loss: 0.3401 - accuracy: 0.8383 - val_loss: 0.2631 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.83328\n",
      "Epoch 67/500\n",
      " - 5s - loss: 0.3395 - accuracy: 0.8385 - val_loss: 0.3382 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.83328\n",
      "Epoch 68/500\n",
      " - 5s - loss: 0.3393 - accuracy: 0.8385 - val_loss: 0.3613 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.83328\n",
      "Epoch 69/500\n",
      " - 5s - loss: 0.3388 - accuracy: 0.8393 - val_loss: 0.5902 - val_accuracy: 0.7903\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.83328\n",
      "Epoch 70/500\n",
      " - 5s - loss: 0.3378 - accuracy: 0.8394 - val_loss: 0.3457 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.83328\n",
      "Epoch 71/500\n",
      " - 5s - loss: 0.3381 - accuracy: 0.8395 - val_loss: 0.2961 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.83328\n",
      "Epoch 72/500\n",
      " - 5s - loss: 0.3373 - accuracy: 0.8396 - val_loss: 0.3118 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.83328\n",
      "Epoch 73/500\n",
      " - 5s - loss: 0.3372 - accuracy: 0.8403 - val_loss: 0.4377 - val_accuracy: 0.8276\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.83328\n",
      "Epoch 74/500\n",
      " - 5s - loss: 0.3370 - accuracy: 0.8395 - val_loss: 0.3828 - val_accuracy: 0.8267\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.83328\n",
      "Epoch 75/500\n",
      " - 5s - loss: 0.3357 - accuracy: 0.8413 - val_loss: 0.2501 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.83328\n",
      "Epoch 76/500\n",
      " - 5s - loss: 0.3353 - accuracy: 0.8406 - val_loss: 0.3497 - val_accuracy: 0.8245\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.83328\n",
      "Epoch 77/500\n",
      " - 5s - loss: 0.3353 - accuracy: 0.8408 - val_loss: 0.1700 - val_accuracy: 0.8204\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.83328\n",
      "Epoch 78/500\n",
      " - 5s - loss: 0.3346 - accuracy: 0.8408 - val_loss: 0.3298 - val_accuracy: 0.8241\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.83328\n",
      "Epoch 79/500\n",
      " - 5s - loss: 0.3343 - accuracy: 0.8411 - val_loss: 0.2865 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.83328\n",
      "Epoch 80/500\n",
      " - 5s - loss: 0.3335 - accuracy: 0.8414 - val_loss: 0.4459 - val_accuracy: 0.8253\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.83328\n",
      "Epoch 81/500\n",
      " - 5s - loss: 0.3337 - accuracy: 0.8418 - val_loss: 0.3680 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.83328\n",
      "Epoch 82/500\n",
      " - 5s - loss: 0.3325 - accuracy: 0.8422 - val_loss: 0.5739 - val_accuracy: 0.8175\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.83328\n",
      "Epoch 83/500\n",
      " - 5s - loss: 0.3326 - accuracy: 0.8426 - val_loss: 0.4354 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.83328\n",
      "Epoch 84/500\n",
      " - 5s - loss: 0.3312 - accuracy: 0.8424 - val_loss: 0.2224 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.83328\n",
      "Epoch 85/500\n",
      " - 5s - loss: 0.3320 - accuracy: 0.8429 - val_loss: 0.2714 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.83328\n",
      "Epoch 86/500\n",
      " - 5s - loss: 0.3315 - accuracy: 0.8428 - val_loss: 0.3145 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.83328\n",
      "Epoch 87/500\n",
      " - 5s - loss: 0.3301 - accuracy: 0.8432 - val_loss: 0.4024 - val_accuracy: 0.8004\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.83328\n",
      "Epoch 88/500\n",
      " - 5s - loss: 0.3303 - accuracy: 0.8433 - val_loss: 0.4043 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.83328\n",
      "Epoch 89/500\n",
      " - 5s - loss: 0.3299 - accuracy: 0.8442 - val_loss: 0.4705 - val_accuracy: 0.8265\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.83328\n",
      "Epoch 90/500\n",
      " - 5s - loss: 0.3290 - accuracy: 0.8442 - val_loss: 0.3693 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.83328\n",
      "Epoch 91/500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import scipy.misc \n",
    "from math import sqrt \n",
    "import itertools\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "input_data_length = 30\n",
    "model_num = 85\n",
    "num_classes = 2\n",
    "\n",
    "Made_X = np.load('Made_X/Made_X %s_%s.npy' % (input_data_length, model_num))\n",
    "Made_Y = np.load('Made_X/Made_Y %s_%s.npy' % (input_data_length, model_num)).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#       dataset 분리      #\n",
    "# dataX 구성 : VOLUME, MA, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC \n",
    "# dataX 구성 : VOLUME, EMA1, EMA2, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC, MACD_ZERO\n",
    "Made_X = Made_X[:, :,[8, 9, 10, 11, 12]]\n",
    "print(Made_X.shape)\n",
    "print(Made_Y.shape)\n",
    "\n",
    "row = Made_X.shape[1]\n",
    "col = Made_X.shape[2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(Made_X, Made_Y, test_size=0.3,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "X_train = X_train.astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "X_val = X_val.astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# Data Class Weight\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(Y_train[:, 0])\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  np.unique(Y_train[:, 0]),\n",
    "                                                  Y_train[:, 0])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "# class_weights[1] *= 0.97\n",
    "# class_weights[2] *= 0.97\n",
    "print(class_weights)\n",
    "# quit()\n",
    "\n",
    "Y_train = Y_train.astype('float32')\n",
    "Y_val = Y_val.astype('float32')\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, num_classes)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "datagen = ImageDataGenerator( \n",
    "#     rotation_range = 60,\n",
    "#     zoom_range = 0.6,\n",
    "#     shear_range = 0.6,\n",
    "#     horizontal_flip = True,\n",
    "#     width_shift_range=0.6,\n",
    "#     height_shift_range=0.6,\n",
    "    fill_mode = 'nearest'\n",
    "    )\n",
    "\n",
    "testgen = ImageDataGenerator( \n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "batch_size = 128\n",
    "\n",
    "for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n",
    "    for i in range(0, 9): \n",
    "        pyplot.axis('off') \n",
    "        pyplot.subplot(330 + 1 + i) \n",
    "        pyplot.imshow(X_batch[i].reshape(input_data_length, col), cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.axis('off') \n",
    "    pyplot.show() \n",
    "    break\n",
    "    \n",
    "    \n",
    "train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n",
    "val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def FER_Model(input_shape=(row, col, 1)):\n",
    "    # first input model\n",
    "    visible = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    net = layers.Conv2D(64, kernel_size=3, padding='same')(visible)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_1 = net\n",
    "\n",
    "    net = layers.Conv2D(128, kernel_size=3, padding='same')(net)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_2 = net\n",
    "\n",
    "#     net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n",
    "#     # net = layers.Activation('relu')(net)\n",
    "#     net = layers.LeakyReLU()(net)\n",
    "#     net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "#     shortcut_3 = net\n",
    "\n",
    "#     net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n",
    "#     # net = layers.Activation('relu')(net)\n",
    "#     net = layers.LeakyReLU()(net)\n",
    "#     net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    net = layers.Flatten()(net)\n",
    "    net = layers.Dense(64)(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.Dense(num_classes, activation='softmax')(net)\n",
    "\n",
    "    # create model \n",
    "    model = Model(inputs =visible, outputs = net)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = FER_Model()\n",
    "# from keras.models import load_model\n",
    "# model = load_model('model/rapid_ascending %s_%s_rsimacd.hdf5' % (input_data_length, model_num))\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "filepath=\"model/rapid_ascending %s_%s_rsimacd.hdf5\" % (input_data_length, model_num)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "checkpoint3 = EarlyStopping(monitor='val_accuracy', patience=100)\n",
    "callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n",
    "\n",
    "# keras.callbacks.Callback 로 부터 log 를 받아와 history log 를 작성할 수 있다.\n",
    "\n",
    "# we iterate 200 times over the entire training set\n",
    "num_epochs = 500\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=2,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    class_weight=class_weights,\n",
    "                    validation_data=val_flow,  \n",
    "                    validation_steps=len(X_val) / batch_size,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model/rapid_ascending %s_%s.hdf5' % (input_data_length, model_num))\n",
    "# model = load_model('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.hdf5' % input_data_length)\n",
    "# loss = model.evaluate_generator(test_flow, steps=len(X_test) / batch_size) \n",
    "# print(\"Test Loss \" + str(loss[0]))\n",
    "# print(\"Test Acc: \" + str(loss[1]))\n",
    "\n",
    "# loss = model.evaluate(X_val, Y_val) \n",
    "# print(X_val.shape)\n",
    "# print(Y_val.shape)\n",
    "\n",
    "# print(\"Val Loss \" + str(loss[0]))\n",
    "# print(\"Val Acc: \" + str(loss[1]))\n",
    "\n",
    "#     Prediction    #\n",
    "Y_pred_ = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Y_pred = Y_pred_[:,[-1]]\n",
    "# print(Y_pred.shape)\n",
    "# print(Y_test.shape)\n",
    "Y_pred = np.argmax(Y_pred_, axis=1)\n",
    "t_te = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#     Manual processing     #\n",
    "Y_pred_one = Y_pred_[:, [-1]]\n",
    "print(Y_pred_)\n",
    "max_value = np.max(Y_pred_one)\n",
    "print(max_value)\n",
    "\n",
    "limit_line = 0.9\n",
    "Y_pred_one = np.where(Y_pred_one > max_value * limit_line, 1, 0)\n",
    "\n",
    "# print(Y_pred_one)\n",
    "Y_pred_one = Y_pred_one.reshape(-1,)\n",
    "# print(Y_pred_1)\n",
    "# print(Y_pred.shape)\n",
    "# print(t_te.shape)\n",
    "\n",
    "# fail = 0\n",
    "# fail2 = 0\n",
    "# for i in range(len(Y_pred)):\n",
    "#   if Y_pred_1[i] != t_te[i]:\n",
    "#     fail += 1\n",
    "\n",
    "#   if Y_pred[i] != t_te[i]:\n",
    "#     fail2 += 1\n",
    "\n",
    "# print(1 - fail / len(Y_pred))\n",
    "# print(1 - fail2 / len(Y_pred))\n",
    "\n",
    "# print(np.sum(Y_pred), np.sum(t_te))\n",
    "# print('Y_pred / Y_test :', np.sum(Y_pred) / np.sum(t_te))\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(Y_test, 'purple', label='test')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(Y_pred_one, 'y', label='pred')\n",
    "plt.show()\n",
    "# plt.savefig('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.png' % input_data_length)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
