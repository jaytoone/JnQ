{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238688, 30, 5)\n",
      "(238688, 1)\n",
      "(167081, 30, 5, 1)\n",
      "(71607, 30, 5, 1)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "{0: 0.5097414087669628, 1: 26.163639210773567}\n",
      "(167081, 2)\n",
      "(71607, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 6s - loss: 0.4808 - accuracy: 0.8128 - val_loss: 1.1792 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76877, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/500\n",
      " - 6s - loss: 0.3854 - accuracy: 0.8193 - val_loss: 0.9016 - val_accuracy: 0.7576\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76877\n",
      "Epoch 3/500\n",
      " - 6s - loss: 0.3537 - accuracy: 0.8235 - val_loss: 0.5845 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76877 to 0.81595, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 4/500\n",
      " - 6s - loss: 0.3396 - accuracy: 0.8270 - val_loss: 0.7226 - val_accuracy: 0.8350\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81595 to 0.83500, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 5/500\n",
      " - 6s - loss: 0.3215 - accuracy: 0.8323 - val_loss: 0.4530 - val_accuracy: 0.8038\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.83500\n",
      "Epoch 6/500\n",
      " - 6s - loss: 0.3080 - accuracy: 0.8349 - val_loss: 0.4997 - val_accuracy: 0.8091\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.83500\n",
      "Epoch 7/500\n",
      " - 6s - loss: 0.3016 - accuracy: 0.8371 - val_loss: 0.3789 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83500 to 0.83834, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 8/500\n",
      " - 6s - loss: 0.2934 - accuracy: 0.8390 - val_loss: 0.5662 - val_accuracy: 0.8108\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83834\n",
      "Epoch 9/500\n",
      " - 6s - loss: 0.2926 - accuracy: 0.8405 - val_loss: 0.1204 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83834 to 0.89575, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 10/500\n",
      " - 6s - loss: 0.2819 - accuracy: 0.8439 - val_loss: 0.2401 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.89575\n",
      "Epoch 11/500\n",
      " - 6s - loss: 0.2827 - accuracy: 0.8432 - val_loss: 0.2310 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.89575\n",
      "Epoch 12/500\n",
      " - 6s - loss: 0.2691 - accuracy: 0.8497 - val_loss: 0.5238 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89575\n",
      "Epoch 13/500\n",
      " - 6s - loss: 0.2696 - accuracy: 0.8490 - val_loss: 0.3965 - val_accuracy: 0.8390\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89575\n",
      "Epoch 14/500\n",
      " - 6s - loss: 0.2688 - accuracy: 0.8496 - val_loss: 0.2589 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89575\n",
      "Epoch 15/500\n",
      " - 6s - loss: 0.2625 - accuracy: 0.8522 - val_loss: 0.4075 - val_accuracy: 0.8416\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89575\n",
      "Epoch 16/500\n",
      " - 6s - loss: 0.2567 - accuracy: 0.8538 - val_loss: 0.2904 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.89575\n",
      "Epoch 17/500\n",
      " - 6s - loss: 0.2553 - accuracy: 0.8552 - val_loss: 0.3601 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89575\n",
      "Epoch 18/500\n",
      " - 6s - loss: 0.2527 - accuracy: 0.8567 - val_loss: 0.2156 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89575\n",
      "Epoch 19/500\n",
      " - 6s - loss: 0.2515 - accuracy: 0.8574 - val_loss: 0.4613 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89575\n",
      "Epoch 20/500\n",
      " - 6s - loss: 0.2457 - accuracy: 0.8596 - val_loss: 0.2784 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89575\n",
      "Epoch 21/500\n",
      " - 6s - loss: 0.2438 - accuracy: 0.8597 - val_loss: 0.3492 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89575\n",
      "Epoch 22/500\n",
      " - 6s - loss: 0.2422 - accuracy: 0.8611 - val_loss: 0.2368 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89575\n",
      "Epoch 23/500\n",
      " - 6s - loss: 0.2394 - accuracy: 0.8621 - val_loss: 0.1499 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89575\n",
      "Epoch 24/500\n",
      " - 6s - loss: 0.2360 - accuracy: 0.8639 - val_loss: 0.3271 - val_accuracy: 0.8354\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.89575\n",
      "Epoch 25/500\n",
      " - 6s - loss: 0.2363 - accuracy: 0.8644 - val_loss: 0.2804 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.89575\n",
      "Epoch 26/500\n",
      " - 6s - loss: 0.2314 - accuracy: 0.8664 - val_loss: 0.1950 - val_accuracy: 0.8946\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.89575\n",
      "Epoch 27/500\n",
      " - 6s - loss: 0.2310 - accuracy: 0.8670 - val_loss: 0.3696 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.89575\n",
      "Epoch 28/500\n",
      " - 6s - loss: 0.2293 - accuracy: 0.8667 - val_loss: 0.1630 - val_accuracy: 0.8960\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.89575 to 0.89603, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 29/500\n",
      " - 6s - loss: 0.2280 - accuracy: 0.8688 - val_loss: 0.3873 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.89603\n",
      "Epoch 30/500\n",
      " - 6s - loss: 0.2242 - accuracy: 0.8701 - val_loss: 0.1551 - val_accuracy: 0.8859\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.89603\n",
      "Epoch 31/500\n",
      " - 6s - loss: 0.2243 - accuracy: 0.8715 - val_loss: 0.3525 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.89603\n",
      "Epoch 32/500\n",
      " - 6s - loss: 0.2209 - accuracy: 0.8722 - val_loss: 0.4903 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.89603\n",
      "Epoch 33/500\n",
      " - 6s - loss: 0.2210 - accuracy: 0.8733 - val_loss: 0.1233 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.89603\n",
      "Epoch 34/500\n",
      " - 6s - loss: 0.2215 - accuracy: 0.8731 - val_loss: 0.1285 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.89603\n",
      "Epoch 35/500\n",
      " - 6s - loss: 0.2175 - accuracy: 0.8749 - val_loss: 0.2890 - val_accuracy: 0.8824\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.89603\n",
      "Epoch 36/500\n",
      " - 6s - loss: 0.2164 - accuracy: 0.8753 - val_loss: 0.1448 - val_accuracy: 0.8814\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.89603\n",
      "Epoch 37/500\n",
      " - 6s - loss: 0.2124 - accuracy: 0.8762 - val_loss: 0.3553 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.89603\n",
      "Epoch 38/500\n",
      " - 6s - loss: 0.2129 - accuracy: 0.8765 - val_loss: 0.3080 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.89603\n",
      "Epoch 39/500\n",
      " - 6s - loss: 0.2094 - accuracy: 0.8792 - val_loss: 1.1514 - val_accuracy: 0.8430\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.89603\n",
      "Epoch 40/500\n",
      " - 6s - loss: 0.2133 - accuracy: 0.8767 - val_loss: 0.3310 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.89603\n",
      "Epoch 41/500\n",
      " - 6s - loss: 0.2095 - accuracy: 0.8792 - val_loss: 0.4631 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.89603\n",
      "Epoch 42/500\n",
      " - 6s - loss: 0.2057 - accuracy: 0.8807 - val_loss: 0.2469 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.89603\n",
      "Epoch 43/500\n",
      " - 6s - loss: 0.2049 - accuracy: 0.8812 - val_loss: 0.2555 - val_accuracy: 0.8708\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.89603\n",
      "Epoch 44/500\n",
      " - 6s - loss: 0.2084 - accuracy: 0.8804 - val_loss: 0.2509 - val_accuracy: 0.8964\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.89603 to 0.89642, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 45/500\n",
      " - 6s - loss: 0.2007 - accuracy: 0.8826 - val_loss: 0.2870 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.89642\n",
      "Epoch 46/500\n",
      " - 6s - loss: 0.2035 - accuracy: 0.8834 - val_loss: 0.2769 - val_accuracy: 0.8789\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.89642\n",
      "Epoch 47/500\n",
      " - 6s - loss: 0.1970 - accuracy: 0.8848 - val_loss: 0.2245 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.89642\n",
      "Epoch 48/500\n",
      " - 6s - loss: 0.2039 - accuracy: 0.8832 - val_loss: 0.1611 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.89642\n",
      "Epoch 49/500\n",
      " - 6s - loss: 0.1981 - accuracy: 0.8852 - val_loss: 0.1332 - val_accuracy: 0.8712\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.89642\n",
      "Epoch 50/500\n",
      " - 6s - loss: 0.1929 - accuracy: 0.8880 - val_loss: 0.2449 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.89642\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.1949 - accuracy: 0.8867 - val_loss: 0.3854 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.89642\n",
      "Epoch 52/500\n",
      " - 6s - loss: 0.1951 - accuracy: 0.8873 - val_loss: 0.2535 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.89642\n",
      "Epoch 53/500\n",
      " - 6s - loss: 0.1930 - accuracy: 0.8875 - val_loss: 0.1202 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.89642\n",
      "Epoch 54/500\n",
      " - 6s - loss: 0.1903 - accuracy: 0.8893 - val_loss: 0.3070 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.89642\n",
      "Epoch 55/500\n",
      " - 6s - loss: 0.1890 - accuracy: 0.8900 - val_loss: 0.5541 - val_accuracy: 0.8585\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.89642\n",
      "Epoch 56/500\n",
      " - 6s - loss: 0.1918 - accuracy: 0.8898 - val_loss: 0.2095 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.89642\n",
      "Epoch 57/500\n",
      " - 6s - loss: 0.1859 - accuracy: 0.8920 - val_loss: 0.2968 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.89642\n",
      "Epoch 58/500\n",
      " - 6s - loss: 0.1852 - accuracy: 0.8930 - val_loss: 0.1326 - val_accuracy: 0.8949\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.89642\n",
      "Epoch 59/500\n",
      " - 6s - loss: 0.1835 - accuracy: 0.8931 - val_loss: 0.1004 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.89642 to 0.90398, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 60/500\n",
      " - 6s - loss: 0.1910 - accuracy: 0.8913 - val_loss: 0.4206 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90398\n",
      "Epoch 61/500\n",
      " - 6s - loss: 0.1839 - accuracy: 0.8933 - val_loss: 0.1746 - val_accuracy: 0.8812\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90398\n",
      "Epoch 62/500\n",
      " - 6s - loss: 0.1810 - accuracy: 0.8954 - val_loss: 0.4566 - val_accuracy: 0.8782\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90398\n",
      "Epoch 63/500\n",
      " - 6s - loss: 0.1859 - accuracy: 0.8930 - val_loss: 0.2509 - val_accuracy: 0.8759\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90398\n",
      "Epoch 64/500\n",
      " - 6s - loss: 0.1800 - accuracy: 0.8953 - val_loss: 0.2392 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.90398 to 0.90815, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 65/500\n",
      " - 6s - loss: 0.1800 - accuracy: 0.8964 - val_loss: 0.2786 - val_accuracy: 0.8802\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90815\n",
      "Epoch 66/500\n",
      " - 6s - loss: 0.1809 - accuracy: 0.8959 - val_loss: 0.0742 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90815\n",
      "Epoch 67/500\n",
      " - 6s - loss: 0.1760 - accuracy: 0.8980 - val_loss: 0.2699 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90815\n",
      "Epoch 68/500\n",
      " - 6s - loss: 0.1781 - accuracy: 0.8976 - val_loss: 0.1688 - val_accuracy: 0.8924\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90815\n",
      "Epoch 69/500\n",
      " - 6s - loss: 0.1784 - accuracy: 0.8979 - val_loss: 0.2877 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90815\n",
      "Epoch 70/500\n",
      " - 6s - loss: 0.1757 - accuracy: 0.8992 - val_loss: 0.0986 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90815\n",
      "Epoch 71/500\n",
      " - 6s - loss: 0.1726 - accuracy: 0.9004 - val_loss: 0.1420 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90815\n",
      "Epoch 72/500\n",
      " - 6s - loss: 0.1750 - accuracy: 0.9001 - val_loss: 0.1559 - val_accuracy: 0.8824\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90815\n",
      "Epoch 73/500\n",
      " - 6s - loss: 0.1762 - accuracy: 0.8993 - val_loss: 0.6052 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90815\n",
      "Epoch 74/500\n",
      " - 6s - loss: 0.1659 - accuracy: 0.9034 - val_loss: 0.1568 - val_accuracy: 0.8824\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90815\n",
      "Epoch 75/500\n",
      " - 6s - loss: 0.1691 - accuracy: 0.9026 - val_loss: 0.2140 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90815\n",
      "Epoch 76/500\n",
      " - 6s - loss: 0.1704 - accuracy: 0.9019 - val_loss: 0.2161 - val_accuracy: 0.8928\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90815\n",
      "Epoch 77/500\n",
      " - 6s - loss: 0.1713 - accuracy: 0.9018 - val_loss: 0.4166 - val_accuracy: 0.9020\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90815\n",
      "Epoch 78/500\n",
      " - 6s - loss: 0.1651 - accuracy: 0.9041 - val_loss: 0.1651 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90815\n",
      "Epoch 79/500\n",
      " - 6s - loss: 0.1640 - accuracy: 0.9054 - val_loss: 0.3719 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90815\n",
      "Epoch 80/500\n",
      " - 6s - loss: 0.1670 - accuracy: 0.9044 - val_loss: 0.4376 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90815\n",
      "Epoch 81/500\n",
      " - 6s - loss: 0.1646 - accuracy: 0.9060 - val_loss: 0.2825 - val_accuracy: 0.8998\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90815\n",
      "Epoch 82/500\n",
      " - 6s - loss: 0.1657 - accuracy: 0.9052 - val_loss: 0.3448 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90815\n",
      "Epoch 83/500\n",
      " - 6s - loss: 0.1614 - accuracy: 0.9073 - val_loss: 0.4422 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90815\n",
      "Epoch 84/500\n",
      " - 6s - loss: 0.1627 - accuracy: 0.9067 - val_loss: 0.1540 - val_accuracy: 0.9127\n",
      "\n",
      "Epoch 00084: val_accuracy improved from 0.90815 to 0.91266, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 85/500\n",
      " - 6s - loss: 0.1624 - accuracy: 0.9075 - val_loss: 0.1586 - val_accuracy: 0.9011\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.91266\n",
      "Epoch 86/500\n",
      " - 6s - loss: 0.1602 - accuracy: 0.9088 - val_loss: 0.1365 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00086: val_accuracy improved from 0.91266 to 0.91453, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 87/500\n",
      " - 6s - loss: 0.1628 - accuracy: 0.9072 - val_loss: 0.1799 - val_accuracy: 0.8959\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.91453\n",
      "Epoch 88/500\n",
      " - 6s - loss: 0.1568 - accuracy: 0.9099 - val_loss: 0.1443 - val_accuracy: 0.8975\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.91453\n",
      "Epoch 89/500\n",
      " - 6s - loss: 0.1604 - accuracy: 0.9085 - val_loss: 0.2717 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.91453\n",
      "Epoch 90/500\n",
      " - 6s - loss: 0.1573 - accuracy: 0.9101 - val_loss: 0.3104 - val_accuracy: 0.8840\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.91453\n",
      "Epoch 91/500\n",
      " - 6s - loss: 0.1564 - accuracy: 0.9107 - val_loss: 0.1851 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.91453\n",
      "Epoch 92/500\n",
      " - 6s - loss: 0.1595 - accuracy: 0.9100 - val_loss: 0.2438 - val_accuracy: 0.8916\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.91453\n",
      "Epoch 93/500\n",
      " - 6s - loss: 0.1545 - accuracy: 0.9117 - val_loss: 0.1608 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.91453\n",
      "Epoch 94/500\n",
      " - 6s - loss: 0.1547 - accuracy: 0.9114 - val_loss: 0.2351 - val_accuracy: 0.8939\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.91453\n",
      "Epoch 95/500\n",
      " - 6s - loss: 0.1568 - accuracy: 0.9112 - val_loss: 0.4190 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.91453\n",
      "Epoch 96/500\n",
      " - 6s - loss: 0.1526 - accuracy: 0.9132 - val_loss: 0.0667 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.91453\n",
      "Epoch 97/500\n",
      " - 6s - loss: 0.1472 - accuracy: 0.9160 - val_loss: 0.1772 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.91453\n",
      "Epoch 98/500\n",
      " - 6s - loss: 0.1552 - accuracy: 0.9117 - val_loss: 0.1912 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.91453\n",
      "Epoch 99/500\n",
      " - 6s - loss: 0.1490 - accuracy: 0.9155 - val_loss: 0.4360 - val_accuracy: 0.8886\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.91453\n",
      "Epoch 100/500\n",
      " - 6s - loss: 0.1505 - accuracy: 0.9143 - val_loss: 0.1930 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.91453\n",
      "Epoch 101/500\n",
      " - 6s - loss: 0.1562 - accuracy: 0.9129 - val_loss: 0.3478 - val_accuracy: 0.8886\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.91453\n",
      "Epoch 102/500\n",
      " - 6s - loss: 0.1440 - accuracy: 0.9175 - val_loss: 0.2307 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.91453\n",
      "Epoch 103/500\n",
      " - 6s - loss: 0.1479 - accuracy: 0.9161 - val_loss: 0.2195 - val_accuracy: 0.8898\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.91453\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.1470 - accuracy: 0.9168 - val_loss: 0.1979 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00104: val_accuracy improved from 0.91453 to 0.91478, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 105/500\n",
      " - 6s - loss: 0.1467 - accuracy: 0.9174 - val_loss: 0.1023 - val_accuracy: 0.8949\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.91478\n",
      "Epoch 106/500\n",
      " - 6s - loss: 0.1437 - accuracy: 0.9186 - val_loss: 0.2288 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.91478\n",
      "Epoch 107/500\n",
      " - 6s - loss: 0.1444 - accuracy: 0.9177 - val_loss: 0.3006 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.91478\n",
      "Epoch 108/500\n",
      " - 6s - loss: 0.1437 - accuracy: 0.9187 - val_loss: 0.3978 - val_accuracy: 0.8891\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.91478\n",
      "Epoch 109/500\n",
      " - 6s - loss: 0.1457 - accuracy: 0.9180 - val_loss: 0.3925 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.91478\n",
      "Epoch 110/500\n",
      " - 6s - loss: 0.1409 - accuracy: 0.9196 - val_loss: 0.2375 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00110: val_accuracy improved from 0.91478 to 0.91666, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 111/500\n",
      " - 6s - loss: 0.1436 - accuracy: 0.9192 - val_loss: 0.2520 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00111: val_accuracy improved from 0.91666 to 0.92076, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 112/500\n",
      " - 6s - loss: 0.1442 - accuracy: 0.9196 - val_loss: 0.0500 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.92076\n",
      "Epoch 113/500\n",
      " - 6s - loss: 0.1397 - accuracy: 0.9206 - val_loss: 0.4012 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.92076\n",
      "Epoch 114/500\n",
      " - 6s - loss: 0.1386 - accuracy: 0.9216 - val_loss: 0.1163 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.92076\n",
      "Epoch 115/500\n",
      " - 6s - loss: 0.1374 - accuracy: 0.9224 - val_loss: 0.0435 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.92076\n",
      "Epoch 116/500\n",
      " - 6s - loss: 0.1349 - accuracy: 0.9231 - val_loss: 0.1164 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00116: val_accuracy improved from 0.92076 to 0.93029, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 117/500\n",
      " - 6s - loss: 0.1404 - accuracy: 0.9219 - val_loss: 0.1747 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.93029\n",
      "Epoch 118/500\n",
      " - 6s - loss: 0.1370 - accuracy: 0.9224 - val_loss: 0.2195 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.93029\n",
      "Epoch 119/500\n",
      " - 6s - loss: 0.1375 - accuracy: 0.9229 - val_loss: 1.0837 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.93029\n",
      "Epoch 120/500\n",
      " - 6s - loss: 0.1387 - accuracy: 0.9229 - val_loss: 0.4011 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.93029\n",
      "Epoch 121/500\n",
      " - 6s - loss: 0.1316 - accuracy: 0.9253 - val_loss: 0.2664 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.93029\n",
      "Epoch 122/500\n",
      " - 6s - loss: 0.1334 - accuracy: 0.9247 - val_loss: 0.1308 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.93029\n",
      "Epoch 123/500\n",
      " - 6s - loss: 0.1321 - accuracy: 0.9260 - val_loss: 0.1705 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.93029\n",
      "Epoch 124/500\n",
      " - 6s - loss: 0.1394 - accuracy: 0.9224 - val_loss: 0.1036 - val_accuracy: 0.9098\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.93029\n",
      "Epoch 125/500\n",
      " - 6s - loss: 0.1294 - accuracy: 0.9270 - val_loss: 0.2476 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.93029\n",
      "Epoch 126/500\n",
      " - 6s - loss: 0.1321 - accuracy: 0.9256 - val_loss: 0.1235 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.93029\n",
      "Epoch 127/500\n",
      " - 6s - loss: 0.1341 - accuracy: 0.9252 - val_loss: 0.0682 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.93029\n",
      "Epoch 128/500\n",
      " - 6s - loss: 0.1317 - accuracy: 0.9262 - val_loss: 0.1946 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.93029\n",
      "Epoch 129/500\n",
      " - 6s - loss: 0.1281 - accuracy: 0.9275 - val_loss: 0.5252 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.93029\n",
      "Epoch 130/500\n",
      " - 6s - loss: 0.1321 - accuracy: 0.9264 - val_loss: 0.2959 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.93029\n",
      "Epoch 131/500\n",
      " - 6s - loss: 0.1268 - accuracy: 0.9289 - val_loss: 0.2518 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.93029\n",
      "Epoch 132/500\n",
      " - 6s - loss: 0.1288 - accuracy: 0.9278 - val_loss: 0.5481 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.93029\n",
      "Epoch 133/500\n",
      " - 6s - loss: 0.1245 - accuracy: 0.9299 - val_loss: 0.0998 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.93029\n",
      "Epoch 134/500\n",
      " - 6s - loss: 0.1284 - accuracy: 0.9281 - val_loss: 0.2484 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.93029\n",
      "Epoch 135/500\n",
      " - 6s - loss: 0.1275 - accuracy: 0.9287 - val_loss: 0.1819 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.93029\n",
      "Epoch 136/500\n",
      " - 6s - loss: 0.1331 - accuracy: 0.9272 - val_loss: 0.1121 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.93029\n",
      "Epoch 137/500\n",
      " - 6s - loss: 0.1209 - accuracy: 0.9322 - val_loss: 0.1412 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.93029\n",
      "Epoch 138/500\n",
      " - 6s - loss: 0.1219 - accuracy: 0.9315 - val_loss: 0.1829 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.93029\n",
      "Epoch 139/500\n",
      " - 6s - loss: 0.1245 - accuracy: 0.9306 - val_loss: 0.3782 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.93029\n",
      "Epoch 140/500\n",
      " - 6s - loss: 0.1228 - accuracy: 0.9316 - val_loss: 0.2042 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.93029\n",
      "Epoch 141/500\n",
      " - 6s - loss: 0.1238 - accuracy: 0.9312 - val_loss: 0.2998 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.93029\n",
      "Epoch 142/500\n",
      " - 6s - loss: 0.1255 - accuracy: 0.9307 - val_loss: 0.0589 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.93029\n",
      "Epoch 143/500\n",
      " - 6s - loss: 0.1194 - accuracy: 0.9330 - val_loss: 0.2440 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.93029\n",
      "Epoch 144/500\n",
      " - 6s - loss: 0.1226 - accuracy: 0.9322 - val_loss: 0.2040 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.93029\n",
      "Epoch 145/500\n",
      " - 6s - loss: 0.1194 - accuracy: 0.9336 - val_loss: 0.3790 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.93029\n",
      "Epoch 146/500\n",
      " - 6s - loss: 0.1213 - accuracy: 0.9322 - val_loss: 0.2261 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00146: val_accuracy improved from 0.93029 to 0.93110, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 147/500\n",
      " - 6s - loss: 0.1237 - accuracy: 0.9320 - val_loss: 0.0497 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.93110\n",
      "Epoch 148/500\n",
      " - 6s - loss: 0.1229 - accuracy: 0.9325 - val_loss: 0.3325 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.93110\n",
      "Epoch 149/500\n",
      " - 6s - loss: 0.1128 - accuracy: 0.9365 - val_loss: 0.2880 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.93110\n",
      "Epoch 150/500\n",
      " - 6s - loss: 0.1183 - accuracy: 0.9342 - val_loss: 0.1825 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.93110\n",
      "Epoch 151/500\n",
      " - 6s - loss: 0.1229 - accuracy: 0.9329 - val_loss: 0.4439 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.93110\n",
      "Epoch 152/500\n",
      " - 6s - loss: 0.1163 - accuracy: 0.9360 - val_loss: 0.1734 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.93110\n",
      "Epoch 153/500\n",
      " - 6s - loss: 0.1136 - accuracy: 0.9369 - val_loss: 0.3566 - val_accuracy: 0.9326\n",
      "\n",
      "Epoch 00153: val_accuracy improved from 0.93110 to 0.93260, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 154/500\n",
      " - 6s - loss: 0.1191 - accuracy: 0.9348 - val_loss: 0.0176 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.93260\n",
      "Epoch 155/500\n",
      " - 6s - loss: 0.1138 - accuracy: 0.9364 - val_loss: 0.3206 - val_accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.93260\n",
      "Epoch 156/500\n",
      " - 6s - loss: 0.1154 - accuracy: 0.9363 - val_loss: 0.0931 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.93260\n",
      "Epoch 157/500\n",
      " - 6s - loss: 0.1152 - accuracy: 0.9361 - val_loss: 0.6848 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.93260\n",
      "Epoch 158/500\n",
      " - 6s - loss: 0.1115 - accuracy: 0.9380 - val_loss: 0.2492 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.93260\n",
      "Epoch 159/500\n",
      " - 6s - loss: 0.1156 - accuracy: 0.9368 - val_loss: 0.3476 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.93260\n",
      "Epoch 160/500\n",
      " - 6s - loss: 0.1144 - accuracy: 0.9373 - val_loss: 0.0609 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.93260\n",
      "Epoch 161/500\n",
      " - 6s - loss: 0.1132 - accuracy: 0.9381 - val_loss: 0.2118 - val_accuracy: 0.9127\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.93260\n",
      "Epoch 162/500\n",
      " - 6s - loss: 0.1076 - accuracy: 0.9404 - val_loss: 0.1776 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.93260\n",
      "Epoch 163/500\n",
      " - 6s - loss: 0.1155 - accuracy: 0.9374 - val_loss: 0.3624 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.93260\n",
      "Epoch 164/500\n",
      " - 6s - loss: 0.1091 - accuracy: 0.9400 - val_loss: 0.2806 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.93260\n",
      "Epoch 165/500\n",
      " - 6s - loss: 0.1103 - accuracy: 0.9393 - val_loss: 0.1623 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.93260\n",
      "Epoch 166/500\n",
      " - 6s - loss: 0.1102 - accuracy: 0.9392 - val_loss: 0.5206 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.93260\n",
      "Epoch 167/500\n",
      " - 6s - loss: 0.1098 - accuracy: 0.9397 - val_loss: 0.2390 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.93260\n",
      "Epoch 168/500\n",
      " - 6s - loss: 0.1103 - accuracy: 0.9397 - val_loss: 0.1060 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.93260\n",
      "Epoch 169/500\n",
      " - 6s - loss: 0.1054 - accuracy: 0.9418 - val_loss: 0.3298 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.93260\n",
      "Epoch 170/500\n",
      " - 6s - loss: 0.1116 - accuracy: 0.9396 - val_loss: 0.2063 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.93260\n",
      "Epoch 171/500\n",
      " - 6s - loss: 0.1067 - accuracy: 0.9416 - val_loss: 0.1711 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.93260\n",
      "Epoch 172/500\n",
      " - 6s - loss: 0.1050 - accuracy: 0.9421 - val_loss: 0.2221 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.93260\n",
      "Epoch 173/500\n",
      " - 6s - loss: 0.1076 - accuracy: 0.9411 - val_loss: 0.1410 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.93260\n",
      "Epoch 174/500\n",
      " - 6s - loss: 0.1103 - accuracy: 0.9402 - val_loss: 0.1105 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.93260\n",
      "Epoch 175/500\n",
      " - 6s - loss: 0.1080 - accuracy: 0.9414 - val_loss: 0.1040 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.93260\n",
      "Epoch 176/500\n",
      " - 6s - loss: 0.1005 - accuracy: 0.9440 - val_loss: 0.0599 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00176: val_accuracy improved from 0.93260 to 0.95027, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 177/500\n",
      " - 6s - loss: 0.1036 - accuracy: 0.9434 - val_loss: 0.1692 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.95027\n",
      "Epoch 178/500\n",
      " - 6s - loss: 0.1110 - accuracy: 0.9406 - val_loss: 0.2494 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.95027\n",
      "Epoch 179/500\n",
      " - 6s - loss: 0.1028 - accuracy: 0.9436 - val_loss: 0.1390 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.95027\n",
      "Epoch 180/500\n",
      " - 6s - loss: 0.1038 - accuracy: 0.9433 - val_loss: 0.3086 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.95027\n",
      "Epoch 181/500\n",
      " - 6s - loss: 0.0998 - accuracy: 0.9451 - val_loss: 0.0846 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.95027\n",
      "Epoch 182/500\n",
      " - 6s - loss: 0.1076 - accuracy: 0.9421 - val_loss: 0.1812 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.95027\n",
      "Epoch 183/500\n",
      " - 6s - loss: 0.1060 - accuracy: 0.9427 - val_loss: 0.0521 - val_accuracy: 0.9176\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.95027\n",
      "Epoch 184/500\n",
      " - 6s - loss: 0.0970 - accuracy: 0.9467 - val_loss: 0.3417 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.95027\n",
      "Epoch 185/500\n",
      " - 6s - loss: 0.1018 - accuracy: 0.9447 - val_loss: 0.3042 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.95027\n",
      "Epoch 186/500\n",
      " - 6s - loss: 0.0970 - accuracy: 0.9465 - val_loss: 0.0868 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.95027\n",
      "Epoch 187/500\n",
      " - 6s - loss: 0.1042 - accuracy: 0.9443 - val_loss: 0.4053 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.95027\n",
      "Epoch 188/500\n",
      " - 6s - loss: 0.0988 - accuracy: 0.9456 - val_loss: 0.0485 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.95027\n",
      "Epoch 189/500\n",
      " - 6s - loss: 0.0982 - accuracy: 0.9470 - val_loss: 0.0957 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.95027\n",
      "Epoch 190/500\n",
      " - 6s - loss: 0.0962 - accuracy: 0.9471 - val_loss: 0.3426 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.95027\n",
      "Epoch 191/500\n",
      " - 6s - loss: 0.0990 - accuracy: 0.9462 - val_loss: 0.2503 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.95027\n",
      "Epoch 192/500\n",
      " - 6s - loss: 0.1069 - accuracy: 0.9448 - val_loss: 0.2419 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.95027\n",
      "Epoch 193/500\n",
      " - 6s - loss: 0.0973 - accuracy: 0.9473 - val_loss: 0.3332 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.95027\n",
      "Epoch 194/500\n",
      " - 6s - loss: 0.0945 - accuracy: 0.9486 - val_loss: 0.1790 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.95027\n",
      "Epoch 195/500\n",
      " - 6s - loss: 0.1007 - accuracy: 0.9468 - val_loss: 0.1373 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.95027\n",
      "Epoch 196/500\n",
      " - 6s - loss: 0.0951 - accuracy: 0.9482 - val_loss: 0.0278 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.95027\n",
      "Epoch 197/500\n",
      " - 6s - loss: 0.0963 - accuracy: 0.9478 - val_loss: 0.5662 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.95027\n",
      "Epoch 198/500\n",
      " - 6s - loss: 0.0924 - accuracy: 0.9497 - val_loss: 0.1680 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.95027\n",
      "Epoch 199/500\n",
      " - 6s - loss: 0.0948 - accuracy: 0.9485 - val_loss: 0.1503 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.95027\n",
      "Epoch 200/500\n",
      " - 6s - loss: 0.0978 - accuracy: 0.9474 - val_loss: 0.8225 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.95027\n",
      "Epoch 201/500\n",
      " - 6s - loss: 0.0984 - accuracy: 0.9473 - val_loss: 0.1512 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.95027\n",
      "Epoch 202/500\n",
      " - 6s - loss: 0.0913 - accuracy: 0.9505 - val_loss: 0.0520 - val_accuracy: 0.9377\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.95027\n",
      "Epoch 203/500\n",
      " - 6s - loss: 0.0930 - accuracy: 0.9492 - val_loss: 0.0622 - val_accuracy: 0.9387\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.95027\n",
      "Epoch 204/500\n",
      " - 6s - loss: 0.0919 - accuracy: 0.9499 - val_loss: 0.1338 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.95027\n",
      "Epoch 205/500\n",
      " - 6s - loss: 0.0911 - accuracy: 0.9503 - val_loss: 0.3713 - val_accuracy: 0.9320\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.95027\n",
      "Epoch 206/500\n",
      " - 6s - loss: 0.0938 - accuracy: 0.9496 - val_loss: 0.2886 - val_accuracy: 0.9087\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.95027\n",
      "Epoch 207/500\n",
      " - 6s - loss: 0.0912 - accuracy: 0.9508 - val_loss: 0.3520 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.95027\n",
      "Epoch 208/500\n",
      " - 6s - loss: 0.0926 - accuracy: 0.9501 - val_loss: 0.1207 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.95027\n",
      "Epoch 209/500\n",
      " - 6s - loss: 0.0918 - accuracy: 0.9510 - val_loss: 0.1874 - val_accuracy: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.95027\n",
      "Epoch 210/500\n",
      " - 6s - loss: 0.0890 - accuracy: 0.9520 - val_loss: 0.1393 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.95027\n",
      "Epoch 211/500\n",
      " - 6s - loss: 0.0950 - accuracy: 0.9491 - val_loss: 0.1397 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.95027\n",
      "Epoch 212/500\n",
      " - 5s - loss: 0.0926 - accuracy: 0.9504 - val_loss: 0.5043 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.95027\n",
      "Epoch 213/500\n",
      " - 5s - loss: 0.0844 - accuracy: 0.9538 - val_loss: 0.1649 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.95027\n",
      "Epoch 214/500\n",
      " - 6s - loss: 0.0891 - accuracy: 0.9519 - val_loss: 0.1048 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.95027\n",
      "Epoch 215/500\n",
      " - 6s - loss: 0.0896 - accuracy: 0.9522 - val_loss: 0.1308 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.95027\n",
      "Epoch 216/500\n",
      " - 6s - loss: 0.0879 - accuracy: 0.9526 - val_loss: 0.2564 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.95027\n",
      "Epoch 217/500\n",
      " - 6s - loss: 0.0887 - accuracy: 0.9523 - val_loss: 0.2315 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.95027\n",
      "Epoch 218/500\n",
      " - 6s - loss: 0.0888 - accuracy: 0.9520 - val_loss: 0.2675 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.95027\n",
      "Epoch 219/500\n",
      " - 6s - loss: 0.0885 - accuracy: 0.9523 - val_loss: 0.2969 - val_accuracy: 0.9408\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.95027\n",
      "Epoch 220/500\n",
      " - 5s - loss: 0.0908 - accuracy: 0.9518 - val_loss: 0.2344 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.95027\n",
      "Epoch 221/500\n",
      " - 5s - loss: 0.0850 - accuracy: 0.9543 - val_loss: 0.0840 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.95027\n",
      "Epoch 222/500\n",
      " - 6s - loss: 0.0866 - accuracy: 0.9534 - val_loss: 0.0933 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.95027\n",
      "Epoch 223/500\n",
      " - 6s - loss: 0.0838 - accuracy: 0.9545 - val_loss: 0.0215 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.95027\n",
      "Epoch 224/500\n",
      " - 6s - loss: 0.0884 - accuracy: 0.9532 - val_loss: 0.1440 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.95027\n",
      "Epoch 225/500\n",
      " - 6s - loss: 0.0907 - accuracy: 0.9523 - val_loss: 0.5271 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.95027\n",
      "Epoch 226/500\n",
      " - 6s - loss: 0.0866 - accuracy: 0.9540 - val_loss: 1.0259 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.95027\n",
      "Epoch 227/500\n",
      " - 6s - loss: 0.0835 - accuracy: 0.9552 - val_loss: 0.1023 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.95027\n",
      "Epoch 228/500\n",
      " - 6s - loss: 0.0820 - accuracy: 0.9562 - val_loss: 0.0382 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.95027\n",
      "Epoch 229/500\n",
      " - 6s - loss: 0.0858 - accuracy: 0.9544 - val_loss: 0.1716 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.95027\n",
      "Epoch 230/500\n",
      " - 6s - loss: 0.0835 - accuracy: 0.9552 - val_loss: 0.1569 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.95027\n",
      "Epoch 231/500\n",
      " - 6s - loss: 0.0879 - accuracy: 0.9537 - val_loss: 0.1886 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.95027\n",
      "Epoch 232/500\n",
      " - 5s - loss: 0.0794 - accuracy: 0.9574 - val_loss: 0.4131 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.95027\n",
      "Epoch 233/500\n",
      " - 5s - loss: 0.0808 - accuracy: 0.9567 - val_loss: 0.0134 - val_accuracy: 0.9390\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.95027\n",
      "Epoch 234/500\n",
      " - 5s - loss: 0.0837 - accuracy: 0.9556 - val_loss: 0.7343 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.95027\n",
      "Epoch 235/500\n",
      " - 5s - loss: 0.0818 - accuracy: 0.9566 - val_loss: 0.2833 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.95027\n",
      "Epoch 236/500\n",
      " - 5s - loss: 0.0816 - accuracy: 0.9566 - val_loss: 0.1679 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.95027\n",
      "Epoch 237/500\n",
      " - 5s - loss: 0.0899 - accuracy: 0.9526 - val_loss: 0.0189 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.95027\n",
      "Epoch 238/500\n",
      " - 5s - loss: 0.0766 - accuracy: 0.9588 - val_loss: 0.4549 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.95027\n",
      "Epoch 239/500\n",
      " - 5s - loss: 0.0849 - accuracy: 0.9552 - val_loss: 0.1667 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.95027\n",
      "Epoch 240/500\n",
      " - 5s - loss: 0.0786 - accuracy: 0.9580 - val_loss: 0.2076 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.95027\n",
      "Epoch 241/500\n",
      " - 5s - loss: 0.0807 - accuracy: 0.9570 - val_loss: 0.1632 - val_accuracy: 0.9401\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.95027\n",
      "Epoch 242/500\n",
      " - 5s - loss: 0.0807 - accuracy: 0.9570 - val_loss: 0.3900 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.95027\n",
      "Epoch 243/500\n",
      " - 5s - loss: 0.0789 - accuracy: 0.9578 - val_loss: 0.1502 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.95027\n",
      "Epoch 244/500\n",
      " - 5s - loss: 0.0821 - accuracy: 0.9562 - val_loss: 0.1513 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.95027\n",
      "Epoch 245/500\n",
      " - 5s - loss: 0.0744 - accuracy: 0.9598 - val_loss: 0.0856 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.95027\n",
      "Epoch 246/500\n",
      " - 5s - loss: 0.0840 - accuracy: 0.9559 - val_loss: 0.1641 - val_accuracy: 0.9387\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.95027\n",
      "Epoch 247/500\n",
      " - 5s - loss: 0.0779 - accuracy: 0.9586 - val_loss: 0.4225 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.95027\n",
      "Epoch 248/500\n",
      " - 5s - loss: 0.0816 - accuracy: 0.9572 - val_loss: 0.1833 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.95027\n",
      "Epoch 249/500\n",
      " - 5s - loss: 0.0751 - accuracy: 0.9599 - val_loss: 0.2722 - val_accuracy: 0.9464\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.95027\n",
      "Epoch 250/500\n",
      " - 5s - loss: 0.0777 - accuracy: 0.9587 - val_loss: 0.0756 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.95027\n",
      "Epoch 251/500\n",
      " - 5s - loss: 0.0852 - accuracy: 0.9562 - val_loss: 0.0446 - val_accuracy: 0.9368\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.95027\n",
      "Epoch 252/500\n",
      " - 5s - loss: 0.0727 - accuracy: 0.9605 - val_loss: 0.1547 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.95027\n",
      "Epoch 253/500\n",
      " - 5s - loss: 0.0742 - accuracy: 0.9598 - val_loss: 0.1010 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00253: val_accuracy improved from 0.95027 to 0.95055, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 254/500\n",
      " - 5s - loss: 0.0783 - accuracy: 0.9587 - val_loss: 0.2928 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.95055\n",
      "Epoch 255/500\n",
      " - 5s - loss: 0.0801 - accuracy: 0.9583 - val_loss: 0.2758 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.95055\n",
      "Epoch 256/500\n",
      " - 5s - loss: 0.0720 - accuracy: 0.9613 - val_loss: 0.2122 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.95055\n",
      "Epoch 257/500\n",
      " - 5s - loss: 0.0756 - accuracy: 0.9597 - val_loss: 0.2822 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.95055\n",
      "Epoch 258/500\n",
      " - 5s - loss: 0.0764 - accuracy: 0.9598 - val_loss: 0.2232 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.95055\n",
      "Epoch 259/500\n",
      " - 5s - loss: 0.0726 - accuracy: 0.9614 - val_loss: 1.8855 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.95055\n",
      "Epoch 260/500\n",
      " - 5s - loss: 0.0756 - accuracy: 0.9605 - val_loss: 0.4049 - val_accuracy: 0.9430\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.95055\n",
      "Epoch 261/500\n",
      " - 5s - loss: 0.0737 - accuracy: 0.9609 - val_loss: 0.6625 - val_accuracy: 0.9366\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.95055\n",
      "Epoch 262/500\n",
      " - 5s - loss: 0.0730 - accuracy: 0.9611 - val_loss: 0.3418 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.95055\n",
      "Epoch 263/500\n",
      " - 5s - loss: 0.0849 - accuracy: 0.9581 - val_loss: 0.1017 - val_accuracy: 0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.95055\n",
      "Epoch 264/500\n",
      " - 5s - loss: 0.0681 - accuracy: 0.9636 - val_loss: 0.4936 - val_accuracy: 0.9440\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.95055\n",
      "Epoch 265/500\n",
      " - 5s - loss: 0.0771 - accuracy: 0.9594 - val_loss: 0.4610 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.95055\n",
      "Epoch 266/500\n",
      " - 5s - loss: 0.0717 - accuracy: 0.9621 - val_loss: 0.1354 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.95055\n",
      "Epoch 267/500\n",
      " - 5s - loss: 0.0752 - accuracy: 0.9611 - val_loss: 0.1102 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.95055\n",
      "Epoch 268/500\n",
      " - 5s - loss: 0.0700 - accuracy: 0.9631 - val_loss: 0.1970 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.95055\n",
      "Epoch 269/500\n",
      " - 5s - loss: 0.0708 - accuracy: 0.9628 - val_loss: 0.1590 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.95055\n",
      "Epoch 270/500\n",
      " - 5s - loss: 0.0778 - accuracy: 0.9596 - val_loss: 0.5640 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.95055\n",
      "Epoch 271/500\n",
      " - 5s - loss: 0.0683 - accuracy: 0.9634 - val_loss: 0.1918 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.95055\n",
      "Epoch 272/500\n",
      " - 5s - loss: 0.0740 - accuracy: 0.9614 - val_loss: 0.1547 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.95055\n",
      "Epoch 273/500\n",
      " - 5s - loss: 0.0674 - accuracy: 0.9643 - val_loss: 0.1136 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.95055\n",
      "Epoch 274/500\n",
      " - 5s - loss: 0.0683 - accuracy: 0.9637 - val_loss: 0.5555 - val_accuracy: 0.9483\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.95055\n",
      "Epoch 275/500\n",
      " - 5s - loss: 0.0740 - accuracy: 0.9620 - val_loss: 0.3787 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.95055\n",
      "Epoch 276/500\n",
      " - 5s - loss: 0.0714 - accuracy: 0.9630 - val_loss: 0.2325 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.95055\n",
      "Epoch 277/500\n",
      " - 5s - loss: 0.0698 - accuracy: 0.9633 - val_loss: 0.1506 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.95055\n",
      "Epoch 278/500\n",
      " - 5s - loss: 0.0695 - accuracy: 0.9639 - val_loss: 0.3217 - val_accuracy: 0.9480\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.95055\n",
      "Epoch 279/500\n",
      " - 5s - loss: 0.0642 - accuracy: 0.9654 - val_loss: 0.1307 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.95055\n",
      "Epoch 280/500\n",
      " - 5s - loss: 0.0701 - accuracy: 0.9632 - val_loss: 0.0780 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.95055\n",
      "Epoch 281/500\n",
      " - 5s - loss: 0.0641 - accuracy: 0.9656 - val_loss: 0.0244 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.95055\n",
      "Epoch 282/500\n",
      " - 5s - loss: 0.0706 - accuracy: 0.9631 - val_loss: 0.0530 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.95055\n",
      "Epoch 283/500\n",
      " - 5s - loss: 0.0647 - accuracy: 0.9658 - val_loss: 0.3778 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.95055\n",
      "Epoch 284/500\n",
      " - 5s - loss: 0.0735 - accuracy: 0.9625 - val_loss: 0.6900 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.95055\n",
      "Epoch 285/500\n",
      " - 5s - loss: 0.0643 - accuracy: 0.9658 - val_loss: 0.2631 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.95055\n",
      "Epoch 286/500\n",
      " - 5s - loss: 0.0684 - accuracy: 0.9640 - val_loss: 1.3118 - val_accuracy: 0.9567\n",
      "\n",
      "Epoch 00286: val_accuracy improved from 0.95055 to 0.95669, saving model to model/rapid_ascending 30_84_obvmacd.hdf5\n",
      "Epoch 287/500\n",
      " - 5s - loss: 0.0660 - accuracy: 0.9653 - val_loss: 0.3002 - val_accuracy: 0.9409\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.95669\n",
      "Epoch 288/500\n",
      " - 5s - loss: 0.0642 - accuracy: 0.9661 - val_loss: 0.0915 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.95669\n",
      "Epoch 289/500\n",
      " - 5s - loss: 0.0703 - accuracy: 0.9635 - val_loss: 0.2744 - val_accuracy: 0.9532\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.95669\n",
      "Epoch 290/500\n",
      " - 5s - loss: 0.0634 - accuracy: 0.9665 - val_loss: 0.4756 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.95669\n",
      "Epoch 291/500\n",
      " - 5s - loss: 0.0696 - accuracy: 0.9641 - val_loss: 0.2546 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.95669\n",
      "Epoch 292/500\n",
      " - 5s - loss: 0.0642 - accuracy: 0.9663 - val_loss: 0.1489 - val_accuracy: 0.9472\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.95669\n",
      "Epoch 293/500\n",
      " - 5s - loss: 0.0681 - accuracy: 0.9649 - val_loss: 0.2315 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.95669\n",
      "Epoch 294/500\n",
      " - 5s - loss: 0.0652 - accuracy: 0.9658 - val_loss: 0.3676 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.95669\n",
      "Epoch 295/500\n",
      " - 5s - loss: 0.0673 - accuracy: 0.9654 - val_loss: 0.0101 - val_accuracy: 0.9413\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.95669\n",
      "Epoch 296/500\n",
      " - 5s - loss: 0.0698 - accuracy: 0.9644 - val_loss: 0.1452 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.95669\n",
      "Epoch 297/500\n",
      " - 5s - loss: 0.0664 - accuracy: 0.9657 - val_loss: 0.0238 - val_accuracy: 0.9320\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.95669\n",
      "Epoch 298/500\n",
      " - 5s - loss: 0.0598 - accuracy: 0.9681 - val_loss: 0.5869 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.95669\n",
      "Epoch 299/500\n",
      " - 5s - loss: 0.0646 - accuracy: 0.9663 - val_loss: 0.0367 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.95669\n",
      "Epoch 300/500\n",
      " - 5s - loss: 0.0612 - accuracy: 0.9679 - val_loss: 0.1590 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.95669\n",
      "Epoch 301/500\n",
      " - 5s - loss: 0.0767 - accuracy: 0.9624 - val_loss: 0.0811 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.95669\n",
      "Epoch 302/500\n",
      " - 5s - loss: 0.0572 - accuracy: 0.9698 - val_loss: 0.3982 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.95669\n",
      "Epoch 303/500\n",
      " - 5s - loss: 0.0567 - accuracy: 0.9701 - val_loss: 0.1953 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.95669\n",
      "Epoch 304/500\n",
      " - 5s - loss: 0.0776 - accuracy: 0.9617 - val_loss: 0.0038 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.95669\n",
      "Epoch 305/500\n",
      " - 5s - loss: 0.0590 - accuracy: 0.9691 - val_loss: 0.3331 - val_accuracy: 0.9335\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.95669\n",
      "Epoch 306/500\n",
      " - 5s - loss: 0.0582 - accuracy: 0.9692 - val_loss: 0.1448 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.95669\n",
      "Epoch 307/500\n",
      " - 5s - loss: 0.0733 - accuracy: 0.9636 - val_loss: 0.1523 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.95669\n",
      "Epoch 308/500\n",
      " - 5s - loss: 0.0619 - accuracy: 0.9677 - val_loss: 0.0940 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.95669\n",
      "Epoch 309/500\n",
      " - 5s - loss: 0.0565 - accuracy: 0.9704 - val_loss: 0.0771 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.95669\n",
      "Epoch 310/500\n",
      " - 5s - loss: 0.0672 - accuracy: 0.9655 - val_loss: 1.1814 - val_accuracy: 0.9551\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.95669\n",
      "Epoch 311/500\n",
      " - 5s - loss: 0.0608 - accuracy: 0.9684 - val_loss: 0.1266 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.95669\n",
      "Epoch 312/500\n",
      " - 5s - loss: 0.0577 - accuracy: 0.9697 - val_loss: 0.0518 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.95669\n",
      "Epoch 313/500\n",
      " - 5s - loss: 0.0635 - accuracy: 0.9676 - val_loss: 0.2139 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.95669\n",
      "Epoch 314/500\n",
      " - 5s - loss: 0.0580 - accuracy: 0.9698 - val_loss: 0.1180 - val_accuracy: 0.9406\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.95669\n",
      "Epoch 315/500\n",
      " - 5s - loss: 0.0672 - accuracy: 0.9669 - val_loss: 0.3309 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.95669\n",
      "Epoch 316/500\n",
      " - 5s - loss: 0.0576 - accuracy: 0.9701 - val_loss: 0.1258 - val_accuracy: 0.9456\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.95669\n",
      "Epoch 317/500\n",
      " - 5s - loss: 0.0603 - accuracy: 0.9689 - val_loss: 0.2956 - val_accuracy: 0.9409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.95669\n",
      "Epoch 318/500\n",
      " - 5s - loss: 0.0658 - accuracy: 0.9665 - val_loss: 0.2206 - val_accuracy: 0.9343\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.95669\n",
      "Epoch 319/500\n",
      " - 5s - loss: 0.0586 - accuracy: 0.9695 - val_loss: 0.2472 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.95669\n",
      "Epoch 320/500\n",
      " - 5s - loss: 0.0648 - accuracy: 0.9673 - val_loss: 0.5992 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.95669\n",
      "Epoch 321/500\n",
      " - 5s - loss: 0.0560 - accuracy: 0.9707 - val_loss: 0.3063 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.95669\n",
      "Epoch 322/500\n",
      " - 5s - loss: 0.0581 - accuracy: 0.9698 - val_loss: 0.9719 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.95669\n",
      "Epoch 323/500\n",
      " - 5s - loss: 0.0588 - accuracy: 0.9692 - val_loss: 0.2245 - val_accuracy: 0.9547\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.95669\n",
      "Epoch 324/500\n",
      " - 5s - loss: 0.0598 - accuracy: 0.9694 - val_loss: 0.1308 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.95669\n",
      "Epoch 325/500\n",
      " - 5s - loss: 0.0662 - accuracy: 0.9672 - val_loss: 0.4742 - val_accuracy: 0.9458\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.95669\n",
      "Epoch 326/500\n",
      " - 5s - loss: 0.0551 - accuracy: 0.9716 - val_loss: 0.2003 - val_accuracy: 0.9479\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.95669\n",
      "Epoch 327/500\n",
      " - 5s - loss: 0.0645 - accuracy: 0.9678 - val_loss: 0.0903 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.95669\n",
      "Epoch 328/500\n",
      " - 5s - loss: 0.0528 - accuracy: 0.9724 - val_loss: 0.2254 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.95669\n",
      "Epoch 329/500\n",
      " - 5s - loss: 0.0697 - accuracy: 0.9660 - val_loss: 0.1417 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.95669\n",
      "Epoch 330/500\n",
      " - 5s - loss: 0.0549 - accuracy: 0.9719 - val_loss: 0.1772 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.95669\n",
      "Epoch 331/500\n",
      " - 5s - loss: 0.0546 - accuracy: 0.9715 - val_loss: 0.4035 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.95669\n",
      "Epoch 332/500\n",
      " - 5s - loss: 0.0565 - accuracy: 0.9706 - val_loss: 0.4326 - val_accuracy: 0.9370\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.95669\n",
      "Epoch 333/500\n",
      " - 5s - loss: 0.0550 - accuracy: 0.9715 - val_loss: 0.2009 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.95669\n",
      "Epoch 334/500\n",
      " - 5s - loss: 0.0636 - accuracy: 0.9680 - val_loss: 0.4999 - val_accuracy: 0.9039\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.95669\n",
      "Epoch 335/500\n",
      " - 5s - loss: 0.0539 - accuracy: 0.9718 - val_loss: 0.0378 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.95669\n",
      "Epoch 336/500\n",
      " - 5s - loss: 0.0607 - accuracy: 0.9693 - val_loss: 0.2459 - val_accuracy: 0.9387\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.95669\n",
      "Epoch 337/500\n",
      " - 5s - loss: 0.0515 - accuracy: 0.9731 - val_loss: 0.0448 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.95669\n",
      "Epoch 338/500\n",
      " - 5s - loss: 0.0539 - accuracy: 0.9718 - val_loss: 0.0770 - val_accuracy: 0.9476\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.95669\n",
      "Epoch 339/500\n",
      " - 5s - loss: 0.0529 - accuracy: 0.9727 - val_loss: 0.0675 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.95669\n",
      "Epoch 340/500\n",
      " - 5s - loss: 0.0605 - accuracy: 0.9698 - val_loss: 0.2633 - val_accuracy: 0.9472\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.95669\n",
      "Epoch 341/500\n",
      " - 5s - loss: 0.0613 - accuracy: 0.9706 - val_loss: 0.2072 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.95669\n",
      "Epoch 342/500\n",
      " - 5s - loss: 0.0499 - accuracy: 0.9739 - val_loss: 0.1556 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.95669\n",
      "Epoch 343/500\n",
      " - 5s - loss: 0.0513 - accuracy: 0.9733 - val_loss: 0.1090 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.95669\n",
      "Epoch 344/500\n",
      " - 5s - loss: 0.0542 - accuracy: 0.9723 - val_loss: 0.0678 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.95669\n",
      "Epoch 345/500\n",
      " - 5s - loss: 0.0652 - accuracy: 0.9684 - val_loss: 0.1587 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.95669\n",
      "Epoch 346/500\n",
      " - 5s - loss: 0.0478 - accuracy: 0.9747 - val_loss: 0.0609 - val_accuracy: 0.9476\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.95669\n",
      "Epoch 347/500\n",
      " - 5s - loss: 0.0533 - accuracy: 0.9728 - val_loss: 0.0751 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.95669\n",
      "Epoch 348/500\n",
      " - 5s - loss: 0.0597 - accuracy: 0.9694 - val_loss: 0.0437 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.95669\n",
      "Epoch 349/500\n",
      " - 6s - loss: 0.0472 - accuracy: 0.9754 - val_loss: 0.2325 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.95669\n",
      "Epoch 350/500\n",
      " - 5s - loss: 0.0581 - accuracy: 0.9706 - val_loss: 0.2406 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.95669\n",
      "Epoch 351/500\n",
      " - 5s - loss: 0.0491 - accuracy: 0.9744 - val_loss: 0.0784 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.95669\n",
      "Epoch 352/500\n",
      " - 5s - loss: 0.0527 - accuracy: 0.9728 - val_loss: 0.1619 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.95669\n",
      "Epoch 353/500\n",
      " - 5s - loss: 0.0555 - accuracy: 0.9715 - val_loss: 0.3520 - val_accuracy: 0.9507\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.95669\n",
      "Epoch 354/500\n",
      " - 5s - loss: 0.0487 - accuracy: 0.9746 - val_loss: 0.0496 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.95669\n",
      "Epoch 355/500\n",
      " - 5s - loss: 0.0498 - accuracy: 0.9738 - val_loss: 0.0936 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.95669\n",
      "Epoch 356/500\n",
      " - 5s - loss: 0.0587 - accuracy: 0.9709 - val_loss: 0.0334 - val_accuracy: 0.9541\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.95669\n",
      "Epoch 357/500\n",
      " - 5s - loss: 0.0481 - accuracy: 0.9751 - val_loss: 0.4495 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.95669\n",
      "Epoch 358/500\n",
      " - 5s - loss: 0.0487 - accuracy: 0.9749 - val_loss: 0.5380 - val_accuracy: 0.9553\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.95669\n",
      "Epoch 359/500\n",
      " - 5s - loss: 0.0572 - accuracy: 0.9713 - val_loss: 0.1093 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.95669\n",
      "Epoch 360/500\n",
      " - 5s - loss: 0.0513 - accuracy: 0.9739 - val_loss: 0.1763 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.95669\n",
      "Epoch 361/500\n",
      " - 5s - loss: 0.0618 - accuracy: 0.9709 - val_loss: 0.2307 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.95669\n",
      "Epoch 362/500\n",
      " - 5s - loss: 0.0462 - accuracy: 0.9764 - val_loss: 2.4879 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.95669\n",
      "Epoch 363/500\n",
      " - 5s - loss: 0.0486 - accuracy: 0.9752 - val_loss: 0.0809 - val_accuracy: 0.9461\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.95669\n",
      "Epoch 364/500\n",
      " - 5s - loss: 0.0464 - accuracy: 0.9761 - val_loss: 0.1195 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.95669\n",
      "Epoch 365/500\n",
      " - 5s - loss: 0.0568 - accuracy: 0.9723 - val_loss: 0.4506 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.95669\n",
      "Epoch 366/500\n",
      " - 5s - loss: 0.0449 - accuracy: 0.9768 - val_loss: 0.2626 - val_accuracy: 0.9544\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.95669\n",
      "Epoch 367/500\n",
      " - 5s - loss: 0.0633 - accuracy: 0.9704 - val_loss: 0.0584 - val_accuracy: 0.9557\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.95669\n",
      "Epoch 368/500\n",
      " - 5s - loss: 0.0465 - accuracy: 0.9760 - val_loss: 0.0999 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.95669\n",
      "Epoch 369/500\n",
      " - 5s - loss: 0.0449 - accuracy: 0.9767 - val_loss: 0.0486 - val_accuracy: 0.9458\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.95669\n",
      "Epoch 370/500\n",
      " - 5s - loss: 0.0647 - accuracy: 0.9689 - val_loss: 1.0719 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.95669\n",
      "Epoch 371/500\n",
      " - 5s - loss: 0.0433 - accuracy: 0.9775 - val_loss: 0.5057 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.95669\n",
      "Epoch 372/500\n",
      " - 5s - loss: 0.0480 - accuracy: 0.9753 - val_loss: 0.0781 - val_accuracy: 0.9533\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.95669\n",
      "Epoch 373/500\n",
      " - 5s - loss: 0.0460 - accuracy: 0.9762 - val_loss: 0.4690 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.95669\n",
      "Epoch 374/500\n",
      " - 5s - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.3484 - val_accuracy: 0.9474\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.95669\n",
      "Epoch 375/500\n",
      " - 5s - loss: 0.0570 - accuracy: 0.9720 - val_loss: 0.2724 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.95669\n",
      "Epoch 376/500\n",
      " - 5s - loss: 0.0425 - accuracy: 0.9780 - val_loss: 1.1151 - val_accuracy: 0.9450\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.95669\n",
      "Epoch 377/500\n",
      " - 5s - loss: 0.0464 - accuracy: 0.9762 - val_loss: 0.0518 - val_accuracy: 0.9530\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.95669\n",
      "Epoch 378/500\n",
      " - 5s - loss: 0.0688 - accuracy: 0.9681 - val_loss: 0.0830 - val_accuracy: 0.9475\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.95669\n",
      "Epoch 379/500\n",
      " - 5s - loss: 0.0428 - accuracy: 0.9779 - val_loss: 0.0860 - val_accuracy: 0.9554\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.95669\n",
      "Epoch 380/500\n",
      " - 5s - loss: 0.0433 - accuracy: 0.9775 - val_loss: 1.8130 - val_accuracy: 0.9485\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.95669\n",
      "Epoch 381/500\n",
      " - 5s - loss: 0.0584 - accuracy: 0.9713 - val_loss: 0.3105 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.95669\n",
      "Epoch 382/500\n",
      " - 5s - loss: 0.0426 - accuracy: 0.9780 - val_loss: 0.2999 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.95669\n",
      "Epoch 383/500\n",
      " - 5s - loss: 0.0459 - accuracy: 0.9766 - val_loss: 0.0127 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.95669\n",
      "Epoch 384/500\n",
      " - 5s - loss: 0.0564 - accuracy: 0.9723 - val_loss: 0.0413 - val_accuracy: 0.9486\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.95669\n",
      "Epoch 385/500\n",
      " - 5s - loss: 0.0417 - accuracy: 0.9785 - val_loss: 2.7141 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.95669\n",
      "Epoch 386/500\n",
      " - 5s - loss: 0.0505 - accuracy: 0.9746 - val_loss: 0.0576 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.95669\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import scipy.misc \n",
    "from math import sqrt \n",
    "import itertools\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "input_data_length = 30\n",
    "model_num = 84\n",
    "num_classes = 2\n",
    "\n",
    "Made_X = np.load('Made_X/Made_X %s_%s.npy' % (input_data_length, model_num))\n",
    "Made_Y = np.load('Made_X/Made_Y %s_%s.npy' % (input_data_length, model_num)).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#       dataset       #\n",
    "# dataX  : VOLUME, MA, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC \n",
    "# dataX  : VOLUME, EMA1, EMA2, CMO, OBV, RSI, MACD, MACD_SIGNAL, MACD_OSC, MACD_ZERO\n",
    "Made_X = Made_X[:, :,[7, 9, 10, 11, 12]]\n",
    "print(Made_X.shape)\n",
    "print(Made_Y.shape)\n",
    "\n",
    "row = Made_X.shape[1]\n",
    "col = Made_X.shape[2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(Made_X, Made_Y, test_size=0.3,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "X_train = X_train.astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "X_val = X_val.astype('float32').reshape(-1, input_data_length, col, 1)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# Data Class Weight\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "print(Y_train[:, 0])\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  np.unique(Y_train[:, 0]),\n",
    "                                                  Y_train[:, 0])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "# class_weights[1] *= 0.97\n",
    "# class_weights[2] *= 0.97\n",
    "print(class_weights)\n",
    "# quit()\n",
    "\n",
    "Y_train = Y_train.astype('float32')\n",
    "Y_val = Y_val.astype('float32')\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_val = np_utils.to_categorical(Y_val, num_classes)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "datagen = ImageDataGenerator( \n",
    "#     rotation_range = 60,\n",
    "#     zoom_range = 0.6,\n",
    "#     shear_range = 0.6,\n",
    "#     horizontal_flip = True,\n",
    "#     width_shift_range=0.6,\n",
    "#     height_shift_range=0.6,\n",
    "    fill_mode = 'nearest'\n",
    "    )\n",
    "\n",
    "testgen = ImageDataGenerator( \n",
    "    )\n",
    "datagen.fit(X_train)\n",
    "batch_size = 128\n",
    "\n",
    "for X_batch, _ in datagen.flow(X_train, Y_train, batch_size=9):\n",
    "    for i in range(0, 9): \n",
    "        pyplot.axis('off') \n",
    "        pyplot.subplot(330 + 1 + i) \n",
    "        pyplot.imshow(X_batch[i].reshape(input_data_length, col))\n",
    "    pyplot.axis('off') \n",
    "    pyplot.show() \n",
    "    break\n",
    "    \n",
    "    \n",
    "train_flow = datagen.flow(X_train, Y_train, batch_size=batch_size) \n",
    "val_flow = testgen.flow(X_val, Y_val, batch_size=batch_size) \n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def FER_Model(input_shape=(row, col, 1)):\n",
    "    # first input model\n",
    "    visible = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    net = layers.Conv2D(64, kernel_size=3, padding='same')(visible)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_1 = net\n",
    "\n",
    "    net = layers.Conv2D(128, kernel_size=3, padding='same')(net)\n",
    "    # net = layers.Activation('relu')(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    shortcut_2 = net\n",
    "\n",
    "#     net = layers.Conv2D(256, kernel_size=3, padding='same')(net)\n",
    "#     # net = layers.Activation('relu')(net)\n",
    "#     net = layers.LeakyReLU()(net)\n",
    "#     net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "#     shortcut_3 = net\n",
    "\n",
    "#     net = layers.Conv2D(128, kernel_size=1, padding='same')(net)\n",
    "#     # net = layers.Activation('relu')(net)\n",
    "#     net = layers.LeakyReLU()(net)\n",
    "#     net = layers.MaxPool2D(pool_size=2)(net)\n",
    "\n",
    "    net = layers.Flatten()(net)\n",
    "    net = layers.Dense(64)(net)\n",
    "    net = layers.LeakyReLU()(net)\n",
    "    net = layers.Dense(num_classes, activation='softmax')(net)\n",
    "\n",
    "    # create model \n",
    "    model = Model(inputs =visible, outputs = net)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model = FER_Model()\n",
    "from keras.models import load_model\n",
    "model = load_model('model/rapid_ascending %s_%s_rsimacd.hdf5' % (input_data_length, model_num))\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "filepath=\"model/rapid_ascending %s_%s_obvmacd.hdf5\" % (input_data_length, model_num)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint2 = TensorBoard(log_dir='Tensorboard_graph',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "checkpoint3 = EarlyStopping(monitor='val_accuracy', patience=100)\n",
    "callbacks_list = [checkpoint, checkpoint2, checkpoint3]\n",
    "\n",
    "# keras.callbacks.Callback   log   history log    .\n",
    "\n",
    "# we iterate 200 times over the entire training set\n",
    "num_epochs = 500\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=2,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    class_weight=class_weights,\n",
    "                    validation_data=val_flow,  \n",
    "                    validation_steps=len(X_val) / batch_size,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model/rapid_ascending %s_%s.hdf5' % (input_data_length, model_num))\n",
    "# model = load_model('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.hdf5' % input_data_length)\n",
    "# loss = model.evaluate_generator(test_flow, steps=len(X_test) / batch_size) \n",
    "# print(\"Test Loss \" + str(loss[0]))\n",
    "# print(\"Test Acc: \" + str(loss[1]))\n",
    "\n",
    "# loss = model.evaluate(X_val, Y_val) \n",
    "# print(X_val.shape)\n",
    "# print(Y_val.shape)\n",
    "\n",
    "# print(\"Val Loss \" + str(loss[0]))\n",
    "# print(\"Val Acc: \" + str(loss[1]))\n",
    "\n",
    "#     Prediction    #\n",
    "Y_pred_ = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Y_pred = Y_pred_[:,[-1]]\n",
    "# print(Y_pred.shape)\n",
    "# print(Y_test.shape)\n",
    "Y_pred = np.argmax(Y_pred_, axis=1)\n",
    "t_te = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#     Manual processing     #\n",
    "Y_pred_one = Y_pred_[:, [-1]]\n",
    "print(Y_pred_)\n",
    "max_value = np.max(Y_pred_one)\n",
    "print(max_value)\n",
    "\n",
    "limit_line = 0.9\n",
    "Y_pred_one = np.where(Y_pred_one > max_value * limit_line, 1, 0)\n",
    "\n",
    "# print(Y_pred_one)\n",
    "Y_pred_one = Y_pred_one.reshape(-1,)\n",
    "# print(Y_pred_1)\n",
    "# print(Y_pred.shape)\n",
    "# print(t_te.shape)\n",
    "\n",
    "# fail = 0\n",
    "# fail2 = 0\n",
    "# for i in range(len(Y_pred)):\n",
    "#   if Y_pred_1[i] != t_te[i]:\n",
    "#     fail += 1\n",
    "\n",
    "#   if Y_pred[i] != t_te[i]:\n",
    "#     fail2 += 1\n",
    "\n",
    "# print(1 - fail / len(Y_pred))\n",
    "# print(1 - fail2 / len(Y_pred))\n",
    "\n",
    "# print(np.sum(Y_pred), np.sum(t_te))\n",
    "# print('Y_pred / Y_test :', np.sum(Y_pred) / np.sum(t_te))\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(Y_test, 'purple', label='test')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(Y_pred_one, 'y', label='pred')\n",
    "plt.show()\n",
    "# plt.savefig('/content/gdrive/My Drive/Colab Notebooks/model/rapid_ascending %s.png' % input_data_length)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
