## Gaussian



##### <u>내가 얻고자 하는 것 :  실시간 데이터로 완성된 CURVED OSC LINE을 만들 수 있는가</u>



```markdown
# 실시간 가우시안 라인에서 trade_state를 정하는 방법 (realtime)
# 실시간 가우시안 라인을 누적해서 trade_state를 정하는 방법
--------------------------------------
realtime vs non_realtime : realtime의 차트가 밀려있다. (느리다..)

# 실시간 crop vs 누적 crop
--------------------------------------
실시간 crop == 누적 crop

# 실시간 crop
--------------------------------------
realtime vs non_realtime : realtime의 차트가 밀려있다. (느리다..)
```

| Setting                                                      | Result                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| sigma, crop_size                                             | **sigma 값이 커지면 차트가 뒤로 밀린다.**  **crop_size는 차트에 영향을 준다** |
| *<u>**차트를 당겨서 고점에서 떨어질 것을 예측하는 걸 학습시킨다**</u>* | 당겨지기는 하는데 이상해짐..                                 |
| **진입을 zero cross_over로 한다면?**                         | **진입이 너무 느려서** 얻는 수익도 적고 손해볼때가 훨 많음   |



## GaussianFilter1d

| Setting                                                      | Result                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| ~~**period의 기울기가 변하는곳 (지금가지 period=2로 해옴)**~~ | **애매하다.. 0이 되기 전에 잘라주어야하는데 그러면, 지정한 값의 기울기를 가진 중간 지점에서 짤리는 일들이 발생해서 잔거래가 많아지며, 전반적으로 잔거래가 많아진다.** |
| <u>***gaussian curve1 과 gaussian curve2의 crossover / under***</u> | *<u>**현재 함수 내에 gaussian iter num이 껴있음**</u>*       |
| <u>**MACDOSC를 당길 수 있는 방법이 있나..?**</u>             | **<u>인공지능으로 가능한가?</u>**                            |



## 실시간 smoothing으로는 완성된 curve를 그릴 수 없다. 인공지능을 이용해보자

```markdown
# 고/저 지표 따로
- 고점 지표는 최고점만 찍으면 됀다.
```



| Model Num    | Description                                                  | Result                                                       |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| _106         |                                                              | **Gaussian Curve가 훨씬 결과가 좋다.** 하지만 차트가 밀리는 문제점 >> 학습 데이터의 y값을 당기면 됄까? |
| _107         | ~~튀어나온 곡선을 누그러트릴수 있는 그런 것~~                |                                                              |
| _108         | 다량의 osc를 학습한 osc_offset                               | 1e-4의 학습률로 한 결과 time_delay가 생긴다. >> 1e-2로 재실험 >> 결과는 동일.. (개선된듯하나) |
| _109         | ml을 활용한 curve 그리기 && 미래 차트 예측하기               | rbf는 잔주름이 많이 생김, poly도 뭐.. 자세히 보면 잔주름이 많아서.. |
| _110         | **thinkdpr.py을 사용한 가우시안 곡선그리기**                 | **차트가 좀더 당겨지는경향이 있다.** <u>있긴 하지만 해결책은 아닌..</u> |
| _111         | osc와 osc_gaussian의 cross                                   | **잔거래가 많음**                                            |
| _112         | curve_offset                                                 | **가능할거 같기도한데?? 차트가 당겨지긴함** >> 폭파! (거래용으로 안됌) |
| ~~_113~~     | ~~지정 수익제 : 양봉에 5% 이전 종가보다 해당봉 종가가 이상~~ | ~~**<u>주가를 max_abs_scalering 하면 수익률이 데이터에 반영되게 된다. 단순히 min max하면, 고저점 사이의 폭이 균일해지나 max abs 하면, 고저점 사이의 폭이 달라지기 때문임! </u> ** >> 별로 쓸만하지 않음..~~ |
| **_114**     | **curve로 고저를 span 라벨링한 이미지 분류 해보기**          | **사용하기 곤란 + confidence 실험** >> span 보다 포인트가 나은거 같음.. |
| **_115**     | **curve point로 삽입하기**                                   | **고저를 분간하지만 짧다 >> 좀 더 개발하면 가능할지도/ osc섞은거보다 ohlc의 결과가 더 깔끔하다. + confidence 실험** >> max_abs 사용하면 predict라인이 완곡해짐 **<u>*(집약도가 상승한다.)*</u>** |
| _116         | 54_23 복원하기                                               | np.argmax 사용한다는 개념이 애초에 잘못됐다. 왜냐하면 상당한 정확도를 요구하는데, **50% 이상으로 언더라인을 잡아버리다니..** **상승장 중간에 진입하지 못하는 단점** |
| _117         | 54_23 renewal                                                | <u>min_max가 다양한 고점을 포함할 수 있음</u>                |
| _118         | **54_23 튜닝하기**                                           | **confidence percentage(고/저점이라고 판단할 수 있는 정확도(%))** idl 54기준 0.8 / idl 100이 차트 밀도가 54보다 훨 높다.. |
| ~~**_119**~~ | ~~**_114 min_max 튜닝**~~                                    | **span -> point 라벨링 데이터**                              |
| **_120**     | **_115 min_max 튜닝**                                        | **_116과 비교 후 max abs 적용 비교 >> _116은 prediction 값이 고저가 없다. / 가우시안으로 포인트 잡은게 훨씬 깔끔하다. / confidence 선정 방법 개발 / 내가 찾아야할 특징 : 최대 predict_confidency가 최고점 또는 최저점** |
| _121         | 잘 나온 모델로 standard scaling 하면?                        | **_120 standard scale**                                      |
| _122         | gaussian 상승추세에서 최저값과 최고값만 라벨링               | + gaussian_curve를 입력데이터에 사용하면??                   |
| _123         | _122 standard                                                | _122 **better**                                              |
|              |                                                              |                                                              |

### 할 일 : confidence logic

> **argsort confidence는 모델들을 비교하기 위함임**

| scaler      | result                                                  |
| ----------- | ------------------------------------------------------- |
| **min_max** | 분산이 좋음(다양한 고저점을 포용)                       |
| max_abs     | min_max가 분산이 더 좋음                                |
| standard    | acc가 높게 나온다. (**높은 곳에 저점 표시하는 불상사**) |

매수 지점 기준 min_max 0.1 이하로 떨어지면 confidence 바꿔서 바로 매도



| TUNE METHOD                                                  | DESCRIPTION                                                  | RESULT                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| np.argmax 대체                                               | 1. 가장 큰 값부터 정렬해 n개 만큼을 선택 2. LABELING BY PERCENTAGE | 1번을 쓰면 안되는 이유 : 고점이 높아질 수록 percentage도 높아지기 때문에 카운팅하는게 의미가 없어진다. (새로운 max값이 갱신된다.) **ㅇ** |
| 시간에 따라 변하는 차트에 대한 고려 (**고점과 저점이 갱신되지 않으면 차트 스케일은 변하지 않는다.**) |                                                              |                                                              |
| **이탈 방법 : 손절가를 정해서 이탈해야하나?**                |                                                              |                                                              |
| **idl : 고점의 빈도수를 조절한다.**                          |                                                              | **idl 54가 가장 적당한 빈도수인건가..?**                     |



| Setting                                             | Result                                                       |
| --------------------------------------------------- | ------------------------------------------------------------ |
| 데이터 학습량 증가시켜보기                          | **학습량이 많으면 완곡한 선이 나오지 않는다..**              |
| std scaler vs max abs scaler                        | **비등하다**                                                 |
| 여러개의 feature 사용                               | **<u>곡선</u>**의 feature를 사용해야할것임                   |
| 모델 깊이, 노드 수                                  | 깊이는 영향 거의 없고, 노드수가 조금 있음                    |
| idl                                                 | **낮은 idl**이 차트가 뒤로 밀리지 않는다. 하지만 **곡선이 첨예해짐** |
| dropout                                             | 잘 모르겠음.. = 영향력이 거의 없다는 거다.                   |
| batch size                                          | 크면 **학습률이 떨어진다. 좋은거같기도**                     |
| **히트맵(이미지) 데이터로 CNN을 사용해 예측해보기** | 동일하다..                                                   |
| **<u>lstm</u>**                                     | 동일하다..                                                   |
| learning rate                                       | **0.05 learning rate 는 가우시안보다 빠르다. (다만 중간에 끊긴다는 점)** |
| input 데이터를 역순으로                             | 확 달라지지는 않는다...                                      |
| model **ensemble**                                  | 동일하다..                                                   |
| activation function                                 | **gelu**                                                     |
| optimizer                                           | sgd 0.01757 momentum 미약한 효과  **RMSprob_epsilon**        |
| sigma                                               | 너무 커서도 안됀다.. **차트 땅기는 데는 low sigma가 직빵이다.** |



## Reference

optimizers : https://twinw.tistory.com/247

plot colors : https://python-graph-gallery.com/196-select-one-color-with-matplotlib/